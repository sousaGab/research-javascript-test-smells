file,type,line,method,source
/__tests__/test-writeTree.js,AnonymousTest,"{'startLine':8,'endLine':127}","it('tree', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-writeTree')
    // Test
    const oid = await writeTree({
      fs,
      gitdir,
      tree: [
        {
          mode: '100644',
          oid: '375f9392774e7a7c8a1ae23a6d13b5c133e42c45',
          path: '.babelrc',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: 'bbf3e21f43fa4fe25eb925bfcb7c0434f7c2dc7d',
          path: '.editorconfig',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: '4a58bdcdef3eb91264dfca0279959d98c16568d5',
          path: '.flowconfig',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: '2b90c4a2353d2977e158c21f4315664063770212',
          path: '.gitignore',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: '63ed03aea9d828c86ebde989b336f5e978fdc3f1',
          path: '.travis.yml',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: 'c675a17ccb1578bca836decf90205fdad743827d',
          path: 'LICENSE.md',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: '9761716146bbdb47f8a7de3d9df98777df9674f3',
          path: 'README.md',
          type: 'blob',
        },
        {
          mode: '040000',
          oid: '63a8130fa218d20b0009c1126375a105c1adba8a',
          path: '__tests__',
          type: 'tree',
        },
        {
          mode: '100644',
          oid: 'bdc76cc9d0da964db203f47333d05185a22d6a18',
          path: 'ci.karma.conf.js',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: '4551a1856279dde6ae9d65862a1dff59a5f199d8',
          path: 'cli.js',
          type: 'blob',
        },
        {
          mode: '040000',
          oid: '69be3467cb125fbc55eb5c7e50caa556fb0e34b4',
          path: 'dist',
          type: 'tree',
        },
        {
          mode: '100644',
          oid: 'af56d48cb8af9c5ba3547c12c4a4a61fc16ff971',
          path: 'karma.conf.js',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: '00b91c8b8ddfb43df70ef334088b7d840e5053db',
          path: 'package-lock.json',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: '7b12188e7e351c1a761b76b38e36c13b5cba6c1f',
          path: 'package-scripts.js',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: 'bfe174beb9bf440c1c49b6fba0094f16cf9c9490',
          path: 'package.json',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: 'a86d1a6c3997dc73e8bf8687edb15fc087892e9d',
          path: 'rollup.config.js',
          type: 'blob',
        },
        {
          mode: '040000',
          oid: 'ae7b4f3ac2c570dc3597124fc108ecb9d6c2b4fd',
          path: 'src',
          type: 'tree',
        },
        {
          mode: '040000',
          oid: '0a7ce5f20a8ccba18463a2ae990baf63ba1e3b43',
          path: 'testling',
          type: 'tree',
        },
      ],
    })
    expect(oid).toEqual('6257985e3378ec42a03a57a7dc8eb952d69a5ff3')
  })",snuts
/__tests__/test-writeTag.js,AnonymousTest,"{'startLine':8,'endLine':47}","it('annotated tag', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-writeTag')
    // Test
    const oid = await writeTag({
      fs,
      gitdir,
      tag: {
        object: 'af4d84a6a9fa7a74acdad07fddf9f17ff3a974ae',
        type: 'commit',
        tag: 'v0.0.9',
        tagger: {
          name: 'Will Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1507071414,
          timezoneOffset: 240,
        },
        message: '0.0.9',
        gpgsig: `-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQIcBAABAgAGBQJZ1BW2AAoJEJYJuKWSi6a5S6EQAJQkK+wIXijDf4ZfVeP1E7Be
aDDdOLga0/gj5p2p081TLLlaKKLcYj2pub8BfFVpEmvT0QRaKaMb+wAtO5PBHTbn
y2s3dCmqqAPQa0AXrChverKomK/gUYZfFzckS8GaJTiw2RyvheXOLOEGSLTHOwy2
wjP8KxGOWfHlXZEhn/Z406OlcYMzMSL70H26pgyggSTe5RNfpXEBAgWmIAA51eEM
9tF9xuijc0mlr6vzxYVmfwat4u38nrwX7JvWp2CvD/qwILMAYGIcZqRXK5jWHemD
/x5RtUGU4cr47++FD3N3zBWx0dBiCMNUwT/v68kmhrBVX20DhcC6UX38yf1sdDfZ
yapht2+TakKQuw/T/K/6bFjoa8MIHdAx7WCnMV84M0qfMr+e9ImeH5Hj592qw4Gh
vSY80gKslkXjRnVes7VHXoL/lVDvCM2VNskWTTLGHqt+rIvSXNFGP05OGtdFYu4d
K9oFVEoRPFTRSeF/9EztyeLb/gtSdBmWP2AhZn9ip0a7rjbyv5yeayZTsedoUfe5
o8cB++UXreD+h3c/F6mTRs8aVELhQTZNZ677PY71HJKsCLbQJAd4n+gS1n8Y/7wv
Zp4YxnShDkMTV3rxZc27vehq2g9gKJzQsueLyZPJTzCHqujumiLbdYV4i4X4CZjy
dBWrLc3kdnemrlhSRzR2
=PrR1
-----END PGP SIGNATURE-----
`,
      },
    })
    expect(oid).toEqual('6e90dfd7573404a225888071ecaa572882b4e45c')
  })",snuts
/__tests__/test-writeRef.js,ConditionalTestLogic,"{'startLine':40,'endLine':40}","it('sets current branch to another', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-writeRef')
    // Test
    await writeRef({
      fs,
      gitdir,
      ref: 'refs/heads/another',
      value: 'HEAD',
    })
    await writeRef({
      fs,
      gitdir,
      ref: 'HEAD',
      value: 'refs/heads/another',
      force: true,
      symbolic: true,
    })
    const newBranch = await currentBranch({ fs, gitdir, fullname: true })
    expect(newBranch).toBe('refs/heads/another')
    if (!newBranch) throw new Error('type error')
    const ref = await resolveRef({ fs, gitdir, ref: newBranch })
    expect(ref).toBe('cfc039a0acb68bee8bb4f3b13b6b211dbb8c1a69')
  })",snuts
/__tests__/test-writeObject.js,AnonymousTest,"{'startLine':8,'endLine':53}","it('parsed', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-writeObject')
    // Test
    const oid = await writeObject({
      fs,
      gitdir,
      format: 'parsed',
      type: 'commit',
      object: {
        author: {
          email: 'wmhilton@gmail.com',
          name: 'Will Hilton',
          timestamp: 1502484200,
          timezoneOffset: 240,
        },
        committer: {
          email: 'wmhilton@gmail.com',
          name: 'Will Hilton',
          timestamp: 1502484200,
          timezoneOffset: 240,
        },
        gpgsig: `-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQIcBAABAgAGBQJZjhboAAoJEJYJuKWSi6a5V5UP/040SfemJ13PRBXst2eB59gs
3hPx29DRKBhFtvk+uS+8523/hUfry2oeWWd6YRkcnkxxAUtBnfzVkI9AgRIc1NTM
h5XtLMQubCAKw8JWvVvoXETzwVAODmdmvC4WSQCLu+opoe6/W7RvkrTD0pbkwH4E
MXoha59sIWZ/FacZX6ByYqhFykfJL8gCFvRSzjiqBIbsP7Xq2Mh4jkAKYl5zxV3u
qCk26hnhL++kwfXlu2YdGtB9+lj3pk1NeWqR379zRzh4P10FxXJ18qSxczbkAFOY
6o5h7a/Mql1KqWB9EFBupCpjydmpAtPo6l1Us4a3liB5LJvCh9xgR2HtShR4b97O
nIpXP4ngy4z9UyrXXxxpiQQn/kVn/uKgtvGp8nOFioo61PCi9js2QmQxcsuBOeO+
DdFq5k2PMNZLwizt4P8EGfVJoPbLhdYP4oWiMCuYV/2fNh0ozl/q176HGszlfrke
332Z0maJ3A5xIRj0b7vRNHV8AAl9Dheo3LspjeovP2iycCHFP03gSpCKdLRBRC4T
X10BBFD8noCMXJxb5qenrf+eKRd8d4g7JtcyzqVgkBQ68GIG844VWRBolOzx4By5
cAaw/SYIZG3RorAc11iZ7sva0jFISejmEzIebuChSzdWO2OOWRVvMdhyZwDLUgAb
Qixh2bmPgr3h9nxq2Dmn
=4+DN
-----END PGP SIGNATURE-----`,
        message: 'Improve resolveRef to handle more kinds of refs. Add tests\n',
        parent: ['b4f8206d9e359416b0f34238cbeb400f7da889a8'],
        tree: 'e0b8f3574060ee24e03e4af3896f65dd208a60cc',
      },
    })
    expect(oid).toEqual('e10ebb90d03eaacca84de1af0a59b444232da99e')
  })",snuts
/__tests__/test-writeObject.js,AnonymousTest,"{'startLine':54,'endLine':69}","it('content', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-writeObject')
    // Test
    const oid = await writeObject({
      fs,
      gitdir,
      type: 'commit',
      object: Buffer.from(
        '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',
        'hex'
      ),
      format: 'content',
    })
    expect(oid).toBe('e10ebb90d03eaacca84de1af0a59b444232da99e')
  })",snuts
/__tests__/test-writeObject.js,AnonymousTest,"{'startLine':70,'endLine':84}","it('wrapped', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-writeObject')
    // Test
    const oid = await writeObject({
      fs,
      gitdir,
      object: Buffer.from(
        '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',
        'hex'
      ),
      format: 'wrapped',
    })
    expect(oid).toBe('e10ebb90d03eaacca84de1af0a59b444232da99e')
  })",snuts
/__tests__/test-writeObject.js,AnonymousTest,"{'startLine':85,'endLine':100}","it('deflated', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-writeObject')
    // Test
    const oid = await writeObject({
      fs,
      gitdir,
      oid: 'e10ebb90d03eaacca84de1af0a59b444232da99e',
      object: Buffer.from(
        '78019d93c9cea3481084e7cc53d4ddea76010586d1cc68001b0cde30fc06ec1b4b4161966237e6e9dbd373ed53e729158a487d522a625a55f9005896e5ff183a8c01869194f2c206411162cc210c798cc294976431158524e1a0148a308e9926ec703d8008a51207c544c6bc2023568c60ca238e97e2084708c274938492248712138e03a11df0f3b204fbbc1c680dfe7a55e4e7f66f568579f93da6d53f8015208724c44108bec1cf05e6a37e1007fc3bd9acc9fa3c03dffe1b75679867601b36704de3ac7cdd9cdd4f9d011eeefa9cd67f02a31e6d034c2c0318905fcd58551455c91443bd5a8f2789a8a2506b67ddadf1e0bbb9180a9e70b3d71f4837c595c5f2b6a306fdc0615590b39e013cb1674ede3a0795e8c354ac467725091cbf26b7b47b7314fb7e22de9d22ae8b79566e835aa78b5798b2923966cc9ebf4e0c2042301c4fd731d294c34bb2fcc99b68b0fb5a5e9e72d956493569c877afda715cd1866271ed6f9ca9e8beb6b0898ad71eed18700a280905b937fdc75a0fe34720aaef7b4bf477915a4729d3f4c9719767deaa66d4db9ba0e54e043d0be5702f8565f6f89101ad567022a9c971b52a5e69508edc3d3106555e954fbe29d833f65b87dfc88bb31064b3509f038b955a778e97a850f4cb9d012215c8265c9fda923db4be2aef74756cb4e6f94eaa46196c2a96ecad47215fe6aa70b4268dc873e670fbc1250e8ae4cd8501b5d90436aab3375ae4dbbb0b82796ef2ebb55e175ebd1e0fd930198d545ff49c5291b5b55c7ef6dcb5bace713faa177c5931609be8ad5070f6e9fc38bef26540b6b43352cfa2767424c9dd46d4cf4fda78f7d65c7a26902ee5ba6537e2dee89732ed0afcf926cf3d60155abc22cca6f384d16672ce7b4f529452de124cf963df3c319d6c2e7fc7da5eb7219fb98d76488e8eea68e88b01010b5555df4a35d54e813547428beb2e5de183934809ca36d610bf97d6cb0af52a4a8669480879bea3d2f2b2cc487d0b0c8895f0b576efe6c3e01dda2931cbe68f4d3f85f0a99b2e7e56bbc5c4d1a8117749fc0b77b9f88e379d12f27ebcb6c75ba6440cb8e633e1a2cace3a9ec8f5dc72dbaa66c0df68b53d33ffd76477defeaa248c59351d9d30e8704fcb093b3805030524ac9312838a761814799df480a61f4bda7f074a928001f743cffc00fa8263c9',
        'hex'
      ),
      format: 'deflated',
    })
    expect(oid).toEqual('e10ebb90d03eaacca84de1af0a59b444232da99e')
  })",snuts
/__tests__/test-writeObject.js,AnonymousTest,"{'startLine':142,'endLine':263}","it('tree', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-writeObject')
    // Test
    const oid = await writeObject({
      fs,
      gitdir,
      type: 'tree',
      format: 'parsed',
      object: [
        {
          mode: '100644',
          oid: '375f9392774e7a7c8a1ae23a6d13b5c133e42c45',
          path: '.babelrc',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: 'bbf3e21f43fa4fe25eb925bfcb7c0434f7c2dc7d',
          path: '.editorconfig',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: '4a58bdcdef3eb91264dfca0279959d98c16568d5',
          path: '.flowconfig',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: '2b90c4a2353d2977e158c21f4315664063770212',
          path: '.gitignore',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: '63ed03aea9d828c86ebde989b336f5e978fdc3f1',
          path: '.travis.yml',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: 'c675a17ccb1578bca836decf90205fdad743827d',
          path: 'LICENSE.md',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: '9761716146bbdb47f8a7de3d9df98777df9674f3',
          path: 'README.md',
          type: 'blob',
        },
        {
          mode: '040000',
          oid: '63a8130fa218d20b0009c1126375a105c1adba8a',
          path: '__tests__',
          type: 'tree',
        },
        {
          mode: '100644',
          oid: 'bdc76cc9d0da964db203f47333d05185a22d6a18',
          path: 'ci.karma.conf.js',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: '4551a1856279dde6ae9d65862a1dff59a5f199d8',
          path: 'cli.js',
          type: 'blob',
        },
        {
          mode: '040000',
          oid: '69be3467cb125fbc55eb5c7e50caa556fb0e34b4',
          path: 'dist',
          type: 'tree',
        },
        {
          mode: '100644',
          oid: 'af56d48cb8af9c5ba3547c12c4a4a61fc16ff971',
          path: 'karma.conf.js',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: '00b91c8b8ddfb43df70ef334088b7d840e5053db',
          path: 'package-lock.json',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: '7b12188e7e351c1a761b76b38e36c13b5cba6c1f',
          path: 'package-scripts.js',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: 'bfe174beb9bf440c1c49b6fba0094f16cf9c9490',
          path: 'package.json',
          type: 'blob',
        },
        {
          mode: '100644',
          oid: 'a86d1a6c3997dc73e8bf8687edb15fc087892e9d',
          path: 'rollup.config.js',
          type: 'blob',
        },
        {
          mode: '040000',
          oid: 'ae7b4f3ac2c570dc3597124fc108ecb9d6c2b4fd',
          path: 'src',
          type: 'tree',
        },
        {
          mode: '040000',
          oid: '0a7ce5f20a8ccba18463a2ae990baf63ba1e3b43',
          path: 'testling',
          type: 'tree',
        },
      ],
    })
    expect(oid).toEqual('6257985e3378ec42a03a57a7dc8eb952d69a5ff3')
  })",snuts
/__tests__/test-writeObject.js,AnonymousTest,"{'startLine':308,'endLine':349}","it('annotated tag', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-writeObject')
    // Test
    const oid = await writeObject({
      fs,
      gitdir,
      format: 'parsed',
      type: 'tag',
      object: {
        object: 'af4d84a6a9fa7a74acdad07fddf9f17ff3a974ae',
        type: 'commit',
        tag: 'v0.0.9',
        tagger: {
          name: 'Will Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1507071414,
          timezoneOffset: 240,
        },
        message: '0.0.9',
        gpgsig: `-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQIcBAABAgAGBQJZ1BW2AAoJEJYJuKWSi6a5S6EQAJQkK+wIXijDf4ZfVeP1E7Be
aDDdOLga0/gj5p2p081TLLlaKKLcYj2pub8BfFVpEmvT0QRaKaMb+wAtO5PBHTbn
y2s3dCmqqAPQa0AXrChverKomK/gUYZfFzckS8GaJTiw2RyvheXOLOEGSLTHOwy2
wjP8KxGOWfHlXZEhn/Z406OlcYMzMSL70H26pgyggSTe5RNfpXEBAgWmIAA51eEM
9tF9xuijc0mlr6vzxYVmfwat4u38nrwX7JvWp2CvD/qwILMAYGIcZqRXK5jWHemD
/x5RtUGU4cr47++FD3N3zBWx0dBiCMNUwT/v68kmhrBVX20DhcC6UX38yf1sdDfZ
yapht2+TakKQuw/T/K/6bFjoa8MIHdAx7WCnMV84M0qfMr+e9ImeH5Hj592qw4Gh
vSY80gKslkXjRnVes7VHXoL/lVDvCM2VNskWTTLGHqt+rIvSXNFGP05OGtdFYu4d
K9oFVEoRPFTRSeF/9EztyeLb/gtSdBmWP2AhZn9ip0a7rjbyv5yeayZTsedoUfe5
o8cB++UXreD+h3c/F6mTRs8aVELhQTZNZ677PY71HJKsCLbQJAd4n+gS1n8Y/7wv
Zp4YxnShDkMTV3rxZc27vehq2g9gKJzQsueLyZPJTzCHqujumiLbdYV4i4X4CZjy
dBWrLc3kdnemrlhSRzR2
=PrR1
-----END PGP SIGNATURE-----
`,
      },
    })
    expect(oid).toEqual('6e90dfd7573404a225888071ecaa572882b4e45c')
  })",snuts
/__tests__/test-writeCommit.js,AnonymousTest,"{'startLine':7,'endLine':50}","it('parsed', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-writeCommit')
    // Test
    const oid = await writeCommit({
      fs,
      gitdir,
      commit: {
        author: {
          email: 'wmhilton@gmail.com',
          name: 'Will Hilton',
          timestamp: 1502484200,
          timezoneOffset: 240,
        },
        committer: {
          email: 'wmhilton@gmail.com',
          name: 'Will Hilton',
          timestamp: 1502484200,
          timezoneOffset: 240,
        },
        gpgsig: `-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQIcBAABAgAGBQJZjhboAAoJEJYJuKWSi6a5V5UP/040SfemJ13PRBXst2eB59gs
3hPx29DRKBhFtvk+uS+8523/hUfry2oeWWd6YRkcnkxxAUtBnfzVkI9AgRIc1NTM
h5XtLMQubCAKw8JWvVvoXETzwVAODmdmvC4WSQCLu+opoe6/W7RvkrTD0pbkwH4E
MXoha59sIWZ/FacZX6ByYqhFykfJL8gCFvRSzjiqBIbsP7Xq2Mh4jkAKYl5zxV3u
qCk26hnhL++kwfXlu2YdGtB9+lj3pk1NeWqR379zRzh4P10FxXJ18qSxczbkAFOY
6o5h7a/Mql1KqWB9EFBupCpjydmpAtPo6l1Us4a3liB5LJvCh9xgR2HtShR4b97O
nIpXP4ngy4z9UyrXXxxpiQQn/kVn/uKgtvGp8nOFioo61PCi9js2QmQxcsuBOeO+
DdFq5k2PMNZLwizt4P8EGfVJoPbLhdYP4oWiMCuYV/2fNh0ozl/q176HGszlfrke
332Z0maJ3A5xIRj0b7vRNHV8AAl9Dheo3LspjeovP2iycCHFP03gSpCKdLRBRC4T
X10BBFD8noCMXJxb5qenrf+eKRd8d4g7JtcyzqVgkBQ68GIG844VWRBolOzx4By5
cAaw/SYIZG3RorAc11iZ7sva0jFISejmEzIebuChSzdWO2OOWRVvMdhyZwDLUgAb
Qixh2bmPgr3h9nxq2Dmn
=4+DN
-----END PGP SIGNATURE-----`,
        message: 'Improve resolveRef to handle more kinds of refs. Add tests\n',
        parent: ['b4f8206d9e359416b0f34238cbeb400f7da889a8'],
        tree: 'e0b8f3574060ee24e03e4af3896f65dd208a60cc',
      },
    })
    expect(oid).toEqual('e10ebb90d03eaacca84de1af0a59b444232da99e')
  })",snuts
/__tests__/test-writeBlob.js,AnonymousTest,"{'startLine':7,'endLine':17}","it('empty blob', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-writeBlob')
    // Test
    const oid = await writeBlob({
      fs,
      gitdir,
      blob: new Uint8Array([]),
    })
    expect(oid).toEqual('e69de29bb2d1d6434b8b29ae775ad8c2e48c5391')
  })",snuts
/__tests__/test-writeBlob.js,AnonymousTest,"{'startLine':18,'endLine':58}","it('blob', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-writeBlob')
    // Test
    const oid = await writeBlob({
      fs,
      gitdir,
      blob: Buffer.from(
        `#!/usr/bin/env node
const minimisted = require('minimisted')
const git = require('.')

// This really isn't much of a CLI. It's mostly for testing.
// But it's very versatile and works surprisingly well.

minimisted(async function ({ _: [command, ...args], ...opts }) {
  const dir = process.cwd()
  const repo = git(dir)
  let cmd = \`git('\${dir}')\`
  for (let key of Object.keys(opts)) {
    // This is how you check for an array, right?
    if (opts[key].length === undefined) {
      repo[key](opts[key])
      cmd += \`.\${key}('\${opts[key]}')\`
    } else {
      repo[key](...opts[key])
      cmd += \`.\${key}(\${opts[key].map(x => \`'\${x}'\`).join(', ')})\`
    }
  }
  cmd += \`.\${command}(\${args.map(x => \`'\${x}'\`).join(', ')})\`
  console.log(cmd)
  let result = await repo[command](...args)
  if (result === undefined) return
  console.log(JSON.stringify(result, null, 2))
})
`,
        'utf8'
      ),
    })
    expect(oid).toEqual('4551a1856279dde6ae9d65862a1dff59a5f199d8')
  })",snuts
/__tests__/test-wire.js,AnonymousTest,"{'startLine':86,'endLine':128}","it('writeRefsAd', async () => {
    const res = await writeRefsAdResponse({
      service: 'git-upload-pack',
      capabilities: [
        'multi_ack',
        'thin-pack',
        'side-band',
        'side-band-64k',
        'ofs-delta',
        'shallow',
        'deepen-since',
        'deepen-not',
        'deepen-relative',
        'no-progress',
        'include-tag',
        'multi_ack_detailed',
        'no-done',
      ],
      symrefs: { HEAD: 'refs/heads/master' },
      refs: {
        HEAD: '9ea43b479f5fedc679e3eb37803275d727bf51b7',
        'refs/heads/js2': 'fb74ea1a9b6a9601df18c38d3de751c51f064bf7',
        'refs/heads/js3': '5faa96fe725306e060386975a70e4b6eacb576ed',
        'refs/heads/master': '9ea43b479f5fedc679e3eb37803275d727bf51b7',
        'refs/heads/master2': 'c1751a5447a7b025e5bca507af483dde7b0b956f',
        'refs/heads/master3': 'd85135a47c42c9c906e20c08def2fbceac4c2a4f',
        'refs/heads/master4': '18f4b62440abf61285fbfdcbfd990ab8434ff35c',
        'refs/heads/master5': 'e5c144897b64a44bd1164a0db60738452c9eaf87',
      },
    })
    const buffer = Buffer.from(await collect(res))
    expect(buffer.toString('utf8')).toBe(
      `01149ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/isomorphic-git@0.0.0-development
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
  })",snuts
/__tests__/test-wire.js,AnonymousTest,"{'startLine':129,'endLine':173}","it('parseRefsAdResponse', async () => {
    const res = [
      Buffer.from(`001e# service=git-upload-pack
000001149ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/isomorphic-git@0.0.0-development
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`),
    ]
    const result = await parseRefsAdResponse(res, {
      service: 'git-upload-pack',
    })
    expect([...result.capabilities]).toEqual([
      'multi_ack',
      'thin-pack',
      'side-band',
      'side-band-64k',
      'ofs-delta',
      'shallow',
      'deepen-since',
      'deepen-not',
      'deepen-relative',
      'no-progress',
      'include-tag',
      'multi_ack_detailed',
      'no-done',
      'symref=HEAD:refs/heads/master',
      'agent=git/isomorphic-git@0.0.0-development',
    ])
    expect([...result.symrefs]).toEqual([['HEAD', 'refs/heads/master']])
    expect([...result.refs]).toEqual([
      ['HEAD', '9ea43b479f5fedc679e3eb37803275d727bf51b7'],
      ['refs/heads/js2', 'fb74ea1a9b6a9601df18c38d3de751c51f064bf7'],
      ['refs/heads/js3', '5faa96fe725306e060386975a70e4b6eacb576ed'],
      ['refs/heads/master', '9ea43b479f5fedc679e3eb37803275d727bf51b7'],
      ['refs/heads/master2', 'c1751a5447a7b025e5bca507af483dde7b0b956f'],
      ['refs/heads/master3', 'd85135a47c42c9c906e20c08def2fbceac4c2a4f'],
      ['refs/heads/master4', '18f4b62440abf61285fbfdcbfd990ab8434ff35c'],
      ['refs/heads/master5', 'e5c144897b64a44bd1164a0db60738452c9eaf87'],
    ])
  })",snuts
/__tests__/test-wire.js,AnonymousTest,"{'startLine':306,'endLine':338}","it('writeUploadPackRequest', async () => {
    const req = {
      capabilities: [
        'multi_ack_detailed',
        'no-done',
        'side-band-64k',
        'thin-pack',
        'ofs-delta',
        'agent=git/2.10.1.windows.1',
      ],
      wants: [
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7',
        '5faa96fe725306e060386975a70e4b6eacb576ed',
        '9ea43b479f5fedc679e3eb37803275d727bf51b7',
        'c1751a5447a7b025e5bca507af483dde7b0b956f',
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f',
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c',
        'e5c144897b64a44bd1164a0db60738452c9eaf87',
      ],
    }
    const result = writeUploadPackRequest(req)
    const buffer = Buffer.from(await collect(result))
    expect(buffer.toString('utf8'))
      .toEqual(`008awant fb74ea1a9b6a9601df18c38d3de751c51f064bf7 multi_ack_detailed no-done side-band-64k thin-pack ofs-delta agent=git/2.10.1.windows.1
0032want 5faa96fe725306e060386975a70e4b6eacb576ed
0032want 9ea43b479f5fedc679e3eb37803275d727bf51b7
0032want c1751a5447a7b025e5bca507af483dde7b0b956f
0032want d85135a47c42c9c906e20c08def2fbceac4c2a4f
0032want 18f4b62440abf61285fbfdcbfd990ab8434ff35c
0032want e5c144897b64a44bd1164a0db60738452c9eaf87
00000009done
`)
  })",snuts
/__tests__/test-wire.js,AnonymousTest,"{'startLine':339,'endLine':370}","it('parseUploadPackRequest', async () => {
    const req = [
      Buffer.from(`008awant fb74ea1a9b6a9601df18c38d3de751c51f064bf7 multi_ack_detailed no-done side-band-64k thin-pack ofs-delta agent=git/2.10.1.windows.1
0032want 5faa96fe725306e060386975a70e4b6eacb576ed
0032want 9ea43b479f5fedc679e3eb37803275d727bf51b7
0032want c1751a5447a7b025e5bca507af483dde7b0b956f
0032want d85135a47c42c9c906e20c08def2fbceac4c2a4f
0032want 18f4b62440abf61285fbfdcbfd990ab8434ff35c
0032want e5c144897b64a44bd1164a0db60738452c9eaf87
00000009done
`),
    ]
    const result = await parseUploadPackRequest(req)
    expect([...result.capabilities]).toEqual([
      'multi_ack_detailed',
      'no-done',
      'side-band-64k',
      'thin-pack',
      'ofs-delta',
      'agent=git/2.10.1.windows.1',
    ])
    expect([...result.wants]).toEqual([
      'fb74ea1a9b6a9601df18c38d3de751c51f064bf7',
      '5faa96fe725306e060386975a70e4b6eacb576ed',
      '9ea43b479f5fedc679e3eb37803275d727bf51b7',
      'c1751a5447a7b025e5bca507af483dde7b0b956f',
      'd85135a47c42c9c906e20c08def2fbceac4c2a4f',
      '18f4b62440abf61285fbfdcbfd990ab8434ff35c',
      'e5c144897b64a44bd1164a0db60738452c9eaf87',
    ])
    expect(result.done).toBe(true)
  })",snuts
/__tests__/test-wire.js,SubOptimalAssert,"{'startLine':222,'endLine':222}","it('parseRefsAdResponse bad service', async () => {
    const res = [
      Buffer.from(`001e# noservice=git-upload-pack
000001149ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/isomorphic-git@0.0.0-development
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`),
    ]
    try {
      await parseRefsAdResponse(res, {
        service: 'git-upload-pack',
      })
      fail('expected an error')
    } catch (error) {
      expect(error instanceof Errors.ParseError).toBe(true)
      expect(error.data).toEqual({
        expected: '# service=git-upload-pack\\n',
        actual: '# noservice=git-upload-pac',
      })
    }
  })",snuts
/__tests__/test-wire.js,SubOptimalAssert,"{'startLine':243,'endLine':243}","it('parseRefsAdResponse bad null separated', async () => {
    const res = [
      Buffer.from(`001e# service=git-upload-pack
0072ERR Repository not found
The requested repository does not exist, or you do not have permission to
access it.
`),
    ]
    try {
      await parseRefsAdResponse(res, {
        service: 'git-upload-pack',
      })
      fail('expected an error')
    } catch (error) {
      expect(error instanceof Errors.ParseError).toBe(true)
      expect(error.data).toEqual({
        expected: `Two strings separated by '\\x00'`,
        actual: `ERR Repository not found
The requested repository does not exist, or you do not have permission to
access it.
`,
      })
    }
  })",snuts
/__tests__/test-wire.js,SubOptimalAssert,"{'startLine':273,'endLine':273}","it('parseRefsAdResponse HEAD bad space separated', async () => {
    // two spaces instead of one
    const res = [
      Buffer.from(`001e# service=git-upload-pack
000001149ea43b479f5fedc679e3eb37803275d727bf51b7  HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/isomorphic-git@0.0.0-development
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`),
    ]
    try {
      await parseRefsAdResponse(res, {
        service: 'git-upload-pack',
      })
      fail('expected an error')
    } catch (error) {
      expect(error instanceof Errors.ParseError).toBe(true)
      expect(error.data).toEqual({
        expected: `Two strings separated by ' '`,
        actual: '9ea43b479f5fedc679e3eb37803275d727bf51b7  HEAD',
      })
    }
  })",snuts
/__tests__/test-wire.js,SubOptimalAssert,"{'startLine':299,'endLine':299}","it('parseRefsAdResponse refs bad space separated', async () => {
    const res = [
      Buffer.from(`001e# service=git-upload-pack
000001149ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/isomorphic-git@0.0.0-development
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`),
    ]
    try {
      await parseRefsAdResponse(res, {
        service: 'git-upload-pack',
      })
      fail('expected an error')
    } catch (error) {
      expect(error instanceof Errors.ParseError).toBe(true)
      expect(error.data).toEqual({
        expected: `Two strings separated by ' '`,
        actual: 'fb74ea1a9b6a9601df18c38d3de751c51f064bf7refs/heads/js2\n0',
      })
    }
  })",snuts
/__tests__/test-walk.js,OvercommentedTest,"{'startLine':266,'endLine':551}","it('autocrlf respected when gitconfig changes', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-walk')
    // BrowserFS has a design quirk where HTTPRequestFS has a default mode of 555 for everything,
    // meaning that files have the executable bit set by default!

    const isBrowserFS = !!fs._original_unwrapped_fs.getRootFS
    const FILEMODE = isBrowserFS ? 0o100755 : 0o100644
    const SYMLINKMODE = isBrowserFS ? 0o100755 : 0o120000
    const toWalkerResult = async walker => {
      return {
        type: await walker.type(),
        mode: await walker.mode(),
        oid: await walker.oid(),
        content:
          (await walker.content()) &&
          Buffer.from(await walker.content()).toString('utf8'),
        hasStat: !!(await walker.stat()),
      }
    }

    // Test
    let matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    const expectedMatrix = [
      [
        '.',
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: undefined,
          hasStat: true,
        },
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: '49a23584c8bc3a928250e5fd164131f2eb0f2e4c',
          hasStat: false,
        },
        {
          type: 'tree',
          mode: undefined,
          content: undefined,
          oid: undefined,
          hasStat: false,
        },
      ],
      [
        'a.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'Hello\n',
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: 'Hello\n',
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: true,
        },
      ],
      [
        'b.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'world!!!',
          oid: '77787b8f756d76b1d470f0dbb919d5d35dc55ef8',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: 'world!',
          oid: 'c944ebc28f05731ef588ac6298485ba5e8bf3704',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'c944ebc28f05731ef588ac6298485ba5e8bf3704',
          hasStat: true,
        },
      ],
      [
        'c.txt',
        null,
        {
          type: 'blob',
          mode: 0o100644,
          content: '!!!',
          oid: '08faabdc782b92e1e8d371fdd13b30c0a3f54676',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: '08faabdc782b92e1e8d371fdd13b30c0a3f54676',
          hasStat: true,
        },
      ],
      [
        'd.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'Hello again',
          oid: '895a23b41a53a99670b5fd4092e4199e3a328e02',
          hasStat: true,
        },
        null,
        null,
      ],
      [
        'folder',
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: undefined,
          hasStat: true,
        },
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: '341e54913a3a43069f2927cc0f703e5a9f730df1',
          hasStat: false,
        },
        {
          type: 'tree',
          mode: undefined,
          content: undefined,
          oid: undefined,
          hasStat: false,
        },
      ],
      [
        'folder/1.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
      ],
      [
        'folder/2.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        null,
        null,
      ],
      [
        'folder/3.txt',
        {
          type: 'blob',
          mode: SYMLINKMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        null,
        {
          type: 'blob',
          mode: 0o120000,
          content: undefined,
          oid: '7999426c516ffbbae9136d93dc44e89091d35a13',
          hasStat: true,
        },
      ],
    ]
    expect(matrix).toEqual(expectedMatrix)

    // Check oid + content updates when changing autocrlf to true
    await setConfig({
      fs,
      gitdir,
      path: 'core.autocrlf',
      value: true,
    })
    await fs.write(dir + '/a.txt', 'Hello\r\nagain', {
      mode: 0o666,
    })

    matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    // core.autocrlf is true \r\n should be replaced with \n
    expectedMatrix[1][1] = {
      type: 'blob',
      mode: 0o100644,
      content: 'Hello\nagain',
      oid: 'e855bd8b67cc7ee321e4dec1b9e5b17e13aec8e1',
      hasStat: true,
    }
    expectedMatrix[1][3].mode = FILEMODE
    expectedMatrix[6][3].mode = FILEMODE
    expect(matrix).toEqual(expectedMatrix)

    // Check oid + content updates when changing autocrlf back to false
    await setConfig({
      fs,
      gitdir,
      path: 'core.autocrlf',
      value: false,
    })

    matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    // core.autocrlf is false \r\n should not be replaced with \n
    expectedMatrix[1][1] = {
      type: 'blob',
      mode: 0o100644,
      content: 'Hello\r\nagain',
      oid: '8d4f7af538be6af26291dc33eb1fde39b558dbea',
      hasStat: true,
    }
    expect(matrix).toEqual(expectedMatrix)
  })",snuts
/__tests__/test-walk.js,VerboseStatement,"{'startLine':266,'endLine':551}","it('autocrlf respected when gitconfig changes', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-walk')
    // BrowserFS has a design quirk where HTTPRequestFS has a default mode of 555 for everything,
    // meaning that files have the executable bit set by default!

    const isBrowserFS = !!fs._original_unwrapped_fs.getRootFS
    const FILEMODE = isBrowserFS ? 0o100755 : 0o100644
    const SYMLINKMODE = isBrowserFS ? 0o100755 : 0o120000
    const toWalkerResult = async walker => {
      return {
        type: await walker.type(),
        mode: await walker.mode(),
        oid: await walker.oid(),
        content:
          (await walker.content()) &&
          Buffer.from(await walker.content()).toString('utf8'),
        hasStat: !!(await walker.stat()),
      }
    }

    // Test
    let matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    const expectedMatrix = [
      [
        '.',
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: undefined,
          hasStat: true,
        },
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: '49a23584c8bc3a928250e5fd164131f2eb0f2e4c',
          hasStat: false,
        },
        {
          type: 'tree',
          mode: undefined,
          content: undefined,
          oid: undefined,
          hasStat: false,
        },
      ],
      [
        'a.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'Hello\n',
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: 'Hello\n',
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: true,
        },
      ],
      [
        'b.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'world!!!',
          oid: '77787b8f756d76b1d470f0dbb919d5d35dc55ef8',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: 'world!',
          oid: 'c944ebc28f05731ef588ac6298485ba5e8bf3704',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'c944ebc28f05731ef588ac6298485ba5e8bf3704',
          hasStat: true,
        },
      ],
      [
        'c.txt',
        null,
        {
          type: 'blob',
          mode: 0o100644,
          content: '!!!',
          oid: '08faabdc782b92e1e8d371fdd13b30c0a3f54676',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: '08faabdc782b92e1e8d371fdd13b30c0a3f54676',
          hasStat: true,
        },
      ],
      [
        'd.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'Hello again',
          oid: '895a23b41a53a99670b5fd4092e4199e3a328e02',
          hasStat: true,
        },
        null,
        null,
      ],
      [
        'folder',
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: undefined,
          hasStat: true,
        },
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: '341e54913a3a43069f2927cc0f703e5a9f730df1',
          hasStat: false,
        },
        {
          type: 'tree',
          mode: undefined,
          content: undefined,
          oid: undefined,
          hasStat: false,
        },
      ],
      [
        'folder/1.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
      ],
      [
        'folder/2.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        null,
        null,
      ],
      [
        'folder/3.txt',
        {
          type: 'blob',
          mode: SYMLINKMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        null,
        {
          type: 'blob',
          mode: 0o120000,
          content: undefined,
          oid: '7999426c516ffbbae9136d93dc44e89091d35a13',
          hasStat: true,
        },
      ],
    ]
    expect(matrix).toEqual(expectedMatrix)

    // Check oid + content updates when changing autocrlf to true
    await setConfig({
      fs,
      gitdir,
      path: 'core.autocrlf',
      value: true,
    })
    await fs.write(dir + '/a.txt', 'Hello\r\nagain', {
      mode: 0o666,
    })

    matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    // core.autocrlf is true \r\n should be replaced with \n
    expectedMatrix[1][1] = {
      type: 'blob',
      mode: 0o100644,
      content: 'Hello\nagain',
      oid: 'e855bd8b67cc7ee321e4dec1b9e5b17e13aec8e1',
      hasStat: true,
    }
    expectedMatrix[1][3].mode = FILEMODE
    expectedMatrix[6][3].mode = FILEMODE
    expect(matrix).toEqual(expectedMatrix)

    // Check oid + content updates when changing autocrlf back to false
    await setConfig({
      fs,
      gitdir,
      path: 'core.autocrlf',
      value: false,
    })

    matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    // core.autocrlf is false \r\n should not be replaced with \n
    expectedMatrix[1][1] = {
      type: 'blob',
      mode: 0o100644,
      content: 'Hello\r\nagain',
      oid: '8d4f7af538be6af26291dc33eb1fde39b558dbea',
      hasStat: true,
    }
    expect(matrix).toEqual(expectedMatrix)
  })",snuts
/__tests__/test-version.js,AnonymousTest,"{'startLine':7,'endLine':10}","it('version', () => {
    const v = version()
    expect(v).toEqual(pkg.version)
  })",snuts
/__tests__/test-validate.js,AnonymousTest,"{'startLine':9,'endLine':28}","it('empty file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    const file = 'a.txt'

    await fs.write(path.join(dir, file), 'Hi', 'utf8')
    await add({ fs, dir, filepath: file })
    await fs.write(path.join(dir, '.git', 'index'), '', 'utf8')

    // Test
    let error = null
    try {
      await status({ fs, dir, filepath: file })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InternalError).toBe(true)
    expect(error.data.message).toEqual('Index file is empty (.git/index)')
  })",snuts
/__tests__/test-validate.js,AnonymousTest,"{'startLine':51,'endLine':72}","it('wrong checksum', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    const file = 'a.txt'

    await fs.write(path.join(dir, file), 'Hi', 'utf8')
    await add({ fs, dir, filepath: file })
    await fs.write(path.join(dir, '.git', 'index'), 'DIRCxxxxx', 'utf8')

    // Test
    let error = null
    try {
      await status({ fs, dir, filepath: file })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InternalError).toBe(true)
    expect(error.data.message).toContain(
      'Invalid checksum in GitIndex buffer: expected 444952437878787878 but saw da39a3ee5e6b4b0d3255bfef95601890afd80709'
    )
  })",snuts
/__tests__/test-validate.js,SubOptimalAssert,"{'startLine':26,'endLine':26}","it('empty file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    const file = 'a.txt'

    await fs.write(path.join(dir, file), 'Hi', 'utf8')
    await add({ fs, dir, filepath: file })
    await fs.write(path.join(dir, '.git', 'index'), '', 'utf8')

    // Test
    let error = null
    try {
      await status({ fs, dir, filepath: file })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InternalError).toBe(true)
    expect(error.data.message).toEqual('Index file is empty (.git/index)')
  })",snuts
/__tests__/test-validate.js,SubOptimalAssert,"{'startLine':47,'endLine':47}","it('no magic number', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    const file = 'a.txt'

    await fs.write(path.join(dir, file), 'Hi', 'utf8')
    await add({ fs, dir, filepath: file })
    await fs.write(path.join(dir, '.git', 'index'), 'no-magic-number', 'utf8')

    // Test
    let error = null
    try {
      await status({ fs, dir, filepath: file })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InternalError).toBe(true)
    expect(error.data.message).toContain('Invalid dircache magic file number')
  })",snuts
/__tests__/test-validate.js,SubOptimalAssert,"{'startLine':68,'endLine':68}","it('wrong checksum', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    const file = 'a.txt'

    await fs.write(path.join(dir, file), 'Hi', 'utf8')
    await add({ fs, dir, filepath: file })
    await fs.write(path.join(dir, '.git', 'index'), 'DIRCxxxxx', 'utf8')

    // Test
    let error = null
    try {
      await status({ fs, dir, filepath: file })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InternalError).toBe(true)
    expect(error.data.message).toContain(
      'Invalid checksum in GitIndex buffer: expected 444952437878787878 but saw da39a3ee5e6b4b0d3255bfef95601890afd80709'
    )
  })",snuts
/__tests__/test-uploadPack.js,AnonymousTest,"{'startLine':7,'endLine':17}","it('advertiseRefs: true', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-uploadPack')
    const res = await uploadPack({ fs, gitdir, advertiseRefs: true })
    const buffer = Buffer.from(await collect(res))
    expect(buffer.toString('utf8')).toBe(
      `00f15a8905a02e181fe1821068b8c0f48cb6633d5b81 HEAD\0thin-pack side-band side-band-64k shallow deepen-since deepen-not allow-tip-sha1-in-want allow-reachable-sha1-in-want symref=HEAD:refs/heads/master agent=git/isomorphic-git@0.0.0-development
003f5a8905a02e181fe1821068b8c0f48cb6633d5b81 refs/heads/master
0000`
    )
  })",snuts
/__tests__/test-unicode-paths.js,AnonymousTest,"{'startLine':92,'endLine':114}","it('checkout ', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-unicode-paths')
    await init({ fs, dir, gitdir })
    await add({ fs, dir, gitdir, filepath: '' })
    await commit({
      fs,
      dir,
      gitdir,
      author: {
        name: '',
        email: '@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      message: '',
    })
    await remove({ fs, dir, gitdir, filepath: '' })
    // Test
    // Check GitIndex object
    await checkout({ fs, dir, gitdir, ref: 'HEAD' })
    expect((await listFiles({ fs, dir, gitdir }))[0]).toBe('')
  })",snuts
/__tests__/test-unicode-paths.js,AnonymousTest,"{'startLine':115,'endLine':139}","it('checkout docs/', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-unicode-paths')
    await fs.mkdir(path.join(dir, 'docs'))
    await fs.write(path.join(dir, 'docs/'), '')
    await init({ fs, dir, gitdir })
    await add({ fs, dir, gitdir, filepath: 'docs/' })
    await commit({
      fs,
      dir,
      gitdir,
      author: {
        name: '',
        email: '@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      message: '',
    })
    await remove({ fs, dir, gitdir, filepath: 'docs/' })
    // Test
    // Check GitIndex object
    await checkout({ fs, dir, gitdir, ref: 'HEAD' })
    expect((await listFiles({ fs, dir, gitdir }))[0]).toBe('docs/')
  })",snuts
/__tests__/test-unicode-paths.js,SubOptimalAssert,"{'startLine':26,'endLine':26}","it('write/read index ', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-unicode-paths')
    await init({ fs, dir, gitdir })
    // Test
    await add({ fs, dir, gitdir, filepath: '' })
    expect((await listFiles({ fs, dir, gitdir }))[0]).toBe('')
    await remove({ fs, dir, gitdir, filepath: '' })
    expect((await listFiles({ fs, dir, gitdir })).length).toBe(0)
  })",snuts
/__tests__/test-unicode-paths.js,SubOptimalAssert,"{'startLine':38,'endLine':38}","it('write/read index docs/', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-unicode-paths')
    await init({ fs, dir, gitdir })
    // Test
    await fs.mkdir(path.join(dir, 'docs'))
    await fs.write(path.join(dir, 'docs/'), '')
    await add({ fs, dir, gitdir, filepath: 'docs/' })
    expect((await listFiles({ fs, dir, gitdir }))[0]).toBe('docs/')
    await remove({ fs, dir, gitdir, filepath: 'docs/' })
    expect((await listFiles({ fs, dir, gitdir })).length).toBe(0)
  })",snuts
/__tests__/test-tag.js,AnonymousTest,"{'startLine':41,'endLine':52}","it('force overwrite', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-tag')
    // Test
    let error = null
    try {
      await tag({ fs, gitdir, ref: 'existing-tag', force: true })
    } catch (err) {
      error = err
    }
    expect(error).toBeNull()
  })",snuts
/__tests__/test-tag.js,SubOptimalAssert,"{'startLine':26,'endLine':26}","it('fails if tag already exists', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-tag')
    // Test
    let error = null
    try {
      await tag({ fs, gitdir, ref: 'existing-tag' })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.AlreadyExistsError).toBe(true)
  })",snuts
/__tests__/test-tag.js,SubOptimalAssert,"{'startLine':39,'endLine':39}","it('fails if tag already exists (packed)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-tag')
    // Test
    let error = null
    try {
      await tag({ fs, gitdir, ref: 'packed-tag' })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.AlreadyExistsError).toBe(true)
  })",snuts
/__tests__/test-statusMatrix.js,AnonymousTest,"{'startLine':9,'endLine':50}","it('statusMatrix', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-statusMatrix')
    // Test
    let matrix = await statusMatrix({ fs, dir, gitdir })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 1],
      ['c.txt', 1, 0, 1],
      ['d.txt', 0, 2, 0],
    ])

    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await add({ fs, dir, gitdir, filepath: 'b.txt' })
    await remove({ fs, dir, gitdir, filepath: 'c.txt' })
    await add({ fs, dir, gitdir, filepath: 'd.txt' })
    matrix = await statusMatrix({ fs, dir, gitdir })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 2],
      ['c.txt', 1, 0, 0],
      ['d.txt', 0, 2, 2],
    ])

    // And finally the weirdo cases
    const acontent = await fs.read(path.join(dir, 'a.txt'))
    await fs.write(path.join(dir, 'a.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await fs.write(path.join(dir, 'a.txt'), acontent)
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['a.txt'] })
    expect(matrix).toEqual([['a.txt', 1, 1, 3]])

    await remove({ fs, dir, gitdir, filepath: 'a.txt' })
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['a.txt'] })
    expect(matrix).toEqual([['a.txt', 1, 1, 0]])

    await fs.write(path.join(dir, 'e.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'e.txt' })
    await fs.rm(path.join(dir, 'e.txt'))
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['e.txt'] })
    expect(matrix).toEqual([['e.txt', 0, 0, 3]])
  })",snuts
/__tests__/test-statusMatrix.js,VerboseStatement,"{'startLine':9,'endLine':50}","it('statusMatrix', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-statusMatrix')
    // Test
    let matrix = await statusMatrix({ fs, dir, gitdir })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 1],
      ['c.txt', 1, 0, 1],
      ['d.txt', 0, 2, 0],
    ])

    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await add({ fs, dir, gitdir, filepath: 'b.txt' })
    await remove({ fs, dir, gitdir, filepath: 'c.txt' })
    await add({ fs, dir, gitdir, filepath: 'd.txt' })
    matrix = await statusMatrix({ fs, dir, gitdir })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 2],
      ['c.txt', 1, 0, 0],
      ['d.txt', 0, 2, 2],
    ])

    // And finally the weirdo cases
    const acontent = await fs.read(path.join(dir, 'a.txt'))
    await fs.write(path.join(dir, 'a.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await fs.write(path.join(dir, 'a.txt'), acontent)
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['a.txt'] })
    expect(matrix).toEqual([['a.txt', 1, 1, 3]])

    await remove({ fs, dir, gitdir, filepath: 'a.txt' })
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['a.txt'] })
    expect(matrix).toEqual([['a.txt', 1, 1, 0]])

    await fs.write(path.join(dir, 'e.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'e.txt' })
    await fs.rm(path.join(dir, 'e.txt'))
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['e.txt'] })
    expect(matrix).toEqual([['e.txt', 0, 0, 3]])
  })",snuts
/__tests__/test-status.js,AnonymousTest,"{'startLine':9,'endLine':67}","it('status', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-status')
    // Test
    const a = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    const b = await status({ fs, dir, gitdir, filepath: 'b.txt' })
    const c = await status({ fs, dir, gitdir, filepath: 'c.txt' })
    const d = await status({ fs, dir, gitdir, filepath: 'd.txt' })
    const e = await status({ fs, dir, gitdir, filepath: 'e.txt' })
    expect(a).toEqual('unmodified')
    expect(b).toEqual('*modified')
    expect(c).toEqual('*deleted')
    expect(d).toEqual('*added')
    expect(e).toEqual('absent')

    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await add({ fs, dir, gitdir, filepath: 'b.txt' })
    await remove({ fs, dir, gitdir, filepath: 'c.txt' })
    await add({ fs, dir, gitdir, filepath: 'd.txt' })
    const a2 = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    const b2 = await status({ fs, dir, gitdir, filepath: 'b.txt' })
    const c2 = await status({ fs, dir, gitdir, filepath: 'c.txt' })
    const d2 = await status({ fs, dir, gitdir, filepath: 'd.txt' })
    expect(a2).toEqual('unmodified')
    expect(b2).toEqual('modified')
    expect(c2).toEqual('deleted')
    expect(d2).toEqual('added')

    // And finally the weirdo cases
    const acontent = await fs.read(path.join(dir, 'a.txt'))
    await fs.write(path.join(dir, 'a.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await fs.write(path.join(dir, 'a.txt'), acontent)
    const a3 = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(a3).toEqual('*unmodified')

    await remove({ fs, dir, gitdir, filepath: 'a.txt' })
    const a4 = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(a4).toEqual('*undeleted')

    await fs.write(path.join(dir, 'e.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'e.txt' })
    await fs.rm(path.join(dir, 'e.txt'))
    const e3 = await status({ fs, dir, gitdir, filepath: 'e.txt' })
    expect(e3).toEqual('*absent')

    // Yay .gitignore!
    // NOTE: make_http_index does not include hidden files, so
    // I had to insert test-status/.gitignore and test-status/i/.gitignore
    // manually into the JSON.
    const f = await status({ fs, dir, gitdir, filepath: 'f.txt' })
    const g = await status({ fs, dir, gitdir, filepath: 'g/g.txt' })
    const h = await status({ fs, dir, gitdir, filepath: 'h/h.txt' })
    const i = await status({ fs, dir, gitdir, filepath: 'i/i.txt' })
    expect(f).toEqual('ignored')
    expect(g).toEqual('ignored')
    expect(h).toEqual('ignored')
    expect(i).toEqual('*added')
  })",snuts
/__tests__/test-status.js,OvercommentedTest,"{'startLine':9,'endLine':67}","it('status', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-status')
    // Test
    const a = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    const b = await status({ fs, dir, gitdir, filepath: 'b.txt' })
    const c = await status({ fs, dir, gitdir, filepath: 'c.txt' })
    const d = await status({ fs, dir, gitdir, filepath: 'd.txt' })
    const e = await status({ fs, dir, gitdir, filepath: 'e.txt' })
    expect(a).toEqual('unmodified')
    expect(b).toEqual('*modified')
    expect(c).toEqual('*deleted')
    expect(d).toEqual('*added')
    expect(e).toEqual('absent')

    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await add({ fs, dir, gitdir, filepath: 'b.txt' })
    await remove({ fs, dir, gitdir, filepath: 'c.txt' })
    await add({ fs, dir, gitdir, filepath: 'd.txt' })
    const a2 = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    const b2 = await status({ fs, dir, gitdir, filepath: 'b.txt' })
    const c2 = await status({ fs, dir, gitdir, filepath: 'c.txt' })
    const d2 = await status({ fs, dir, gitdir, filepath: 'd.txt' })
    expect(a2).toEqual('unmodified')
    expect(b2).toEqual('modified')
    expect(c2).toEqual('deleted')
    expect(d2).toEqual('added')

    // And finally the weirdo cases
    const acontent = await fs.read(path.join(dir, 'a.txt'))
    await fs.write(path.join(dir, 'a.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await fs.write(path.join(dir, 'a.txt'), acontent)
    const a3 = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(a3).toEqual('*unmodified')

    await remove({ fs, dir, gitdir, filepath: 'a.txt' })
    const a4 = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(a4).toEqual('*undeleted')

    await fs.write(path.join(dir, 'e.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'e.txt' })
    await fs.rm(path.join(dir, 'e.txt'))
    const e3 = await status({ fs, dir, gitdir, filepath: 'e.txt' })
    expect(e3).toEqual('*absent')

    // Yay .gitignore!
    // NOTE: make_http_index does not include hidden files, so
    // I had to insert test-status/.gitignore and test-status/i/.gitignore
    // manually into the JSON.
    const f = await status({ fs, dir, gitdir, filepath: 'f.txt' })
    const g = await status({ fs, dir, gitdir, filepath: 'g/g.txt' })
    const h = await status({ fs, dir, gitdir, filepath: 'h/h.txt' })
    const i = await status({ fs, dir, gitdir, filepath: 'i/i.txt' })
    expect(f).toEqual('ignored')
    expect(g).toEqual('ignored')
    expect(h).toEqual('ignored')
    expect(i).toEqual('*added')
  })",snuts
/__tests__/test-status.js,VerboseStatement,"{'startLine':9,'endLine':67}","it('status', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-status')
    // Test
    const a = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    const b = await status({ fs, dir, gitdir, filepath: 'b.txt' })
    const c = await status({ fs, dir, gitdir, filepath: 'c.txt' })
    const d = await status({ fs, dir, gitdir, filepath: 'd.txt' })
    const e = await status({ fs, dir, gitdir, filepath: 'e.txt' })
    expect(a).toEqual('unmodified')
    expect(b).toEqual('*modified')
    expect(c).toEqual('*deleted')
    expect(d).toEqual('*added')
    expect(e).toEqual('absent')

    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await add({ fs, dir, gitdir, filepath: 'b.txt' })
    await remove({ fs, dir, gitdir, filepath: 'c.txt' })
    await add({ fs, dir, gitdir, filepath: 'd.txt' })
    const a2 = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    const b2 = await status({ fs, dir, gitdir, filepath: 'b.txt' })
    const c2 = await status({ fs, dir, gitdir, filepath: 'c.txt' })
    const d2 = await status({ fs, dir, gitdir, filepath: 'd.txt' })
    expect(a2).toEqual('unmodified')
    expect(b2).toEqual('modified')
    expect(c2).toEqual('deleted')
    expect(d2).toEqual('added')

    // And finally the weirdo cases
    const acontent = await fs.read(path.join(dir, 'a.txt'))
    await fs.write(path.join(dir, 'a.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await fs.write(path.join(dir, 'a.txt'), acontent)
    const a3 = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(a3).toEqual('*unmodified')

    await remove({ fs, dir, gitdir, filepath: 'a.txt' })
    const a4 = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(a4).toEqual('*undeleted')

    await fs.write(path.join(dir, 'e.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'e.txt' })
    await fs.rm(path.join(dir, 'e.txt'))
    const e3 = await status({ fs, dir, gitdir, filepath: 'e.txt' })
    expect(e3).toEqual('*absent')

    // Yay .gitignore!
    // NOTE: make_http_index does not include hidden files, so
    // I had to insert test-status/.gitignore and test-status/i/.gitignore
    // manually into the JSON.
    const f = await status({ fs, dir, gitdir, filepath: 'f.txt' })
    const g = await status({ fs, dir, gitdir, filepath: 'g/g.txt' })
    const h = await status({ fs, dir, gitdir, filepath: 'h/h.txt' })
    const i = await status({ fs, dir, gitdir, filepath: 'i/i.txt' })
    expect(f).toEqual('ignored')
    expect(g).toEqual('ignored')
    expect(h).toEqual('ignored')
    expect(i).toEqual('*added')
  })",snuts
/__tests__/test-stash.js,SensitiveEquality,"{'startLine':96,'endLine':96}",Unknown,snuts
/__tests__/test-stash.js,SensitiveEquality,"{'startLine':99,'endLine':99}",Unknown,snuts
/__tests__/test-stash.js,SensitiveEquality,"{'startLine':895,'endLine':897}","it('stash apply with untracked files - with other staged and unstaged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyUntracked')

    await addUserConfig(fs, dir, gitdir)
    await fs.write(`${dir}/a.txt`, 'staged changes - a')
    await fs.write(`${dir}/b.js`, 'unstaged changes - b')

    await add({ fs, dir, gitdir, filepath: ['a.txt'] }) // only staged a.txt

    // Create untracked files
    await fs.write(`${dir}/c.txt`, 'untracked file - c')
    await fs.write(`${dir}/d.js`, 'untracked file - d')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })
      const cContentBeforeApply = await fs.read(`${dir}/c.txt`)
      const dContentBeforeStash = await fs.read(`${dir}/d.js`)

      await stash({ fs, dir, gitdir, op: 'apply' })

      const cContentAfterApply = await fs.read(`${dir}/c.txt`)
      const dContentAfterStash = await fs.read(`${dir}/d.js`)

      expect(cContentAfterApply.toString()).toEqual(
        cContentBeforeApply.toString()
      )
      expect(dContentAfterStash.toString()).toEqual(
        dContentBeforeStash.toString()
      )
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
  })",snuts
/__tests__/test-stash.js,SensitiveEquality,"{'startLine':898,'endLine':900}","it('stash apply with untracked files - with other staged and unstaged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyUntracked')

    await addUserConfig(fs, dir, gitdir)
    await fs.write(`${dir}/a.txt`, 'staged changes - a')
    await fs.write(`${dir}/b.js`, 'unstaged changes - b')

    await add({ fs, dir, gitdir, filepath: ['a.txt'] }) // only staged a.txt

    // Create untracked files
    await fs.write(`${dir}/c.txt`, 'untracked file - c')
    await fs.write(`${dir}/d.js`, 'untracked file - d')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })
      const cContentBeforeApply = await fs.read(`${dir}/c.txt`)
      const dContentBeforeStash = await fs.read(`${dir}/d.js`)

      await stash({ fs, dir, gitdir, op: 'apply' })

      const cContentAfterApply = await fs.read(`${dir}/c.txt`)
      const dContentAfterStash = await fs.read(`${dir}/d.js`)

      expect(cContentAfterApply.toString()).toEqual(
        cContentBeforeApply.toString()
      )
      expect(dContentAfterStash.toString()).toEqual(
        dContentBeforeStash.toString()
      )
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
  })",snuts
/__tests__/test-stash.js,SubOptimalAssert,"{'startLine':286,'endLine':286}","it('stash create with staged changes - returns commit hash without modifying working dir', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createOne')
    await addUserConfig(fs, dir, gitdir)

    const aOriginalContent = 'staged changes - a'
    const bOriginalContent = 'staged changes - b'

    await fs.write(`${dir}/a.txt`, aOriginalContent)
    await fs.write(`${dir}/b.js`, bOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })

    const aStatusBefore = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatusBefore).toBe('modified')
    const bStatusBefore = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatusBefore).toBe('modified')

    let stashCommitHash = null
    let error = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()
    expect(typeof stashCommitHash).toBe('string')
    expect(stashCommitHash.length).toBe(40) // SHA-1 hash length

    // Verify working directory is NOT modified
    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual(aOriginalContent)
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual(bOriginalContent)

    // Verify status is still modified
    const aStatusAfter = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatusAfter).toBe('modified')
    const bStatusAfter = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatusAfter).toBe('modified')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",snuts
/__tests__/test-stash.js,SubOptimalAssert,"{'startLine':302,'endLine':302}","it('stash create with staged changes - returns commit hash without modifying working dir', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createOne')
    await addUserConfig(fs, dir, gitdir)

    const aOriginalContent = 'staged changes - a'
    const bOriginalContent = 'staged changes - b'

    await fs.write(`${dir}/a.txt`, aOriginalContent)
    await fs.write(`${dir}/b.js`, bOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })

    const aStatusBefore = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatusBefore).toBe('modified')
    const bStatusBefore = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatusBefore).toBe('modified')

    let stashCommitHash = null
    let error = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()
    expect(typeof stashCommitHash).toBe('string')
    expect(stashCommitHash.length).toBe(40) // SHA-1 hash length

    // Verify working directory is NOT modified
    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual(aOriginalContent)
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual(bOriginalContent)

    // Verify status is still modified
    const aStatusAfter = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatusAfter).toBe('modified')
    const bStatusAfter = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatusAfter).toBe('modified')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",snuts
/__tests__/test-stash.js,SubOptimalAssert,"{'startLine':355,'endLine':355}","it('stash create with staged and unstaged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createTwo')
    await addUserConfig(fs, dir, gitdir)

    const aOriginalContent = 'staged changes - a'
    const bOriginalContent = 'staged changes - b'
    const mOriginalContent = '<unstaged>m</unstaged>'

    await fs.write(`${dir}/a.txt`, aOriginalContent)
    await fs.write(`${dir}/b.js`, bOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })

    await fs.write(`${dir}/m.xml`, mOriginalContent)

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({
        fs,
        dir,
        gitdir,
        op: 'create',
        message: 'custom message',
      })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()
    expect(typeof stashCommitHash).toBe('string')

    // Verify working directory is NOT modified
    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual(aOriginalContent)
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual(bOriginalContent)
    const mContent = await fs.read(`${dir}/m.xml`)
    expect(mContent.toString()).toEqual(mOriginalContent)

    // Verify status remains unchanged
    const aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('modified')
    const bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
    const mStatus = await status({ fs, dir, gitdir, filepath: 'm.xml' })
    expect(mStatus).toBe('*modified')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",snuts
/__tests__/test-stash.js,SubOptimalAssert,"{'startLine':498,'endLine':498}","it('stash create with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createDeleted')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Files should remain deleted in working directory
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",snuts
/__tests__/test-stash.js,SubOptimalAssert,"{'startLine':573,'endLine':573}","it('stash create multiple times returns different hashes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createMultiple')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/a.txt`, 'first change')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })

    const firstHash = await stash({
      fs,
      dir,
      gitdir,
      op: 'create',
      message: 'first',
    })

    await fs.write(`${dir}/a.txt`, 'second change')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })

    const secondHash = await stash({
      fs,
      dir,
      gitdir,
      op: 'create',
      message: 'second',
    })

    expect(firstHash).not.toBeNull()
    expect(secondHash).not.toBeNull()
    expect(firstHash).not.toEqual(secondHash)

    // Verify no stash refs were created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",snuts
/__tests__/test-stash.js,SubOptimalAssert,"{'startLine':586,'endLine':586}","it('stash create does not interfere with existing stash list', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createWithExisting')
    await addUserConfig(fs, dir, gitdir)

    // Create a regular stash first
    await fs.write(`${dir}/a.txt`, 'first stash change')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })
    await stash({ fs, dir, gitdir, op: 'push', message: 'regular stash' })

    let stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)

    // Now use stash create
    await fs.write(`${dir}/b.js`, 'create change')
    await add({ fs, dir, gitdir, filepath: ['b.js'] })
    const createHash = await stash({
      fs,
      dir,
      gitdir,
      op: 'create',
      message: 'create stash',
    })

    expect(createHash).not.toBeNull()

    // Verify stash list is unchanged
    stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)
    expect(stashList[0]).toContain('regular stash')
  })",snuts
/__tests__/test-stash.js,SubOptimalAssert,"{'startLine':603,'endLine':603}","it('stash create does not interfere with existing stash list', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createWithExisting')
    await addUserConfig(fs, dir, gitdir)

    // Create a regular stash first
    await fs.write(`${dir}/a.txt`, 'first stash change')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })
    await stash({ fs, dir, gitdir, op: 'push', message: 'regular stash' })

    let stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)

    // Now use stash create
    await fs.write(`${dir}/b.js`, 'create change')
    await add({ fs, dir, gitdir, filepath: ['b.js'] })
    const createHash = await stash({
      fs,
      dir,
      gitdir,
      op: 'create',
      message: 'create stash',
    })

    expect(createHash).not.toBeNull()

    // Verify stash list is unchanged
    stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)
    expect(stashList[0]).toContain('regular stash')
  })",snuts
/__tests__/test-stash.js,SubOptimalAssert,"{'startLine':633,'endLine':633}","it('stash create with custom message', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createMessage')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/a.txt`, 'test content')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })

    const customMessage = 'my custom stash message'
    let stashCommitHash = null
    let error = null

    try {
      stashCommitHash = await stash({
        fs,
        dir,
        gitdir,
        op: 'create',
        message: customMessage,
      })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()
    expect(typeof stashCommitHash).toBe('string')
    expect(stashCommitHash.length).toBe(40)

    // Read the commit to verify message format
    const commitObj = await readCommit({
      fs,
      dir,
      gitdir,
      oid: stashCommitHash,
    })
    expect(commitObj.commit.message).toContain(customMessage)
  })",snuts
/__tests__/test-stash.js,SubOptimalAssert,"{'startLine':969,'endLine':969}","it('stash list with 1 stash', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('test-stash')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged 3 file changes

    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)
  })",snuts
/__tests__/test-stash.js,SubOptimalAssert,"{'startLine':979,'endLine':979}","it('stash list with 2 stashes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('test-stash')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes
    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(2)
  })",snuts
/__tests__/test-stash.js,SubOptimalAssert,"{'startLine':1037,'endLine':1037}","it('stash drop with stash', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('test-stash')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'drop' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",snuts
/__tests__/test-stash.js,SubOptimalAssert,"{'startLine':1115,'endLine':1115}","it('stash clear with stash', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('test-stash')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'clear' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",snuts
/__tests__/test-stash.js,SubOptimalAssert,"{'startLine':1133,'endLine':1133}","it('stash clear with 2 stashes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('test-stash')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes
    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'clear' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",snuts
/__tests__/test-stash.js,SubOptimalAssert,"{'startLine':1165,'endLine':1165}","it('stash pop with 1 stash', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('popTwo')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'pop' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",snuts
/__tests__/test-stash.js,SubOptimalAssert,"{'startLine':1183,'endLine':1183}","it('stash pop with 2 stashes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('popThree')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes
    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'pop' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)
  })",snuts
/__tests__/test-stash.js,SubOptimalAssert,"{'startLine':1254,'endLine':1254}","it('should not lose stashes after stash pop followed by stash push', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('stashRegression')
    await addUserConfig(fs, dir, gitdir)

    // --- stash 1 ---
    await fs.write(dir + '/a.txt', 'change 1')
    await stash({ fs, dir, gitdir, message: 'stash 1', op: 'push' })
    // --- stash 2 ---
    await fs.write(dir + '/a.txt', 'change 2')
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    let stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)

    // Pop stash 2
    await stash({ fs, dir, gitdir, op: 'pop' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(1)
    // Push stash 2 again
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)
  })",snuts
/__tests__/test-stash.js,SubOptimalAssert,"{'startLine':1260,'endLine':1260}","it('should not lose stashes after stash pop followed by stash push', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('stashRegression')
    await addUserConfig(fs, dir, gitdir)

    // --- stash 1 ---
    await fs.write(dir + '/a.txt', 'change 1')
    await stash({ fs, dir, gitdir, message: 'stash 1', op: 'push' })
    // --- stash 2 ---
    await fs.write(dir + '/a.txt', 'change 2')
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    let stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)

    // Pop stash 2
    await stash({ fs, dir, gitdir, op: 'pop' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(1)
    // Push stash 2 again
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)
  })",snuts
/__tests__/test-stash.js,SubOptimalAssert,"{'startLine':1265,'endLine':1265}","it('should not lose stashes after stash pop followed by stash push', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('stashRegression')
    await addUserConfig(fs, dir, gitdir)

    // --- stash 1 ---
    await fs.write(dir + '/a.txt', 'change 1')
    await stash({ fs, dir, gitdir, message: 'stash 1', op: 'push' })
    // --- stash 2 ---
    await fs.write(dir + '/a.txt', 'change 2')
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    let stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)

    // Pop stash 2
    await stash({ fs, dir, gitdir, op: 'pop' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(1)
    // Push stash 2 again
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)
  })",snuts
/__tests__/test-stash.js,VerboseStatement,"{'startLine':191,'endLine':220}","it('stash with untracked files - with other changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('pushUntracked')

    await addUserConfig(fs, dir, gitdir)
    await fs.write(`${dir}/a.txt`, 'staged changes - a')
    await fs.write(`${dir}/b.js`, 'staged changes - b')

    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })

    const cContentBeforeStash = 'untracked file - c'
    const dContentBeforeStash = 'console.log(""untracked file - d"")'

    // Create untracked files
    await fs.write(`${dir}/c.txt`, cContentBeforeStash)
    await fs.write(`${dir}/d.js`, dContentBeforeStash)

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const cContentAfterStash = await fs.read(`${dir}/c.txt`)
    const dContentAfterStash = await fs.read(`${dir}/d.js`)

    expect(cContentAfterStash.toString()).toEqual(cContentBeforeStash)
    expect(dContentAfterStash.toString()).toEqual(dContentBeforeStash)
  })",snuts
/__tests__/test-stash.js,VerboseStatement,"{'startLine':259,'endLine':303}","it('stash create with staged changes - returns commit hash without modifying working dir', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createOne')
    await addUserConfig(fs, dir, gitdir)

    const aOriginalContent = 'staged changes - a'
    const bOriginalContent = 'staged changes - b'

    await fs.write(`${dir}/a.txt`, aOriginalContent)
    await fs.write(`${dir}/b.js`, bOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })

    const aStatusBefore = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatusBefore).toBe('modified')
    const bStatusBefore = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatusBefore).toBe('modified')

    let stashCommitHash = null
    let error = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()
    expect(typeof stashCommitHash).toBe('string')
    expect(stashCommitHash.length).toBe(40) // SHA-1 hash length

    // Verify working directory is NOT modified
    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual(aOriginalContent)
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual(bOriginalContent)

    // Verify status is still modified
    const aStatusAfter = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatusAfter).toBe('modified')
    const bStatusAfter = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatusAfter).toBe('modified')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",snuts
/__tests__/test-stash.js,VerboseStatement,"{'startLine':305,'endLine':356}","it('stash create with staged and unstaged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createTwo')
    await addUserConfig(fs, dir, gitdir)

    const aOriginalContent = 'staged changes - a'
    const bOriginalContent = 'staged changes - b'
    const mOriginalContent = '<unstaged>m</unstaged>'

    await fs.write(`${dir}/a.txt`, aOriginalContent)
    await fs.write(`${dir}/b.js`, bOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })

    await fs.write(`${dir}/m.xml`, mOriginalContent)

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({
        fs,
        dir,
        gitdir,
        op: 'create',
        message: 'custom message',
      })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()
    expect(typeof stashCommitHash).toBe('string')

    // Verify working directory is NOT modified
    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual(aOriginalContent)
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual(bOriginalContent)
    const mContent = await fs.read(`${dir}/m.xml`)
    expect(mContent.toString()).toEqual(mOriginalContent)

    // Verify status remains unchanged
    const aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('modified')
    const bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
    const mStatus = await status({ fs, dir, gitdir, filepath: 'm.xml' })
    expect(mStatus).toBe('*modified')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",snuts
/__tests__/test-stash.js,VerboseStatement,"{'startLine':358,'endLine':395}","it('stash create with staged and unstaged changes on same file', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createThree')
    await addUserConfig(fs, dir, gitdir)

    const aStagedContent = 'staged changes - a'
    const aUnstagedContent = 'unstaged changes - a - again'

    await fs.write(`${dir}/a.txt`, aStagedContent)
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })
    await fs.write(`${dir}/a.txt`, aUnstagedContent)

    const bOriginalContent = 'staged changes - b'
    await fs.write(`${dir}/b.js`, bOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['b.js'] })

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Verify working directory is NOT modified
    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual(aUnstagedContent)
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual(bOriginalContent)

    // Verify status remains unchanged
    const aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*modified')
    const bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
  })",snuts
/__tests__/test-stash.js,VerboseStatement,"{'startLine':422,'endLine':465}","it('stash create with untracked files - with other changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash(
      'createUntrackedWithChanges'
    )

    await addUserConfig(fs, dir, gitdir)
    const aOriginalContent = 'staged changes - a'
    const bOriginalContent = 'staged changes - b'

    await fs.write(`${dir}/a.txt`, aOriginalContent)
    await fs.write(`${dir}/b.js`, bOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })

    const cContentBeforeStash = 'untracked file - c'
    const dContentBeforeStash = 'console.log(""untracked file - d"")'

    // Create untracked files
    await fs.write(`${dir}/c.txt`, cContentBeforeStash)
    await fs.write(`${dir}/d.js`, dContentBeforeStash)

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Untracked files should remain unchanged
    const cContentAfterStash = await fs.read(`${dir}/c.txt`)
    const dContentAfterStash = await fs.read(`${dir}/d.js`)

    expect(cContentAfterStash.toString()).toEqual(cContentBeforeStash)
    expect(dContentAfterStash.toString()).toEqual(dContentBeforeStash)

    // Tracked files should remain in modified state
    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual(aOriginalContent)
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual(bOriginalContent)
  })",snuts
/__tests__/test-stash.js,VerboseStatement,"{'startLine':467,'endLine':499}","it('stash create with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createDeleted')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Files should remain deleted in working directory
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",snuts
/__tests__/test-stash.js,VerboseStatement,"{'startLine':501,'endLine':539}","it('stash create with changes in nested folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createNested')
    await addUserConfig(fs, dir, gitdir)

    const cOriginalContent = 'staged changes - c'
    const dOriginalContent = 'staged changes - d'

    await fs.write(`${dir}/folder/c.txt`, cOriginalContent)
    await fs.write(`${dir}/folder/d.js`, dOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })

    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Verify files still exist in working directory
    const cContent = await fs.read(`${dir}/folder/c.txt`)
    expect(cContent.toString()).toEqual(cOriginalContent)
    const dContent = await fs.read(`${dir}/folder/d.js`)
    expect(dContent.toString()).toEqual(dOriginalContent)

    // Verify status remains unchanged
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",snuts
/__tests__/test-stash.js,VerboseStatement,"{'startLine':576,'endLine':605}","it('stash create does not interfere with existing stash list', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createWithExisting')
    await addUserConfig(fs, dir, gitdir)

    // Create a regular stash first
    await fs.write(`${dir}/a.txt`, 'first stash change')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })
    await stash({ fs, dir, gitdir, op: 'push', message: 'regular stash' })

    let stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)

    // Now use stash create
    await fs.write(`${dir}/b.js`, 'create change')
    await add({ fs, dir, gitdir, filepath: ['b.js'] })
    const createHash = await stash({
      fs,
      dir,
      gitdir,
      op: 'create',
      message: 'create stash',
    })

    expect(createHash).not.toBeNull()

    // Verify stash list is unchanged
    stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)
    expect(stashList[0]).toContain('regular stash')
  })",snuts
/__tests__/test-stash.js,VerboseStatement,"{'startLine':607,'endLine':643}","it('stash create with custom message', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createMessage')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/a.txt`, 'test content')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })

    const customMessage = 'my custom stash message'
    let stashCommitHash = null
    let error = null

    try {
      stashCommitHash = await stash({
        fs,
        dir,
        gitdir,
        op: 'create',
        message: customMessage,
      })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()
    expect(typeof stashCommitHash).toBe('string')
    expect(stashCommitHash.length).toBe(40)

    // Read the commit to verify message format
    const commitObj = await readCommit({
      fs,
      dir,
      gitdir,
      oid: stashCommitHash,
    })
    expect(commitObj.commit.message).toContain(customMessage)
  })",snuts
/__tests__/test-stash.js,VerboseStatement,"{'startLine':671,'endLine':697}","it('stash apply with staged and unstaged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyTwo')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual('staged changes - a') // make sure the staged changes are applied
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual('staged changes - b') // make sure the staged changes are applied
    const mContent = await fs.read(`${dir}/m.xml`)
    expect(mContent.toString()).toEqual('<unstaged>m</unstaged>') // make sure the unstaged changes are applied

    expect(error).toBeNull()
    const aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('modified')
    const bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
    const mStatus = await status({ fs, dir, gitdir, filepath: 'm.xml' })
    expect(mStatus).toBe('*modified') // m.xml is not staged
  })",snuts
/__tests__/test-stash.js,VerboseStatement,"{'startLine':724,'endLine':760}","it('stash apply with staged changes under two folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFour')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/folder/c.txt`, 'staged changes - c')
    await fs.write(`${dir}/folder/d.js`, 'staged changes - d')

    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })
    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })
      aStatus = await status({
        fs,
        dir,
        gitdir,
        filepath: 'folder/c.txt',
      })
      expect(aStatus).toBe('absent')
      bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
      expect(bStatus).toBe('absent')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",snuts
/__tests__/test-stash.js,VerboseStatement,"{'startLine':762,'endLine':793}","it('stash apply with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFive')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')
  })",snuts
/__tests__/test-stash.js,VerboseStatement,"{'startLine':795,'endLine':831}","it('stash apply with deleted files and staged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySix')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.write(`${dir}/b.js`, 'staged changes - b')

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*modified')

    await add({ fs, dir, gitdir, filepath: ['b.js'] })

    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
  })",snuts
/__tests__/test-stash.js,VerboseStatement,"{'startLine':833,'endLine':869}","it('stash apply with delete folder', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySeven')
    await addUserConfig(fs, dir, gitdir)

    await fs.mkdir(`${dir}/folder`)
    await fs.write(`${dir}/folder/e.js`, 'commited change - e')
    await add({ fs, dir, gitdir, filepath: ['folder', 'folder/e.js'] })
    await commit({
      fs,
      dir,
      gitdir,
      author: { name: 'author', email: 'author@test' },
      message: 'add folder',
    })

    // await fs.rmdir(`${dir}/folder`)
    await fs.rm(`${dir}/folder/e.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
    expect(aStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
      expect(aStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
    expect(aStatus).toBe('*deleted')
  })",snuts
/__tests__/test-stash.js,VerboseStatement,"{'startLine':925,'endLine':952}","it('stash apply with non-default ref idx', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyInvalidRefIdx')

    await stashChanges(fs, dir, gitdir, false, false, 'stash one') // no unstaged changes

    const aOriginalContent = 'stash two staged changes - aa'
    const bOriginalContent = 'console.log(""stash two staged changes - bb"")'
    await fs.write(`${dir}/a.txt`, aOriginalContent)
    await fs.write(`${dir}/b.js`, bOriginalContent)

    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })
    await stash({ fs, dir, gitdir, op: 'push', message: 'stash two' })

    await stashChanges(fs, dir, gitdir, true, true, 'stash three')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'apply', refIdx: 1 })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual(aOriginalContent) // make sure the 2nd staged changes are applied
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual(bOriginalContent) // make sure the 2nd staged changes are applied
  })",snuts
/__tests__/test-stash.js,VerboseStatement,"{'startLine':1204,'endLine':1238}","it('stash pop with non-default ref idx', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('dropValidRefIdx')

    await stashChanges(fs, dir, gitdir, false, false, 'stash one') // no unstaged changes

    const aNewContent = 'stash two staged changes - aaa'
    const bNewContent = 'console.log(""stash two staged changes - bbb"")'

    await fs.write(`${dir}/a.txt`, aNewContent)
    await fs.write(`${dir}/b.js`, bNewContent)

    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })
    await stash({ fs, dir, gitdir, op: 'push', message: 'stash two' })

    await stashChanges(fs, dir, gitdir, true, true, 'stash three')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'pop', refIdx: 1 })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()

    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList).toEqual([
      'stash@{0}: stash three: 3ca31f1 initial commit',
      'stash@{1}: stash one: 3ca31f1 initial commit',
    ])
    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual(aNewContent) // make sure the 2nd staged changes are applied
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual(bNewContent) // make sure the 2nd staged changes are applied
  })",snuts
/__tests__/test-stash.js,VerboseStatement,"{'startLine':1242,'endLine':1266}","it('should not lose stashes after stash pop followed by stash push', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('stashRegression')
    await addUserConfig(fs, dir, gitdir)

    // --- stash 1 ---
    await fs.write(dir + '/a.txt', 'change 1')
    await stash({ fs, dir, gitdir, message: 'stash 1', op: 'push' })
    // --- stash 2 ---
    await fs.write(dir + '/a.txt', 'change 2')
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    let stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)

    // Pop stash 2
    await stash({ fs, dir, gitdir, op: 'pop' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(1)
    // Push stash 2 again
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)
  })",snuts
/__tests__/test-resolveRef.js,AnonymousTest,"{'startLine':7,'endLine':17}","it('1e40fdfba1cf17f3c9f9f3d6b392b1865e5147b9', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-resolveRef')
    // Test
    const ref = await resolveRef({
      fs,
      gitdir,
      ref: '1e40fdfba1cf17f3c9f9f3d6b392b1865e5147b9',
    })
    expect(ref).toBe('1e40fdfba1cf17f3c9f9f3d6b392b1865e5147b9')
  })",snuts
/__tests__/test-resolveRef.js,AnonymousTest,"{'startLine':18,'endLine':28}","it('test-branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-resolveRef')
    // Test
    const ref = await resolveRef({
      fs,
      gitdir,
      ref: 'origin/test-branch',
    })
    expect(ref).toBe('e10ebb90d03eaacca84de1af0a59b444232da99e')
  })",snuts
/__tests__/test-resolveRef.js,AnonymousTest,"{'startLine':29,'endLine':39}","it('config', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-resolveRef')
    // Test
    const ref = await resolveRef({
      fs,
      gitdir,
      ref: 'config',
    })
    expect(ref).toBe('e10ebb90d03eaacca84de1af0a59b444232da99e')
  })",snuts
/__tests__/test-resolveRef.js,AnonymousTest,"{'startLine':40,'endLine':50}","it('test-tag', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-resolveRef')
    // Test
    const ref = await resolveRef({
      fs,
      gitdir,
      ref: 'test-tag',
    })
    expect(ref).toBe('1e40fdfba1cf17f3c9f9f3d6b392b1865e5147b9')
  })",snuts
/__tests__/test-resolveRef.js,AnonymousTest,"{'startLine':51,'endLine':61}","it('HEAD', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-resolveRef')
    // Test
    const ref = await resolveRef({
      fs,
      gitdir,
      ref: 'HEAD',
    })
    expect(ref).toBe('033417ae18b174f078f2f44232cb7a374f4c60ce')
  })",snuts
/__tests__/test-resolveRef.js,AnonymousTest,"{'startLine':62,'endLine':73}","it('HEAD depth', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-resolveRef')
    // Test
    const ref = await resolveRef({
      fs,
      gitdir,
      ref: 'HEAD',
      depth: 2,
    })
    expect(ref).toBe('refs/heads/master')
  })",snuts
/__tests__/test-resolveRef.js,AnonymousTest,"{'startLine':74,'endLine':84}","it('packed-refs', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-resolveRef')
    // Test
    const ref = await resolveRef({
      fs,
      gitdir,
      ref: 'v0.0.1',
    })
    expect(ref).toBe('1a2149e96a9767b281a8f10fd014835322da2d14')
  })",snuts
/__tests__/test-resolveRef.js,AnonymousTest,"{'startLine':85,'endLine':101}","it('non-existant refs', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-resolveRef')
    // Test
    let error = {}
    try {
      await resolveRef({
        fs,
        gitdir,
        ref: 'this-is-not-a-ref',
      })
    } catch (err) {
      error = err
    }
    expect(error.message).toBeDefined()
    expect(error.caller).toEqual('git.resolveRef')
  })",snuts
/__tests__/test-resetIndex.js,AnonymousTest,"{'startLine':7,'endLine':29}","it('modified', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-resetIndex')
    // Test
    const before = await listFiles({ fs, gitdir })
    expect(before).toMatchInlineSnapshot(`
      Array [
        ""a.txt"",
        ""b.txt"",
        ""d.txt"",
      ]
    `)
    await resetIndex({ fs, dir, gitdir, filepath: 'a.txt' })
    const after = await listFiles({ fs, gitdir })
    expect(after).toMatchInlineSnapshot(`
      Array [
        ""a.txt"",
        ""b.txt"",
        ""d.txt"",
      ]
    `)
    expect(before.length === after.length).toBe(true)
  })",snuts
/__tests__/test-resetIndex.js,AnonymousTest,"{'startLine':30,'endLine':51}","it('new file', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-resetIndex')
    // Test
    const before = await listFiles({ fs, gitdir })
    expect(before).toMatchInlineSnapshot(`
      Array [
        ""a.txt"",
        ""b.txt"",
        ""d.txt"",
      ]
    `)
    await resetIndex({ fs, dir, gitdir, filepath: 'd.txt' })
    const after = await listFiles({ fs, gitdir })
    expect(after).toMatchInlineSnapshot(`
      Array [
        ""a.txt"",
        ""b.txt"",
      ]
    `)
    expect(before.length === after.length + 1).toBe(true)
  })",snuts
/__tests__/test-resetIndex.js,AnonymousTest,"{'startLine':52,'endLine':71}","it('new repository', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-resetIndex-new')
    // Test
    const before = await listFiles({ fs, gitdir })
    expect(before).toMatchInlineSnapshot(`
      Array [
        ""a.txt"",
        ""b.txt"",
      ]
    `)
    await resetIndex({ fs, dir, gitdir, filepath: 'b.txt' })
    const after = await listFiles({ fs, gitdir })
    expect(after).toMatchInlineSnapshot(`
      Array [
        ""a.txt"",
      ]
    `)
    expect(before.length === after.length + 1).toBe(true)
  })",snuts
/__tests__/test-resetIndex.js,AnonymousTest,"{'startLine':72,'endLine':117}","it('oid', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-resetIndex-oid')
    // Test
    const before = await statusMatrix({ fs, dir, gitdir })
    expect(before).toMatchInlineSnapshot(`
      Array [
        Array [
          ""a.txt"",
          1,
          1,
          1,
        ],
        Array [
          ""b.txt"",
          1,
          1,
          1,
        ],
      ]
    `)
    await resetIndex({
      fs,
      dir,
      gitdir,
      filepath: 'b.txt',
      ref: '572d5ec8ea719ed6780ef0e6a115a75999cb3091',
    })
    const after = await statusMatrix({ fs, dir, gitdir })
    expect(after).toMatchInlineSnapshot(`
      Array [
        Array [
          ""a.txt"",
          1,
          1,
          1,
        ],
        Array [
          ""b.txt"",
          1,
          1,
          0,
        ],
      ]
    `)
  })",snuts
/__tests__/test-resetIndex.js,SubOptimalAssert,"{'startLine':28,'endLine':28}","it('modified', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-resetIndex')
    // Test
    const before = await listFiles({ fs, gitdir })
    expect(before).toMatchInlineSnapshot(`
      Array [
        ""a.txt"",
        ""b.txt"",
        ""d.txt"",
      ]
    `)
    await resetIndex({ fs, dir, gitdir, filepath: 'a.txt' })
    const after = await listFiles({ fs, gitdir })
    expect(after).toMatchInlineSnapshot(`
      Array [
        ""a.txt"",
        ""b.txt"",
        ""d.txt"",
      ]
    `)
    expect(before.length === after.length).toBe(true)
  })",snuts
/__tests__/test-resetIndex.js,SubOptimalAssert,"{'startLine':50,'endLine':50}","it('new file', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-resetIndex')
    // Test
    const before = await listFiles({ fs, gitdir })
    expect(before).toMatchInlineSnapshot(`
      Array [
        ""a.txt"",
        ""b.txt"",
        ""d.txt"",
      ]
    `)
    await resetIndex({ fs, dir, gitdir, filepath: 'd.txt' })
    const after = await listFiles({ fs, gitdir })
    expect(after).toMatchInlineSnapshot(`
      Array [
        ""a.txt"",
        ""b.txt"",
      ]
    `)
    expect(before.length === after.length + 1).toBe(true)
  })",snuts
/__tests__/test-resetIndex.js,SubOptimalAssert,"{'startLine':70,'endLine':70}","it('new repository', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-resetIndex-new')
    // Test
    const before = await listFiles({ fs, gitdir })
    expect(before).toMatchInlineSnapshot(`
      Array [
        ""a.txt"",
        ""b.txt"",
      ]
    `)
    await resetIndex({ fs, dir, gitdir, filepath: 'b.txt' })
    const after = await listFiles({ fs, gitdir })
    expect(after).toMatchInlineSnapshot(`
      Array [
        ""a.txt"",
      ]
    `)
    expect(before.length === after.length + 1).toBe(true)
  })",snuts
/__tests__/test-renameBranch.js,AnonymousTest,"{'startLine':99,'endLine':113}","it('rename branch', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-renameBranch')
    // Test
    await renameBranch({
      fs,
      dir,
      gitdir,
      oldref: 'test-branch',
      ref: 'other-branch',
    })
    const files = await fs.readdir(path.resolve(gitdir, 'refs', 'heads'))
    expect(files.includes('test-branch')).toBe(false)
    expect(await currentBranch({ fs, dir, gitdir })).toEqual('master')
  })",snuts
/__tests__/test-renameBranch.js,SubOptimalAssert,"{'startLine':26,'endLine':26}","it('branch already exists', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-renameBranch')
    let error = null
    // Test
    try {
      await renameBranch({
        fs,
        dir,
        gitdir,
        oldref: 'test-branch',
        ref: 'existing-branch',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.AlreadyExistsError).toBe(true)
  })",snuts
/__tests__/test-renameBranch.js,SubOptimalAssert,"{'startLine':46,'endLine':46}","it('invalid new branch name', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-renameBranch')
    let error = null
    // Test
    try {
      await renameBranch({
        fs,
        dir,
        gitdir,
        oldref: 'test-branch',
        ref: 'inv@{id..branch.lock',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidRefNameError).toBe(true)
  })",snuts
/__tests__/test-renameBranch.js,SubOptimalAssert,"{'startLine':66,'endLine':66}","it('invalid old branch name', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-renameBranch')
    let error = null
    // Test
    try {
      await renameBranch({
        fs,
        dir,
        gitdir,
        ref: 'other-branch',
        oldref: 'inv@{id..branch.lock',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidRefNameError).toBe(true)
  })",snuts
/__tests__/test-renameBranch.js,SubOptimalAssert,"{'startLine':81,'endLine':81}","it('missing ref argument', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-renameBranch')
    let error = null
    // Test
    try {
      // @ts-ignore
      await renameBranch({ fs, dir, gitdir, oldref: 'test-branch' })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.MissingParameterError).toBe(true)
  })",snuts
/__tests__/test-renameBranch.js,SubOptimalAssert,"{'startLine':96,'endLine':96}","it('missing oldref argument', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-renameBranch')
    let error = null
    // Test
    try {
      // @ts-ignore
      await renameBranch({ fs, dir, gitdir, ref: 'other-branch' })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.MissingParameterError).toBe(true)
  })",snuts
/__tests__/test-removeNote.js,SubOptimalAssert,"{'startLine':15,'endLine':15}","it('from default branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-removeNote')
    // Test
    let notes = await listNotes({
      fs,
      gitdir,
    })
    expect(notes.length).toBe(3)
    const oid = await removeNote({
      fs,
      gitdir,
      author: {
        name: 'William Hilton',
        email: 'wmhilton@gmail.com',
        timestamp: 1578937310,
        timezoneOffset: 300,
      },
      oid: '199948939a0b95c6f27668689102496574b2c332',
    })
    notes = await listNotes({
      fs,
      gitdir,
    })
    expect(notes.length).toBe(2)
    expect(oid).toBe('96cc0598c9f2eaac733d0817981039596c0c410f')
  })",snuts
/__tests__/test-removeNote.js,SubOptimalAssert,"{'startLine':31,'endLine':31}","it('from default branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-removeNote')
    // Test
    let notes = await listNotes({
      fs,
      gitdir,
    })
    expect(notes.length).toBe(3)
    const oid = await removeNote({
      fs,
      gitdir,
      author: {
        name: 'William Hilton',
        email: 'wmhilton@gmail.com',
        timestamp: 1578937310,
        timezoneOffset: 300,
      },
      oid: '199948939a0b95c6f27668689102496574b2c332',
    })
    notes = await listNotes({
      fs,
      gitdir,
    })
    expect(notes.length).toBe(2)
    expect(oid).toBe('96cc0598c9f2eaac733d0817981039596c0c410f')
  })",snuts
/__tests__/test-removeNote.js,SubOptimalAssert,"{'startLine':43,'endLine':43}","it('from alternate branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-removeNote')
    // Test
    let notes = await listNotes({
      fs,
      gitdir,
      ref: 'refs/notes/alt',
    })
    expect(notes.length).toBe(1)
    const oid = await removeNote({
      fs,
      gitdir,
      author: {
        name: 'William Hilton',
        email: 'wmhilton@gmail.com',
        timestamp: 1578937310,
        timezoneOffset: 300,
      },
      ref: 'refs/notes/alt',
      oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
    })
    notes = await listNotes({
      fs,
      gitdir,
      ref: 'refs/notes/alt',
    })
    expect(notes.length).toBe(0)
    expect(oid).toBe('cfab6e154843d83173626d8d39d1dbe0f603921b')
  })",snuts
/__tests__/test-removeNote.js,SubOptimalAssert,"{'startLine':61,'endLine':61}","it('from alternate branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-removeNote')
    // Test
    let notes = await listNotes({
      fs,
      gitdir,
      ref: 'refs/notes/alt',
    })
    expect(notes.length).toBe(1)
    const oid = await removeNote({
      fs,
      gitdir,
      author: {
        name: 'William Hilton',
        email: 'wmhilton@gmail.com',
        timestamp: 1578937310,
        timezoneOffset: 300,
      },
      ref: 'refs/notes/alt',
      oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
    })
    notes = await listNotes({
      fs,
      gitdir,
      ref: 'refs/notes/alt',
    })
    expect(notes.length).toBe(0)
    expect(oid).toBe('cfab6e154843d83173626d8d39d1dbe0f603921b')
  })",snuts
/__tests__/test-remove.js,AnonymousTest,"{'startLine':7,'endLine':70}","it('file', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-remove')
    // Test
    const before = await listFiles({ fs, gitdir })
    expect(before).toMatchInlineSnapshot(`
      Array [
        "".babelrc"",
        "".editorconfig"",
        "".flowconfig"",
        "".gitignore"",
        "".travis.yml"",
        ""LICENSE.md"",
        ""package-lock.json"",
        ""package.json"",
        ""shrinkwrap.yaml"",
        ""src/commands/checkout.js"",
        ""src/commands/config.js"",
        ""src/commands/fetch.js"",
        ""src/commands/init.js"",
        ""src/index.js"",
        ""src/models/GitBlob.js"",
        ""src/models/GitCommit.js"",
        ""src/models/GitConfig.js"",
        ""src/models/GitObject.js"",
        ""src/models/GitTree.js"",
        ""src/utils/exists.js"",
        ""src/utils/mkdirs.js"",
        ""src/utils/read.js"",
        ""src/utils/resolveRef.js"",
        ""src/utils/write.js"",
      ]
    `)
    await remove({ fs, gitdir, filepath: 'LICENSE.md' })
    const after = await listFiles({ fs, gitdir })
    expect(after).toMatchInlineSnapshot(`
      Array [
        "".babelrc"",
        "".editorconfig"",
        "".flowconfig"",
        "".gitignore"",
        "".travis.yml"",
        ""package-lock.json"",
        ""package.json"",
        ""shrinkwrap.yaml"",
        ""src/commands/checkout.js"",
        ""src/commands/config.js"",
        ""src/commands/fetch.js"",
        ""src/commands/init.js"",
        ""src/index.js"",
        ""src/models/GitBlob.js"",
        ""src/models/GitCommit.js"",
        ""src/models/GitConfig.js"",
        ""src/models/GitObject.js"",
        ""src/models/GitTree.js"",
        ""src/utils/exists.js"",
        ""src/utils/mkdirs.js"",
        ""src/utils/read.js"",
        ""src/utils/resolveRef.js"",
        ""src/utils/write.js"",
      ]
    `)
    expect(before.length === after.length + 1).toBe(true)
  })",snuts
/__tests__/test-remove.js,AnonymousTest,"{'startLine':71,'endLine':130}","it('dir', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-remove')
    // Test
    const before = await listFiles({ fs, gitdir })
    expect(before).toMatchInlineSnapshot(`
      Array [
        "".babelrc"",
        "".editorconfig"",
        "".flowconfig"",
        "".gitignore"",
        "".travis.yml"",
        ""LICENSE.md"",
        ""package-lock.json"",
        ""package.json"",
        ""shrinkwrap.yaml"",
        ""src/commands/checkout.js"",
        ""src/commands/config.js"",
        ""src/commands/fetch.js"",
        ""src/commands/init.js"",
        ""src/index.js"",
        ""src/models/GitBlob.js"",
        ""src/models/GitCommit.js"",
        ""src/models/GitConfig.js"",
        ""src/models/GitObject.js"",
        ""src/models/GitTree.js"",
        ""src/utils/exists.js"",
        ""src/utils/mkdirs.js"",
        ""src/utils/read.js"",
        ""src/utils/resolveRef.js"",
        ""src/utils/write.js"",
      ]
    `)
    await remove({ fs, gitdir, filepath: 'src/models' })
    const after = await listFiles({ fs, gitdir })
    expect(after).toMatchInlineSnapshot(`
      Array [
        "".babelrc"",
        "".editorconfig"",
        "".flowconfig"",
        "".gitignore"",
        "".travis.yml"",
        ""LICENSE.md"",
        ""package-lock.json"",
        ""package.json"",
        ""shrinkwrap.yaml"",
        ""src/commands/checkout.js"",
        ""src/commands/config.js"",
        ""src/commands/fetch.js"",
        ""src/commands/init.js"",
        ""src/index.js"",
        ""src/utils/exists.js"",
        ""src/utils/mkdirs.js"",
        ""src/utils/read.js"",
        ""src/utils/resolveRef.js"",
        ""src/utils/write.js"",
      ]
    `)
    expect(before.length === after.length + 5).toBe(true)
  })",snuts
/__tests__/test-remove.js,SubOptimalAssert,"{'startLine':69,'endLine':69}","it('file', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-remove')
    // Test
    const before = await listFiles({ fs, gitdir })
    expect(before).toMatchInlineSnapshot(`
      Array [
        "".babelrc"",
        "".editorconfig"",
        "".flowconfig"",
        "".gitignore"",
        "".travis.yml"",
        ""LICENSE.md"",
        ""package-lock.json"",
        ""package.json"",
        ""shrinkwrap.yaml"",
        ""src/commands/checkout.js"",
        ""src/commands/config.js"",
        ""src/commands/fetch.js"",
        ""src/commands/init.js"",
        ""src/index.js"",
        ""src/models/GitBlob.js"",
        ""src/models/GitCommit.js"",
        ""src/models/GitConfig.js"",
        ""src/models/GitObject.js"",
        ""src/models/GitTree.js"",
        ""src/utils/exists.js"",
        ""src/utils/mkdirs.js"",
        ""src/utils/read.js"",
        ""src/utils/resolveRef.js"",
        ""src/utils/write.js"",
      ]
    `)
    await remove({ fs, gitdir, filepath: 'LICENSE.md' })
    const after = await listFiles({ fs, gitdir })
    expect(after).toMatchInlineSnapshot(`
      Array [
        "".babelrc"",
        "".editorconfig"",
        "".flowconfig"",
        "".gitignore"",
        "".travis.yml"",
        ""package-lock.json"",
        ""package.json"",
        ""shrinkwrap.yaml"",
        ""src/commands/checkout.js"",
        ""src/commands/config.js"",
        ""src/commands/fetch.js"",
        ""src/commands/init.js"",
        ""src/index.js"",
        ""src/models/GitBlob.js"",
        ""src/models/GitCommit.js"",
        ""src/models/GitConfig.js"",
        ""src/models/GitObject.js"",
        ""src/models/GitTree.js"",
        ""src/utils/exists.js"",
        ""src/utils/mkdirs.js"",
        ""src/utils/read.js"",
        ""src/utils/resolveRef.js"",
        ""src/utils/write.js"",
      ]
    `)
    expect(before.length === after.length + 1).toBe(true)
  })",snuts
/__tests__/test-remove.js,SubOptimalAssert,"{'startLine':129,'endLine':129}","it('dir', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-remove')
    // Test
    const before = await listFiles({ fs, gitdir })
    expect(before).toMatchInlineSnapshot(`
      Array [
        "".babelrc"",
        "".editorconfig"",
        "".flowconfig"",
        "".gitignore"",
        "".travis.yml"",
        ""LICENSE.md"",
        ""package-lock.json"",
        ""package.json"",
        ""shrinkwrap.yaml"",
        ""src/commands/checkout.js"",
        ""src/commands/config.js"",
        ""src/commands/fetch.js"",
        ""src/commands/init.js"",
        ""src/index.js"",
        ""src/models/GitBlob.js"",
        ""src/models/GitCommit.js"",
        ""src/models/GitConfig.js"",
        ""src/models/GitObject.js"",
        ""src/models/GitTree.js"",
        ""src/utils/exists.js"",
        ""src/utils/mkdirs.js"",
        ""src/utils/read.js"",
        ""src/utils/resolveRef.js"",
        ""src/utils/write.js"",
      ]
    `)
    await remove({ fs, gitdir, filepath: 'src/models' })
    const after = await listFiles({ fs, gitdir })
    expect(after).toMatchInlineSnapshot(`
      Array [
        "".babelrc"",
        "".editorconfig"",
        "".flowconfig"",
        "".gitignore"",
        "".travis.yml"",
        ""LICENSE.md"",
        ""package-lock.json"",
        ""package.json"",
        ""shrinkwrap.yaml"",
        ""src/commands/checkout.js"",
        ""src/commands/config.js"",
        ""src/commands/fetch.js"",
        ""src/commands/init.js"",
        ""src/index.js"",
        ""src/utils/exists.js"",
        ""src/utils/mkdirs.js"",
        ""src/utils/read.js"",
        ""src/utils/resolveRef.js"",
        ""src/utils/write.js"",
      ]
    `)
    expect(before.length === after.length + 5).toBe(true)
  })",snuts
/__tests__/test-readTree.js,AnonymousTest,"{'startLine':130,'endLine':252}","it('peels tags', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readTree')
    // Test
    const { oid, tree } = await readTree({
      fs,
      gitdir,
      oid: '86167ce7861387275b2fbd188e031e00aff446f9',
    })
    expect(oid).toEqual('6257985e3378ec42a03a57a7dc8eb952d69a5ff3')
    expect(tree).toMatchInlineSnapshot(`
      Array [
        Object {
          ""mode"": ""100644"",
          ""oid"": ""375f9392774e7a7c8a1ae23a6d13b5c133e42c45"",
          ""path"": "".babelrc"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""bbf3e21f43fa4fe25eb925bfcb7c0434f7c2dc7d"",
          ""path"": "".editorconfig"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""4a58bdcdef3eb91264dfca0279959d98c16568d5"",
          ""path"": "".flowconfig"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""2b90c4a2353d2977e158c21f4315664063770212"",
          ""path"": "".gitignore"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""63ed03aea9d828c86ebde989b336f5e978fdc3f1"",
          ""path"": "".travis.yml"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""c675a17ccb1578bca836decf90205fdad743827d"",
          ""path"": ""LICENSE.md"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""9761716146bbdb47f8a7de3d9df98777df9674f3"",
          ""path"": ""README.md"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""63a8130fa218d20b0009c1126375a105c1adba8a"",
          ""path"": ""__tests__"",
          ""type"": ""tree"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""bdc76cc9d0da964db203f47333d05185a22d6a18"",
          ""path"": ""ci.karma.conf.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""4551a1856279dde6ae9d65862a1dff59a5f199d8"",
          ""path"": ""cli.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""69be3467cb125fbc55eb5c7e50caa556fb0e34b4"",
          ""path"": ""dist"",
          ""type"": ""tree"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""af56d48cb8af9c5ba3547c12c4a4a61fc16ff971"",
          ""path"": ""karma.conf.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""00b91c8b8ddfb43df70ef334088b7d840e5053db"",
          ""path"": ""package-lock.json"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""7b12188e7e351c1a761b76b38e36c13b5cba6c1f"",
          ""path"": ""package-scripts.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""bfe174beb9bf440c1c49b6fba0094f16cf9c9490"",
          ""path"": ""package.json"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""a86d1a6c3997dc73e8bf8687edb15fc087892e9d"",
          ""path"": ""rollup.config.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""ae7b4f3ac2c570dc3597124fc108ecb9d6c2b4fd"",
          ""path"": ""src"",
          ""type"": ""tree"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""0a7ce5f20a8ccba18463a2ae990baf63ba1e3b43"",
          ""path"": ""testling"",
          ""type"": ""tree"",
        },
      ]
    `)
  })",snuts
/__tests__/test-readTree.js,ComplexSnapshots,"{'startLine':17,'endLine':128}","it('read a tree directly', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readTree')
    // Test
    const { oid, tree } = await readTree({
      fs,
      gitdir,
      oid: '6257985e3378ec42a03a57a7dc8eb952d69a5ff3',
    })
    expect(oid).toEqual('6257985e3378ec42a03a57a7dc8eb952d69a5ff3')
    expect(tree).toMatchInlineSnapshot(`
      Array [
        Object {
          ""mode"": ""100644"",
          ""oid"": ""375f9392774e7a7c8a1ae23a6d13b5c133e42c45"",
          ""path"": "".babelrc"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""bbf3e21f43fa4fe25eb925bfcb7c0434f7c2dc7d"",
          ""path"": "".editorconfig"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""4a58bdcdef3eb91264dfca0279959d98c16568d5"",
          ""path"": "".flowconfig"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""2b90c4a2353d2977e158c21f4315664063770212"",
          ""path"": "".gitignore"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""63ed03aea9d828c86ebde989b336f5e978fdc3f1"",
          ""path"": "".travis.yml"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""c675a17ccb1578bca836decf90205fdad743827d"",
          ""path"": ""LICENSE.md"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""9761716146bbdb47f8a7de3d9df98777df9674f3"",
          ""path"": ""README.md"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""63a8130fa218d20b0009c1126375a105c1adba8a"",
          ""path"": ""__tests__"",
          ""type"": ""tree"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""bdc76cc9d0da964db203f47333d05185a22d6a18"",
          ""path"": ""ci.karma.conf.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""4551a1856279dde6ae9d65862a1dff59a5f199d8"",
          ""path"": ""cli.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""69be3467cb125fbc55eb5c7e50caa556fb0e34b4"",
          ""path"": ""dist"",
          ""type"": ""tree"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""af56d48cb8af9c5ba3547c12c4a4a61fc16ff971"",
          ""path"": ""karma.conf.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""00b91c8b8ddfb43df70ef334088b7d840e5053db"",
          ""path"": ""package-lock.json"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""7b12188e7e351c1a761b76b38e36c13b5cba6c1f"",
          ""path"": ""package-scripts.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""bfe174beb9bf440c1c49b6fba0094f16cf9c9490"",
          ""path"": ""package.json"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""a86d1a6c3997dc73e8bf8687edb15fc087892e9d"",
          ""path"": ""rollup.config.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""ae7b4f3ac2c570dc3597124fc108ecb9d6c2b4fd"",
          ""path"": ""src"",
          ""type"": ""tree"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""0a7ce5f20a8ccba18463a2ae990baf63ba1e3b43"",
          ""path"": ""testling"",
          ""type"": ""tree"",
        },
      ]
    `)
  })",snuts
/__tests__/test-readTree.js,ComplexSnapshots,"{'startLine':140,'endLine':251}","it('peels tags', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readTree')
    // Test
    const { oid, tree } = await readTree({
      fs,
      gitdir,
      oid: '86167ce7861387275b2fbd188e031e00aff446f9',
    })
    expect(oid).toEqual('6257985e3378ec42a03a57a7dc8eb952d69a5ff3')
    expect(tree).toMatchInlineSnapshot(`
      Array [
        Object {
          ""mode"": ""100644"",
          ""oid"": ""375f9392774e7a7c8a1ae23a6d13b5c133e42c45"",
          ""path"": "".babelrc"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""bbf3e21f43fa4fe25eb925bfcb7c0434f7c2dc7d"",
          ""path"": "".editorconfig"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""4a58bdcdef3eb91264dfca0279959d98c16568d5"",
          ""path"": "".flowconfig"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""2b90c4a2353d2977e158c21f4315664063770212"",
          ""path"": "".gitignore"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""63ed03aea9d828c86ebde989b336f5e978fdc3f1"",
          ""path"": "".travis.yml"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""c675a17ccb1578bca836decf90205fdad743827d"",
          ""path"": ""LICENSE.md"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""9761716146bbdb47f8a7de3d9df98777df9674f3"",
          ""path"": ""README.md"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""63a8130fa218d20b0009c1126375a105c1adba8a"",
          ""path"": ""__tests__"",
          ""type"": ""tree"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""bdc76cc9d0da964db203f47333d05185a22d6a18"",
          ""path"": ""ci.karma.conf.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""4551a1856279dde6ae9d65862a1dff59a5f199d8"",
          ""path"": ""cli.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""69be3467cb125fbc55eb5c7e50caa556fb0e34b4"",
          ""path"": ""dist"",
          ""type"": ""tree"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""af56d48cb8af9c5ba3547c12c4a4a61fc16ff971"",
          ""path"": ""karma.conf.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""00b91c8b8ddfb43df70ef334088b7d840e5053db"",
          ""path"": ""package-lock.json"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""7b12188e7e351c1a761b76b38e36c13b5cba6c1f"",
          ""path"": ""package-scripts.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""bfe174beb9bf440c1c49b6fba0094f16cf9c9490"",
          ""path"": ""package.json"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""a86d1a6c3997dc73e8bf8687edb15fc087892e9d"",
          ""path"": ""rollup.config.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""ae7b4f3ac2c570dc3597124fc108ecb9d6c2b4fd"",
          ""path"": ""src"",
          ""type"": ""tree"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""0a7ce5f20a8ccba18463a2ae990baf63ba1e3b43"",
          ""path"": ""testling"",
          ""type"": ""tree"",
        },
      ]
    `)
  })",snuts
/__tests__/test-readTree.js,ComplexSnapshots,"{'startLine':264,'endLine':375}","it('with simple filepath to tree', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readTree')
    // Test
    const { oid, tree } = await readTree({
      fs,
      gitdir,
      oid: 'be1e63da44b26de8877a184359abace1cddcb739',
      filepath: '',
    })
    expect(oid).toEqual('6257985e3378ec42a03a57a7dc8eb952d69a5ff3')
    expect(tree).toMatchInlineSnapshot(`
      Array [
        Object {
          ""mode"": ""100644"",
          ""oid"": ""375f9392774e7a7c8a1ae23a6d13b5c133e42c45"",
          ""path"": "".babelrc"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""bbf3e21f43fa4fe25eb925bfcb7c0434f7c2dc7d"",
          ""path"": "".editorconfig"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""4a58bdcdef3eb91264dfca0279959d98c16568d5"",
          ""path"": "".flowconfig"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""2b90c4a2353d2977e158c21f4315664063770212"",
          ""path"": "".gitignore"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""63ed03aea9d828c86ebde989b336f5e978fdc3f1"",
          ""path"": "".travis.yml"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""c675a17ccb1578bca836decf90205fdad743827d"",
          ""path"": ""LICENSE.md"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""9761716146bbdb47f8a7de3d9df98777df9674f3"",
          ""path"": ""README.md"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""63a8130fa218d20b0009c1126375a105c1adba8a"",
          ""path"": ""__tests__"",
          ""type"": ""tree"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""bdc76cc9d0da964db203f47333d05185a22d6a18"",
          ""path"": ""ci.karma.conf.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""4551a1856279dde6ae9d65862a1dff59a5f199d8"",
          ""path"": ""cli.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""69be3467cb125fbc55eb5c7e50caa556fb0e34b4"",
          ""path"": ""dist"",
          ""type"": ""tree"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""af56d48cb8af9c5ba3547c12c4a4a61fc16ff971"",
          ""path"": ""karma.conf.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""00b91c8b8ddfb43df70ef334088b7d840e5053db"",
          ""path"": ""package-lock.json"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""7b12188e7e351c1a761b76b38e36c13b5cba6c1f"",
          ""path"": ""package-scripts.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""bfe174beb9bf440c1c49b6fba0094f16cf9c9490"",
          ""path"": ""package.json"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""a86d1a6c3997dc73e8bf8687edb15fc087892e9d"",
          ""path"": ""rollup.config.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""ae7b4f3ac2c570dc3597124fc108ecb9d6c2b4fd"",
          ""path"": ""src"",
          ""type"": ""tree"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""0a7ce5f20a8ccba18463a2ae990baf63ba1e3b43"",
          ""path"": ""testling"",
          ""type"": ""tree"",
        },
      ]
    `)
  })",snuts
/__tests__/test-readTree.js,ComplexSnapshots,"{'startLine':388,'endLine':505}","it('with deep filepath to tree', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readTree')
    // Test
    const { oid, tree } = await readTree({
      fs,
      gitdir,
      oid: 'be1e63da44b26de8877a184359abace1cddcb739',
      filepath: 'src/commands',
    })
    expect(oid).toEqual('7704a6e8a802efcdbe6cf3dfa114c105f1d5c67a')
    expect(tree).toMatchInlineSnapshot(`
      Array [
        Object {
          ""mode"": ""100644"",
          ""oid"": ""c0c25b4e4c418eff366132e6cb2b16c8d9a7798c"",
          ""path"": ""add.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""85cd837ae2a5577a6247937cb1e0404a0101705b"",
          ""path"": ""checkout.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""5264f23285d8be3ce45f95c102001ffa1d5391d3"",
          ""path"": ""clone.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""1ac40ceb71b7fd182808decfd14d644d65887d52"",
          ""path"": ""commit.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""9d9432818d654e7884b41223f7ae8ef4defec959"",
          ""path"": ""config.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""1c473b86b3e693e34363b4be9cdcd0c50e0bfed4"",
          ""path"": ""fetch.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""de854e230503c548d530a71442ba0d03824eefbb"",
          ""path"": ""findRoot.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""f309f5b14fc9897a3816547d0129f117788ffef1"",
          ""path"": ""init.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""9184088c0d0b75dba8108433f8d26fece09c36dc"",
          ""path"": ""list.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""1f67512a0eb40a8a955ad3ca56dfcd4231a935f9"",
          ""path"": ""listBranches.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""d740a56e95cada64654c6e9e52616cc3318be4cb"",
          ""path"": ""log.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""600a1006b12f2c7244fc034d8c64ad21c9597237"",
          ""path"": ""pack.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""9b3a67837dcabde4eee4862d6ad78b3ebf68915e"",
          ""path"": ""push.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""46e96d7d5b4cb91210ce169824feda77c3bd6cc3"",
          ""path"": ""remove.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""3a3ea110eb4967ca7e9d3eef41b073e779c329d1"",
          ""path"": ""resolveRef.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""f913d87e7844579afbe02fe116c88a6b51bf1bca"",
          ""path"": ""status.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""67e79f9e10d44eb692be57e746639b9f2b54e816"",
          ""path"": ""unpack.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""007e7738d257fe78da6938990a40e4310dfc0757"",
          ""path"": ""verify.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""9584ccddb392f8185101dca41496fba0fd264d6a"",
          ""path"": ""version.js"",
          ""type"": ""blob"",
        },
      ]
    `)
  })",snuts
/__tests__/test-readTree.js,SubOptimalAssert,"{'startLine':523,'endLine':523}","it('with erroneous filepath (directory is a file)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readTree')
    // Test
    let error = null
    try {
      await readTree({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        filepath: 'src/commands/clone.js/isntafolder.txt',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.ObjectTypeError).toBe(true)
  })",snuts
/__tests__/test-readTree.js,SubOptimalAssert,"{'startLine':541,'endLine':541}","it('with erroneous filepath (no such directory)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readTree')
    // Test
    let error = null
    try {
      await readTree({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        filepath: 'src/isntafolder',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",snuts
/__tests__/test-readTree.js,SubOptimalAssert,"{'startLine':559,'endLine':559}","it('with erroneous filepath (leading slash)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readTree')
    // Test
    let error = null
    try {
      await readTree({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        filepath: '/src',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidFilepathError).toBe(true)
    expect(error.data.reason).toBe('leading-slash')
  })",snuts
/__tests__/test-readTree.js,SubOptimalAssert,"{'startLine':578,'endLine':578}","it('with erroneous filepath (trailing slash)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readTree')
    // Test
    let error = null
    try {
      await readTree({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        filepath: 'src/',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidFilepathError).toBe(true)
    expect(error.data.reason).toBe('trailing-slash')
  })",snuts
/__tests__/test-readTag.js,AnonymousTest,"{'startLine':7,'endLine':43}","it('annotated tag', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readTag')
    // Test
    const tag = await readTag({
      fs,
      gitdir,
      oid: '587d3f8290b513e2ee85ecd317e6efecd545aee6',
    })
    expect(tag).toMatchInlineSnapshot(`
      Object {
        ""oid"": ""587d3f8290b513e2ee85ecd317e6efecd545aee6"",
        ""payload"": ""object 033417ae18b174f078f2f44232cb7a374f4c60ce
      type commit
      tag mytag
      tagger William Hilton <wmhilton@gmail.com> 1578802395 -0500

      This is a tag message.

      "",
        ""tag"": Object {
          ""gpgsig"": undefined,
          ""message"": ""This is a tag message.
      "",
          ""object"": ""033417ae18b174f078f2f44232cb7a374f4c60ce"",
          ""tag"": ""mytag"",
          ""tagger"": Object {
            ""email"": ""wmhilton@gmail.com"",
            ""name"": ""William Hilton"",
            ""timestamp"": 1578802395,
            ""timezoneOffset"": 300,
          },
          ""type"": ""commit"",
        },
      }
    `)
  })",snuts
/__tests__/test-readObject.js,AnonymousTest,"{'startLine':7,'endLine':23}","it('test missing', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    let error = null
    try {
      await readObject({
        fs,
        gitdir,
        oid: 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",snuts
/__tests__/test-readObject.js,AnonymousTest,"{'startLine':24,'endLine':80}","it('parsed', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'e10ebb90d03eaacca84de1af0a59b444232da99e',
    })
    expect(ref).toMatchInlineSnapshot(`
      Object {
        ""format"": ""parsed"",
        ""object"": Object {
          ""author"": Object {
            ""email"": ""wmhilton@gmail.com"",
            ""name"": ""Will Hilton"",
            ""timestamp"": 1502484200,
            ""timezoneOffset"": 240,
          },
          ""committer"": Object {
            ""email"": ""wmhilton@gmail.com"",
            ""name"": ""Will Hilton"",
            ""timestamp"": 1502484200,
            ""timezoneOffset"": 240,
          },
          ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZjhboAAoJEJYJuKWSi6a5V5UP/040SfemJ13PRBXst2eB59gs
      3hPx29DRKBhFtvk+uS+8523/hUfry2oeWWd6YRkcnkxxAUtBnfzVkI9AgRIc1NTM
      h5XtLMQubCAKw8JWvVvoXETzwVAODmdmvC4WSQCLu+opoe6/W7RvkrTD0pbkwH4E
      MXoha59sIWZ/FacZX6ByYqhFykfJL8gCFvRSzjiqBIbsP7Xq2Mh4jkAKYl5zxV3u
      qCk26hnhL++kwfXlu2YdGtB9+lj3pk1NeWqR379zRzh4P10FxXJ18qSxczbkAFOY
      6o5h7a/Mql1KqWB9EFBupCpjydmpAtPo6l1Us4a3liB5LJvCh9xgR2HtShR4b97O
      nIpXP4ngy4z9UyrXXxxpiQQn/kVn/uKgtvGp8nOFioo61PCi9js2QmQxcsuBOeO+
      DdFq5k2PMNZLwizt4P8EGfVJoPbLhdYP4oWiMCuYV/2fNh0ozl/q176HGszlfrke
      332Z0maJ3A5xIRj0b7vRNHV8AAl9Dheo3LspjeovP2iycCHFP03gSpCKdLRBRC4T
      X10BBFD8noCMXJxb5qenrf+eKRd8d4g7JtcyzqVgkBQ68GIG844VWRBolOzx4By5
      cAaw/SYIZG3RorAc11iZ7sva0jFISejmEzIebuChSzdWO2OOWRVvMdhyZwDLUgAb
      Qixh2bmPgr3h9nxq2Dmn
      =4+DN
      -----END PGP SIGNATURE-----"",
          ""message"": ""Improve resolveRef to handle more kinds of refs. Add tests
      "",
          ""parent"": Array [
            ""b4f8206d9e359416b0f34238cbeb400f7da889a8"",
          ],
          ""tree"": ""e0b8f3574060ee24e03e4af3896f65dd208a60cc"",
        },
        ""oid"": ""e10ebb90d03eaacca84de1af0a59b444232da99e"",
        ""source"": ""objects/e1/0ebb90d03eaacca84de1af0a59b444232da99e"",
        ""type"": ""commit"",
      }
    `)
    expect(ref.format).toEqual('parsed')
    expect(ref.type).toEqual('commit')
  })",snuts
/__tests__/test-readObject.js,AnonymousTest,"{'startLine':81,'endLine':98}","it('content', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'e10ebb90d03eaacca84de1af0a59b444232da99e',
      format: 'content',
    })
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('commit')
    expect(ref.source).toBe('objects/e1/0ebb90d03eaacca84de1af0a59b444232da99e')
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      '""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""'
    )
  })",snuts
/__tests__/test-readObject.js,AnonymousTest,"{'startLine':99,'endLine':116}","it('wrapped', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'e10ebb90d03eaacca84de1af0a59b444232da99e',
      format: 'wrapped',
    })
    expect(ref.format).toEqual('wrapped')
    expect(ref.type).toEqual('wrapped')
    expect(ref.source).toBe('objects/e1/0ebb90d03eaacca84de1af0a59b444232da99e')
    if (ref.format !== 'wrapped') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      '""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""'
    )
  })",snuts
/__tests__/test-readObject.js,AnonymousTest,"{'startLine':117,'endLine':134}","it('deflated', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'e10ebb90d03eaacca84de1af0a59b444232da99e',
      format: 'deflated',
    })
    expect(ref.format).toEqual('deflated')
    expect(ref.type).toEqual('deflated')
    expect(ref.source).toBe('objects/e1/0ebb90d03eaacca84de1af0a59b444232da99e')
    if (ref.format !== 'deflated') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      '""78019d93c9cea3481084e7cc53d4ddea76010586d1cc68001b0cde30fc06ec1b4b4161966237e6e9dbd373ed53e729158a487d522a625a55f9005896e5ff183a8c01869194f2c206411162cc210c798cc294976431158524e1a0148a308e9926ec703d8008a51207c544c6bc2023568c60ca238e97e2084708c274938492248712138e03a11df0f3b204fbbc1c680dfe7a55e4e7f66f568579f93da6d53f8015208724c44108bec1cf05e6a37e1007fc3bd9acc9fa3c03dffe1b75679867601b36704de3ac7cdd9cdd4f9d011eeefa9cd67f02a31e6d034c2c0318905fcd58551455c91443bd5a8f2789a8a2506b67ddadf1e0bbb9180a9e70b3d71f4837c595c5f2b6a306fdc0615590b39e013cb1674ede3a0795e8c354ac467725091cbf26b7b47b7314fb7e22de9d22ae8b79566e835aa78b5798b2923966cc9ebf4e0c2042301c4fd731d294c34bb2fcc99b68b0fb5a5e9e72d956493569c877afda715cd1866271ed6f9ca9e8beb6b0898ad71eed18700a280905b937fdc75a0fe34720aaef7b4bf477915a4729d3f4c9719767deaa66d4db9ba0e54e043d0be5702f8565f6f89101ad567022a9c971b52a5e69508edc3d3106555e954fbe29d833f65b87dfc88bb31064b3509f038b955a778e97a850f4cb9d012215c8265c9fda923db4be2aef74756cb4e6f94eaa46196c2a96ecad47215fe6aa70b4268dc873e670fbc1250e8ae4cd8501b5d90436aab3375ae4dbbb0b82796ef2ebb55e175ebd1e0fd930198d545ff49c5291b5b55c7ef6dcb5bace713faa177c5931609be8ad5070f6e9fc38bef26540b6b43352cfa2767424c9dd46d4cf4fda78f7d65c7a26902ee5ba6537e2dee89732ed0afcf926cf3d60155abc22cca6f384d16672ce7b4f529452de124cf963df3c319d6c2e7fc7da5eb7219fb98d76488e8eea68e88b01010b5555df4a35d54e813547428beb2e5de183934809ca36d610bf97d6cb0af52a4a8669480879bea3d2f2b2cc487d0b0c8895f0b576efe6c3e01dda2931cbe68f4d3f85f0a99b2e7e56bbc5c4d1a8117749fc0b77b9f88e379d12f27ebcb6c75ba6440cb8e633e1a2cace3a9ec8f5dc72dbaa66c0df68b53d33ffd76477defeaa248c59351d9d30e8704fcb093b3805030524ac9312838a761814799df480a61f4bda7f074a928001f743cffc00fa8263c9""'
    )
  })",snuts
/__tests__/test-readObject.js,ComplexSnapshots,"{'startLine':302,'endLine':413}","it('with simple filepath to tree', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'be1e63da44b26de8877a184359abace1cddcb739',
      format: 'parsed',
      filepath: '',
    })
    expect(ref.format).toEqual('parsed')
    expect(ref.type).toEqual('tree')
    expect(ref.source).toBe(
      'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
    )
    expect(ref.oid).toEqual('6257985e3378ec42a03a57a7dc8eb952d69a5ff3')
    expect(ref.object).toMatchInlineSnapshot(`
      Array [
        Object {
          ""mode"": ""100644"",
          ""oid"": ""375f9392774e7a7c8a1ae23a6d13b5c133e42c45"",
          ""path"": "".babelrc"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""bbf3e21f43fa4fe25eb925bfcb7c0434f7c2dc7d"",
          ""path"": "".editorconfig"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""4a58bdcdef3eb91264dfca0279959d98c16568d5"",
          ""path"": "".flowconfig"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""2b90c4a2353d2977e158c21f4315664063770212"",
          ""path"": "".gitignore"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""63ed03aea9d828c86ebde989b336f5e978fdc3f1"",
          ""path"": "".travis.yml"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""c675a17ccb1578bca836decf90205fdad743827d"",
          ""path"": ""LICENSE.md"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""9761716146bbdb47f8a7de3d9df98777df9674f3"",
          ""path"": ""README.md"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""63a8130fa218d20b0009c1126375a105c1adba8a"",
          ""path"": ""__tests__"",
          ""type"": ""tree"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""bdc76cc9d0da964db203f47333d05185a22d6a18"",
          ""path"": ""ci.karma.conf.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""4551a1856279dde6ae9d65862a1dff59a5f199d8"",
          ""path"": ""cli.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""69be3467cb125fbc55eb5c7e50caa556fb0e34b4"",
          ""path"": ""dist"",
          ""type"": ""tree"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""af56d48cb8af9c5ba3547c12c4a4a61fc16ff971"",
          ""path"": ""karma.conf.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""00b91c8b8ddfb43df70ef334088b7d840e5053db"",
          ""path"": ""package-lock.json"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""7b12188e7e351c1a761b76b38e36c13b5cba6c1f"",
          ""path"": ""package-scripts.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""bfe174beb9bf440c1c49b6fba0094f16cf9c9490"",
          ""path"": ""package.json"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""a86d1a6c3997dc73e8bf8687edb15fc087892e9d"",
          ""path"": ""rollup.config.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""ae7b4f3ac2c570dc3597124fc108ecb9d6c2b4fd"",
          ""path"": ""src"",
          ""type"": ""tree"",
        },
        Object {
          ""mode"": ""040000"",
          ""oid"": ""0a7ce5f20a8ccba18463a2ae990baf63ba1e3b43"",
          ""path"": ""testling"",
          ""type"": ""tree"",
        },
      ]
    `)
  })",snuts
/__tests__/test-readObject.js,ComplexSnapshots,"{'startLine':429,'endLine':546}","it('with deep filepath to tree', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'be1e63da44b26de8877a184359abace1cddcb739',
      format: 'parsed',
      filepath: 'src/commands',
    })
    expect(ref.format).toEqual('parsed')
    expect(ref.type).toEqual('tree')
    expect(ref.oid).toEqual('7704a6e8a802efcdbe6cf3dfa114c105f1d5c67a')
    expect(ref.object).toMatchInlineSnapshot(`
      Array [
        Object {
          ""mode"": ""100644"",
          ""oid"": ""c0c25b4e4c418eff366132e6cb2b16c8d9a7798c"",
          ""path"": ""add.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""85cd837ae2a5577a6247937cb1e0404a0101705b"",
          ""path"": ""checkout.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""5264f23285d8be3ce45f95c102001ffa1d5391d3"",
          ""path"": ""clone.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""1ac40ceb71b7fd182808decfd14d644d65887d52"",
          ""path"": ""commit.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""9d9432818d654e7884b41223f7ae8ef4defec959"",
          ""path"": ""config.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""1c473b86b3e693e34363b4be9cdcd0c50e0bfed4"",
          ""path"": ""fetch.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""de854e230503c548d530a71442ba0d03824eefbb"",
          ""path"": ""findRoot.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""f309f5b14fc9897a3816547d0129f117788ffef1"",
          ""path"": ""init.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""9184088c0d0b75dba8108433f8d26fece09c36dc"",
          ""path"": ""list.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""1f67512a0eb40a8a955ad3ca56dfcd4231a935f9"",
          ""path"": ""listBranches.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""d740a56e95cada64654c6e9e52616cc3318be4cb"",
          ""path"": ""log.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""600a1006b12f2c7244fc034d8c64ad21c9597237"",
          ""path"": ""pack.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""9b3a67837dcabde4eee4862d6ad78b3ebf68915e"",
          ""path"": ""push.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""46e96d7d5b4cb91210ce169824feda77c3bd6cc3"",
          ""path"": ""remove.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""3a3ea110eb4967ca7e9d3eef41b073e779c329d1"",
          ""path"": ""resolveRef.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""f913d87e7844579afbe02fe116c88a6b51bf1bca"",
          ""path"": ""status.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""67e79f9e10d44eb692be57e746639b9f2b54e816"",
          ""path"": ""unpack.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""007e7738d257fe78da6938990a40e4310dfc0757"",
          ""path"": ""verify.js"",
          ""type"": ""blob"",
        },
        Object {
          ""mode"": ""100644"",
          ""oid"": ""9584ccddb392f8185101dca41496fba0fd264d6a"",
          ""path"": ""version.js"",
          ""type"": ""blob"",
        },
      ]
    `)
  })",snuts
/__tests__/test-readObject.js,ConditionalTestLogic,"{'startLine':94,'endLine':94}","it('content', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'e10ebb90d03eaacca84de1af0a59b444232da99e',
      format: 'content',
    })
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('commit')
    expect(ref.source).toBe('objects/e1/0ebb90d03eaacca84de1af0a59b444232da99e')
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      '""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""'
    )
  })",snuts
/__tests__/test-readObject.js,ConditionalTestLogic,"{'startLine':112,'endLine':112}","it('wrapped', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'e10ebb90d03eaacca84de1af0a59b444232da99e',
      format: 'wrapped',
    })
    expect(ref.format).toEqual('wrapped')
    expect(ref.type).toEqual('wrapped')
    expect(ref.source).toBe('objects/e1/0ebb90d03eaacca84de1af0a59b444232da99e')
    if (ref.format !== 'wrapped') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      '""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""'
    )
  })",snuts
/__tests__/test-readObject.js,ConditionalTestLogic,"{'startLine':130,'endLine':130}","it('deflated', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'e10ebb90d03eaacca84de1af0a59b444232da99e',
      format: 'deflated',
    })
    expect(ref.format).toEqual('deflated')
    expect(ref.type).toEqual('deflated')
    expect(ref.source).toBe('objects/e1/0ebb90d03eaacca84de1af0a59b444232da99e')
    if (ref.format !== 'deflated') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      '""78019d93c9cea3481084e7cc53d4ddea76010586d1cc68001b0cde30fc06ec1b4b4161966237e6e9dbd373ed53e729158a487d522a625a55f9005896e5ff183a8c01869194f2c206411162cc210c798cc294976431158524e1a0148a308e9926ec703d8008a51207c544c6bc2023568c60ca238e97e2084708c274938492248712138e03a11df0f3b204fbbc1c680dfe7a55e4e7f66f568579f93da6d53f8015208724c44108bec1cf05e6a37e1007fc3bd9acc9fa3c03dffe1b75679867601b36704de3ac7cdd9cdd4f9d011eeefa9cd67f02a31e6d034c2c0318905fcd58551455c91443bd5a8f2789a8a2506b67ddadf1e0bbb9180a9e70b3d71f4837c595c5f2b6a306fdc0615590b39e013cb1674ede3a0795e8c354ac467725091cbf26b7b47b7314fb7e22de9d22ae8b79566e835aa78b5798b2923966cc9ebf4e0c2042301c4fd731d294c34bb2fcc99b68b0fb5a5e9e72d956493569c877afda715cd1866271ed6f9ca9e8beb6b0898ad71eed18700a280905b937fdc75a0fe34720aaef7b4bf477915a4729d3f4c9719767deaa66d4db9ba0e54e043d0be5702f8565f6f89101ad567022a9c971b52a5e69508edc3d3106555e954fbe29d833f65b87dfc88bb31064b3509f038b955a778e97a850f4cb9d012215c8265c9fda923db4be2aef74756cb4e6f94eaa46196c2a96ecad47215fe6aa70b4268dc873e670fbc1250e8ae4cd8501b5d90436aab3375ae4dbbb0b82796ef2ebb55e175ebd1e0fd930198d545ff49c5291b5b55c7ef6dcb5bace713faa177c5931609be8ad5070f6e9fc38bef26540b6b43352cfa2767424c9dd46d4cf4fda78f7d65c7a26902ee5ba6537e2dee89732ed0afcf926cf3d60155abc22cca6f384d16672ce7b4f529452de124cf963df3c319d6c2e7fc7da5eb7219fb98d76488e8eea68e88b01010b5555df4a35d54e813547428beb2e5de183934809ca36d610bf97d6cb0af52a4a8669480879bea3d2f2b2cc487d0b0c8895f0b576efe6c3e01dda2931cbe68f4d3f85f0a99b2e7e56bbc5c4d1a8117749fc0b77b9f88e379d12f27ebcb6c75ba6440cb8e633e1a2cace3a9ec8f5dc72dbaa66c0df68b53d33ffd76477defeaa248c59351d9d30e8704fcb093b3805030524ac9312838a761814799df480a61f4bda7f074a928001f743cffc00fa8263c9""'
    )
  })",snuts
/__tests__/test-readObject.js,ConditionalTestLogic,"{'startLine':151,'endLine':151}","it('from packfile deflated', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: '0b8faa11b353db846b40eb064dfb299816542a46',
      format: 'deflated',
    })
    // packed objects will always be returned as 'content' format
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('commit')
    expect(ref.source).toBe(
      'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
    )
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      `""7472656520346431363665323666636639666537623231383633343336313337633434613339613231613930660a706172656e7420666264353662343964343030613139656531383561653733353431376264623334633038343632310a617574686f722057696c6c69616d2048696c746f6e203c776d68696c746f6e40676d61696c2e636f6d3e2031353038323034303133202d303430300a636f6d6d69747465722057696c6c69616d2048696c746f6e203c776d68696c746f6e40676d61696c2e636f6d3e2031353038323034303133202d303430300a0a696e646578206f6e206d61737465723a2066626435366234204164642027756e706b6727206b657920746f207061636b6167652e6a736f6e0a""`
    )
  })",snuts
/__tests__/test-readObject.js,ConditionalTestLogic,"{'startLine':172,'endLine':172}","it('from packfile wrapped', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: '0b8faa11b353db846b40eb064dfb299816542a46',
      format: 'wrapped',
    })
    // packed objects will always be returned as 'content' format
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('commit')
    expect(ref.source).toBe(
      'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
    )
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      `""7472656520346431363665323666636639666537623231383633343336313337633434613339613231613930660a706172656e7420666264353662343964343030613139656531383561653733353431376264623334633038343632310a617574686f722057696c6c69616d2048696c746f6e203c776d68696c746f6e40676d61696c2e636f6d3e2031353038323034303133202d303430300a636f6d6d69747465722057696c6c69616d2048696c746f6e203c776d68696c746f6e40676d61696c2e636f6d3e2031353038323034303133202d303430300a0a696e646578206f6e206d61737465723a2066626435366234204164642027756e706b6727206b657920746f207061636b6167652e6a736f6e0a""`
    )
  })",snuts
/__tests__/test-readObject.js,ConditionalTestLogic,"{'startLine':192,'endLine':192}","it('from packfile content', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: '0b8faa11b353db846b40eb064dfb299816542a46',
      format: 'content',
    })
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('commit')
    expect(ref.source).toBe(
      'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
    )
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      `""7472656520346431363665323666636639666537623231383633343336313337633434613339613231613930660a706172656e7420666264353662343964343030613139656531383561653733353431376264623334633038343632310a617574686f722057696c6c69616d2048696c746f6e203c776d68696c746f6e40676d61696c2e636f6d3e2031353038323034303133202d303430300a636f6d6d69747465722057696c6c69616d2048696c746f6e203c776d68696c746f6e40676d61696c2e636f6d3e2031353038323034303133202d303430300a0a696e646578206f6e206d61737465723a2066626435366234204164642027756e706b6727206b657920746f207061636b6167652e6a736f6e0a""`
    )
  })",snuts
/__tests__/test-readObject.js,ConditionalTestLogic,"{'startLine':261,'endLine':261}","it('with simple filepath to blob', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'be1e63da44b26de8877a184359abace1cddcb739',
      format: 'parsed',
      filepath: 'cli.js',
    })
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('blob')
    expect(ref.source).toBe(
      'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
    )
    expect(ref.oid).toEqual('4551a1856279dde6ae9d65862a1dff59a5f199d8')
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      '""23212f7573722f62696e2f656e76206e6f64650a636f6e7374206d696e696d6973746564203d207265717569726528276d696e696d697374656427290a636f6e737420676974203d207265717569726528272e27290a0a2f2f2054686973207265616c6c792069736e2774206d756368206f66206120434c492e2049742773206d6f73746c7920666f722074657374696e672e0a2f2f204275742069742773207665727920766572736174696c6520616e6420776f726b732073757270726973696e676c792077656c6c2e0a0a6d696e696d6973746564286173796e632066756e6374696f6e20287b205f3a205b636f6d6d616e642c202e2e2e617267735d2c202e2e2e6f707473207d29207b0a2020636f6e737420646972203d2070726f636573732e63776428290a2020636f6e7374207265706f203d2067697428646972290a20206c657420636d64203d20606769742827247b6469727d2729600a2020666f7220286c6574206b6579206f66204f626a6563742e6b657973286f7074732929207b0a202020202f2f205468697320697320686f7720796f7520636865636b20666f7220616e2061727261792c2072696768743f0a20202020696620286f7074735b6b65795d2e6c656e677468203d3d3d20756e646566696e656429207b0a2020202020207265706f5b6b65795d286f7074735b6b65795d290a202020202020636d64202b3d20602e247b6b65797d2827247b6f7074735b6b65795d7d2729600a202020207d20656c7365207b0a2020202020207265706f5b6b65795d282e2e2e6f7074735b6b65795d290a202020202020636d64202b3d20602e247b6b65797d28247b6f7074735b6b65795d2e6d61702878203d3e206027247b787d2760292e6a6f696e28272c2027297d29600a202020207d0a20207d0a2020636d64202b3d20602e247b636f6d6d616e647d28247b617267732e6d61702878203d3e206027247b787d2760292e6a6f696e28272c2027297d29600a2020636f6e736f6c652e6c6f6728636d64290a20206c657420726573756c74203d206177616974207265706f5b636f6d6d616e645d282e2e2e61726773290a202069662028726573756c74203d3d3d20756e646566696e6564292072657475726e0a2020636f6e736f6c652e6c6f67284a534f4e2e737472696e6769667928726573756c742c206e756c6c2c203229290a7d290a""'
    )
  })",snuts
/__tests__/test-readObject.js,ConditionalTestLogic,"{'startLine':280,'endLine':280}","it('with deep filepath to blob', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'be1e63da44b26de8877a184359abace1cddcb739',
      format: 'parsed',
      filepath: 'src/commands/clone.js',
    })
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('blob')
    expect(ref.oid).toEqual('5264f23285d8be3ce45f95c102001ffa1d5391d3')
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      '""696d706f7274207b20696e6974207d2066726f6d20272e2f696e6974270a696d706f7274207b20636f6e666967207d2066726f6d20272e2f636f6e666967270a696d706f7274207b206665746368207d2066726f6d20272e2f6665746368270a696d706f7274207b20636865636b6f7574207d2066726f6d20272e2f636865636b6f7574270a0a6578706f7274206173796e632066756e6374696f6e20636c6f6e6520287b0a2020776f726b6469722c0a20206769746469722c0a202075726c2c0a202072656d6f74652c0a20207265662c0a202061757468557365726e616d652c0a20206175746850617373776f72642c0a202064657074682c0a202073696e63652c0a20206578636c7564652c0a202072656c61746976652c0a20206f6e70726f67726573730a7d29207b0a202072656d6f7465203d2072656d6f7465207c7c20276f726967696e270a2020617761697420696e6974287b20676974646972207d290a20202f2f204164642072656d6f74650a2020617761697420636f6e666967287b0a202020206769746469722c0a20202020706174683a206072656d6f74652e247b72656d6f74657d2e75726c602c0a2020202076616c75653a2075726c0a20207d290a20202f2f20466574636820636f6d6d6974730a20206177616974206665746368287b0a202020206769746469722c0a202020207265662c0a2020202072656d6f74652c0a2020202061757468557365726e616d652c0a202020206175746850617373776f72642c0a2020202064657074682c0a2020202073696e63652c0a202020206578636c7564652c0a2020202072656c61746976652c0a202020206f6e70726f67726573730a20207d290a20202f2f20436865636b6f7574206272616e63680a2020617761697420636865636b6f7574287b0a20202020776f726b6469722c0a202020206769746469722c0a202020207265662c0a2020202072656d6f74650a20207d290a7d0a""'
    )
  })",snuts
/__tests__/test-readObject.js,SubOptimalAssert,"{'startLine':22,'endLine':22}","it('test missing', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    let error = null
    try {
      await readObject({
        fs,
        gitdir,
        oid: 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",snuts
/__tests__/test-readObject.js,SubOptimalAssert,"{'startLine':565,'endLine':565}","it('with erroneous filepath (directory is a file)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    let error = null
    try {
      await readObject({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        format: 'parsed',
        filepath: 'src/commands/clone.js/isntafolder.txt',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.ObjectTypeError).toBe(true)
  })",snuts
/__tests__/test-readObject.js,SubOptimalAssert,"{'startLine':584,'endLine':584}","it('with erroneous filepath (no such directory)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    let error = null
    try {
      await readObject({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        format: 'parsed',
        filepath: 'src/isntafolder',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",snuts
/__tests__/test-readObject.js,SubOptimalAssert,"{'startLine':603,'endLine':603}","it('with erroneous filepath (leading slash)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    let error = null
    try {
      await readObject({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        format: 'parsed',
        filepath: '/src',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidFilepathError).toBe(true)
    expect(error.data.reason).toBe('leading-slash')
  })",snuts
/__tests__/test-readObject.js,SubOptimalAssert,"{'startLine':623,'endLine':623}","it('with erroneous filepath (trailing slash)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    let error = null
    try {
      await readObject({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        format: 'parsed',
        filepath: 'src/',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidFilepathError).toBe(true)
    expect(error.data.reason).toBe('trailing-slash')
  })",snuts
/__tests__/test-readCommit.js,AnonymousTest,"{'startLine':7,'endLine':23}","it('test missing', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readCommit')
    // Test
    let error = null
    try {
      await readCommit({
        fs,
        gitdir,
        oid: 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",snuts
/__tests__/test-readCommit.js,AnonymousTest,"{'startLine':24,'endLine':82}","it('parsed', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readCommit')
    // Test
    const result = await readCommit({
      fs,
      gitdir,
      oid: 'e10ebb90d03eaacca84de1af0a59b444232da99e',
    })
    expect(result).toMatchInlineSnapshot(`
      Object {
        ""commit"": Object {
          ""author"": Object {
            ""email"": ""wmhilton@gmail.com"",
            ""name"": ""Will Hilton"",
            ""timestamp"": 1502484200,
            ""timezoneOffset"": 240,
          },
          ""committer"": Object {
            ""email"": ""wmhilton@gmail.com"",
            ""name"": ""Will Hilton"",
            ""timestamp"": 1502484200,
            ""timezoneOffset"": 240,
          },
          ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZjhboAAoJEJYJuKWSi6a5V5UP/040SfemJ13PRBXst2eB59gs
      3hPx29DRKBhFtvk+uS+8523/hUfry2oeWWd6YRkcnkxxAUtBnfzVkI9AgRIc1NTM
      h5XtLMQubCAKw8JWvVvoXETzwVAODmdmvC4WSQCLu+opoe6/W7RvkrTD0pbkwH4E
      MXoha59sIWZ/FacZX6ByYqhFykfJL8gCFvRSzjiqBIbsP7Xq2Mh4jkAKYl5zxV3u
      qCk26hnhL++kwfXlu2YdGtB9+lj3pk1NeWqR379zRzh4P10FxXJ18qSxczbkAFOY
      6o5h7a/Mql1KqWB9EFBupCpjydmpAtPo6l1Us4a3liB5LJvCh9xgR2HtShR4b97O
      nIpXP4ngy4z9UyrXXxxpiQQn/kVn/uKgtvGp8nOFioo61PCi9js2QmQxcsuBOeO+
      DdFq5k2PMNZLwizt4P8EGfVJoPbLhdYP4oWiMCuYV/2fNh0ozl/q176HGszlfrke
      332Z0maJ3A5xIRj0b7vRNHV8AAl9Dheo3LspjeovP2iycCHFP03gSpCKdLRBRC4T
      X10BBFD8noCMXJxb5qenrf+eKRd8d4g7JtcyzqVgkBQ68GIG844VWRBolOzx4By5
      cAaw/SYIZG3RorAc11iZ7sva0jFISejmEzIebuChSzdWO2OOWRVvMdhyZwDLUgAb
      Qixh2bmPgr3h9nxq2Dmn
      =4+DN
      -----END PGP SIGNATURE-----"",
          ""message"": ""Improve resolveRef to handle more kinds of refs. Add tests
      "",
          ""parent"": Array [
            ""b4f8206d9e359416b0f34238cbeb400f7da889a8"",
          ],
          ""tree"": ""e0b8f3574060ee24e03e4af3896f65dd208a60cc"",
        },
        ""oid"": ""e10ebb90d03eaacca84de1af0a59b444232da99e"",
        ""payload"": ""tree e0b8f3574060ee24e03e4af3896f65dd208a60cc
      parent b4f8206d9e359416b0f34238cbeb400f7da889a8
      author Will Hilton <wmhilton@gmail.com> 1502484200 -0400
      committer Will Hilton <wmhilton@gmail.com> 1502484200 -0400
      
      Improve resolveRef to handle more kinds of refs. Add tests
      "",
      }
    `)
  })",snuts
/__tests__/test-readCommit.js,AnonymousTest,"{'startLine':83,'endLine':124}","it('from packfile', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readCommit')
    // Test
    const result = await readCommit({
      fs,
      gitdir,
      oid: '0b8faa11b353db846b40eb064dfb299816542a46',
    })
    expect(result).toMatchInlineSnapshot(`
      Object {
        ""commit"": Object {
          ""author"": Object {
            ""email"": ""wmhilton@gmail.com"",
            ""name"": ""William Hilton"",
            ""timestamp"": 1508204013,
            ""timezoneOffset"": 240,
          },
          ""committer"": Object {
            ""email"": ""wmhilton@gmail.com"",
            ""name"": ""William Hilton"",
            ""timestamp"": 1508204013,
            ""timezoneOffset"": 240,
          },
          ""message"": ""index on master: fbd56b4 Add 'unpkg' key to package.json
      "",
          ""parent"": Array [
            ""fbd56b49d400a19ee185ae735417bdb34c084621"",
          ],
          ""tree"": ""4d166e26fcf9fe7b21863436137c44a39a21a90f"",
        },
        ""oid"": ""0b8faa11b353db846b40eb064dfb299816542a46"",
        ""payload"": ""tree 4d166e26fcf9fe7b21863436137c44a39a21a90f
      parent fbd56b49d400a19ee185ae735417bdb34c084621
      author William Hilton <wmhilton@gmail.com> 1508204013 -0400
      committer William Hilton <wmhilton@gmail.com> 1508204013 -0400
      
      index on master: fbd56b4 Add 'unpkg' key to package.json
      "",
      }
    `)
  })",snuts
/__tests__/test-readCommit.js,AnonymousTest,"{'startLine':125,'endLine':135}","it('peels tags', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readCommit')
    // Test
    const result = await readCommit({
      fs,
      gitdir,
      oid: '587d3f8290b513e2ee85ecd317e6efecd545aee6',
    })
    expect(result.oid).toBe('033417ae18b174f078f2f44232cb7a374f4c60ce')
  })",snuts
/__tests__/test-readCommit.js,SubOptimalAssert,"{'startLine':22,'endLine':22}","it('test missing', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readCommit')
    // Test
    let error = null
    try {
      await readCommit({
        fs,
        gitdir,
        oid: 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",snuts
/__tests__/test-readBlob.js,AnonymousTest,"{'startLine':7,'endLine':23}","it('test missing', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readBlob')
    // Test
    let error = null
    try {
      await readBlob({
        fs,
        gitdir,
        oid: 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",snuts
/__tests__/test-readBlob.js,AnonymousTest,"{'startLine':24,'endLine':63}","it('blob', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readBlob')
    // Test
    const { blob } = await readBlob({
      fs,
      gitdir,
      oid: '4551a1856279dde6ae9d65862a1dff59a5f199d8',
    })
    expect(Buffer.from(blob).toString('utf8')).toMatchInlineSnapshot(`
      ""#!/usr/bin/env node
      const minimisted = require('minimisted')
      const git = require('.')
      
      // This really isn't much of a CLI. It's mostly for testing.
      // But it's very versatile and works surprisingly well.
      
      minimisted(async function ({ _: [command, ...args], ...opts }) {
        const dir = process.cwd()
        const repo = git(dir)
        let cmd = \`git('\${dir}')\`
        for (let key of Object.keys(opts)) {
          // This is how you check for an array, right?
          if (opts[key].length === undefined) {
            repo[key](opts[key])
            cmd += \`.\${key}('\${opts[key]}')\`
          } else {
            repo[key](...opts[key])
            cmd += \`.\${key}(\${opts[key].map(x => \`'\${x}'\`).join(', ')})\`
          }
        }
        cmd += \`.\${command}(\${args.map(x => \`'\${x}'\`).join(', ')})\`
        console.log(cmd)
        let result = await repo[command](...args)
        if (result === undefined) return
        console.log(JSON.stringify(result, null, 2))
      })
      ""
    `)
  })",snuts
/__tests__/test-readBlob.js,AnonymousTest,"{'startLine':64,'endLine':74}","it('peels tags', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readBlob')
    // Test
    const { oid } = await readBlob({
      fs,
      gitdir,
      oid: 'cdf8e34555b62edbbe978f20d7b4796cff781f9d',
    })
    expect(oid).toBe('4551a1856279dde6ae9d65862a1dff59a5f199d8')
  })",snuts
/__tests__/test-readBlob.js,SubOptimalAssert,"{'startLine':22,'endLine':22}","it('test missing', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readBlob')
    // Test
    let error = null
    try {
      await readBlob({
        fs,
        gitdir,
        oid: 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",snuts
/__tests__/test-readBlob.js,SubOptimalAssert,"{'startLine':121,'endLine':121}","it('with simple filepath to tree', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readBlob')
    // Test
    let error = null
    try {
      await readBlob({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        filepath: '',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.ObjectTypeError).toBe(true)
  })",snuts
/__tests__/test-readBlob.js,SubOptimalAssert,"{'startLine':139,'endLine':139}","it('with erroneous filepath (directory is a file)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readBlob')
    // Test
    let error = null
    try {
      await readBlob({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        filepath: 'src/commands/clone.js/isntafolder.txt',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.ObjectTypeError).toBe(true)
  })",snuts
/__tests__/test-readBlob.js,SubOptimalAssert,"{'startLine':157,'endLine':157}","it('with erroneous filepath (no such directory)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readBlob')
    // Test
    let error = null
    try {
      await readBlob({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        filepath: 'src/isntafolder',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",snuts
/__tests__/test-readBlob.js,SubOptimalAssert,"{'startLine':175,'endLine':175}","it('with erroneous filepath (leading slash)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readBlob')
    // Test
    let error = null
    try {
      await readBlob({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        filepath: '/src',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidFilepathError).toBe(true)
    expect(error.data.reason).toBe('leading-slash')
  })",snuts
/__tests__/test-readBlob.js,SubOptimalAssert,"{'startLine':194,'endLine':194}","it('with erroneous filepath (trailing slash)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readBlob')
    // Test
    let error = null
    try {
      await readBlob({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        filepath: 'src/',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidFilepathError).toBe(true)
    expect(error.data.reason).toBe('trailing-slash')
  })",snuts
/__tests__/test-push.js,AnonymousTest,"{'startLine':20,'endLine':89}","it('push', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-push')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.karma.url',
      value: `http://${localhost}:8888/test-push-server.git`,
    })
    const output = []
    const onPrePush = []
    // Test
    const res = await push({
      fs,
      http,
      gitdir,
      onMessage: async m => {
        output.push(m)
      },
      remote: 'karma',
      ref: 'refs/heads/master',
      onPrePush: args => {
        onPrePush.push(args)
        return true
      },
    })
    expect(res).toBeTruthy()
    expect(res.ok).toBe(true)
    expect(res.refs['refs/heads/master'].ok).toBe(true)
    expect(output).toMatchInlineSnapshot(`
      Array [
        ""build started...
      "",
        ""build completed...
      "",
        ""tests started...
      "",
        ""tests completed...
      "",
        ""starting server...
      "",
        ""server running
      "",
        ""Here is a message from 'post-receive' hook.
      "",
      ]
    `)
    expect(onPrePush).toEqual([
      {
        localRef: {
          oid: 'c03e131196f43a78888415924bcdcbf3090f3316',
          ref: 'refs/heads/master',
        },
        remote: 'karma',
        remoteRef: {
          oid: '5a8905a02e181fe1821068b8c0f48cb6633d5b81',
          ref: 'refs/heads/master',
        },
        url: `http://${localhost}:8888/test-push-server.git`,
      },
    ])

    // Test that remote ref is updated
    expect(
      await resolveRef({ fs, gitdir, ref: 'refs/remotes/karma/master' })
    ).toEqual(await resolveRef({ fs, gitdir, ref: 'refs/heads/master' }))
    expect(
      await resolveRef({ fs, gitdir, ref: 'refs/remotes/karma/master' })
    ).toEqual('c03e131196f43a78888415924bcdcbf3090f3316')
  })",snuts
/__tests__/test-push.js,AnonymousTest,"{'startLine':90,'endLine':109}","it('push empty', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-fetch-server')
    await clone({
      fs,
      http,
      dir,
      gitdir,
      url: `http://${localhost}:8888/test-fetch-server.git`,
    })
    // Test
    const res = await push({
      fs,
      http,
      gitdir,
    })
    expect(res).toBeTruthy()
    expect(res.ok).toBe(true)
    expect(res.refs['refs/heads/master'].ok).toBe(true)
  })",snuts
/__tests__/test-push.js,AnonymousTest,"{'startLine':243,'endLine':297}","it('push delete', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-push')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.karma.url',
      value: `http://${localhost}:8888/test-push-server.git`,
    })
    await push({
      fs,
      http,
      gitdir,
      remote: 'karma',
      ref: 'master',
      remoteRef: 'foobar',
    })
    expect(await listBranches({ fs, gitdir, remote: 'karma' })).toContain(
      'foobar'
    )
    // Test
    const onPrePush = []
    const res = await push({
      fs,
      http,
      gitdir,
      remote: 'karma',
      remoteRef: 'foobar',
      delete: true,
      onPrePush: args => {
        onPrePush.push(args)
        return true
      },
    })
    expect(res).toBeTruthy()
    expect(res.ok).toBe(true)
    expect(res.refs['refs/heads/foobar'].ok).toBe(true)
    expect(await listBranches({ fs, gitdir, remote: 'karma' })).not.toContain(
      'foobar'
    )
    expect(onPrePush).toEqual([
      {
        localRef: {
          oid: '0000000000000000000000000000000000000000',
          ref: '(delete)',
        },
        remote: 'karma',
        remoteRef: {
          oid: '0000000000000000000000000000000000000000', // This is OK: mock server threw away information about newly created branch
          ref: 'refs/heads/foobar',
        },
        url: `http://${localhost}:8888/test-push-server.git`,
      },
    ])
  })",snuts
/__tests__/test-push.js,AnonymousTest,"{'startLine':417,'endLine':468}","it('onAuthSuccess', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-push')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.auth.url',
      value: `http://${localhost}:8888/test-push-server-auth.git`,
    })
    // Test
    const onAuthArgs = []
    const onAuthSuccessArgs = []
    const onAuthFailureArgs = []
    await push({
      fs,
      http,
      gitdir,
      remote: 'auth',
      ref: 'master',
      async onAuth(...args) {
        onAuthArgs.push(args)
        return {
          username: 'testuser',
          password: 'testpassword',
        }
      },
      async onAuthSuccess(...args) {
        onAuthSuccessArgs.push(args)
      },
      async onAuthFailure(...args) {
        onAuthFailureArgs.push(args)
      },
    })
    expect(onAuthArgs).toEqual([
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          headers: {},
        },
      ],
    ])
    expect(onAuthSuccessArgs).toEqual([
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          username: 'testuser',
          password: 'testpassword',
        },
      ],
    ])
    expect(onAuthFailureArgs).toEqual([])
  })",snuts
/__tests__/test-push.js,AnonymousTest,"{'startLine':470,'endLine':565}","it('onAuthFailure', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-push')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.auth.url',
      value: `http://${localhost}:8888/test-push-server-auth.git`,
    })
    // Test
    let err
    const onAuthArgs = []
    const onAuthSuccessArgs = []
    const onAuthFailureArgs = []
    try {
      await push({
        fs,
        http,
        gitdir,
        remote: 'auth',
        ref: 'master',
        async onAuth(...args) {
          onAuthArgs.push(args)
          return {
            username: 'testuser',
            password: 'NoT_rIgHt',
          }
        },
        async onAuthSuccess(...args) {
          onAuthSuccessArgs.push(args)
        },
        async onAuthFailure(...args) {
          onAuthFailureArgs.push(args)
          switch (onAuthFailureArgs.length) {
            case 1:
              return {
                username: 'testuser',
                password: 'St1ll_NoT_rIgHt',
              }
            case 2:
              return {
                headers: {
                  Authorization: 'Bearer Big Bear',
                  'X-Authorization': 'supersecret',
                },
              }
          }
        },
      })
    } catch (e) {
      err = e
    }
    expect(err).toBeDefined()
    expect(err.code).toBe(Errors.HttpError.code)
    expect(err.data.response).toBeTruthy()
    expect(onAuthArgs).toEqual([
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          headers: {},
        },
      ],
    ])
    expect(onAuthSuccessArgs).toEqual([])
    expect(onAuthFailureArgs).toEqual([
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          headers: {
            Authorization: 'Basic dGVzdHVzZXI6Tm9UX3JJZ0h0',
          },
          username: 'testuser',
          password: 'NoT_rIgHt',
        },
      ],
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          headers: {
            Authorization: 'Basic dGVzdHVzZXI6U3QxbGxfTm9UX3JJZ0h0',
          },
          username: 'testuser',
          password: 'St1ll_NoT_rIgHt',
        },
      ],
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          headers: {
            Authorization: 'Bearer Big Bear',
            'X-Authorization': 'supersecret',
          },
        },
      ],
    ])
  })",snuts
/__tests__/test-push.js,AnonymousTest,"{'startLine':705,'endLine':733}","it('onPrePush abort', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-fetch-server')
    await clone({
      fs,
      http,
      dir,
      gitdir,
      url: `http://${localhost}:8888/test-fetch-server.git`,
    })
    // Test
    let err
    try {
      await push({
        fs,
        http,
        gitdir,
        onPrePush: args => {
          return false
        },
      })
    } catch (e) {
      err = e
    }

    expect(err).toBeDefined()
    expect(err instanceof Errors.UserCanceledError).toBe(true)
    expect(err.code).toBe('UserCanceledError')
  })",snuts
/__tests__/test-push.js,SubOptimalAssert,"{'startLine':691,'endLine':691}","it('onAuth + cancel', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-push')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.auth.url',
      value: `http://${localhost}:8888/test-push-server-auth.git`,
    })
    // Test
    let err
    const onAuthArgs = []
    const onAuthSuccessArgs = []
    const onAuthFailureArgs = []
    try {
      await push({
        fs,
        http,
        gitdir,
        remote: 'auth',
        ref: 'master',
        async onAuth(...args) {
          onAuthArgs.push(args)
          return {
            cancel: true,
          }
        },
        async onAuthSuccess(...args) {
          onAuthSuccessArgs.push(args)
        },
        async onAuthFailure(...args) {
          onAuthFailureArgs.push(args)
        },
      })
    } catch (e) {
      err = e
    }
    expect(err).toBeDefined()
    expect(err instanceof Errors.UserCanceledError).toBe(true)
    expect(err.code).toBe('UserCanceledError')
    expect(onAuthArgs).toEqual([
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          headers: {},
        },
      ],
    ])
    expect(onAuthSuccessArgs).toEqual([])
    expect(onAuthFailureArgs).toEqual([])
  })",snuts
/__tests__/test-push.js,SubOptimalAssert,"{'startLine':731,'endLine':731}","it('onPrePush abort', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-fetch-server')
    await clone({
      fs,
      http,
      dir,
      gitdir,
      url: `http://${localhost}:8888/test-fetch-server.git`,
    })
    // Test
    let err
    try {
      await push({
        fs,
        http,
        gitdir,
        onPrePush: args => {
          return false
        },
      })
    } catch (e) {
      err = e
    }

    expect(err).toBeDefined()
    expect(err instanceof Errors.UserCanceledError).toBe(true)
    expect(err.code).toBe('UserCanceledError')
  })",snuts
/__tests__/test-pull.js,AnonymousTest,"{'startLine':15,'endLine':49}","it('pull', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-pull')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.origin.url',
      value: `http://${localhost}:8888/test-pull-server.git`,
    })
    // Test
    let logs = await log({ fs, gitdir, dir, ref: 'refs/heads/master' })
    expect(logs.map(({ commit }) => commit.message)).toEqual([
      'Initial commit\n',
    ])
    await pull({
      fs,
      http,
      gitdir,
      dir,
      remote: 'origin',
      ref: 'refs/heads/master',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
    })
    logs = await log({ fs, gitdir, dir, ref: 'refs/heads/master' })
    expect(logs.map(({ commit }) => commit.message)).toEqual([
      'Added c.txt\n',
      'Added b.txt\n',
      'Initial commit\n',
    ])
  })",snuts
/__tests__/test-packObjects.js,AnonymousTest,"{'startLine':36,'endLine':90}","it('save packfile', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-packObjects')
    const oids = [
      '5a9da3272badb2d3c8dbab463aed5741acb15a33',
      '0bfe8fa3764089465235461624f2ede1533e74ec',
      '414a0afa7e20452d90ab52de1c024182531c5c52',
      '97b32c43e96acc7873a1990e409194cb92421522',
      '328e74b65839f7e5a8ae3b54e0b49180a5b7b82b',
      'fdba2ad440c231d15a2179f729b4b50ab5860df2',
      '5171f8a8291d7edc31a6670800d5967cfd6be830',
      '7983b4770a894a068152dfe6f347ea9b5ae561c5',
      'f03ae7b490022507f83729b9227e723ab1587a38',
      'a59efbcd7640e659ec81887a2599711f8d9ef801',
      'e5abf40a5b37382c700f51ac5c2aeefdadb8e184',
      '5477471ab5a6a8f2c217023532475044117a8f2c',
    ]
    const { filename } = await packObjects({
      fs,
      gitdir,
      oids,
      write: true,
    })
    const filepath = `objects/pack/${filename}`
    const cache = {}
    const fixcache = {}
    const fixdir = path.join(dir, 'git')
    const fullpath = path.join(gitdir, filepath)
    expect(await fs.exists(fullpath)).toBe(true)
    const getExternalRefDelta = oid => readObject({ fs, cache, gitdir, oid })
    await indexPack({ fs, dir: gitdir, filepath, gitdir, cache })
    await Promise.all(
      oids.map(async oid => {
        const object = await readObjectPacked({
          fs,
          gitdir,
          oid,
          cache,
          getExternalRefDelta,
        })
        const fixture = await readObjectPacked({
          fs,
          gitdir: fixdir,
          oid,
          getExternalRefDelta,
          cache: fixcache,
        })
        // the packfile can have different source when compression changes
        // There are no guarantee that the compression will always give same result
        delete object.source
        delete fixture.source
        expect(object).toEqual(fixture)
      })
    )
  })",snuts
/__tests__/test-packObjects.js,ConditionalTestLogic,"{'startLine':31,'endLine':31}","it('makes a packfile', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-packObjects')
    const { filename, packfile } = await packObjects({
      fs,
      gitdir,
      oids: [
        '5a9da3272badb2d3c8dbab463aed5741acb15a33',
        '0bfe8fa3764089465235461624f2ede1533e74ec',
        '414a0afa7e20452d90ab52de1c024182531c5c52',
        '97b32c43e96acc7873a1990e409194cb92421522',
        '328e74b65839f7e5a8ae3b54e0b49180a5b7b82b',
        'fdba2ad440c231d15a2179f729b4b50ab5860df2',
        '5171f8a8291d7edc31a6670800d5967cfd6be830',
        '7983b4770a894a068152dfe6f347ea9b5ae561c5',
        'f03ae7b490022507f83729b9227e723ab1587a38',
        'a59efbcd7640e659ec81887a2599711f8d9ef801',
        'e5abf40a5b37382c700f51ac5c2aeefdadb8e184',
        '5477471ab5a6a8f2c217023532475044117a8f2c',
      ],
    })
    if (!packfile) throw new Error('type error')
    expect(await fs.exists(path.join(gitdir, `objects/pack/${filename}`))).toBe(
      false
    )
  })",snuts
/__tests__/test-merge.js,ConditionalTestLogic,"{'startLine':381,'endLine':381}","it(""merge 'delete-first-half' and 'delete-second-half' (dryRun)"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')
    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'delete-first-half-merge-delete-second-half',
      })
    )[0]
    const originalCommit = (
      await log({
        fs,
        gitdir,
        ref: 'delete-first-half',
        depth: 1,
      })
    )[0]
    // Test
    const report = await merge({
      fs,
      gitdir,
      ours: 'delete-first-half',
      theirs: 'delete-second-half',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      dryRun: true,
    })
    expect(report.tree).toBe(commit.commit.tree)
    // make sure branch hasn't been moved
    const notMergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'delete-first-half',
        depth: 1,
      })
    )[0]
    expect(notMergeCommit.oid).toEqual(originalCommit.oid)
    if (!report.oid) throw new Error('type error')
    // make sure no commit object was created
    expect(
      await fs.exists(
        `${gitdir}/objects/${report.oid.slice(0, 2)}/${report.oid.slice(2)}`
      )
    ).toBe(false)
  })",snuts
/__tests__/test-merge.js,ConditionalTestLogic,"{'startLine':434,'endLine':434}","it(""merge 'delete-first-half' and 'delete-second-half' (noUpdateBranch)"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')
    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'delete-first-half-merge-delete-second-half',
      })
    )[0]
    const originalCommit = (
      await log({
        fs,
        gitdir,
        ref: 'delete-first-half',
        depth: 1,
      })
    )[0]
    // Test
    const report = await merge({
      fs,
      gitdir,
      ours: 'delete-first-half',
      theirs: 'delete-second-half',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      noUpdateBranch: true,
    })
    expect(report.tree).toBe(commit.commit.tree)
    // make sure branch hasn't been moved
    const notMergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'delete-first-half',
        depth: 1,
      })
    )[0]
    expect(notMergeCommit.oid).toEqual(originalCommit.oid)
    if (!report.oid) throw new Error('type error')
    // but make sure the commit object exists
    expect(
      await fs.exists(
        `${gitdir}/objects/${report.oid.slice(0, 2)}/${report.oid.slice(2)}`
      )
    ).toBe(true)
  })",snuts
/__tests__/test-merge.js,ConditionalTestLogic,"{'startLine':756,'endLine':758}","it(""merge two branches that modified the same file, custom conflict resolver (prefer our changes)'"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')

    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'a-merge-c-recursive-ours',
      })
    )[0].commit
    // Test
    const report = await merge({
      fs,
      gitdir,
      ours: 'a',
      theirs: 'c',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      mergeDriver: ({ branches, contents }) => {
        const baseContent = contents[0]
        const ourContent = contents[1]
        const theirContent = contents[2]

        const LINEBREAKS = /^.*(\r?\n|$)/gm
        const ours = ourContent.match(LINEBREAKS)
        const base = baseContent.match(LINEBREAKS)
        const theirs = theirContent.match(LINEBREAKS)
        const result = diff3Merge(ours, base, theirs)
        let mergedText = ''
        for (const item of result) {
          if (item.ok) {
            mergedText += item.ok.join('')
          }
          if (item.conflict) {
            mergedText += item.conflict.a.join('')
          }
        }
        return { cleanMerge: true, mergedText }
      },
    })
    const mergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'a',
        depth: 1,
      })
    )[0].commit
    expect(report.tree).toBe(commit.tree)
    expect(mergeCommit.tree).toEqual(commit.tree)
    expect(mergeCommit.message).toEqual(commit.message)
    expect(mergeCommit.parent).toEqual(commit.parent)
  })",snuts
/__tests__/test-merge.js,ConditionalTestLogic,"{'startLine':759,'endLine':761}","it(""merge two branches that modified the same file, custom conflict resolver (prefer our changes)'"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')

    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'a-merge-c-recursive-ours',
      })
    )[0].commit
    // Test
    const report = await merge({
      fs,
      gitdir,
      ours: 'a',
      theirs: 'c',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      mergeDriver: ({ branches, contents }) => {
        const baseContent = contents[0]
        const ourContent = contents[1]
        const theirContent = contents[2]

        const LINEBREAKS = /^.*(\r?\n|$)/gm
        const ours = ourContent.match(LINEBREAKS)
        const base = baseContent.match(LINEBREAKS)
        const theirs = theirContent.match(LINEBREAKS)
        const result = diff3Merge(ours, base, theirs)
        let mergedText = ''
        for (const item of result) {
          if (item.ok) {
            mergedText += item.ok.join('')
          }
          if (item.conflict) {
            mergedText += item.conflict.a.join('')
          }
        }
        return { cleanMerge: true, mergedText }
      },
    })
    const mergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'a',
        depth: 1,
      })
    )[0].commit
    expect(report.tree).toBe(commit.tree)
    expect(mergeCommit.tree).toEqual(commit.tree)
    expect(mergeCommit.message).toEqual(commit.message)
    expect(mergeCommit.parent).toEqual(commit.parent)
  })",snuts
/__tests__/test-merge.js,ConditionalTestLogic,"{'startLine':815,'endLine':817}","it(""merge two branches that modified the same file, custom conflict resolver (prefer their changes)'"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')

    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'a-merge-c-recursive-theirs',
      })
    )[0].commit
    // Test
    const report = await merge({
      fs,
      gitdir,
      ours: 'a',
      theirs: 'c',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      mergeDriver: ({ branches, contents }) => {
        const baseContent = contents[0]
        const ourContent = contents[1]
        const theirContent = contents[2]

        const LINEBREAKS = /^.*(\r?\n|$)/gm
        const ours = ourContent.match(LINEBREAKS)
        const base = baseContent.match(LINEBREAKS)
        const theirs = theirContent.match(LINEBREAKS)
        const result = diff3Merge(ours, base, theirs)
        let mergedText = ''
        for (const item of result) {
          if (item.ok) {
            mergedText += item.ok.join('')
          }
          if (item.conflict) {
            mergedText += item.conflict.b.join('')
          }
        }
        return { cleanMerge: true, mergedText }
      },
    })
    const mergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'a',
        depth: 1,
      })
    )[0].commit
    expect(report.tree).toBe(commit.tree)
    expect(mergeCommit.tree).toEqual(commit.tree)
    expect(mergeCommit.message).toEqual(commit.message)
    expect(mergeCommit.parent).toEqual(commit.parent)
  })",snuts
/__tests__/test-merge.js,ConditionalTestLogic,"{'startLine':818,'endLine':820}","it(""merge two branches that modified the same file, custom conflict resolver (prefer their changes)'"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')

    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'a-merge-c-recursive-theirs',
      })
    )[0].commit
    // Test
    const report = await merge({
      fs,
      gitdir,
      ours: 'a',
      theirs: 'c',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      mergeDriver: ({ branches, contents }) => {
        const baseContent = contents[0]
        const ourContent = contents[1]
        const theirContent = contents[2]

        const LINEBREAKS = /^.*(\r?\n|$)/gm
        const ours = ourContent.match(LINEBREAKS)
        const base = baseContent.match(LINEBREAKS)
        const theirs = theirContent.match(LINEBREAKS)
        const result = diff3Merge(ours, base, theirs)
        let mergedText = ''
        for (const item of result) {
          if (item.ok) {
            mergedText += item.ok.join('')
          }
          if (item.conflict) {
            mergedText += item.conflict.b.join('')
          }
        }
        return { cleanMerge: true, mergedText }
      },
    })
    const mergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'a',
        depth: 1,
      })
    )[0].commit
    expect(report.tree).toBe(commit.tree)
    expect(mergeCommit.tree).toEqual(commit.tree)
    expect(mergeCommit.message).toEqual(commit.message)
    expect(mergeCommit.parent).toEqual(commit.parent)
  })",snuts
/__tests__/test-merge.js,ConditionalTestLogic,"{'startLine':994,'endLine':994}","it(""merge two branches that modified the same file, manual conflict resolution'"", async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-merge')

    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'a-merge-c-manual-resolve',
      })
    )[0].commit
    // Test
    await merge({
      fs,
      dir,
      gitdir,
      ours: 'a',
      theirs: 'c',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      abortOnConflict: false,
    }).catch(e => {
      if (!(e instanceof Errors.MergeConflictError)) throw e
    })
    await add({
      fs,
      dir,
      gitdir,
      filepath: '.',
    })
    await gitCommit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      ref: 'a',
      message: ""Merge branch 'c' into a"",
      parent: ['a', 'c'],
    })
    const mergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'a',
        depth: 1,
      })
    )[0].commit

    expect(mergeCommit.tree).toEqual(commit.tree)
    expect(mergeCommit.message).toEqual(commit.message)
    expect(mergeCommit.parent).toEqual(commit.parent)
  })",snuts
/__tests__/test-merge.js,SubOptimalAssert,"{'startLine':333,'endLine':333}","it(""merge 'delete-first-half' and 'delete-second-half' (dryRun, missing author)"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')
    // Test
    let error = null
    try {
      await merge({
        fs,
        gitdir,
        ours: 'delete-first-half',
        theirs: 'delete-second-half',
        dryRun: true,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBe(null)
    expect(error.code).toBe(Errors.MissingNameError.code)
  })",snuts
/__tests__/test-merge.js,SubOptimalAssert,"{'startLine':1232,'endLine':1232}","it('merge two branches with unrelated histories where they add 2 files having different name', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-empty')

    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }

    // First root commit on 'master'
    await fs.write(`${dir}/a.txt`, 'hello a')
    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'master',
      message: 'Add a.txt',
      author,
    })

    // Second root commit on unrelated branch 'other'
    await fs.write(`${dir}/b.txt`, 'hello b')
    await add({ fs, dir, gitdir, filepath: 'b.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'other',
      message: 'Add b.txt',
      author,
    })

    const report = await merge({
      fs,
      gitdir,
      ours: 'master',
      theirs: 'other',
      abortOnConflict: false,
      allowUnrelatedHistories: true,
      author,
    })

    expect(report).toBeTruthy()
    expect(report.mergeCommit).toBeTruthy()
    const mergeHead = (await log({ fs, gitdir, ref: 'master', depth: 1 }))[0]
      .commit
    expect(mergeHead.parent.length).toBe(2)

    const matrix = await statusMatrix({ fs, dir, gitdir })
    const trackedFiles = matrix.map(row => row[0])
    expect(trackedFiles.join()).toEqual(['a.txt', 'b.txt'].join())

    const history = await log({ fs, gitdir, ref: 'master', depth: 3 })
    const messages = history.map(entry =>
      entry.commit.message.replace('\n', '')
    )
    expect(messages.join()).toEqual(
      [`Merge branch 'other' into master`, 'Add b.txt', 'Add a.txt'].join()
    )
  })",snuts
/__tests__/test-merge.js,SubOptimalAssert,"{'startLine':1364,'endLine':1364}","it('merge two branches with unrelated histories where they add files in nested directories', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-empty')

    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }

    // First root commit on 'master' with nested directory
    await fs.mkdir(`${dir}/dir1`)
    await fs.mkdir(`${dir}/dir1/subdir1`)
    await fs.write(`${dir}/dir1/subdir1/file1.txt`, 'content from master')
    await add({ fs, dir, gitdir, filepath: 'dir1/subdir1/file1.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'master',
      message: 'Add file in nested directory on master',
      author,
    })

    // Second root commit on unrelated branch 'other' with different nested directory
    await fs.mkdir(`${dir}/dir2`)
    await fs.mkdir(`${dir}/dir2/subdir2`)
    await fs.write(`${dir}/dir2/subdir2/file2.txt`, 'content from other')
    await add({ fs, dir, gitdir, filepath: 'dir2/subdir2/file2.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'other',
      message: 'Add file in different nested directory on other',
      author,
    })

    const report = await merge({
      fs,
      gitdir,
      ours: 'master',
      theirs: 'other',
      abortOnConflict: false,
      allowUnrelatedHistories: true,
      author,
    })

    expect(report).toBeTruthy()
    expect(report.mergeCommit).toBeTruthy()
    const mergeHead = (await log({ fs, gitdir, ref: 'master', depth: 1 }))[0]
      .commit
    expect(mergeHead.parent.length).toBe(2)

    const matrix = await statusMatrix({ fs, dir, gitdir })
    const trackedFiles = matrix.map(row => row[0])
    expect(trackedFiles.join()).toEqual(
      ['dir1/subdir1/file1.txt', 'dir2/subdir2/file2.txt'].join()
    )

    const history = await log({ fs, gitdir, ref: 'master', depth: 3 })
    const messages = history.map(entry =>
      entry.commit.message.replace('\n', '')
    )
    expect(messages.join()).toEqual(
      [
        `Merge branch 'other' into master`,
        'Add file in different nested directory on other',
        'Add file in nested directory on master',
      ].join()
    )
  })",snuts
/__tests__/test-merge.js,VerboseStatement,"{'startLine':1184,'endLine':1245}","it('merge two branches with unrelated histories where they add 2 files having different name', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-empty')

    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }

    // First root commit on 'master'
    await fs.write(`${dir}/a.txt`, 'hello a')
    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'master',
      message: 'Add a.txt',
      author,
    })

    // Second root commit on unrelated branch 'other'
    await fs.write(`${dir}/b.txt`, 'hello b')
    await add({ fs, dir, gitdir, filepath: 'b.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'other',
      message: 'Add b.txt',
      author,
    })

    const report = await merge({
      fs,
      gitdir,
      ours: 'master',
      theirs: 'other',
      abortOnConflict: false,
      allowUnrelatedHistories: true,
      author,
    })

    expect(report).toBeTruthy()
    expect(report.mergeCommit).toBeTruthy()
    const mergeHead = (await log({ fs, gitdir, ref: 'master', depth: 1 }))[0]
      .commit
    expect(mergeHead.parent.length).toBe(2)

    const matrix = await statusMatrix({ fs, dir, gitdir })
    const trackedFiles = matrix.map(row => row[0])
    expect(trackedFiles.join()).toEqual(['a.txt', 'b.txt'].join())

    const history = await log({ fs, gitdir, ref: 'master', depth: 3 })
    const messages = history.map(entry =>
      entry.commit.message.replace('\n', '')
    )
    expect(messages.join()).toEqual(
      [`Merge branch 'other' into master`, 'Add b.txt', 'Add a.txt'].join()
    )
  })",snuts
/__tests__/test-merge.js,VerboseStatement,"{'startLine':1247,'endLine':1310}","it('merge two branches with unrelated histories where they add 2 files having same name', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-empty')
    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }

    // First root commit on master adding same.txt
    await fs.write(`${dir}/same.txt`, 'content from master')
    await add({ fs, dir, gitdir, filepath: 'same.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'master',
      message: 'Add same.txt on master',
      author,
    })

    // Second unrelated root commit on branch 'other' adding same.txt with different content
    await fs.write(`${dir}/same.txt`, 'content from other')
    await add({ fs, dir, gitdir, filepath: 'same.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'other',
      parent: [],
      message: 'Add same.txt on other',
      author,
    })

    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'master',
        theirs: 'other',
        abortOnConflict: false,
        allowUnrelatedHistories: true,
        author,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)
    const resultText = await fs.read(`${dir}/same.txt`, 'utf8')
    expect(resultText).toContain('<<<<<<<')

    const matrix = await statusMatrix({ fs, dir, gitdir })
    const trackedFiles = matrix.map(row => row[0])
    expect(trackedFiles.join()).toEqual(['same.txt'].join())

    const history = await log({ fs, gitdir, ref: 'master', depth: 3 })
    const messages = history.map(entry =>
      entry.commit.message.replace('\n', '')
    )
    expect(messages.join()).toEqual(['Add same.txt on master'].join())
  })",snuts
/__tests__/test-merge.js,VerboseStatement,"{'startLine':1312,'endLine':1383}","it('merge two branches with unrelated histories where they add files in nested directories', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-empty')

    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }

    // First root commit on 'master' with nested directory
    await fs.mkdir(`${dir}/dir1`)
    await fs.mkdir(`${dir}/dir1/subdir1`)
    await fs.write(`${dir}/dir1/subdir1/file1.txt`, 'content from master')
    await add({ fs, dir, gitdir, filepath: 'dir1/subdir1/file1.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'master',
      message: 'Add file in nested directory on master',
      author,
    })

    // Second root commit on unrelated branch 'other' with different nested directory
    await fs.mkdir(`${dir}/dir2`)
    await fs.mkdir(`${dir}/dir2/subdir2`)
    await fs.write(`${dir}/dir2/subdir2/file2.txt`, 'content from other')
    await add({ fs, dir, gitdir, filepath: 'dir2/subdir2/file2.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'other',
      message: 'Add file in different nested directory on other',
      author,
    })

    const report = await merge({
      fs,
      gitdir,
      ours: 'master',
      theirs: 'other',
      abortOnConflict: false,
      allowUnrelatedHistories: true,
      author,
    })

    expect(report).toBeTruthy()
    expect(report.mergeCommit).toBeTruthy()
    const mergeHead = (await log({ fs, gitdir, ref: 'master', depth: 1 }))[0]
      .commit
    expect(mergeHead.parent.length).toBe(2)

    const matrix = await statusMatrix({ fs, dir, gitdir })
    const trackedFiles = matrix.map(row => row[0])
    expect(trackedFiles.join()).toEqual(
      ['dir1/subdir1/file1.txt', 'dir2/subdir2/file2.txt'].join()
    )

    const history = await log({ fs, gitdir, ref: 'master', depth: 3 })
    const messages = history.map(entry =>
      entry.commit.message.replace('\n', '')
    )
    expect(messages.join()).toEqual(
      [
        `Merge branch 'other' into master`,
        'Add file in different nested directory on other',
        'Add file in nested directory on master',
      ].join()
    )
  })",snuts
/__tests__/test-merge.js,VerboseStatement,"{'startLine':1385,'endLine':1452}","it('merge two branches with unrelated histories where they add files with same path in nested directories', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-empty')
    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }

    // First root commit on master adding nested file
    await fs.mkdir(`${dir}/shared`)
    await fs.mkdir(`${dir}/shared/path`)
    await fs.write(`${dir}/shared/path/conflict.txt`, 'content from master')
    await add({ fs, dir, gitdir, filepath: 'shared/path/conflict.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'master',
      message: 'Add nested file on master',
      author,
    })

    // Second unrelated root commit on branch 'other' adding same nested file with different content
    await fs.mkdir(`${dir}/shared`)
    await fs.mkdir(`${dir}/shared/path`)
    await fs.write(`${dir}/shared/path/conflict.txt`, 'content from other')
    await add({ fs, dir, gitdir, filepath: 'shared/path/conflict.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'other',
      parent: [],
      message: 'Add nested file on other',
      author,
    })

    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'master',
        theirs: 'other',
        abortOnConflict: false,
        allowUnrelatedHistories: true,
        author,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)
    const resultText = await fs.read(`${dir}/shared/path/conflict.txt`, 'utf8')
    expect(resultText).toContain('<<<<<<<')

    const matrix = await statusMatrix({ fs, dir, gitdir })
    const trackedFiles = matrix.map(row => row[0])
    expect(trackedFiles.join()).toEqual(['shared/path/conflict.txt'].join())

    const history = await log({ fs, gitdir, ref: 'master', depth: 3 })
    const messages = history.map(entry =>
      entry.commit.message.replace('\n', '')
    )
    expect(messages.join()).toEqual(['Add nested file on master'].join())
  })",snuts
/__tests__/test-log.js,AnonymousTest,"{'startLine':8,'endLine':248}","it('HEAD', async () => {
    const { fs, gitdir } = await makeFixture('test-log')
    const commits = await log({ fs, gitdir, ref: 'HEAD' })
    expect(commits.length).toBe(5)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501475810,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501475810,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfrPiAAoJEJYJuKWSi6a5r7AP/0iG5t9oO4OFkvxCbhUd5fra
      Q2Z/ujck0yJFW3xF/2/Rzi/4PZ93RPhwB/JUVa8I9zPi5mVJMV6+ZoqiRLmgMb8g
      RJyw5Umi2JxtkpssaVfd7RUzjPiXBl9fb0lYgZttGf/sUXoEAUtX0hCwFqN/jALZ
      R+x6DqQy4XPkRpLJtQ/ABIL6dpRWflQVsONE7a4M/PA/dON4JaoCl9NTEsOPDs+J
      uY/dus3C8DTa2cdeb5OCxpjG7uQEzhMF7PfO/j+uAMNh96HVLvZGQcomxDzfglph
      EbEYm21QnpfmYCddnrM2TM3CsYnLutnk85nfz8JcaO40H2uBoxXf6iJguTUDeDWx
      eUDoQNpegfWf2VqoHqsAPamqEDnKt5sWDfx5GLhM7tkbmCDZYKiCIc6YZX2lySlu
      plaAg/NuAETtnHknDABWlVz9TQUrW6VG+iseS/rN+ZvxFQHZQvX3pNLigAa5Ey4T
      bYTU2r/JAajb+e91tEV52+ZzF7QO5URhDBQkiSurFV830HfBFBel/TcOvzWvsW8l
      gaESl+Pz8194Z/fEfIVec8IeLPURpSfOKzRZRbu80qBwgE6IBbhbiveVKE5TmaLO
      OgA2QgYxLNoaP6fR0mzBa/XqVZeTTGUrgPpGprP/AktZdl+8hPT2s8TkeO9wAVL2
      PwpokxoC+HRjO+bEBAs5
      =n8ff
      -----END PGP SIGNATURE-----"",
            ""message"": ""Update gitignore
      "",
            ""parent"": Array [
              ""ae054080bcfd04c84e0820e0cf74b31f4a422d7c"",
            ],
            ""tree"": ""24224c8f5d4cb40dc61f4210e7eb2c964f7e2407"",
          },
          ""oid"": ""3c945912219e6fc27a9100bf099687c69c88afed"",
          ""payload"": ""tree 24224c8f5d4cb40dc61f4210e7eb2c964f7e2407
      parent ae054080bcfd04c84e0820e0cf74b31f4a422d7c
      author Will Hilton <wmhilton@gmail.com> 1501475810 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501475810 -0400
      
      Update gitignore
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501475755,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501475755,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfrOrAAoJEJYJuKWSi6a5VWMP/il3myaUFoxh2DaM/1+F5GFC
      OdS+jUheAMak+M8s87kGrH8Fhv+q46RpSIrrQoz9COYM0tBFDygn2xiIdoMgqwP+
      uSXVRWzawZS+0T0nYIVCZLAN41iniL6um3XopNExpOF6rzsgi5t4s+Ch2fksOhBz
      Ze7jVtFOrmd2O9QlofgM9ICXJDJcrFRd9tPSQO9Nu4sJPpZjcYUfIfOcSIvwrB6p
      ySR4Kyh9zrNRxxY8LEbcXZGvet2wvmhBV6oQo1Xh++E5xINvcHHNo0frZl+/wSSm
      QpVE4ErEOBKYnjFqrtsdra9fmAa30/gl0pC3kBbAYdqbB1k0LgWeBfZ08Lmw5qON
      ZEDzm2jV9PFCuDs6DTk20dguyhIQIvSetpM8LEWUpVSUiXMJkJs48TZ5nTry79me
      QHf3gGNTZ6TQ9Wnjj7QXplVHFMbUc/9TJkXwQ1yYiRCY4z6g9j75qEZmhmWcUg5G
      1wHb2xcx5uNysb8gFJT4Anb1GL9VdNAy82uaEt7OgpaFozLnqS/ZqZljnM4VUY+e
      A0/Fw1cirSCuVCboA3pPNFyD5vrQcYU+RYEyxdMCf9BBO1/Zuf2qfsVOcIr3hGB6
      EaqfZgz3hL/6DRoaira+wo6vQWDLDfbkKmJTSVTXO/p9gWhOGo2J1w75fJmmwbte
      DW9rcJWg376XhOdUJYjl
      =kq+d
      -----END PGP SIGNATURE-----"",
            ""message"": ""Finished implementing fetching trees and blobs from Github API, even if we can't push to it.
      "",
            ""parent"": Array [
              ""3e80cede3c2a753a5272ed4d93496b67bb65cb0d"",
            ],
            ""tree"": ""6b858a95cc8e87677aff79a645ae178923caa5f5"",
          },
          ""oid"": ""ae054080bcfd04c84e0820e0cf74b31f4a422d7c"",
          ""payload"": ""tree 6b858a95cc8e87677aff79a645ae178923caa5f5
      parent 3e80cede3c2a753a5272ed4d93496b67bb65cb0d
      author Will Hilton <wmhilton@gmail.com> 1501475755 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501475755 -0400
      
      Finished implementing fetching trees and blobs from Github API, even if we can't push to it.
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501462174,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501462174,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfn6eAAoJEJYJuKWSi6a5H/wP/0iG/chGZyd1b0ZIpI43saW9
      GzGZsKMgUmCmy+CWPIUDJ5p6p045xBDwRrMqdKPvDsJrpDmcUvV8usbL3nQWKvZj
      oeSeOvC4C6yw6k66Zr0YtCrcAjqfAUAsyEdiZ+7JNigDB9MqUufw2sYurlulYtBu
      2zv22QIep5AYG0pDhSWFbeNuzesL+uk1sxoGTqQN7ER/qnKPWPQwMBNezpA65a3O
      WgH2lnPpyDPc6S356Nkr8f9fvQMxx66vXdR07cIw9gsA6dzgW+aUC9w4rAZ9Afk2
      SPsARmm8DH1vwwQMbiVzcKuvZ5/yWpy2XJjR2v/IhtD8dtYZDAlUbq+5jIpS9eoa
      046xp7GJ5cawOXhoWJfpvmj9ozFkQA8yZvNQ/DmUX7mrknR3pvOuxKFd/WAHZ0R/
      M696r6MIbAWWmy6/g76qcj//oEhlTWiaoxqBL5HNxRIAJzhM8gGBmtv7L+mSxKtb
      b5foIdbQZ/s890Cnm632KxTQdPkVwInP7oratrYsvpXoe+X6/EOYvhPZYaFARm+C
      KS0bq7XbfGxgswD7/6rOjOL4G3WNs0eBBf4KTOZQ4HLM72cjgcMsSSgHMUarLfCo
      KLW+2DEuHJhzF4yBcR9uSUdT0t/BbqXpRwNL0QI8nOKmvbuZqMkDHJZHOCqbjn+8
      hkMXWZGGpdRSNcNY9Hw8
      =VFL/
      -----END PGP SIGNATURE-----"",
            ""message"": ""My oh shit moment
      "",
            ""parent"": Array [
              ""1c04ba2c3b7c61cdfc0ddc3f9515116bc0e06863"",
            ],
            ""tree"": ""d1a3e8c5371d481b54e32916da162e08a87ad294"",
          },
          ""oid"": ""3e80cede3c2a753a5272ed4d93496b67bb65cb0d"",
          ""payload"": ""tree d1a3e8c5371d481b54e32916da162e08a87ad294
      parent 1c04ba2c3b7c61cdfc0ddc3f9515116bc0e06863
      author Will Hilton <wmhilton@gmail.com> 1501462174 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501462174 -0400
      
      My oh shit moment
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501454660,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501454660,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfmFEAAoJEJYJuKWSi6a5UeUP/3H2AdaOG5g1awkyHSC7sax9
      ZAQZhHumcufXoe4jNlKNogk0SUNud7H9dbhG3D7pbpujrLfjPPQ5rrQ5k2RdbuzR
      /YRuPPv9fdukWSCX3tXp63BzeNF18i/scIODgX2tT3RmihRldSWopgGpfRnks9o1
      cTAhmhjEIOH2wNki7u0M9WT6ntSUw99kglZ2vQGlExp97NFuVS68LsGjdlOpL/Lx
      kYxZUap5NVU1CFQZRgeSKZYKGVanuAbSFrGp5dHdY33YXxUQ2POzzH/sZIRRvnFZ
      T11K4AN4O7NhO0nujJS9VDrNgU20Kxwxl9FsVMwjSDdlf8ZROVbkse1U/pGjchwN
      V+1j3wMzbu0AHCcqkMB5zny/6fLrZigclOTXgq/zFiwh4FjMYwraGIKIYpTWYQ65
      d+BfM3nb7j6otAQvrxiIyNe7dwWPI39OZeFk6krAQNg1Lm1cxWwqWiWgXpZAmQwd
      yNlgQ9WLjZqiKUI8uxYJB3IznpDjIvO7t8Fq2EmDF0L4/t2LTD4JIGPOlKBx0Abr
      5J9lI+2GLTk1ZRPpDk/7w/UJpSxoeGyo5+bI9RaWQRgzkpSLyPTlvipuBLgZefj2
      njEC13b2FdnupU2qhjTqptwh1t5qrOQ4COYehMFJyhHllu/S1gV53pdBQ3N1sw35
      R4YVFfBN+FJiRwiGq3vn
      =zxDV
      -----END PGP SIGNATURE-----"",
            ""message"": ""Git init, and parts of git fetch
      "",
            ""parent"": Array [
              ""1e40fdfba1cf17f3c9f9f3d6b392b1865e5147b9"",
            ],
            ""tree"": ""dd92ed7e55ddc0c74f467a8899cc281d909c6bb9"",
          },
          ""oid"": ""1c04ba2c3b7c61cdfc0ddc3f9515116bc0e06863"",
          ""payload"": ""tree dd92ed7e55ddc0c74f467a8899cc281d909c6bb9
      parent 1e40fdfba1cf17f3c9f9f3d6b392b1865e5147b9
      author Will Hilton <wmhilton@gmail.com> 1501454660 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501454660 -0400
      
      Git init, and parts of git fetch
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501381894,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501381894,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfUUGAAoJEJYJuKWSi6a51VIQAJPwVk7bFWbNoLbi9Hi931k3
      E6kGW8JnWwcT6Y7fpm0oNpoXt+UzqJdUhVTi+79ws3yKc0u1cA23nVXDUQYmNBT7
      3YkzXP2b6OE8i7n0ffzWbOIwHqWPn7lm0RlssSEYMAwGzDTP4fj2isRCFBqQ2lb3
      dqp7ZbzikvkkQONs9AKpE7LpWYTVuyElBwO2RtlIcZQrs29fBxZg4q4fkF+mqOhp
      DMWMIvTNeCa35sjmWh4+iPXO2CtoYVKXfCzZStzleeCuwQGRhfCLxrxtcuXOREjG
      DilGnCZ0iM9+ClzD4wDUf/aY3F5exyq2oqktIq78EhFvIIozY+gUaTn6zXicr5ud
      30QQP063Tf8wC3Cy95aEq9QqLYkMXhOYBDym5fWawEWo7ssmOIW1o0ISfSI8pTVZ
      bZr5f9gQZETlTWhSPh5IGqqdHrI2fw5pkmO1N/OEn4L8D7R8josty28V4+wk2gsO
      wUSPyBv7EpVx2JtO+9Wu941fZK2qOBBmTjcTYys9PQeY9UHtrTQ3y/1r/qdLpdUH
      9HK/x5yNHqpnSATHpRiZnfkvKfaxxwIbaOLBPV8khPa/zu9dD+0WxDXStLVBWfXg
      MvYAu4q+mQSgON1Qu+kWg67lNhx//kRH0K+vUMJMIvc8M+yUgkJhRqH/HIEzEcJV
      ee4fN2IIWX0CTNr8Fs8a
      =0Txp
      -----END PGP SIGNATURE-----"",
            ""message"": ""Initial commit
      "",
            ""parent"": Array [],
            ""tree"": ""421909592ea5e22c6dda69d1cc85118240478444"",
          },
          ""oid"": ""1e40fdfba1cf17f3c9f9f3d6b392b1865e5147b9"",
          ""payload"": ""tree 421909592ea5e22c6dda69d1cc85118240478444
      author Will Hilton <wmhilton@gmail.com> 1501381894 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501381894 -0400
      
      Initial commit
      "",
        },
      ]
    `)
  })",snuts
/__tests__/test-log.js,AnonymousTest,"{'startLine':249,'endLine':253}","it('HEAD depth', async () => {
    const { fs, gitdir } = await makeFixture('test-log')
    const commits = await log({ fs, gitdir, ref: 'HEAD', depth: 1 })
    expect(commits.length).toBe(1)
  })",snuts
/__tests__/test-log.js,AnonymousTest,"{'startLine':254,'endLine':263}","it('HEAD since', async () => {
    const { fs, gitdir } = await makeFixture('test-log')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      since: new Date(1501462174000),
    })
    expect(commits.length).toBe(2)
  })",snuts
/__tests__/test-log.js,AnonymousTest,"{'startLine':264,'endLine':318}","it('shallow branch', async () => {
    const { fs, gitdir } = await makeFixture('test-log')
    const commits = await log({ fs, gitdir, ref: 'origin/shallow-branch' })
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1502484200,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1502484200,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZjhboAAoJEJYJuKWSi6a5V5UP/040SfemJ13PRBXst2eB59gs
      3hPx29DRKBhFtvk+uS+8523/hUfry2oeWWd6YRkcnkxxAUtBnfzVkI9AgRIc1NTM
      h5XtLMQubCAKw8JWvVvoXETzwVAODmdmvC4WSQCLu+opoe6/W7RvkrTD0pbkwH4E
      MXoha59sIWZ/FacZX6ByYqhFykfJL8gCFvRSzjiqBIbsP7Xq2Mh4jkAKYl5zxV3u
      qCk26hnhL++kwfXlu2YdGtB9+lj3pk1NeWqR379zRzh4P10FxXJ18qSxczbkAFOY
      6o5h7a/Mql1KqWB9EFBupCpjydmpAtPo6l1Us4a3liB5LJvCh9xgR2HtShR4b97O
      nIpXP4ngy4z9UyrXXxxpiQQn/kVn/uKgtvGp8nOFioo61PCi9js2QmQxcsuBOeO+
      DdFq5k2PMNZLwizt4P8EGfVJoPbLhdYP4oWiMCuYV/2fNh0ozl/q176HGszlfrke
      332Z0maJ3A5xIRj0b7vRNHV8AAl9Dheo3LspjeovP2iycCHFP03gSpCKdLRBRC4T
      X10BBFD8noCMXJxb5qenrf+eKRd8d4g7JtcyzqVgkBQ68GIG844VWRBolOzx4By5
      cAaw/SYIZG3RorAc11iZ7sva0jFISejmEzIebuChSzdWO2OOWRVvMdhyZwDLUgAb
      Qixh2bmPgr3h9nxq2Dmn
      =4+DN
      -----END PGP SIGNATURE-----"",
            ""message"": ""Improve resolveRef to handle more kinds of refs. Add tests
      "",
            ""parent"": Array [
              ""b4f8206d9e359416b0f34238cbeb400f7da889a8"",
            ],
            ""tree"": ""e0b8f3574060ee24e03e4af3896f65dd208a60cc"",
          },
          ""oid"": ""e10ebb90d03eaacca84de1af0a59b444232da99e"",
          ""payload"": ""tree e0b8f3574060ee24e03e4af3896f65dd208a60cc
      parent b4f8206d9e359416b0f34238cbeb400f7da889a8
      author Will Hilton <wmhilton@gmail.com> 1502484200 -0400
      committer Will Hilton <wmhilton@gmail.com> 1502484200 -0400
      
      Improve resolveRef to handle more kinds of refs. Add tests
      "",
        },
      ]
    `)
  })",snuts
/__tests__/test-log.js,ComplexSnapshots,"{'startLine':12,'endLine':247}","it('HEAD', async () => {
    const { fs, gitdir } = await makeFixture('test-log')
    const commits = await log({ fs, gitdir, ref: 'HEAD' })
    expect(commits.length).toBe(5)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501475810,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501475810,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfrPiAAoJEJYJuKWSi6a5r7AP/0iG5t9oO4OFkvxCbhUd5fra
      Q2Z/ujck0yJFW3xF/2/Rzi/4PZ93RPhwB/JUVa8I9zPi5mVJMV6+ZoqiRLmgMb8g
      RJyw5Umi2JxtkpssaVfd7RUzjPiXBl9fb0lYgZttGf/sUXoEAUtX0hCwFqN/jALZ
      R+x6DqQy4XPkRpLJtQ/ABIL6dpRWflQVsONE7a4M/PA/dON4JaoCl9NTEsOPDs+J
      uY/dus3C8DTa2cdeb5OCxpjG7uQEzhMF7PfO/j+uAMNh96HVLvZGQcomxDzfglph
      EbEYm21QnpfmYCddnrM2TM3CsYnLutnk85nfz8JcaO40H2uBoxXf6iJguTUDeDWx
      eUDoQNpegfWf2VqoHqsAPamqEDnKt5sWDfx5GLhM7tkbmCDZYKiCIc6YZX2lySlu
      plaAg/NuAETtnHknDABWlVz9TQUrW6VG+iseS/rN+ZvxFQHZQvX3pNLigAa5Ey4T
      bYTU2r/JAajb+e91tEV52+ZzF7QO5URhDBQkiSurFV830HfBFBel/TcOvzWvsW8l
      gaESl+Pz8194Z/fEfIVec8IeLPURpSfOKzRZRbu80qBwgE6IBbhbiveVKE5TmaLO
      OgA2QgYxLNoaP6fR0mzBa/XqVZeTTGUrgPpGprP/AktZdl+8hPT2s8TkeO9wAVL2
      PwpokxoC+HRjO+bEBAs5
      =n8ff
      -----END PGP SIGNATURE-----"",
            ""message"": ""Update gitignore
      "",
            ""parent"": Array [
              ""ae054080bcfd04c84e0820e0cf74b31f4a422d7c"",
            ],
            ""tree"": ""24224c8f5d4cb40dc61f4210e7eb2c964f7e2407"",
          },
          ""oid"": ""3c945912219e6fc27a9100bf099687c69c88afed"",
          ""payload"": ""tree 24224c8f5d4cb40dc61f4210e7eb2c964f7e2407
      parent ae054080bcfd04c84e0820e0cf74b31f4a422d7c
      author Will Hilton <wmhilton@gmail.com> 1501475810 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501475810 -0400
      
      Update gitignore
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501475755,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501475755,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfrOrAAoJEJYJuKWSi6a5VWMP/il3myaUFoxh2DaM/1+F5GFC
      OdS+jUheAMak+M8s87kGrH8Fhv+q46RpSIrrQoz9COYM0tBFDygn2xiIdoMgqwP+
      uSXVRWzawZS+0T0nYIVCZLAN41iniL6um3XopNExpOF6rzsgi5t4s+Ch2fksOhBz
      Ze7jVtFOrmd2O9QlofgM9ICXJDJcrFRd9tPSQO9Nu4sJPpZjcYUfIfOcSIvwrB6p
      ySR4Kyh9zrNRxxY8LEbcXZGvet2wvmhBV6oQo1Xh++E5xINvcHHNo0frZl+/wSSm
      QpVE4ErEOBKYnjFqrtsdra9fmAa30/gl0pC3kBbAYdqbB1k0LgWeBfZ08Lmw5qON
      ZEDzm2jV9PFCuDs6DTk20dguyhIQIvSetpM8LEWUpVSUiXMJkJs48TZ5nTry79me
      QHf3gGNTZ6TQ9Wnjj7QXplVHFMbUc/9TJkXwQ1yYiRCY4z6g9j75qEZmhmWcUg5G
      1wHb2xcx5uNysb8gFJT4Anb1GL9VdNAy82uaEt7OgpaFozLnqS/ZqZljnM4VUY+e
      A0/Fw1cirSCuVCboA3pPNFyD5vrQcYU+RYEyxdMCf9BBO1/Zuf2qfsVOcIr3hGB6
      EaqfZgz3hL/6DRoaira+wo6vQWDLDfbkKmJTSVTXO/p9gWhOGo2J1w75fJmmwbte
      DW9rcJWg376XhOdUJYjl
      =kq+d
      -----END PGP SIGNATURE-----"",
            ""message"": ""Finished implementing fetching trees and blobs from Github API, even if we can't push to it.
      "",
            ""parent"": Array [
              ""3e80cede3c2a753a5272ed4d93496b67bb65cb0d"",
            ],
            ""tree"": ""6b858a95cc8e87677aff79a645ae178923caa5f5"",
          },
          ""oid"": ""ae054080bcfd04c84e0820e0cf74b31f4a422d7c"",
          ""payload"": ""tree 6b858a95cc8e87677aff79a645ae178923caa5f5
      parent 3e80cede3c2a753a5272ed4d93496b67bb65cb0d
      author Will Hilton <wmhilton@gmail.com> 1501475755 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501475755 -0400
      
      Finished implementing fetching trees and blobs from Github API, even if we can't push to it.
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501462174,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501462174,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfn6eAAoJEJYJuKWSi6a5H/wP/0iG/chGZyd1b0ZIpI43saW9
      GzGZsKMgUmCmy+CWPIUDJ5p6p045xBDwRrMqdKPvDsJrpDmcUvV8usbL3nQWKvZj
      oeSeOvC4C6yw6k66Zr0YtCrcAjqfAUAsyEdiZ+7JNigDB9MqUufw2sYurlulYtBu
      2zv22QIep5AYG0pDhSWFbeNuzesL+uk1sxoGTqQN7ER/qnKPWPQwMBNezpA65a3O
      WgH2lnPpyDPc6S356Nkr8f9fvQMxx66vXdR07cIw9gsA6dzgW+aUC9w4rAZ9Afk2
      SPsARmm8DH1vwwQMbiVzcKuvZ5/yWpy2XJjR2v/IhtD8dtYZDAlUbq+5jIpS9eoa
      046xp7GJ5cawOXhoWJfpvmj9ozFkQA8yZvNQ/DmUX7mrknR3pvOuxKFd/WAHZ0R/
      M696r6MIbAWWmy6/g76qcj//oEhlTWiaoxqBL5HNxRIAJzhM8gGBmtv7L+mSxKtb
      b5foIdbQZ/s890Cnm632KxTQdPkVwInP7oratrYsvpXoe+X6/EOYvhPZYaFARm+C
      KS0bq7XbfGxgswD7/6rOjOL4G3WNs0eBBf4KTOZQ4HLM72cjgcMsSSgHMUarLfCo
      KLW+2DEuHJhzF4yBcR9uSUdT0t/BbqXpRwNL0QI8nOKmvbuZqMkDHJZHOCqbjn+8
      hkMXWZGGpdRSNcNY9Hw8
      =VFL/
      -----END PGP SIGNATURE-----"",
            ""message"": ""My oh shit moment
      "",
            ""parent"": Array [
              ""1c04ba2c3b7c61cdfc0ddc3f9515116bc0e06863"",
            ],
            ""tree"": ""d1a3e8c5371d481b54e32916da162e08a87ad294"",
          },
          ""oid"": ""3e80cede3c2a753a5272ed4d93496b67bb65cb0d"",
          ""payload"": ""tree d1a3e8c5371d481b54e32916da162e08a87ad294
      parent 1c04ba2c3b7c61cdfc0ddc3f9515116bc0e06863
      author Will Hilton <wmhilton@gmail.com> 1501462174 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501462174 -0400
      
      My oh shit moment
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501454660,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501454660,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfmFEAAoJEJYJuKWSi6a5UeUP/3H2AdaOG5g1awkyHSC7sax9
      ZAQZhHumcufXoe4jNlKNogk0SUNud7H9dbhG3D7pbpujrLfjPPQ5rrQ5k2RdbuzR
      /YRuPPv9fdukWSCX3tXp63BzeNF18i/scIODgX2tT3RmihRldSWopgGpfRnks9o1
      cTAhmhjEIOH2wNki7u0M9WT6ntSUw99kglZ2vQGlExp97NFuVS68LsGjdlOpL/Lx
      kYxZUap5NVU1CFQZRgeSKZYKGVanuAbSFrGp5dHdY33YXxUQ2POzzH/sZIRRvnFZ
      T11K4AN4O7NhO0nujJS9VDrNgU20Kxwxl9FsVMwjSDdlf8ZROVbkse1U/pGjchwN
      V+1j3wMzbu0AHCcqkMB5zny/6fLrZigclOTXgq/zFiwh4FjMYwraGIKIYpTWYQ65
      d+BfM3nb7j6otAQvrxiIyNe7dwWPI39OZeFk6krAQNg1Lm1cxWwqWiWgXpZAmQwd
      yNlgQ9WLjZqiKUI8uxYJB3IznpDjIvO7t8Fq2EmDF0L4/t2LTD4JIGPOlKBx0Abr
      5J9lI+2GLTk1ZRPpDk/7w/UJpSxoeGyo5+bI9RaWQRgzkpSLyPTlvipuBLgZefj2
      njEC13b2FdnupU2qhjTqptwh1t5qrOQ4COYehMFJyhHllu/S1gV53pdBQ3N1sw35
      R4YVFfBN+FJiRwiGq3vn
      =zxDV
      -----END PGP SIGNATURE-----"",
            ""message"": ""Git init, and parts of git fetch
      "",
            ""parent"": Array [
              ""1e40fdfba1cf17f3c9f9f3d6b392b1865e5147b9"",
            ],
            ""tree"": ""dd92ed7e55ddc0c74f467a8899cc281d909c6bb9"",
          },
          ""oid"": ""1c04ba2c3b7c61cdfc0ddc3f9515116bc0e06863"",
          ""payload"": ""tree dd92ed7e55ddc0c74f467a8899cc281d909c6bb9
      parent 1e40fdfba1cf17f3c9f9f3d6b392b1865e5147b9
      author Will Hilton <wmhilton@gmail.com> 1501454660 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501454660 -0400
      
      Git init, and parts of git fetch
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501381894,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501381894,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfUUGAAoJEJYJuKWSi6a51VIQAJPwVk7bFWbNoLbi9Hi931k3
      E6kGW8JnWwcT6Y7fpm0oNpoXt+UzqJdUhVTi+79ws3yKc0u1cA23nVXDUQYmNBT7
      3YkzXP2b6OE8i7n0ffzWbOIwHqWPn7lm0RlssSEYMAwGzDTP4fj2isRCFBqQ2lb3
      dqp7ZbzikvkkQONs9AKpE7LpWYTVuyElBwO2RtlIcZQrs29fBxZg4q4fkF+mqOhp
      DMWMIvTNeCa35sjmWh4+iPXO2CtoYVKXfCzZStzleeCuwQGRhfCLxrxtcuXOREjG
      DilGnCZ0iM9+ClzD4wDUf/aY3F5exyq2oqktIq78EhFvIIozY+gUaTn6zXicr5ud
      30QQP063Tf8wC3Cy95aEq9QqLYkMXhOYBDym5fWawEWo7ssmOIW1o0ISfSI8pTVZ
      bZr5f9gQZETlTWhSPh5IGqqdHrI2fw5pkmO1N/OEn4L8D7R8josty28V4+wk2gsO
      wUSPyBv7EpVx2JtO+9Wu941fZK2qOBBmTjcTYys9PQeY9UHtrTQ3y/1r/qdLpdUH
      9HK/x5yNHqpnSATHpRiZnfkvKfaxxwIbaOLBPV8khPa/zu9dD+0WxDXStLVBWfXg
      MvYAu4q+mQSgON1Qu+kWg67lNhx//kRH0K+vUMJMIvc8M+yUgkJhRqH/HIEzEcJV
      ee4fN2IIWX0CTNr8Fs8a
      =0Txp
      -----END PGP SIGNATURE-----"",
            ""message"": ""Initial commit
      "",
            ""parent"": Array [],
            ""tree"": ""421909592ea5e22c6dda69d1cc85118240478444"",
          },
          ""oid"": ""1e40fdfba1cf17f3c9f9f3d6b392b1865e5147b9"",
          ""payload"": ""tree 421909592ea5e22c6dda69d1cc85118240478444
      author Will Hilton <wmhilton@gmail.com> 1501381894 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501381894 -0400
      
      Initial commit
      "",
        },
      ]
    `)
  })",snuts
/__tests__/test-log.js,ComplexSnapshots,"{'startLine':388,'endLine':724}","it('with complex merging history', async () => {
    const { fs, gitdir } = await makeFixture('test-log-complex')
    const commits = await log({ fs, gitdir, ref: 'master' })
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605340,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605340,
              ""timezoneOffset"": 240,
            },
            ""message"": ""Merge branches 'foo' and 'baz'
      "",
            ""parent"": Array [
              ""8bb702b66d8def74b2a9642309eb23a5f76779dc"",
              ""ccc9ef071f1b27210fa0df2f8665f4ad550358e8"",
              ""1ce759dd468c1ea830e8befbbdcf79e591346153"",
            ],
            ""tree"": ""4b825dc642cb6eb9a060e54bf8d69288fbee4904"",
          },
          ""oid"": ""9eeab5143ea4a6dde4ede004e4882e2467dde340"",
          ""payload"": ""tree 4b825dc642cb6eb9a060e54bf8d69288fbee4904
      parent 8bb702b66d8def74b2a9642309eb23a5f76779dc
      parent ccc9ef071f1b27210fa0df2f8665f4ad550358e8
      parent 1ce759dd468c1ea830e8befbbdcf79e591346153
      author William Hilton <wmhilton@gmail.com> 1528605340 -0400
      committer William Hilton <wmhilton@gmail.com> 1528605340 -0400
      
      Merge branches 'foo' and 'baz'
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605325,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605325,
              ""timezoneOffset"": 240,
            },
            ""message"": ""Other sixth commit
      "",
            ""parent"": Array [
              ""f1eca35203ee2b578f23e0e7c8b8c2c48927d597"",
            ],
            ""tree"": ""4b825dc642cb6eb9a060e54bf8d69288fbee4904"",
          },
          ""oid"": ""8bb702b66d8def74b2a9642309eb23a5f76779dc"",
          ""payload"": ""tree 4b825dc642cb6eb9a060e54bf8d69288fbee4904
      parent f1eca35203ee2b578f23e0e7c8b8c2c48927d597
      author William Hilton <wmhilton@gmail.com> 1528605325 -0400
      committer William Hilton <wmhilton@gmail.com> 1528605325 -0400
      
      Other sixth commit
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605315,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605315,
              ""timezoneOffset"": 240,
            },
            ""message"": ""Sixth commit
      "",
            ""parent"": Array [
              ""f1eca35203ee2b578f23e0e7c8b8c2c48927d597"",
            ],
            ""tree"": ""4b825dc642cb6eb9a060e54bf8d69288fbee4904"",
          },
          ""oid"": ""1ce759dd468c1ea830e8befbbdcf79e591346153"",
          ""payload"": ""tree 4b825dc642cb6eb9a060e54bf8d69288fbee4904
      parent f1eca35203ee2b578f23e0e7c8b8c2c48927d597
      author William Hilton <wmhilton@gmail.com> 1528605315 -0400
      committer William Hilton <wmhilton@gmail.com> 1528605315 -0400
      
      Sixth commit
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605295,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605295,
              ""timezoneOffset"": 240,
            },
            ""message"": ""Fifth commit
      "",
            ""parent"": Array [
              ""6cabb8ab77d3fc40858db84416dfd1a41fe1c2fd"",
            ],
            ""tree"": ""4b825dc642cb6eb9a060e54bf8d69288fbee4904"",
          },
          ""oid"": ""f1eca35203ee2b578f23e0e7c8b8c2c48927d597"",
          ""payload"": ""tree 4b825dc642cb6eb9a060e54bf8d69288fbee4904
      parent 6cabb8ab77d3fc40858db84416dfd1a41fe1c2fd
      author William Hilton <wmhilton@gmail.com> 1528605295 -0400
      committer William Hilton <wmhilton@gmail.com> 1528605295 -0400
      
      Fifth commit
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605245,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605245,
              ""timezoneOffset"": 240,
            },
            ""message"": ""Merge branch 'bar' into foo
      "",
            ""parent"": Array [
              ""ad5f1992b8ff758bc9fe457acf905093dd75b7b1"",
              ""ec2db34cd04249ea6c31ed6d367656b0f2ab25c6"",
            ],
            ""tree"": ""4b825dc642cb6eb9a060e54bf8d69288fbee4904"",
          },
          ""oid"": ""ccc9ef071f1b27210fa0df2f8665f4ad550358e8"",
          ""payload"": ""tree 4b825dc642cb6eb9a060e54bf8d69288fbee4904
      parent ad5f1992b8ff758bc9fe457acf905093dd75b7b1
      parent ec2db34cd04249ea6c31ed6d367656b0f2ab25c6
      author William Hilton <wmhilton@gmail.com> 1528605245 -0400
      committer William Hilton <wmhilton@gmail.com> 1528605245 -0400
      
      Merge branch 'bar' into foo
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605228,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605228,
              ""timezoneOffset"": 240,
            },
            ""message"": ""Other fourth commit
      "",
            ""parent"": Array [
              ""b5129e2726d68c93ed09a3eaec9dda5e76fd4a87"",
            ],
            ""tree"": ""4b825dc642cb6eb9a060e54bf8d69288fbee4904"",
          },
          ""oid"": ""ec2db34cd04249ea6c31ed6d367656b0f2ab25c6"",
          ""payload"": ""tree 4b825dc642cb6eb9a060e54bf8d69288fbee4904
      parent b5129e2726d68c93ed09a3eaec9dda5e76fd4a87
      author William Hilton <wmhilton@gmail.com> 1528605228 -0400
      committer William Hilton <wmhilton@gmail.com> 1528605228 -0400
      
      Other fourth commit
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605214,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605214,
              ""timezoneOffset"": 240,
            },
            ""message"": ""Fourth commit
      "",
            ""parent"": Array [
              ""c4e447f61fcaf49032265bfe3dea32383339d910"",
            ],
            ""tree"": ""4b825dc642cb6eb9a060e54bf8d69288fbee4904"",
          },
          ""oid"": ""ad5f1992b8ff758bc9fe457acf905093dd75b7b1"",
          ""payload"": ""tree 4b825dc642cb6eb9a060e54bf8d69288fbee4904
      parent c4e447f61fcaf49032265bfe3dea32383339d910
      author William Hilton <wmhilton@gmail.com> 1528605214 -0400
      committer William Hilton <wmhilton@gmail.com> 1528605214 -0400
      
      Fourth commit
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605200,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605200,
              ""timezoneOffset"": 240,
            },
            ""message"": ""Other third commit
      "",
            ""parent"": Array [
              ""6cabb8ab77d3fc40858db84416dfd1a41fe1c2fd"",
            ],
            ""tree"": ""4b825dc642cb6eb9a060e54bf8d69288fbee4904"",
          },
          ""oid"": ""b5129e2726d68c93ed09a3eaec9dda5e76fd4a87"",
          ""payload"": ""tree 4b825dc642cb6eb9a060e54bf8d69288fbee4904
      parent 6cabb8ab77d3fc40858db84416dfd1a41fe1c2fd
      author William Hilton <wmhilton@gmail.com> 1528605200 -0400
      committer William Hilton <wmhilton@gmail.com> 1528605200 -0400
      
      Other third commit
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605169,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605169,
              ""timezoneOffset"": 240,
            },
            ""message"": ""Third commit
      "",
            ""parent"": Array [
              ""6cabb8ab77d3fc40858db84416dfd1a41fe1c2fd"",
            ],
            ""tree"": ""4b825dc642cb6eb9a060e54bf8d69288fbee4904"",
          },
          ""oid"": ""c4e447f61fcaf49032265bfe3dea32383339d910"",
          ""payload"": ""tree 4b825dc642cb6eb9a060e54bf8d69288fbee4904
      parent 6cabb8ab77d3fc40858db84416dfd1a41fe1c2fd
      author William Hilton <wmhilton@gmail.com> 1528605169 -0400
      committer William Hilton <wmhilton@gmail.com> 1528605169 -0400
      
      Third commit
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605133,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605133,
              ""timezoneOffset"": 240,
            },
            ""message"": ""Second commit
      "",
            ""parent"": Array [
              ""4acc58cd881f48c4662c4554ab268e77bcd34b71"",
            ],
            ""tree"": ""4b825dc642cb6eb9a060e54bf8d69288fbee4904"",
          },
          ""oid"": ""6cabb8ab77d3fc40858db84416dfd1a41fe1c2fd"",
          ""payload"": ""tree 4b825dc642cb6eb9a060e54bf8d69288fbee4904
      parent 4acc58cd881f48c4662c4554ab268e77bcd34b71
      author William Hilton <wmhilton@gmail.com> 1528605133 -0400
      committer William Hilton <wmhilton@gmail.com> 1528605133 -0400
      
      Second commit
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605128,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""William Hilton"",
              ""timestamp"": 1528605128,
              ""timezoneOffset"": 240,
            },
            ""message"": ""Initial commit
      "",
            ""parent"": Array [],
            ""tree"": ""4b825dc642cb6eb9a060e54bf8d69288fbee4904"",
          },
          ""oid"": ""4acc58cd881f48c4662c4554ab268e77bcd34b71"",
          ""payload"": ""tree 4b825dc642cb6eb9a060e54bf8d69288fbee4904
      author William Hilton <wmhilton@gmail.com> 1528605128 -0400
      committer William Hilton <wmhilton@gmail.com> 1528605128 -0400
      
      Initial commit
      "",
        },
      ]
    `)
  })",snuts
/__tests__/test-log.js,SubOptimalAssert,"{'startLine':11,'endLine':11}","it('HEAD', async () => {
    const { fs, gitdir } = await makeFixture('test-log')
    const commits = await log({ fs, gitdir, ref: 'HEAD' })
    expect(commits.length).toBe(5)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501475810,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501475810,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfrPiAAoJEJYJuKWSi6a5r7AP/0iG5t9oO4OFkvxCbhUd5fra
      Q2Z/ujck0yJFW3xF/2/Rzi/4PZ93RPhwB/JUVa8I9zPi5mVJMV6+ZoqiRLmgMb8g
      RJyw5Umi2JxtkpssaVfd7RUzjPiXBl9fb0lYgZttGf/sUXoEAUtX0hCwFqN/jALZ
      R+x6DqQy4XPkRpLJtQ/ABIL6dpRWflQVsONE7a4M/PA/dON4JaoCl9NTEsOPDs+J
      uY/dus3C8DTa2cdeb5OCxpjG7uQEzhMF7PfO/j+uAMNh96HVLvZGQcomxDzfglph
      EbEYm21QnpfmYCddnrM2TM3CsYnLutnk85nfz8JcaO40H2uBoxXf6iJguTUDeDWx
      eUDoQNpegfWf2VqoHqsAPamqEDnKt5sWDfx5GLhM7tkbmCDZYKiCIc6YZX2lySlu
      plaAg/NuAETtnHknDABWlVz9TQUrW6VG+iseS/rN+ZvxFQHZQvX3pNLigAa5Ey4T
      bYTU2r/JAajb+e91tEV52+ZzF7QO5URhDBQkiSurFV830HfBFBel/TcOvzWvsW8l
      gaESl+Pz8194Z/fEfIVec8IeLPURpSfOKzRZRbu80qBwgE6IBbhbiveVKE5TmaLO
      OgA2QgYxLNoaP6fR0mzBa/XqVZeTTGUrgPpGprP/AktZdl+8hPT2s8TkeO9wAVL2
      PwpokxoC+HRjO+bEBAs5
      =n8ff
      -----END PGP SIGNATURE-----"",
            ""message"": ""Update gitignore
      "",
            ""parent"": Array [
              ""ae054080bcfd04c84e0820e0cf74b31f4a422d7c"",
            ],
            ""tree"": ""24224c8f5d4cb40dc61f4210e7eb2c964f7e2407"",
          },
          ""oid"": ""3c945912219e6fc27a9100bf099687c69c88afed"",
          ""payload"": ""tree 24224c8f5d4cb40dc61f4210e7eb2c964f7e2407
      parent ae054080bcfd04c84e0820e0cf74b31f4a422d7c
      author Will Hilton <wmhilton@gmail.com> 1501475810 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501475810 -0400
      
      Update gitignore
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501475755,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501475755,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfrOrAAoJEJYJuKWSi6a5VWMP/il3myaUFoxh2DaM/1+F5GFC
      OdS+jUheAMak+M8s87kGrH8Fhv+q46RpSIrrQoz9COYM0tBFDygn2xiIdoMgqwP+
      uSXVRWzawZS+0T0nYIVCZLAN41iniL6um3XopNExpOF6rzsgi5t4s+Ch2fksOhBz
      Ze7jVtFOrmd2O9QlofgM9ICXJDJcrFRd9tPSQO9Nu4sJPpZjcYUfIfOcSIvwrB6p
      ySR4Kyh9zrNRxxY8LEbcXZGvet2wvmhBV6oQo1Xh++E5xINvcHHNo0frZl+/wSSm
      QpVE4ErEOBKYnjFqrtsdra9fmAa30/gl0pC3kBbAYdqbB1k0LgWeBfZ08Lmw5qON
      ZEDzm2jV9PFCuDs6DTk20dguyhIQIvSetpM8LEWUpVSUiXMJkJs48TZ5nTry79me
      QHf3gGNTZ6TQ9Wnjj7QXplVHFMbUc/9TJkXwQ1yYiRCY4z6g9j75qEZmhmWcUg5G
      1wHb2xcx5uNysb8gFJT4Anb1GL9VdNAy82uaEt7OgpaFozLnqS/ZqZljnM4VUY+e
      A0/Fw1cirSCuVCboA3pPNFyD5vrQcYU+RYEyxdMCf9BBO1/Zuf2qfsVOcIr3hGB6
      EaqfZgz3hL/6DRoaira+wo6vQWDLDfbkKmJTSVTXO/p9gWhOGo2J1w75fJmmwbte
      DW9rcJWg376XhOdUJYjl
      =kq+d
      -----END PGP SIGNATURE-----"",
            ""message"": ""Finished implementing fetching trees and blobs from Github API, even if we can't push to it.
      "",
            ""parent"": Array [
              ""3e80cede3c2a753a5272ed4d93496b67bb65cb0d"",
            ],
            ""tree"": ""6b858a95cc8e87677aff79a645ae178923caa5f5"",
          },
          ""oid"": ""ae054080bcfd04c84e0820e0cf74b31f4a422d7c"",
          ""payload"": ""tree 6b858a95cc8e87677aff79a645ae178923caa5f5
      parent 3e80cede3c2a753a5272ed4d93496b67bb65cb0d
      author Will Hilton <wmhilton@gmail.com> 1501475755 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501475755 -0400
      
      Finished implementing fetching trees and blobs from Github API, even if we can't push to it.
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501462174,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501462174,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfn6eAAoJEJYJuKWSi6a5H/wP/0iG/chGZyd1b0ZIpI43saW9
      GzGZsKMgUmCmy+CWPIUDJ5p6p045xBDwRrMqdKPvDsJrpDmcUvV8usbL3nQWKvZj
      oeSeOvC4C6yw6k66Zr0YtCrcAjqfAUAsyEdiZ+7JNigDB9MqUufw2sYurlulYtBu
      2zv22QIep5AYG0pDhSWFbeNuzesL+uk1sxoGTqQN7ER/qnKPWPQwMBNezpA65a3O
      WgH2lnPpyDPc6S356Nkr8f9fvQMxx66vXdR07cIw9gsA6dzgW+aUC9w4rAZ9Afk2
      SPsARmm8DH1vwwQMbiVzcKuvZ5/yWpy2XJjR2v/IhtD8dtYZDAlUbq+5jIpS9eoa
      046xp7GJ5cawOXhoWJfpvmj9ozFkQA8yZvNQ/DmUX7mrknR3pvOuxKFd/WAHZ0R/
      M696r6MIbAWWmy6/g76qcj//oEhlTWiaoxqBL5HNxRIAJzhM8gGBmtv7L+mSxKtb
      b5foIdbQZ/s890Cnm632KxTQdPkVwInP7oratrYsvpXoe+X6/EOYvhPZYaFARm+C
      KS0bq7XbfGxgswD7/6rOjOL4G3WNs0eBBf4KTOZQ4HLM72cjgcMsSSgHMUarLfCo
      KLW+2DEuHJhzF4yBcR9uSUdT0t/BbqXpRwNL0QI8nOKmvbuZqMkDHJZHOCqbjn+8
      hkMXWZGGpdRSNcNY9Hw8
      =VFL/
      -----END PGP SIGNATURE-----"",
            ""message"": ""My oh shit moment
      "",
            ""parent"": Array [
              ""1c04ba2c3b7c61cdfc0ddc3f9515116bc0e06863"",
            ],
            ""tree"": ""d1a3e8c5371d481b54e32916da162e08a87ad294"",
          },
          ""oid"": ""3e80cede3c2a753a5272ed4d93496b67bb65cb0d"",
          ""payload"": ""tree d1a3e8c5371d481b54e32916da162e08a87ad294
      parent 1c04ba2c3b7c61cdfc0ddc3f9515116bc0e06863
      author Will Hilton <wmhilton@gmail.com> 1501462174 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501462174 -0400
      
      My oh shit moment
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501454660,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501454660,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfmFEAAoJEJYJuKWSi6a5UeUP/3H2AdaOG5g1awkyHSC7sax9
      ZAQZhHumcufXoe4jNlKNogk0SUNud7H9dbhG3D7pbpujrLfjPPQ5rrQ5k2RdbuzR
      /YRuPPv9fdukWSCX3tXp63BzeNF18i/scIODgX2tT3RmihRldSWopgGpfRnks9o1
      cTAhmhjEIOH2wNki7u0M9WT6ntSUw99kglZ2vQGlExp97NFuVS68LsGjdlOpL/Lx
      kYxZUap5NVU1CFQZRgeSKZYKGVanuAbSFrGp5dHdY33YXxUQ2POzzH/sZIRRvnFZ
      T11K4AN4O7NhO0nujJS9VDrNgU20Kxwxl9FsVMwjSDdlf8ZROVbkse1U/pGjchwN
      V+1j3wMzbu0AHCcqkMB5zny/6fLrZigclOTXgq/zFiwh4FjMYwraGIKIYpTWYQ65
      d+BfM3nb7j6otAQvrxiIyNe7dwWPI39OZeFk6krAQNg1Lm1cxWwqWiWgXpZAmQwd
      yNlgQ9WLjZqiKUI8uxYJB3IznpDjIvO7t8Fq2EmDF0L4/t2LTD4JIGPOlKBx0Abr
      5J9lI+2GLTk1ZRPpDk/7w/UJpSxoeGyo5+bI9RaWQRgzkpSLyPTlvipuBLgZefj2
      njEC13b2FdnupU2qhjTqptwh1t5qrOQ4COYehMFJyhHllu/S1gV53pdBQ3N1sw35
      R4YVFfBN+FJiRwiGq3vn
      =zxDV
      -----END PGP SIGNATURE-----"",
            ""message"": ""Git init, and parts of git fetch
      "",
            ""parent"": Array [
              ""1e40fdfba1cf17f3c9f9f3d6b392b1865e5147b9"",
            ],
            ""tree"": ""dd92ed7e55ddc0c74f467a8899cc281d909c6bb9"",
          },
          ""oid"": ""1c04ba2c3b7c61cdfc0ddc3f9515116bc0e06863"",
          ""payload"": ""tree dd92ed7e55ddc0c74f467a8899cc281d909c6bb9
      parent 1e40fdfba1cf17f3c9f9f3d6b392b1865e5147b9
      author Will Hilton <wmhilton@gmail.com> 1501454660 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501454660 -0400
      
      Git init, and parts of git fetch
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501381894,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501381894,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfUUGAAoJEJYJuKWSi6a51VIQAJPwVk7bFWbNoLbi9Hi931k3
      E6kGW8JnWwcT6Y7fpm0oNpoXt+UzqJdUhVTi+79ws3yKc0u1cA23nVXDUQYmNBT7
      3YkzXP2b6OE8i7n0ffzWbOIwHqWPn7lm0RlssSEYMAwGzDTP4fj2isRCFBqQ2lb3
      dqp7ZbzikvkkQONs9AKpE7LpWYTVuyElBwO2RtlIcZQrs29fBxZg4q4fkF+mqOhp
      DMWMIvTNeCa35sjmWh4+iPXO2CtoYVKXfCzZStzleeCuwQGRhfCLxrxtcuXOREjG
      DilGnCZ0iM9+ClzD4wDUf/aY3F5exyq2oqktIq78EhFvIIozY+gUaTn6zXicr5ud
      30QQP063Tf8wC3Cy95aEq9QqLYkMXhOYBDym5fWawEWo7ssmOIW1o0ISfSI8pTVZ
      bZr5f9gQZETlTWhSPh5IGqqdHrI2fw5pkmO1N/OEn4L8D7R8josty28V4+wk2gsO
      wUSPyBv7EpVx2JtO+9Wu941fZK2qOBBmTjcTYys9PQeY9UHtrTQ3y/1r/qdLpdUH
      9HK/x5yNHqpnSATHpRiZnfkvKfaxxwIbaOLBPV8khPa/zu9dD+0WxDXStLVBWfXg
      MvYAu4q+mQSgON1Qu+kWg67lNhx//kRH0K+vUMJMIvc8M+yUgkJhRqH/HIEzEcJV
      ee4fN2IIWX0CTNr8Fs8a
      =0Txp
      -----END PGP SIGNATURE-----"",
            ""message"": ""Initial commit
      "",
            ""parent"": Array [],
            ""tree"": ""421909592ea5e22c6dda69d1cc85118240478444"",
          },
          ""oid"": ""1e40fdfba1cf17f3c9f9f3d6b392b1865e5147b9"",
          ""payload"": ""tree 421909592ea5e22c6dda69d1cc85118240478444
      author Will Hilton <wmhilton@gmail.com> 1501381894 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501381894 -0400
      
      Initial commit
      "",
        },
      ]
    `)
  })",snuts
/__tests__/test-log.js,SubOptimalAssert,"{'startLine':252,'endLine':252}","it('HEAD depth', async () => {
    const { fs, gitdir } = await makeFixture('test-log')
    const commits = await log({ fs, gitdir, ref: 'HEAD', depth: 1 })
    expect(commits.length).toBe(1)
  })",snuts
/__tests__/test-log.js,SubOptimalAssert,"{'startLine':262,'endLine':262}","it('HEAD since', async () => {
    const { fs, gitdir } = await makeFixture('test-log')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      since: new Date(1501462174000),
    })
    expect(commits.length).toBe(2)
  })",snuts
/__tests__/test-log.js,SubOptimalAssert,"{'startLine':324,'endLine':324}","it('has correct payloads and gpgsig', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-log')
    // Test
    const commits = await log({ fs, gitdir, ref: 'HEAD' })
    expect(commits.length).toBe(5)
    // Verify
    for (const commit of commits) {
      const { valid } = await pgp.verify({
        payload: commit.payload,
        publicKey: `-----BEGIN PGP PUBLIC KEY BLOCK-----
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=QSo+
-----END PGP PUBLIC KEY BLOCK-----`,
        signature: commit.commit.gpgsig,
      })
      expect(valid).toEqual(['9609b8a5928ba6b9'])
    }
  })",snuts
/__tests__/test-log-file.js,ComplexSnapshots,"{'startLine':17,'endLine':80}","it('a newly added file', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'newfile.md',
    })
    expect(commits.length).toBe(2)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""araknast@protonmail.com"",
              ""name"": ""araknast"",
              ""timestamp"": 1653969605,
              ""timezoneOffset"": 420,
            },
            ""committer"": Object {
              ""email"": ""araknast@protonmail.com"",
              ""name"": ""araknast"",
              ""timestamp"": 1653969605,
              ""timezoneOffset"": 420,
            },
            ""message"": ""update newfile
      "",
            ""parent"": Array [
              ""dcb1c5fe6cc28e7757c4bc4d7dbf5b061c38ec48"",
            ],
            ""tree"": ""331f342f6e9b38c45e17189691134cb4a72189d2"",
          },
          ""oid"": ""04833cdb10e0f8fa81800cafa98e1381a1c6c58e"",
          ""payload"": ""tree 331f342f6e9b38c45e17189691134cb4a72189d2
      parent dcb1c5fe6cc28e7757c4bc4d7dbf5b061c38ec48
      author araknast <araknast@protonmail.com> 1653969605 -0700
      committer araknast <araknast@protonmail.com> 1653969605 -0700
      
      update newfile
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""araknast@protonmail.com"",
              ""name"": ""araknast"",
              ""timestamp"": 1653969041,
              ""timezoneOffset"": 420,
            },
            ""committer"": Object {
              ""email"": ""araknast@protonmail.com"",
              ""name"": ""araknast"",
              ""timestamp"": 1653969041,
              ""timezoneOffset"": 420,
            },
            ""message"": ""add newfile
      "",
            ""parent"": Array [
              ""18f202dfed5cb66a295dc57f1f4ba1b7f6b74f36"",
            ],
            ""tree"": ""59c1caba006bb27077d11f1c0ff7ad3ff4b2b422"",
          },
          ""oid"": ""dcb1c5fe6cc28e7757c4bc4d7dbf5b061c38ec48"",
          ""payload"": ""tree 59c1caba006bb27077d11f1c0ff7ad3ff4b2b422
      parent 18f202dfed5cb66a295dc57f1f4ba1b7f6b74f36
      author araknast <araknast@protonmail.com> 1653969041 -0700
      committer araknast <araknast@protonmail.com> 1653969041 -0700
      
      add newfile
      "",
        },
      ]
    `)
  })",snuts
/__tests__/test-log-file.js,ComplexSnapshots,"{'startLine':91,'endLine':229}","it('a file only', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'README.md',
    })
    expect(commits.length).toBe(3)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509836,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509836,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77B8wACgkQEPFehIUs
      uGi0CQ//ciB5DDcHppFv1caaOiEYUos8oc871eMMbXtl+y9eTfzN6VEwpXY8matE
      3hxMpe4YAUpivfQ3a75d5MEy5iEpF/U9rCkWBlGpdqG3+rvmrvpQXo+PZEzdP84E
      7rz1Ue2PnfivXCzo2zvDoyMLWqFbNgxXIwr0ST2SxuBTsVIwF/6y80uXa/8VQXfK
      MBCFKKcBK03ruZAWiLIwMNvYTxDIMvupRIN2rzyRpOb8lCSWmyw1/eqzF5soVy62
      HraCZlK1iyv9XaL0qn+SlAGYYsJylp8sfLUmU0y2qeEtLYdRLS25yRAK9h7l5RD2
      qTmQwPb5vx1ldFALr90qgVZc3j7xI5xnL6UtiMGSoZM+HuJ3eioOisXf0aAaxr6U
      ImY98WAIPuAAx6rUhHP27r0w0hDABFZmrMtO7FkH6wcqM2LJIweLGFZtKXePmR14
      CH4cQw4ylSjtrcQFguUF7rvz0sX69IeDTTF2ppaH9uQclL+3F0Bj78XiH9Dflx4E
      6+HfY98tdLPcjGfcdAguLBbKZslmYz7uUeqvHyrgVER6xMFcrGR7IUPLI0IWjtqY
      CL+5+gxD2O4FIUhY2hwISLHx+cWsCsAmiBZKx5OhQeW9nn4D8ex4WQK/go7iCrEe
      LnuTba+0qmNBTF7f7a+U0x1ReeipUk19bEuP7P1K7Ppc1C+BYT4=
      =nAWS
      -----END PGP SIGNATURE-----"",
            ""message"": ""feat: update to readme and hi.md
      "",
            ""parent"": Array [
              ""8e98db35c3e3e01014f78a60786b1b3b96a49960"",
            ],
            ""tree"": ""281d4cba64e37323777e7f3ee222d504ed8fa0ea"",
          },
          ""oid"": ""bba48a582aaa7e572c844cf7f42f3cd03eab81f0"",
          ""payload"": ""tree 281d4cba64e37323777e7f3ee222d504ed8fa0ea
      parent 8e98db35c3e3e01014f78a60786b1b3b96a49960
      author Riceball LEE <snowyu.lee@gmail.com> 1593509836 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509836 +0800

      feat: update to readme and hi.md
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509669,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509669,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77ByUACgkQEPFehIUs
      uGjJYQ/9HNh4TJO/V+ckTyMDzf+Z4Aih6ytn63ispZnfbKb5hPEV+eG1HRuPthF4
      kNilem8w//QYbllbih9bbw3tKvh2SaWYHIOEDI6eA/1k5Bd0nYLi5HNWZG+bOZNR
      XdDI+yPBAQSl4607S2xGeOH7HrSzVSVbheDjNhwYBiRDOvbFxhx3Sc/G+vO8IfdU
      MCLzVhwizNNclKIMWKaUSpBpJuqxsRK4oINT8wJQLB4LRQ/M2CXgjSjZt0e9NtFl
      +6OxGKBbgioNMg6TXzvmqFJ4eqGk1tgMz/qYX1zjCRR2jZ1g/anht8OJRppdz2/0
      k87EN+lLpN5H/Z2tSJMrKBHaCJWo72vrcyQzpLjtVUVdHNdOB66+60yqSDZiz7pc
      1ou/9jM3cbtEwtvaD+W/JJvG7ctFOM7efM3iGghW2jccJ7Ku/DIlxwCXE6HNCjDf
      azPFqO0Y9fw7ZoJl+D7sotea2xaWMhxspUoHxtnYxah6tzJ6KQ8eZ4GR8FoMw2dj
      szUaHVtLRg+Nx/G5YWimOFNUrgA3lQYjh9+fgvodxhIQvd9KVW/qCdX6ZQM9vDXU
      o9d+QEdd/hzkMrOEHscT3nqKgeIEj6JSBg27kDraM6L0dAP4wCN/9h2dbR2ke0j2
      im+CRYtkgJz5EpJ4uN1B7SDUvdBrjYIzC2Aqiohh6M2ehP1in7g=
      =IvVn
      -----END PGP SIGNATURE-----"",
            ""message"": ""feat: update to README
      "",
            ""parent"": Array [
              ""533131624898bb8ff588b48c77b26d63e7eb180f"",
            ],
            ""tree"": ""2ed69fff23ee6e239744c7277ab80bf40a644ece"",
          },
          ""oid"": ""37c51dcbe78dd2fbdca15cf74c6c540f879a5bbb"",
          ""payload"": ""tree 2ed69fff23ee6e239744c7277ab80bf40a644ece
      parent 533131624898bb8ff588b48c77b26d63e7eb180f
      author Riceball LEE <snowyu.lee@gmail.com> 1593509669 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509669 +0800

      feat: update to README
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509547,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509547,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77BqsACgkQEPFehIUs
      uGj/oRAAmOMhskEjKwcFaEnC7InU/UMd4PHAy3XlKwqUCiQVEJWWi6B81n5IYsWi
      mDOKXGYenlYOAf0HFqs7nPBeINDRFQp03d01wZT7JgacpERCvvu53IHLH8ndJehL
      MQaRtWV/SpScj4OZH4Wzm6tjB4IBB/agZWM67tU4KKI2i6TOhQw8ktBoXbXGWO9g
      OwjHW4mZn5eggIhyNzNKWRwzImopYlcBGqtYil5l4LWXADBfxAYfBCA296HkiD1N
      sFzsi5mak7bKyW5/dFI9uP27BQSLLbGdbJIJlkYXi8XIo/sLPJGA0BHuiNLAVXUn
      E/CO4hBH/tZtJNk3jg0TPLey4Lh34d3Tw8+6z6CvMKQtZ9JUXy8rAWMvAXg0+YVp
      IvT+xA6HxECuBZ6UAYLU1ZHAvQtZch6XhJTirOJ5SMklTNKSiGaCLfDP/iuRWOYo
      4x52uwkInIuintkcIZocjwEQ5DsG6jO4ylbwmEaWgpzEuR7xOuIBx38dsCoSDD+D
      kyZF7ijammlt5Wc6A2u7ewEgCEy/GMEMJ+hUXqhJJ9Gi2uYU/WmC9GJDqD12JsEa
      m6FFvEd+zCH/9K+O5eBUS9WFpiwXPP+amaXGBWkXnlbEYf/j9QemZXi/dkn1qCE7
      yM9yzr8Tb0dJWqvovK42AlCuYsZ9BYOBM3zz+pGhpSdES9OYO08=
      =/hmk
      -----END PGP SIGNATURE-----"",
            ""message"": ""first commit
      "",
            ""parent"": Array [],
            ""tree"": ""5640888e247e986136d36b1d52a9881abc7170f6"",
          },
          ""oid"": ""8651dcc28c58d96439e99aa2bf239bf2ab238b73"",
          ""payload"": ""tree 5640888e247e986136d36b1d52a9881abc7170f6
      author Riceball LEE <snowyu.lee@gmail.com> 1593509547 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509547 +0800

      first commit
      "",
        },
      ]
    `)
  })",snuts
/__tests__/test-log-file.js,ComplexSnapshots,"{'startLine':257,'endLine':533}","it('a deleted file forced', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'a/b/rm.md',
      force: true,
    })
    expect(commits.length).toBe(6)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593652995,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593652995,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl79NwMACgkQEPFehIUs
      uGh+EA//f+cNby3i8IhD5LL5elmR6qp+KFNLQMEa7nvcUmYQX2Ffx4QAN0WtPQ+O
      y6PmrQg5MLfCPzANthY3oKnkvjIYbpnBF2JTeN2HA8mF8/HtGakMfeykkeuaGP6V
      Kdk4I2jiXC22g/Zy7VAzbYdJTk96yWw71lpufQa1voy8ykCCu/YgeO4EjQME2RYn
      82W9+X4Qxx5bu0C0lKMwfdhAcR/MDTye0jbu33krwnuXsNyA+6OKBIOfIAWK8PWY
      iTwvkfQ+61T0dGFAdi8tJCfGZ6JRBf482KHR/gSwmwq59g7quS/snnybB6kGwrqZ
      tScHZ6Sy08xHYRbibV8HmOAyIBKZr1ZPtEjBx5Aj6Q4qKsTkZ3Q5ZTTi8Ayhm1SM
      y1mJ20d3B0WM9F48w0a8qbKxNn7zefW88QHq3PB6wdGechkZ/Wq0xN2z/h3Sl5W3
      ZSmJcvgMFJwc/p7ci2spkR+ibVnFNdvn0xinUvrJGftFuiEqlZfHwo1t6KkmX9st
      X7+30WwKmotxgeBfV0g1Br4YpaZTKJc5V2JkU+gtjnIlb/7XU6eWm+vCInad5QdL
      NeiYCPsrT9ejboKghAIteNNfiuauiRnpZ/06H5gi2OVeyChA1urD/pKjJyaNllbh
      XZTv9Wqzt6oQzR6FV0HH5H9ACqOnCJXsTUoydzt843MFHmPDL0Y=
      =77Yr
      -----END PGP SIGNATURE-----"",
            ""message"": ""redel rm.md
      "",
            ""parent"": Array [
              ""91e66ded3cee73f5f181fbd0e7a4703f1c12bb9f"",
            ],
            ""tree"": ""7ab59df3bfd122ef5d24c70f9c8977f03b35e720"",
          },
          ""oid"": ""9a4eb099547166c9cf28628a127cfc9e59fa4f29"",
          ""payload"": ""tree 7ab59df3bfd122ef5d24c70f9c8977f03b35e720
      parent 91e66ded3cee73f5f181fbd0e7a4703f1c12bb9f
      author Riceball LEE <snowyu.lee@gmail.com> 1593652995 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593652995 +0800

      redel rm.md
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593652652,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593652652,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl79NawACgkQEPFehIUs
      uGj7BRAAjZjpjaP6Kl++qtsHS5GdzMCVyocVOE+UCOWU55ImjJI9g2ajlnWfIUuM
      oZTFCG123eY0vGtXTCpcrNUPO3QvVtkIlZybMMFcJJMoENWjQ1rWZEVX4UK/skkM
      kKt1ZFVJHfgLnqsFGcyR5Fmr9omm3faVinyIxQhhdNxIYV44x4Uj5IszZul4yeQr
      NBdrPpmChT53ST3+WNp1/c7iSeMjUpXO+CVkmmG0kieThJgKBqkBTlholwYrVCgS
      B5MTgVzLh9NGoJHs+9Qd5pze41tIPNJbCWtWimoOdWJTo91L29qT747tNC14v6zh
      dkemZgUsO81lq96WiTekDS2E9PDWVWk1mi2XAXrsQ8OqDKYDwkLQa4GvlxjQrNEU
      1FG0btHD0ddYYEwBN4uK5wsXA60i1qDetggGT+CcYi2yX4MqFCI4GJgf4Oj0htht
      ltX7fMFZu5sKSOd1vLE8RxS2c4IgNQZ4ZFCAW1mfBAV31RLXG4BH1f/4laKvMrKO
      5EUufJcPIW4vKAXVVGyPMgenkEUrXL/ImYt1kuSAMx2pffahWQzaF7rTXAWO2YK+
      bqajFbubxMPbDPW70pnYQJLwuLve2IqBbPsMghx+B30F0PzCajg3XvJv7ZdqodSE
      wKn2DCea/8Rj7O/GYRPJJtJ8ITwhGMLxRC5s7j6mJAxj5IdB2fw=
      =z3mu
      -----END PGP SIGNATURE-----"",
            ""message"": ""feat: readd the rm.md
      "",
            ""parent"": Array [
              ""1bc226bc219beea3fb177de96350d8ad2f4c57cd"",
            ],
            ""tree"": ""e7bd10ca01b3377fa6fbe633ce104698b5d7dd29"",
          },
          ""oid"": ""91e66ded3cee73f5f181fbd0e7a4703f1c12bb9f"",
          ""payload"": ""tree e7bd10ca01b3377fa6fbe633ce104698b5d7dd29
      parent 1bc226bc219beea3fb177de96350d8ad2f4c57cd
      author Riceball LEE <snowyu.lee@gmail.com> 1593652652 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593652652 +0800

      feat: readd the rm.md
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509970,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509970,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77CFIACgkQEPFehIUs
      uGicBhAAr9NDElwaYSoKk8ayUnlO00E/Kr555Xr+/U0wgfXBoVJoDbVSsIi3IhzZ
      vkWJXVeb1puUyyhYR4o2gdySJ3u3kcpj1xLIeXp+gvNftJyOaCN04m6Hnay2eMXS
      9vZX55PppFXS0B1lB9L95k6ciJEVnoKjEVT1mDunmo1G932qrs6QkU0smKJ7M6fm
      cEonSzi+VCpcACs4toN4PMhrFdPvFEvYK0iG8LXxLkKV+bhmKPeD45TKhJTAfjvV
      86SltUU1ftyJTu2FxsuWeMzxAw57bI/xET4eHVboOnWp3cSPAWX2Mc5H5yWBzRZy
      cPwDIwwvj0WSOtXOWJMW743O+29sNSKZZjoLjrSpwrYWnNYT4ThzdGvKvl2XD9uM
      vzZWgQihdT+My0qXLVuDMAnH56jeUN/fdiBw2oxK+sDMiwssD4Y3GulTQ7o067aU
      dqVCeV0LXTXmLUCvkbSwbKnxRRRxdA/OowH0NDbaYyjMoZ7UqBYiF5M9W1bcB9Op
      RCAfWVB7U7gwgu0PO70g6+LUr1lS+1UnszIvopwsqo301O1qTQBzM4ftuBwQa57P
      SHDxCpZ7bBObayNmW+PLkZSwc/Ak+uGzJdJkVrOA0kq2rlsLxnbysj1XxohIQsnQ
      +RZMMYcW8eev2DeDB+vtr94O8bxQZOH3cfx5gbxvRX5ixG5dn44=
      =8VVM
      -----END PGP SIGNATURE-----"",
            ""message"": ""fix: remove rm.md
      "",
            ""parent"": Array [
              ""58aa7508ff84bc25552b4576b1b5ab0ddc5e41dd"",
            ],
            ""tree"": ""b0904e4ea2e2548d0ebc5c9401b8a0390c0888cd"",
          },
          ""oid"": ""2584400512051e6cb07fda5ff7e8dde556fc3124"",
          ""payload"": ""tree b0904e4ea2e2548d0ebc5c9401b8a0390c0888cd
      parent 58aa7508ff84bc25552b4576b1b5ab0ddc5e41dd
      author Riceball LEE <snowyu.lee@gmail.com> 1593509970 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509970 +0800

      fix: remove rm.md
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509879,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509879,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77B/cACgkQEPFehIUs
      uGj+hxAAhidyrgiKXUdOh038Wvho48rd0opD2b+1C5kUpjSIrnd+7zKAS34Grveo
      wjdUsk4/Ao/qNLrZHuMwdca9KMt2bywc6X8AToNZXIapXvow3wj/1w9wtxeLyuaR
      7HFFVxBtVHZ9pntMvr5GXUMLqvm8sxXyOQVFxCjXgBCkFku+9Hi9PdTlt5PIvQ5C
      8ORynFVcdl8JPGYe510+lPSZVdgB/lrfDpyFwa1cnpVzXiefQFGSbNDYvh5DUnxv
      5cDmXLS79HFJg+9tnkOeMqKiSPvJU9giPE/Thrq1RYBk+rvEJA8yfl/QdFQBiFp0
      gOetxGoaJestpWNDh5qaCNdgyH3UwP1eR17WUFwR6f9wTaRwUlY8KkDbELjOn5IP
      jD7QopZPCbhSiEcC+5aER6Cfcae1DtQnftG3A/PpNlVRYAdZY/Ls8rxFsac1tdeg
      Q/0a6fpOG9WtsTXyzIvwk+b8ddJshXVslxLWj8Zw5F/PH27p4yRfZT0UscApO3Gf
      xX/nh+4Rs8/BDu8jmUMpJmqR3RVO1WnyShNgB2ONGaDc17bcGNwSz7IKnN5MXOZ6
      HCTNCtysIkl6uKAHq5TydZxz6LVwq+d62AVy1dKnVUqqLySOb7PLiWwZ06Qsvyfq
      iKPeOnlFPUrRBvNdtTfXpRpb4gJ1OJBxsvuxsApr2+vh1be8PCA=
      =Vmf5
      -----END PGP SIGNATURE-----"",
            ""message"": ""feat: update to rm.md
      "",
            ""parent"": Array [
              ""bba48a582aaa7e572c844cf7f42f3cd03eab81f0"",
            ],
            ""tree"": ""996a1c302a71aeeb3ba865c1a8720bbec39657b9"",
          },
          ""oid"": ""58aa7508ff84bc25552b4576b1b5ab0ddc5e41dd"",
          ""payload"": ""tree 996a1c302a71aeeb3ba865c1a8720bbec39657b9
      parent bba48a582aaa7e572c844cf7f42f3cd03eab81f0
      author Riceball LEE <snowyu.lee@gmail.com> 1593509879 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509879 +0800

      feat: update to rm.md
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509597,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509597,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77Bt0ACgkQEPFehIUs
      uGjwEhAAt+YBPtElFAv+hs5ybANPDKncpDdzYwJ+55aVG/RiWtN51BLj19pGm7Wg
      lxw2NUPPaFkeMvsula7sS8kgDeuEnpapkoBAnPDUUon5KtLR77qn6JGAvdl6EGDN
      x1Vyb3eOTjM0bW34gNTaAS6cHGhjmFFvX+w1Q1i0/kXBzn+/Gzy9IJTxYpoPYm0R
      IIZ+FI34hb7/UV6UjEqT9JqbRq8NQMr4nV5IQeEFBkBW3k9lPkoJvKAk585nGcaG
      NrqFCYI+S1RGChW1JO9dK9iNagvcEp5q1qs3R0Qag5ddf4502gQrHwIrvJBhiRXf
      kg5SBYae+C+UedUEAMI7kEDvzJY2n3s/l2T69HcrCL/0Uzay9hHF7+uQUoXMz+og
      u8kPJSMxEa5Ay2qThFL425d0bv7fm99kv8tVZrgDGAORF7F6cEj+0zAXrG66q7+C
      3zby8ZOtBo5m9lEXhKWfkg3qjHBWSIEzFSf2sIsHZwMwaP/UX4bHc2+gsU4ZuSV9
      ERuEM5rIcbUywNtVDCvRgyABNf+R9u1+OlbEE2gHkso1DiWzVhJl8OgoohNeQ6ve
      usuE81K6Hl0RXFPZEGiP9+VvBKegZr+TpChj/U9Xxg5Xo8h1IJofq+pcM7szyiW+
      XjQ2JObzauS9s+vlQZ3k01acgUxXF+izIb3JLWgZPo8ZQW57evA=
      =8Fqf
      -----END PGP SIGNATURE-----"",
            ""message"": ""feat: add content to rm.md
      "",
            ""parent"": Array [
              ""8651dcc28c58d96439e99aa2bf239bf2ab238b73"",
            ],
            ""tree"": ""c8a2583e243cfdd458a6ff40ff6f7a2d57fbaa96"",
          },
          ""oid"": ""533131624898bb8ff588b48c77b26d63e7eb180f"",
          ""payload"": ""tree c8a2583e243cfdd458a6ff40ff6f7a2d57fbaa96
      parent 8651dcc28c58d96439e99aa2bf239bf2ab238b73
      author Riceball LEE <snowyu.lee@gmail.com> 1593509597 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509597 +0800

      feat: add content to rm.md
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509547,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509547,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77BqsACgkQEPFehIUs
      uGj/oRAAmOMhskEjKwcFaEnC7InU/UMd4PHAy3XlKwqUCiQVEJWWi6B81n5IYsWi
      mDOKXGYenlYOAf0HFqs7nPBeINDRFQp03d01wZT7JgacpERCvvu53IHLH8ndJehL
      MQaRtWV/SpScj4OZH4Wzm6tjB4IBB/agZWM67tU4KKI2i6TOhQw8ktBoXbXGWO9g
      OwjHW4mZn5eggIhyNzNKWRwzImopYlcBGqtYil5l4LWXADBfxAYfBCA296HkiD1N
      sFzsi5mak7bKyW5/dFI9uP27BQSLLbGdbJIJlkYXi8XIo/sLPJGA0BHuiNLAVXUn
      E/CO4hBH/tZtJNk3jg0TPLey4Lh34d3Tw8+6z6CvMKQtZ9JUXy8rAWMvAXg0+YVp
      IvT+xA6HxECuBZ6UAYLU1ZHAvQtZch6XhJTirOJ5SMklTNKSiGaCLfDP/iuRWOYo
      4x52uwkInIuintkcIZocjwEQ5DsG6jO4ylbwmEaWgpzEuR7xOuIBx38dsCoSDD+D
      kyZF7ijammlt5Wc6A2u7ewEgCEy/GMEMJ+hUXqhJJ9Gi2uYU/WmC9GJDqD12JsEa
      m6FFvEd+zCH/9K+O5eBUS9WFpiwXPP+amaXGBWkXnlbEYf/j9QemZXi/dkn1qCE7
      yM9yzr8Tb0dJWqvovK42AlCuYsZ9BYOBM3zz+pGhpSdES9OYO08=
      =/hmk
      -----END PGP SIGNATURE-----"",
            ""message"": ""first commit
      "",
            ""parent"": Array [],
            ""tree"": ""5640888e247e986136d36b1d52a9881abc7170f6"",
          },
          ""oid"": ""8651dcc28c58d96439e99aa2bf239bf2ab238b73"",
          ""payload"": ""tree 5640888e247e986136d36b1d52a9881abc7170f6
      author Riceball LEE <snowyu.lee@gmail.com> 1593509547 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509547 +0800

      first commit
      "",
        },
      ]
    `)
  })",snuts
/__tests__/test-log-file.js,ComplexSnapshots,"{'startLine':545,'endLine':732}","it('a rename file with follow', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'a/rename1.md',
      follow: true,
    })
    expect(commits.length).toBe(4)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510674,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510674,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77CxIACgkQEPFehIUs
      uGhgYg//c7Add1QPUgdVP11OSH9MGAyxjLes14+g6lyf+5raDa4bvQAgRVydiqbt
      yI9SKwDni7HkZUK9CrqDtGwivvDjNK7n0R+ebNXRa4LYPrm9v9Htd6AqFNpSU6LG
      Fvi/AQarINtnSt7prKAExgf4Dt9Q9tZrVLqNIxi/6AMq3yQHwcDb6hKubaAkXWdw
      fkjmkUKtSSzycUy2HdrDSWX04frjN9ostqZHWQRvEztI1DdStwMIGMWibDioJoi+
      xlT1I28NvRtF0hgGgjFUQoa5xN7WwVYpx2byXQdfFavhZxqfQjnR0MMyIouIBxGQ
      aQGQNNEAgzVCMcnbTynLyZuG31daIS55AuoHS73RlTn+cJey32oblvnWRje9x7Vo
      J52QpRJPu4CTWQM75vc43n9acZYxATNCr/tEW8SIb4PVR5q0lfh6M1+MyfHxNJrp
      iRLkZaOlSsXxdU+oV5rcFg7YlpDIaqHBWTHjffqSUvBQ26S0Wot5W/kNkua35qcl
      S4fomYCphl/zAxyp+O31MQYCS36MObIM3FXEGdfm1c6XWtrAhtMPTKtsk5YB2ltP
      7MmLM1OwKltT6b55+RUnmQ4GyN92xIop9JMgDNDQfln/TRW73DaDFZt7OyZOZxQm
      qkdT/ALm0qLz8iPf4q0zBbSd0e4RnYxD0FwfPQ7aVMAA77hzMoA=
      =1cFE
      -----END PGP SIGNATURE-----"",
            ""message"": ""update rename1
      "",
            ""parent"": Array [
              ""cc9bcf734480b44d2e884ae75a11805e42c938d8"",
            ],
            ""tree"": ""7ab59df3bfd122ef5d24c70f9c8977f03b35e720"",
          },
          ""oid"": ""1bc226bc219beea3fb177de96350d8ad2f4c57cd"",
          ""payload"": ""tree 7ab59df3bfd122ef5d24c70f9c8977f03b35e720
      parent cc9bcf734480b44d2e884ae75a11805e42c938d8
      author Riceball LEE <snowyu.lee@gmail.com> 1593510674 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593510674 +0800

      update rename1
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510498,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510498,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77CmIACgkQEPFehIUs
      uGi8fQ//VBw8UB5s5UvklkBbhhF/D6UsaH8ry1GU5fQoUZlf7ouBiKkdLv0Sqe7P
      dTsohbo1FGHK/+shXddsL9fsp9yQgySt0Zck7HcG2hM8TyeHycsHIZf2jdkfqWob
      3mjl2YoQLnht5z5+PoN7mHm6a4cNqFpKnQsHXuIMKjZLnvGDkgUOlxCiNrFsMmAx
      sho1ROVR+TCkSi8KrR66CvA6a8sIRVib7Y93WX7QgpFQgw24ZbpZvlDR0TjullLi
      df+9TBOEg89oZFtPBvpdURFSKltl6PMS7WnAoXgIFRAnwM5PnPZHkA37GanmSrj8
      awLBkCapWuTF4/K+Bhu5hfURRac6IPJi56ygQWKpThAwk3h2L/saKTJFqD9vb/Go
      +FM/fmex3lOGbVbZs1EtvkKwYIAb9pWKIcsnpzH6L6PrQE7DsLX2NP23hwMsXRt6
      9vQDUuY8Dd45ttM8XPcVP0bM5C4PqmCErxXVFLcuLUtkF98RaUNnEdkDCo0yfojF
      eQqn74zmQ0c3Q4WufxKM+4kQ1EflScv4uxOuBraj3hFcyac4u1CyLD0sv7InkdRB
      T0iS+pLIyaJQIHV4AximpRISitVGuYnNtSuTrJJDmjmGGSMyC/jCsDrr1t0lMxdb
      vdDuh3t+Ch9rvXHEPtnIokOW9U+hrVIeIGeiD0KM5QHD2CjcgwQ=
      =2hns
      -----END PGP SIGNATURE-----"",
            ""message"": ""rename it
      "",
            ""parent"": Array [
              ""b9a8e7ed4e394942ba0a45f19563e8ad90b94ea9"",
            ],
            ""tree"": ""641ca0a41cfbccf4fb5c366840270fd25ec48b4f"",
          },
          ""oid"": ""cc9bcf734480b44d2e884ae75a11805e42c938d8"",
          ""payload"": ""tree 641ca0a41cfbccf4fb5c366840270fd25ec48b4f
      parent b9a8e7ed4e394942ba0a45f19563e8ad90b94ea9
      author Riceball LEE <snowyu.lee@gmail.com> 1593510498 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593510498 +0800

      rename it
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510465,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510465,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77CkEACgkQEPFehIUs
      uGiGZA//Y5XlL5XeP05m7Jp2h2GBOc1nF6W7AAxRUSintdiX706aaoSAbVD3PwB3
      zMuGiBIePPvQk+Oo+U8E0h2cD0bIY13BHJ+z23Qmn/1I1Vtup9uuWRCDR7T1Gy0r
      3rUsdtyuZ3qIjliCP/j5254x6hspIUVBFUeHd/BWTWIimKIuYKRg8am9qNn2Dhir
      o889/ZKuImsgF1eNsIaqlWN71n8KUGmDNcTdQ7eZzk4wUSsASyWRvnr3+OYkhjTp
      ffJubsdA+FvixxCM8kg6UAoOFlMzJapVi/AdLXRQ6758tEpTPWdz2WVxrI3P1ACq
      HzqvSIDoEISZDkKw/5maL9/89dV0qSuJcv3EqZQKxB3I7DAQgseHBAgThtChtdkh
      a6OrCIkeJyNjQhgXpqtIJ71P6mVTDNnveDWO+9OilCrHfLa3nqYCz+xPZ2txRwG/
      Z6+491WZVJAzU9rICT9AvrDpllacofr95LZCYdLd5J6qTYxq4m92AoZLOq5iKH1w
      nCYyrfswZolEmbq50MhD7JdZKE3IPf5sfZfU+X4EfPYkr//P5M6wGzYVXYv6KttJ
      jsekDsWczkATsKkp0xiC0lRVMNYwxl2Ly03JBZ/U2lBWEKhDgz1ELKa1XM9qEqSH
      CbwmGwIWyAOFmjkBjWUHIqrm2zQFskpXu4a+03dqV5pCQlsf4qs=
      =qvhP
      -----END PGP SIGNATURE-----"",
            ""message"": ""update rename
      "",
            ""parent"": Array [
              ""01cd249eaaceb8572bee5b24d8ed728c95f61bd6"",
            ],
            ""tree"": ""b76aafd52bf2d588756a32ebc9fa1ae0e68052c9"",
          },
          ""oid"": ""b9a8e7ed4e394942ba0a45f19563e8ad90b94ea9"",
          ""payload"": ""tree b76aafd52bf2d588756a32ebc9fa1ae0e68052c9
      parent 01cd249eaaceb8572bee5b24d8ed728c95f61bd6
      author Riceball LEE <snowyu.lee@gmail.com> 1593510465 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593510465 +0800

      update rename
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510416,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510416,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77ChAACgkQEPFehIUs
      uGj/rxAAtVD1LSNM4gfyHQQB8G/E4JWmqoTlOJlC2s+zZRzMUgKPPqItt4p4FFMs
      4GstDmVhGVKNpZjCkzZUX5N2Htm6PzWDdjtI5t+yl1rLfCR73VQKA/ztdUT2w1tg
      jewPYRht9VrP46MqCxbnUpdt5zYhshGa3/Q9WRy11rakvjrbF9S9jKP+qiNyS1X2
      3LGyDNQlS7XymSUFz4PSiOVTEpkSoOuGM6PnOhzmdNgl/JPY2vVCFcejO+qDq2K+
      0EbLH6Ab0r7EiFQXufOSR0m6i3SXnfg66+ttiW5Olm2yfT0H05flvHUp93aeAoYf
      qOvnSR5nX4jzQaLyHBvSWlotNfAgLSgLVZlUSoShYjRm/4UuFShZn546ykEZ1vTZ
      rMU5PNvu8pqhCEneHnl7WEuxrlxt10vwtzWDUalaUZgNKXoIYDWISpVfzdOEuOu3
      xNaH1GwZuGEtGZbDwOzsdTkJC5OTRzkb5c0SF/wlCUaW6rWW0J1cc/PX3bi4euwH
      TdUe8v0KT2jX275FjpzvCQixduMrM9lm6vwOYSWplk6Au+v5ot2vaGob2ok5dMIP
      Ai2oopT87heuC/iPcL2DKES1TItiXbRvYYu6jB3qCxD2cQUFxXgYyTuAnS3uSnhx
      w89ElnO5qtr32gZ5+609hodFg8zrxZWxXxpNcIHfTgh17qHZuPg=
      =iSgt
      -----END PGP SIGNATURE-----"",
            ""message"": ""add rename.md
      "",
            ""parent"": Array [
              ""2584400512051e6cb07fda5ff7e8dde556fc3124"",
            ],
            ""tree"": ""8ad18556d7692aef283e7cf30a287b6010c362a4"",
          },
          ""oid"": ""01cd249eaaceb8572bee5b24d8ed728c95f61bd6"",
          ""payload"": ""tree 8ad18556d7692aef283e7cf30a287b6010c362a4
      parent 2584400512051e6cb07fda5ff7e8dde556fc3124
      author Riceball LEE <snowyu.lee@gmail.com> 1593510416 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593510416 +0800

      add rename.md
      "",
        },
      ]
    `)
  })",snuts
/__tests__/test-log-file.js,ComplexSnapshots,"{'startLine':744,'endLine':839}","it('a rename file forced without follow', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'a/rename1.md',
      force: true,
    })
    expect(commits.length).toBe(2)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510674,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510674,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77CxIACgkQEPFehIUs
      uGhgYg//c7Add1QPUgdVP11OSH9MGAyxjLes14+g6lyf+5raDa4bvQAgRVydiqbt
      yI9SKwDni7HkZUK9CrqDtGwivvDjNK7n0R+ebNXRa4LYPrm9v9Htd6AqFNpSU6LG
      Fvi/AQarINtnSt7prKAExgf4Dt9Q9tZrVLqNIxi/6AMq3yQHwcDb6hKubaAkXWdw
      fkjmkUKtSSzycUy2HdrDSWX04frjN9ostqZHWQRvEztI1DdStwMIGMWibDioJoi+
      xlT1I28NvRtF0hgGgjFUQoa5xN7WwVYpx2byXQdfFavhZxqfQjnR0MMyIouIBxGQ
      aQGQNNEAgzVCMcnbTynLyZuG31daIS55AuoHS73RlTn+cJey32oblvnWRje9x7Vo
      J52QpRJPu4CTWQM75vc43n9acZYxATNCr/tEW8SIb4PVR5q0lfh6M1+MyfHxNJrp
      iRLkZaOlSsXxdU+oV5rcFg7YlpDIaqHBWTHjffqSUvBQ26S0Wot5W/kNkua35qcl
      S4fomYCphl/zAxyp+O31MQYCS36MObIM3FXEGdfm1c6XWtrAhtMPTKtsk5YB2ltP
      7MmLM1OwKltT6b55+RUnmQ4GyN92xIop9JMgDNDQfln/TRW73DaDFZt7OyZOZxQm
      qkdT/ALm0qLz8iPf4q0zBbSd0e4RnYxD0FwfPQ7aVMAA77hzMoA=
      =1cFE
      -----END PGP SIGNATURE-----"",
            ""message"": ""update rename1
      "",
            ""parent"": Array [
              ""cc9bcf734480b44d2e884ae75a11805e42c938d8"",
            ],
            ""tree"": ""7ab59df3bfd122ef5d24c70f9c8977f03b35e720"",
          },
          ""oid"": ""1bc226bc219beea3fb177de96350d8ad2f4c57cd"",
          ""payload"": ""tree 7ab59df3bfd122ef5d24c70f9c8977f03b35e720
      parent cc9bcf734480b44d2e884ae75a11805e42c938d8
      author Riceball LEE <snowyu.lee@gmail.com> 1593510674 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593510674 +0800

      update rename1
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510498,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510498,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77CmIACgkQEPFehIUs
      uGi8fQ//VBw8UB5s5UvklkBbhhF/D6UsaH8ry1GU5fQoUZlf7ouBiKkdLv0Sqe7P
      dTsohbo1FGHK/+shXddsL9fsp9yQgySt0Zck7HcG2hM8TyeHycsHIZf2jdkfqWob
      3mjl2YoQLnht5z5+PoN7mHm6a4cNqFpKnQsHXuIMKjZLnvGDkgUOlxCiNrFsMmAx
      sho1ROVR+TCkSi8KrR66CvA6a8sIRVib7Y93WX7QgpFQgw24ZbpZvlDR0TjullLi
      df+9TBOEg89oZFtPBvpdURFSKltl6PMS7WnAoXgIFRAnwM5PnPZHkA37GanmSrj8
      awLBkCapWuTF4/K+Bhu5hfURRac6IPJi56ygQWKpThAwk3h2L/saKTJFqD9vb/Go
      +FM/fmex3lOGbVbZs1EtvkKwYIAb9pWKIcsnpzH6L6PrQE7DsLX2NP23hwMsXRt6
      9vQDUuY8Dd45ttM8XPcVP0bM5C4PqmCErxXVFLcuLUtkF98RaUNnEdkDCo0yfojF
      eQqn74zmQ0c3Q4WufxKM+4kQ1EflScv4uxOuBraj3hFcyac4u1CyLD0sv7InkdRB
      T0iS+pLIyaJQIHV4AximpRISitVGuYnNtSuTrJJDmjmGGSMyC/jCsDrr1t0lMxdb
      vdDuh3t+Ch9rvXHEPtnIokOW9U+hrVIeIGeiD0KM5QHD2CjcgwQ=
      =2hns
      -----END PGP SIGNATURE-----"",
            ""message"": ""rename it
      "",
            ""parent"": Array [
              ""b9a8e7ed4e394942ba0a45f19563e8ad90b94ea9"",
            ],
            ""tree"": ""641ca0a41cfbccf4fb5c366840270fd25ec48b4f"",
          },
          ""oid"": ""cc9bcf734480b44d2e884ae75a11805e42c938d8"",
          ""payload"": ""tree 641ca0a41cfbccf4fb5c366840270fd25ec48b4f
      parent b9a8e7ed4e394942ba0a45f19563e8ad90b94ea9
      author Riceball LEE <snowyu.lee@gmail.com> 1593510498 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593510498 +0800

      rename it
      "",
        },
      ]
    `)
  })",snuts
/__tests__/test-log-file.js,ComplexSnapshots,"{'startLine':851,'endLine':946}","it('a rename file with follow multi same content files', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'rename-2.md',
      follow: true,
    })
    expect(commits.length).toBe(2)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1594594854,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1594594854,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl8LliYACgkQEPFehIUs
      uGgGvBAAy4yXnK1dpMDe0x4fzWcNo9r5Ong/UFPBN8Wda0OMivmg7RbhmF1ZJxwS
      J+IuSSVyunnFGqJPE6kF+CdNlCVC/Ol7LJV2rYIi+R+EBVLjU+eW1i6lSRCzJlPt
      rwyWsLzvNWWsA8S88ndHMvNcr9NliSepsdXsF0dbbjru5aHct9Crvz9blb9q8WrN
      yc2HLtE7TliPCxfNBqz5I2aLYwfjcEQbdnMYXQfseJBI1md0qzupY5YKkYTA+Yuf
      1yEcPEOsACNrSalCTGooMgfKBC051HBnUVebAfdqUeR6XHjl6fVHTRsMKETsBQeH
      hIHuN+dKjdX1zvzXbq3IStXTvTLAnK5f5td866FRvkuuTki3BiWYq/AfpwchpKKt
      S3HkZnPhQXvOBSyYwI6fz+leZvpJDp+HjGDiNbB+H6iO1rDc7tVTzGKVniRsXVKJ
      /L/OkP0B5pt+ElSGrlQ38Mk5uN0xtnbGPGCA074Tgry/rC8G5E8x9a1ZbsO5lQ1g
      WuDwTuyzPlb6fxrctGPBI7yD+dxx/xIRjXkMRUo3GwcQSzTALl+x63SxOl4AfvmQ
      Hyh2/osfJh8YUd67QDSQOY0tagXodZhAT4YkfXhqehHOBQ1Sc4GZI5wT/7nn0NTy
      CP5jdSuA/wAIac/vGIQ89C71keAlKMgeEVrDOh6PISUGp4q8wy8=
      =dlF4
      -----END PGP SIGNATURE-----"",
            ""message"": ""rename rename2 to rename-2
      "",
            ""parent"": Array [
              ""c7a666607cd986eee187b3df2c4adef3b7e56c94"",
            ],
            ""tree"": ""2d8cf1942da4577aa3f205108c228e1a95b33940"",
          },
          ""oid"": ""18f202dfed5cb66a295dc57f1f4ba1b7f6b74f36"",
          ""payload"": ""tree 2d8cf1942da4577aa3f205108c228e1a95b33940
      parent c7a666607cd986eee187b3df2c4adef3b7e56c94
      author Riceball LEE <snowyu.lee@gmail.com> 1594594854 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1594594854 +0800

      rename rename2 to rename-2
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1594594440,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1594594440,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl8LlIgACgkQEPFehIUs
      uGjWiA/+Oda2OuPc7X9TFgDvnAwIWMRFThUebrGe2NaVstvtAAHte3Y/9FYqU062
      0IWLycCENb7EbSTlIb6Lew09KXibnB4E39WrIcWYJJx2zICETNW56yedkd+1UJKZ
      XwCewsgxyOVA960awxyLa2au06aHDF8U6128lHPZDVYIVgdYzhrn+18j+TXc4anB
      p1whk5vAq7nkdTS0yATbLvlbBgymKaDxsGM7RO1giFSVQxzULb0RyH1BfnvkV4Ox
      QxkyMPIYuziZXBpYBZmZOdIq1E5zOVkyoQIELpXy8NrLZ4Wj+r2P9RujdlA6zitA
      xaeihDikZNRQc1vPsb119psabrrgXY/dxW9+p60kSXsUGWhX5RBKuPodfmpRHJTD
      XKe5lckrPTUkCwbVMGXUx2nj9jCcF5FEMDQKEd/dBFKX9QPY6JnjaimIY1E8ulAX
      rwXN91oECmt5OvPI2icOYLCkPkbNMy8rW3hEu4QDj8bCfPBtgHhon9SIsWKE6Bh9
      sRLGU9cJWFPXNlyV9nj3G2w5MXrzm2SqJrxH/reuDdkB1Y2kYMM5pSNmlS1+IGk8
      mTkYjlsCT4WxHRyyMJUtGxvdTisyp2odP7BEcEjq97ZHKKgUDtTbsmD0tfo0k0eL
      KBa7eI7ag4KMAJ4MWk3X70f2qAeoaSNXAsYDSI+kt/rFgFsYSH0=
      =AaPG
      -----END PGP SIGNATURE-----"",
            ""message"": ""add rename2
      "",
            ""parent"": Array [
              ""9a4eb099547166c9cf28628a127cfc9e59fa4f29"",
            ],
            ""tree"": ""795c22aa0265ce8c2d1cd3d4bf2d62ac1605b5ca"",
          },
          ""oid"": ""f44bab8dd4229486c7f6acc448cfc158bcbe5cfd"",
          ""payload"": ""tree 795c22aa0265ce8c2d1cd3d4bf2d62ac1605b5ca
      parent 9a4eb099547166c9cf28628a127cfc9e59fa4f29
      author Riceball LEE <snowyu.lee@gmail.com> 1594594440 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1594594440 +0800

      add rename2
      "",
        },
      ]
    `)
  })",snuts
/__tests__/test-log-file.js,ComplexSnapshots,"{'startLine':958,'endLine':1099}","it('a rename file2 with follow multi same content files', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'rename22.md',
      follow: true,
    })
    // expect(commits.length).toBe(2)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1594594611,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1594594611,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl8LlTMACgkQEPFehIUs
      uGhUxhAAl4RTZr0osT5fs+bT/X5Ru2PvWyB8MJhc7Qy3nGQmpowqqlmU5UD+BKRI
      oQfzGmZ7hKNRegS51HcNsv/kPqEA7maAAFDTqCKUFbLdeMKTf0vPCx90+U5hUamd
      n3sLVK9lSSkz0FF3nVD28Fmcrh6oxHY4XQ/KHVBD8PZyIJ2DB4rYpqYB1p7Mx1LO
      1mlMfru1J5Nc6DF+n6tANn95opkgwDjtPJkThZTfWDHQGy6mAJXbp0TChef/Rx+G
      BegdvrkkMjP/Gq/+2b5LHEZb0Anode5zAYdz2J/SeqD2OiRvvR7nG0wVZAe6z7ZD
      StnVFtTa0zaAGhxps6teyWEK3dtBkmybxs/1PbEDZcyFN3LYmOSSpIpoyU4S2m19
      0Q3keZnyP2d3qajlgg25uW8ejh31TomcbQZ6n0VXqxysPpLAj394iFNt1ZKRrkFZ
      rBKWTwhYYhzBAb3qMPAiOpN6UnTVzeeGrc5mN3DSh3WAPUOQmwTxFp9gkpWr7mgN
      a3OZnSGg+7/fNUW8XUFyPIhud2C3BCDrm77bZPlHTZpZT31dWUxm30mIIM+wn3rF
      LUmPaXY6jbCbig0Y0wAL+K+8ELs/XC7RJC70IRtYuXKnP2H9dE483cssmFALOTjF
      2AikacC0uRtiJdMAe/YcFNzfYxEUo20Amkk3iutUAN+/kTlMNrM=
      =WpAk
      -----END PGP SIGNATURE-----"",
            ""message"": ""update rename22
      "",
            ""parent"": Array [
              ""c87ae5071b9e674a1cfa3d853e33993c162c5def"",
            ],
            ""tree"": ""6ae7cfe2d19e1ab121ec7c31fac66f33f1ef9957"",
          },
          ""oid"": ""c7a666607cd986eee187b3df2c4adef3b7e56c94"",
          ""payload"": ""tree 6ae7cfe2d19e1ab121ec7c31fac66f33f1ef9957
      parent c87ae5071b9e674a1cfa3d853e33993c162c5def
      author Riceball LEE <snowyu.lee@gmail.com> 1594594611 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1594594611 +0800

      update rename22
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1594594590,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1594594590,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl8LlR4ACgkQEPFehIUs
      uGgjuhAAxg/R9VUR69KDvtfI4dYffv/Oj36FYsEeBPTY1Gdy3p4fgXDaQ0D4KE4+
      XOPKj25EKlydR0iDu9Uc3WxsXmfON0p1YChMiO8+YZojEQVbSkfOECnznOuK8VfR
      6V7nIVJr9apYCGUeU80ZN22Ax1KlpVC9mkN+7VejAGKgf374URUvGoKBXuEAEkve
      Bq54EJdWhWX5wg2fN88NXLf0kHYchM2vyVC5L2cNpIq3UxZ5SK8KCQoxgr7fst2a
      RymJz8sQpKJiprv+D1YYCjONX8bqtFroy0aK/3RMKZ0bDm5IQq749C6ptDjd3uSW
      ojzGuWMA6W8BAuM5Dj+5rxIHH+DXv3h/Q0kFbNYfS9/dnmXR0jzQaAlf7VaGvMXT
      1UfCrrvLnbqy1Sc17xaUav7QQ46Yl22VF1gN8DCfol1i8IP0z6QsOWY+53Ok3t4C
      X73OgGXqijP9BBgLIS9CplefV+oQX7Tyjw/jT3YdHRThPetxbtFgknjTrZ/2UlVo
      kkBdrNNEk8mGMYZC1VljCdHEEWGl/GJEqaqoN3OdkJFkCge4qFHPjo10x9n3Qv5K
      Zp0JYtM/roKelfUJh75p2OZoSMCV+jT+PoVPh3mCstSNCSt+2OSwTzFqQphRbU44
      a38BGcs3PtlZIQuHDprQC93YYdRYZ7DvDbWEgGNcmOY24/4+qUY=
      =7Pky
      -----END PGP SIGNATURE-----"",
            ""message"": ""rename rename2-2 to rename22
      "",
            ""parent"": Array [
              ""b3886fec49477755dcc5591c8df04f66535c0d79"",
            ],
            ""tree"": ""b5d1f7500bb4d6dd31b70c19c2ddf89955a3e509"",
          },
          ""oid"": ""c87ae5071b9e674a1cfa3d853e33993c162c5def"",
          ""payload"": ""tree b5d1f7500bb4d6dd31b70c19c2ddf89955a3e509
      parent b3886fec49477755dcc5591c8df04f66535c0d79
      author Riceball LEE <snowyu.lee@gmail.com> 1594594590 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1594594590 +0800

      rename rename2-2 to rename22
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1594594501,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1594594501,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl8LlMUACgkQEPFehIUs
      uGhLsBAAorySvEQFjCKL1kIi2fJyF4xWcnbzlO2xd6HWaSB6VQZZZwrGQIRFOoVX
      ExiOzHrcmcXrdH2so3hlLS7XjlmI3oGSKDxryscfe/wJEvRMr9flXAVIvQdMrG7T
      K/mNYKs5Pu/0oOQu+UMNZHWOjnABiW8VAhs16WwyNWndr9sE22F97cn1dmMESL/K
      W5OcpSkH3JuEaZTYSwbyyO8SYeLacyyBmKvqT0NBzt7mcZa0P/qAKWRWcmV5mQn+
      pWB2EB2m7bwG09xjlyMwwDnVlbYfv7s2xz8pBLh2n+ye1d4roghTiGbCGjIe+CAy
      8/lrwpARQNiXig3aaLNs7n//EaIkds8MWxygJk7tKwJTMPWF3mzM6k06XJKlKD9r
      2JjTIRpmF01TdjUou8CLTNsfky1f4zCWUb5CNMReyvZellBFUDfh148Q3WlxDDVK
      /XuHWIpr1mlzbYhXBWARJ4DMnqNWP6bL9Eo5ne9tbGFzh2rlitfzJdkMNwJ2QBKW
      rbIy7jSEcpKDYUshg3VcbUkAKxCD4i2VWwDfTxzxwMiD6rWvP6Ig7seqj8Tfy2LU
      ppVZj8VIxSQ5FH4s1MDbgHRyHz3OV+WS4MMLpdE8hhf8ZXFqlD+5b28ILEVO3EL3
      kA3hblT2W8wSVy4NLzxf+inLsQ7UcU/qAAskaEG1sryZqkEZojI=
      =bJdJ
      -----END PGP SIGNATURE-----"",
            ""message"": ""add rename2-2
      "",
            ""parent"": Array [
              ""58ebbeb4ea12bf4b0bdedfdf89e3d8c8f456e094"",
            ],
            ""tree"": ""84230a4664bf41b53034b9cab3c823db721055eb"",
          },
          ""oid"": ""6f2d819bb115a70fa9d831717d32ce2bdec3b83b"",
          ""payload"": ""tree 84230a4664bf41b53034b9cab3c823db721055eb
      parent 58ebbeb4ea12bf4b0bdedfdf89e3d8c8f456e094
      author Riceball LEE <snowyu.lee@gmail.com> 1594594501 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1594594501 +0800

      add rename2-2
      "",
        },
      ]
    `)
  })",snuts
/__tests__/test-log-file.js,SubOptimalAssert,"{'startLine':16,'endLine':16}","it('a newly added file', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'newfile.md',
    })
    expect(commits.length).toBe(2)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""araknast@protonmail.com"",
              ""name"": ""araknast"",
              ""timestamp"": 1653969605,
              ""timezoneOffset"": 420,
            },
            ""committer"": Object {
              ""email"": ""araknast@protonmail.com"",
              ""name"": ""araknast"",
              ""timestamp"": 1653969605,
              ""timezoneOffset"": 420,
            },
            ""message"": ""update newfile
      "",
            ""parent"": Array [
              ""dcb1c5fe6cc28e7757c4bc4d7dbf5b061c38ec48"",
            ],
            ""tree"": ""331f342f6e9b38c45e17189691134cb4a72189d2"",
          },
          ""oid"": ""04833cdb10e0f8fa81800cafa98e1381a1c6c58e"",
          ""payload"": ""tree 331f342f6e9b38c45e17189691134cb4a72189d2
      parent dcb1c5fe6cc28e7757c4bc4d7dbf5b061c38ec48
      author araknast <araknast@protonmail.com> 1653969605 -0700
      committer araknast <araknast@protonmail.com> 1653969605 -0700
      
      update newfile
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""araknast@protonmail.com"",
              ""name"": ""araknast"",
              ""timestamp"": 1653969041,
              ""timezoneOffset"": 420,
            },
            ""committer"": Object {
              ""email"": ""araknast@protonmail.com"",
              ""name"": ""araknast"",
              ""timestamp"": 1653969041,
              ""timezoneOffset"": 420,
            },
            ""message"": ""add newfile
      "",
            ""parent"": Array [
              ""18f202dfed5cb66a295dc57f1f4ba1b7f6b74f36"",
            ],
            ""tree"": ""59c1caba006bb27077d11f1c0ff7ad3ff4b2b422"",
          },
          ""oid"": ""dcb1c5fe6cc28e7757c4bc4d7dbf5b061c38ec48"",
          ""payload"": ""tree 59c1caba006bb27077d11f1c0ff7ad3ff4b2b422
      parent 18f202dfed5cb66a295dc57f1f4ba1b7f6b74f36
      author araknast <araknast@protonmail.com> 1653969041 -0700
      committer araknast <araknast@protonmail.com> 1653969041 -0700
      
      add newfile
      "",
        },
      ]
    `)
  })",snuts
/__tests__/test-log-file.js,SubOptimalAssert,"{'startLine':90,'endLine':90}","it('a file only', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'README.md',
    })
    expect(commits.length).toBe(3)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509836,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509836,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77B8wACgkQEPFehIUs
      uGi0CQ//ciB5DDcHppFv1caaOiEYUos8oc871eMMbXtl+y9eTfzN6VEwpXY8matE
      3hxMpe4YAUpivfQ3a75d5MEy5iEpF/U9rCkWBlGpdqG3+rvmrvpQXo+PZEzdP84E
      7rz1Ue2PnfivXCzo2zvDoyMLWqFbNgxXIwr0ST2SxuBTsVIwF/6y80uXa/8VQXfK
      MBCFKKcBK03ruZAWiLIwMNvYTxDIMvupRIN2rzyRpOb8lCSWmyw1/eqzF5soVy62
      HraCZlK1iyv9XaL0qn+SlAGYYsJylp8sfLUmU0y2qeEtLYdRLS25yRAK9h7l5RD2
      qTmQwPb5vx1ldFALr90qgVZc3j7xI5xnL6UtiMGSoZM+HuJ3eioOisXf0aAaxr6U
      ImY98WAIPuAAx6rUhHP27r0w0hDABFZmrMtO7FkH6wcqM2LJIweLGFZtKXePmR14
      CH4cQw4ylSjtrcQFguUF7rvz0sX69IeDTTF2ppaH9uQclL+3F0Bj78XiH9Dflx4E
      6+HfY98tdLPcjGfcdAguLBbKZslmYz7uUeqvHyrgVER6xMFcrGR7IUPLI0IWjtqY
      CL+5+gxD2O4FIUhY2hwISLHx+cWsCsAmiBZKx5OhQeW9nn4D8ex4WQK/go7iCrEe
      LnuTba+0qmNBTF7f7a+U0x1ReeipUk19bEuP7P1K7Ppc1C+BYT4=
      =nAWS
      -----END PGP SIGNATURE-----"",
            ""message"": ""feat: update to readme and hi.md
      "",
            ""parent"": Array [
              ""8e98db35c3e3e01014f78a60786b1b3b96a49960"",
            ],
            ""tree"": ""281d4cba64e37323777e7f3ee222d504ed8fa0ea"",
          },
          ""oid"": ""bba48a582aaa7e572c844cf7f42f3cd03eab81f0"",
          ""payload"": ""tree 281d4cba64e37323777e7f3ee222d504ed8fa0ea
      parent 8e98db35c3e3e01014f78a60786b1b3b96a49960
      author Riceball LEE <snowyu.lee@gmail.com> 1593509836 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509836 +0800

      feat: update to readme and hi.md
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509669,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509669,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77ByUACgkQEPFehIUs
      uGjJYQ/9HNh4TJO/V+ckTyMDzf+Z4Aih6ytn63ispZnfbKb5hPEV+eG1HRuPthF4
      kNilem8w//QYbllbih9bbw3tKvh2SaWYHIOEDI6eA/1k5Bd0nYLi5HNWZG+bOZNR
      XdDI+yPBAQSl4607S2xGeOH7HrSzVSVbheDjNhwYBiRDOvbFxhx3Sc/G+vO8IfdU
      MCLzVhwizNNclKIMWKaUSpBpJuqxsRK4oINT8wJQLB4LRQ/M2CXgjSjZt0e9NtFl
      +6OxGKBbgioNMg6TXzvmqFJ4eqGk1tgMz/qYX1zjCRR2jZ1g/anht8OJRppdz2/0
      k87EN+lLpN5H/Z2tSJMrKBHaCJWo72vrcyQzpLjtVUVdHNdOB66+60yqSDZiz7pc
      1ou/9jM3cbtEwtvaD+W/JJvG7ctFOM7efM3iGghW2jccJ7Ku/DIlxwCXE6HNCjDf
      azPFqO0Y9fw7ZoJl+D7sotea2xaWMhxspUoHxtnYxah6tzJ6KQ8eZ4GR8FoMw2dj
      szUaHVtLRg+Nx/G5YWimOFNUrgA3lQYjh9+fgvodxhIQvd9KVW/qCdX6ZQM9vDXU
      o9d+QEdd/hzkMrOEHscT3nqKgeIEj6JSBg27kDraM6L0dAP4wCN/9h2dbR2ke0j2
      im+CRYtkgJz5EpJ4uN1B7SDUvdBrjYIzC2Aqiohh6M2ehP1in7g=
      =IvVn
      -----END PGP SIGNATURE-----"",
            ""message"": ""feat: update to README
      "",
            ""parent"": Array [
              ""533131624898bb8ff588b48c77b26d63e7eb180f"",
            ],
            ""tree"": ""2ed69fff23ee6e239744c7277ab80bf40a644ece"",
          },
          ""oid"": ""37c51dcbe78dd2fbdca15cf74c6c540f879a5bbb"",
          ""payload"": ""tree 2ed69fff23ee6e239744c7277ab80bf40a644ece
      parent 533131624898bb8ff588b48c77b26d63e7eb180f
      author Riceball LEE <snowyu.lee@gmail.com> 1593509669 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509669 +0800

      feat: update to README
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509547,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509547,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77BqsACgkQEPFehIUs
      uGj/oRAAmOMhskEjKwcFaEnC7InU/UMd4PHAy3XlKwqUCiQVEJWWi6B81n5IYsWi
      mDOKXGYenlYOAf0HFqs7nPBeINDRFQp03d01wZT7JgacpERCvvu53IHLH8ndJehL
      MQaRtWV/SpScj4OZH4Wzm6tjB4IBB/agZWM67tU4KKI2i6TOhQw8ktBoXbXGWO9g
      OwjHW4mZn5eggIhyNzNKWRwzImopYlcBGqtYil5l4LWXADBfxAYfBCA296HkiD1N
      sFzsi5mak7bKyW5/dFI9uP27BQSLLbGdbJIJlkYXi8XIo/sLPJGA0BHuiNLAVXUn
      E/CO4hBH/tZtJNk3jg0TPLey4Lh34d3Tw8+6z6CvMKQtZ9JUXy8rAWMvAXg0+YVp
      IvT+xA6HxECuBZ6UAYLU1ZHAvQtZch6XhJTirOJ5SMklTNKSiGaCLfDP/iuRWOYo
      4x52uwkInIuintkcIZocjwEQ5DsG6jO4ylbwmEaWgpzEuR7xOuIBx38dsCoSDD+D
      kyZF7ijammlt5Wc6A2u7ewEgCEy/GMEMJ+hUXqhJJ9Gi2uYU/WmC9GJDqD12JsEa
      m6FFvEd+zCH/9K+O5eBUS9WFpiwXPP+amaXGBWkXnlbEYf/j9QemZXi/dkn1qCE7
      yM9yzr8Tb0dJWqvovK42AlCuYsZ9BYOBM3zz+pGhpSdES9OYO08=
      =/hmk
      -----END PGP SIGNATURE-----"",
            ""message"": ""first commit
      "",
            ""parent"": Array [],
            ""tree"": ""5640888e247e986136d36b1d52a9881abc7170f6"",
          },
          ""oid"": ""8651dcc28c58d96439e99aa2bf239bf2ab238b73"",
          ""payload"": ""tree 5640888e247e986136d36b1d52a9881abc7170f6
      author Riceball LEE <snowyu.lee@gmail.com> 1593509547 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509547 +0800

      first commit
      "",
        },
      ]
    `)
  })",snuts
/__tests__/test-log-file.js,SubOptimalAssert,"{'startLine':256,'endLine':256}","it('a deleted file forced', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'a/b/rm.md',
      force: true,
    })
    expect(commits.length).toBe(6)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593652995,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593652995,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl79NwMACgkQEPFehIUs
      uGh+EA//f+cNby3i8IhD5LL5elmR6qp+KFNLQMEa7nvcUmYQX2Ffx4QAN0WtPQ+O
      y6PmrQg5MLfCPzANthY3oKnkvjIYbpnBF2JTeN2HA8mF8/HtGakMfeykkeuaGP6V
      Kdk4I2jiXC22g/Zy7VAzbYdJTk96yWw71lpufQa1voy8ykCCu/YgeO4EjQME2RYn
      82W9+X4Qxx5bu0C0lKMwfdhAcR/MDTye0jbu33krwnuXsNyA+6OKBIOfIAWK8PWY
      iTwvkfQ+61T0dGFAdi8tJCfGZ6JRBf482KHR/gSwmwq59g7quS/snnybB6kGwrqZ
      tScHZ6Sy08xHYRbibV8HmOAyIBKZr1ZPtEjBx5Aj6Q4qKsTkZ3Q5ZTTi8Ayhm1SM
      y1mJ20d3B0WM9F48w0a8qbKxNn7zefW88QHq3PB6wdGechkZ/Wq0xN2z/h3Sl5W3
      ZSmJcvgMFJwc/p7ci2spkR+ibVnFNdvn0xinUvrJGftFuiEqlZfHwo1t6KkmX9st
      X7+30WwKmotxgeBfV0g1Br4YpaZTKJc5V2JkU+gtjnIlb/7XU6eWm+vCInad5QdL
      NeiYCPsrT9ejboKghAIteNNfiuauiRnpZ/06H5gi2OVeyChA1urD/pKjJyaNllbh
      XZTv9Wqzt6oQzR6FV0HH5H9ACqOnCJXsTUoydzt843MFHmPDL0Y=
      =77Yr
      -----END PGP SIGNATURE-----"",
            ""message"": ""redel rm.md
      "",
            ""parent"": Array [
              ""91e66ded3cee73f5f181fbd0e7a4703f1c12bb9f"",
            ],
            ""tree"": ""7ab59df3bfd122ef5d24c70f9c8977f03b35e720"",
          },
          ""oid"": ""9a4eb099547166c9cf28628a127cfc9e59fa4f29"",
          ""payload"": ""tree 7ab59df3bfd122ef5d24c70f9c8977f03b35e720
      parent 91e66ded3cee73f5f181fbd0e7a4703f1c12bb9f
      author Riceball LEE <snowyu.lee@gmail.com> 1593652995 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593652995 +0800

      redel rm.md
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593652652,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593652652,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl79NawACgkQEPFehIUs
      uGj7BRAAjZjpjaP6Kl++qtsHS5GdzMCVyocVOE+UCOWU55ImjJI9g2ajlnWfIUuM
      oZTFCG123eY0vGtXTCpcrNUPO3QvVtkIlZybMMFcJJMoENWjQ1rWZEVX4UK/skkM
      kKt1ZFVJHfgLnqsFGcyR5Fmr9omm3faVinyIxQhhdNxIYV44x4Uj5IszZul4yeQr
      NBdrPpmChT53ST3+WNp1/c7iSeMjUpXO+CVkmmG0kieThJgKBqkBTlholwYrVCgS
      B5MTgVzLh9NGoJHs+9Qd5pze41tIPNJbCWtWimoOdWJTo91L29qT747tNC14v6zh
      dkemZgUsO81lq96WiTekDS2E9PDWVWk1mi2XAXrsQ8OqDKYDwkLQa4GvlxjQrNEU
      1FG0btHD0ddYYEwBN4uK5wsXA60i1qDetggGT+CcYi2yX4MqFCI4GJgf4Oj0htht
      ltX7fMFZu5sKSOd1vLE8RxS2c4IgNQZ4ZFCAW1mfBAV31RLXG4BH1f/4laKvMrKO
      5EUufJcPIW4vKAXVVGyPMgenkEUrXL/ImYt1kuSAMx2pffahWQzaF7rTXAWO2YK+
      bqajFbubxMPbDPW70pnYQJLwuLve2IqBbPsMghx+B30F0PzCajg3XvJv7ZdqodSE
      wKn2DCea/8Rj7O/GYRPJJtJ8ITwhGMLxRC5s7j6mJAxj5IdB2fw=
      =z3mu
      -----END PGP SIGNATURE-----"",
            ""message"": ""feat: readd the rm.md
      "",
            ""parent"": Array [
              ""1bc226bc219beea3fb177de96350d8ad2f4c57cd"",
            ],
            ""tree"": ""e7bd10ca01b3377fa6fbe633ce104698b5d7dd29"",
          },
          ""oid"": ""91e66ded3cee73f5f181fbd0e7a4703f1c12bb9f"",
          ""payload"": ""tree e7bd10ca01b3377fa6fbe633ce104698b5d7dd29
      parent 1bc226bc219beea3fb177de96350d8ad2f4c57cd
      author Riceball LEE <snowyu.lee@gmail.com> 1593652652 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593652652 +0800

      feat: readd the rm.md
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509970,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509970,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77CFIACgkQEPFehIUs
      uGicBhAAr9NDElwaYSoKk8ayUnlO00E/Kr555Xr+/U0wgfXBoVJoDbVSsIi3IhzZ
      vkWJXVeb1puUyyhYR4o2gdySJ3u3kcpj1xLIeXp+gvNftJyOaCN04m6Hnay2eMXS
      9vZX55PppFXS0B1lB9L95k6ciJEVnoKjEVT1mDunmo1G932qrs6QkU0smKJ7M6fm
      cEonSzi+VCpcACs4toN4PMhrFdPvFEvYK0iG8LXxLkKV+bhmKPeD45TKhJTAfjvV
      86SltUU1ftyJTu2FxsuWeMzxAw57bI/xET4eHVboOnWp3cSPAWX2Mc5H5yWBzRZy
      cPwDIwwvj0WSOtXOWJMW743O+29sNSKZZjoLjrSpwrYWnNYT4ThzdGvKvl2XD9uM
      vzZWgQihdT+My0qXLVuDMAnH56jeUN/fdiBw2oxK+sDMiwssD4Y3GulTQ7o067aU
      dqVCeV0LXTXmLUCvkbSwbKnxRRRxdA/OowH0NDbaYyjMoZ7UqBYiF5M9W1bcB9Op
      RCAfWVB7U7gwgu0PO70g6+LUr1lS+1UnszIvopwsqo301O1qTQBzM4ftuBwQa57P
      SHDxCpZ7bBObayNmW+PLkZSwc/Ak+uGzJdJkVrOA0kq2rlsLxnbysj1XxohIQsnQ
      +RZMMYcW8eev2DeDB+vtr94O8bxQZOH3cfx5gbxvRX5ixG5dn44=
      =8VVM
      -----END PGP SIGNATURE-----"",
            ""message"": ""fix: remove rm.md
      "",
            ""parent"": Array [
              ""58aa7508ff84bc25552b4576b1b5ab0ddc5e41dd"",
            ],
            ""tree"": ""b0904e4ea2e2548d0ebc5c9401b8a0390c0888cd"",
          },
          ""oid"": ""2584400512051e6cb07fda5ff7e8dde556fc3124"",
          ""payload"": ""tree b0904e4ea2e2548d0ebc5c9401b8a0390c0888cd
      parent 58aa7508ff84bc25552b4576b1b5ab0ddc5e41dd
      author Riceball LEE <snowyu.lee@gmail.com> 1593509970 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509970 +0800

      fix: remove rm.md
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509879,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509879,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77B/cACgkQEPFehIUs
      uGj+hxAAhidyrgiKXUdOh038Wvho48rd0opD2b+1C5kUpjSIrnd+7zKAS34Grveo
      wjdUsk4/Ao/qNLrZHuMwdca9KMt2bywc6X8AToNZXIapXvow3wj/1w9wtxeLyuaR
      7HFFVxBtVHZ9pntMvr5GXUMLqvm8sxXyOQVFxCjXgBCkFku+9Hi9PdTlt5PIvQ5C
      8ORynFVcdl8JPGYe510+lPSZVdgB/lrfDpyFwa1cnpVzXiefQFGSbNDYvh5DUnxv
      5cDmXLS79HFJg+9tnkOeMqKiSPvJU9giPE/Thrq1RYBk+rvEJA8yfl/QdFQBiFp0
      gOetxGoaJestpWNDh5qaCNdgyH3UwP1eR17WUFwR6f9wTaRwUlY8KkDbELjOn5IP
      jD7QopZPCbhSiEcC+5aER6Cfcae1DtQnftG3A/PpNlVRYAdZY/Ls8rxFsac1tdeg
      Q/0a6fpOG9WtsTXyzIvwk+b8ddJshXVslxLWj8Zw5F/PH27p4yRfZT0UscApO3Gf
      xX/nh+4Rs8/BDu8jmUMpJmqR3RVO1WnyShNgB2ONGaDc17bcGNwSz7IKnN5MXOZ6
      HCTNCtysIkl6uKAHq5TydZxz6LVwq+d62AVy1dKnVUqqLySOb7PLiWwZ06Qsvyfq
      iKPeOnlFPUrRBvNdtTfXpRpb4gJ1OJBxsvuxsApr2+vh1be8PCA=
      =Vmf5
      -----END PGP SIGNATURE-----"",
            ""message"": ""feat: update to rm.md
      "",
            ""parent"": Array [
              ""bba48a582aaa7e572c844cf7f42f3cd03eab81f0"",
            ],
            ""tree"": ""996a1c302a71aeeb3ba865c1a8720bbec39657b9"",
          },
          ""oid"": ""58aa7508ff84bc25552b4576b1b5ab0ddc5e41dd"",
          ""payload"": ""tree 996a1c302a71aeeb3ba865c1a8720bbec39657b9
      parent bba48a582aaa7e572c844cf7f42f3cd03eab81f0
      author Riceball LEE <snowyu.lee@gmail.com> 1593509879 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509879 +0800

      feat: update to rm.md
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509597,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509597,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77Bt0ACgkQEPFehIUs
      uGjwEhAAt+YBPtElFAv+hs5ybANPDKncpDdzYwJ+55aVG/RiWtN51BLj19pGm7Wg
      lxw2NUPPaFkeMvsula7sS8kgDeuEnpapkoBAnPDUUon5KtLR77qn6JGAvdl6EGDN
      x1Vyb3eOTjM0bW34gNTaAS6cHGhjmFFvX+w1Q1i0/kXBzn+/Gzy9IJTxYpoPYm0R
      IIZ+FI34hb7/UV6UjEqT9JqbRq8NQMr4nV5IQeEFBkBW3k9lPkoJvKAk585nGcaG
      NrqFCYI+S1RGChW1JO9dK9iNagvcEp5q1qs3R0Qag5ddf4502gQrHwIrvJBhiRXf
      kg5SBYae+C+UedUEAMI7kEDvzJY2n3s/l2T69HcrCL/0Uzay9hHF7+uQUoXMz+og
      u8kPJSMxEa5Ay2qThFL425d0bv7fm99kv8tVZrgDGAORF7F6cEj+0zAXrG66q7+C
      3zby8ZOtBo5m9lEXhKWfkg3qjHBWSIEzFSf2sIsHZwMwaP/UX4bHc2+gsU4ZuSV9
      ERuEM5rIcbUywNtVDCvRgyABNf+R9u1+OlbEE2gHkso1DiWzVhJl8OgoohNeQ6ve
      usuE81K6Hl0RXFPZEGiP9+VvBKegZr+TpChj/U9Xxg5Xo8h1IJofq+pcM7szyiW+
      XjQ2JObzauS9s+vlQZ3k01acgUxXF+izIb3JLWgZPo8ZQW57evA=
      =8Fqf
      -----END PGP SIGNATURE-----"",
            ""message"": ""feat: add content to rm.md
      "",
            ""parent"": Array [
              ""8651dcc28c58d96439e99aa2bf239bf2ab238b73"",
            ],
            ""tree"": ""c8a2583e243cfdd458a6ff40ff6f7a2d57fbaa96"",
          },
          ""oid"": ""533131624898bb8ff588b48c77b26d63e7eb180f"",
          ""payload"": ""tree c8a2583e243cfdd458a6ff40ff6f7a2d57fbaa96
      parent 8651dcc28c58d96439e99aa2bf239bf2ab238b73
      author Riceball LEE <snowyu.lee@gmail.com> 1593509597 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509597 +0800

      feat: add content to rm.md
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509547,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509547,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77BqsACgkQEPFehIUs
      uGj/oRAAmOMhskEjKwcFaEnC7InU/UMd4PHAy3XlKwqUCiQVEJWWi6B81n5IYsWi
      mDOKXGYenlYOAf0HFqs7nPBeINDRFQp03d01wZT7JgacpERCvvu53IHLH8ndJehL
      MQaRtWV/SpScj4OZH4Wzm6tjB4IBB/agZWM67tU4KKI2i6TOhQw8ktBoXbXGWO9g
      OwjHW4mZn5eggIhyNzNKWRwzImopYlcBGqtYil5l4LWXADBfxAYfBCA296HkiD1N
      sFzsi5mak7bKyW5/dFI9uP27BQSLLbGdbJIJlkYXi8XIo/sLPJGA0BHuiNLAVXUn
      E/CO4hBH/tZtJNk3jg0TPLey4Lh34d3Tw8+6z6CvMKQtZ9JUXy8rAWMvAXg0+YVp
      IvT+xA6HxECuBZ6UAYLU1ZHAvQtZch6XhJTirOJ5SMklTNKSiGaCLfDP/iuRWOYo
      4x52uwkInIuintkcIZocjwEQ5DsG6jO4ylbwmEaWgpzEuR7xOuIBx38dsCoSDD+D
      kyZF7ijammlt5Wc6A2u7ewEgCEy/GMEMJ+hUXqhJJ9Gi2uYU/WmC9GJDqD12JsEa
      m6FFvEd+zCH/9K+O5eBUS9WFpiwXPP+amaXGBWkXnlbEYf/j9QemZXi/dkn1qCE7
      yM9yzr8Tb0dJWqvovK42AlCuYsZ9BYOBM3zz+pGhpSdES9OYO08=
      =/hmk
      -----END PGP SIGNATURE-----"",
            ""message"": ""first commit
      "",
            ""parent"": Array [],
            ""tree"": ""5640888e247e986136d36b1d52a9881abc7170f6"",
          },
          ""oid"": ""8651dcc28c58d96439e99aa2bf239bf2ab238b73"",
          ""payload"": ""tree 5640888e247e986136d36b1d52a9881abc7170f6
      author Riceball LEE <snowyu.lee@gmail.com> 1593509547 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509547 +0800

      first commit
      "",
        },
      ]
    `)
  })",snuts
/__tests__/test-log-file.js,SubOptimalAssert,"{'startLine':544,'endLine':544}","it('a rename file with follow', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'a/rename1.md',
      follow: true,
    })
    expect(commits.length).toBe(4)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510674,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510674,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77CxIACgkQEPFehIUs
      uGhgYg//c7Add1QPUgdVP11OSH9MGAyxjLes14+g6lyf+5raDa4bvQAgRVydiqbt
      yI9SKwDni7HkZUK9CrqDtGwivvDjNK7n0R+ebNXRa4LYPrm9v9Htd6AqFNpSU6LG
      Fvi/AQarINtnSt7prKAExgf4Dt9Q9tZrVLqNIxi/6AMq3yQHwcDb6hKubaAkXWdw
      fkjmkUKtSSzycUy2HdrDSWX04frjN9ostqZHWQRvEztI1DdStwMIGMWibDioJoi+
      xlT1I28NvRtF0hgGgjFUQoa5xN7WwVYpx2byXQdfFavhZxqfQjnR0MMyIouIBxGQ
      aQGQNNEAgzVCMcnbTynLyZuG31daIS55AuoHS73RlTn+cJey32oblvnWRje9x7Vo
      J52QpRJPu4CTWQM75vc43n9acZYxATNCr/tEW8SIb4PVR5q0lfh6M1+MyfHxNJrp
      iRLkZaOlSsXxdU+oV5rcFg7YlpDIaqHBWTHjffqSUvBQ26S0Wot5W/kNkua35qcl
      S4fomYCphl/zAxyp+O31MQYCS36MObIM3FXEGdfm1c6XWtrAhtMPTKtsk5YB2ltP
      7MmLM1OwKltT6b55+RUnmQ4GyN92xIop9JMgDNDQfln/TRW73DaDFZt7OyZOZxQm
      qkdT/ALm0qLz8iPf4q0zBbSd0e4RnYxD0FwfPQ7aVMAA77hzMoA=
      =1cFE
      -----END PGP SIGNATURE-----"",
            ""message"": ""update rename1
      "",
            ""parent"": Array [
              ""cc9bcf734480b44d2e884ae75a11805e42c938d8"",
            ],
            ""tree"": ""7ab59df3bfd122ef5d24c70f9c8977f03b35e720"",
          },
          ""oid"": ""1bc226bc219beea3fb177de96350d8ad2f4c57cd"",
          ""payload"": ""tree 7ab59df3bfd122ef5d24c70f9c8977f03b35e720
      parent cc9bcf734480b44d2e884ae75a11805e42c938d8
      author Riceball LEE <snowyu.lee@gmail.com> 1593510674 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593510674 +0800

      update rename1
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510498,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510498,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77CmIACgkQEPFehIUs
      uGi8fQ//VBw8UB5s5UvklkBbhhF/D6UsaH8ry1GU5fQoUZlf7ouBiKkdLv0Sqe7P
      dTsohbo1FGHK/+shXddsL9fsp9yQgySt0Zck7HcG2hM8TyeHycsHIZf2jdkfqWob
      3mjl2YoQLnht5z5+PoN7mHm6a4cNqFpKnQsHXuIMKjZLnvGDkgUOlxCiNrFsMmAx
      sho1ROVR+TCkSi8KrR66CvA6a8sIRVib7Y93WX7QgpFQgw24ZbpZvlDR0TjullLi
      df+9TBOEg89oZFtPBvpdURFSKltl6PMS7WnAoXgIFRAnwM5PnPZHkA37GanmSrj8
      awLBkCapWuTF4/K+Bhu5hfURRac6IPJi56ygQWKpThAwk3h2L/saKTJFqD9vb/Go
      +FM/fmex3lOGbVbZs1EtvkKwYIAb9pWKIcsnpzH6L6PrQE7DsLX2NP23hwMsXRt6
      9vQDUuY8Dd45ttM8XPcVP0bM5C4PqmCErxXVFLcuLUtkF98RaUNnEdkDCo0yfojF
      eQqn74zmQ0c3Q4WufxKM+4kQ1EflScv4uxOuBraj3hFcyac4u1CyLD0sv7InkdRB
      T0iS+pLIyaJQIHV4AximpRISitVGuYnNtSuTrJJDmjmGGSMyC/jCsDrr1t0lMxdb
      vdDuh3t+Ch9rvXHEPtnIokOW9U+hrVIeIGeiD0KM5QHD2CjcgwQ=
      =2hns
      -----END PGP SIGNATURE-----"",
            ""message"": ""rename it
      "",
            ""parent"": Array [
              ""b9a8e7ed4e394942ba0a45f19563e8ad90b94ea9"",
            ],
            ""tree"": ""641ca0a41cfbccf4fb5c366840270fd25ec48b4f"",
          },
          ""oid"": ""cc9bcf734480b44d2e884ae75a11805e42c938d8"",
          ""payload"": ""tree 641ca0a41cfbccf4fb5c366840270fd25ec48b4f
      parent b9a8e7ed4e394942ba0a45f19563e8ad90b94ea9
      author Riceball LEE <snowyu.lee@gmail.com> 1593510498 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593510498 +0800

      rename it
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510465,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510465,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77CkEACgkQEPFehIUs
      uGiGZA//Y5XlL5XeP05m7Jp2h2GBOc1nF6W7AAxRUSintdiX706aaoSAbVD3PwB3
      zMuGiBIePPvQk+Oo+U8E0h2cD0bIY13BHJ+z23Qmn/1I1Vtup9uuWRCDR7T1Gy0r
      3rUsdtyuZ3qIjliCP/j5254x6hspIUVBFUeHd/BWTWIimKIuYKRg8am9qNn2Dhir
      o889/ZKuImsgF1eNsIaqlWN71n8KUGmDNcTdQ7eZzk4wUSsASyWRvnr3+OYkhjTp
      ffJubsdA+FvixxCM8kg6UAoOFlMzJapVi/AdLXRQ6758tEpTPWdz2WVxrI3P1ACq
      HzqvSIDoEISZDkKw/5maL9/89dV0qSuJcv3EqZQKxB3I7DAQgseHBAgThtChtdkh
      a6OrCIkeJyNjQhgXpqtIJ71P6mVTDNnveDWO+9OilCrHfLa3nqYCz+xPZ2txRwG/
      Z6+491WZVJAzU9rICT9AvrDpllacofr95LZCYdLd5J6qTYxq4m92AoZLOq5iKH1w
      nCYyrfswZolEmbq50MhD7JdZKE3IPf5sfZfU+X4EfPYkr//P5M6wGzYVXYv6KttJ
      jsekDsWczkATsKkp0xiC0lRVMNYwxl2Ly03JBZ/U2lBWEKhDgz1ELKa1XM9qEqSH
      CbwmGwIWyAOFmjkBjWUHIqrm2zQFskpXu4a+03dqV5pCQlsf4qs=
      =qvhP
      -----END PGP SIGNATURE-----"",
            ""message"": ""update rename
      "",
            ""parent"": Array [
              ""01cd249eaaceb8572bee5b24d8ed728c95f61bd6"",
            ],
            ""tree"": ""b76aafd52bf2d588756a32ebc9fa1ae0e68052c9"",
          },
          ""oid"": ""b9a8e7ed4e394942ba0a45f19563e8ad90b94ea9"",
          ""payload"": ""tree b76aafd52bf2d588756a32ebc9fa1ae0e68052c9
      parent 01cd249eaaceb8572bee5b24d8ed728c95f61bd6
      author Riceball LEE <snowyu.lee@gmail.com> 1593510465 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593510465 +0800

      update rename
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510416,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510416,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77ChAACgkQEPFehIUs
      uGj/rxAAtVD1LSNM4gfyHQQB8G/E4JWmqoTlOJlC2s+zZRzMUgKPPqItt4p4FFMs
      4GstDmVhGVKNpZjCkzZUX5N2Htm6PzWDdjtI5t+yl1rLfCR73VQKA/ztdUT2w1tg
      jewPYRht9VrP46MqCxbnUpdt5zYhshGa3/Q9WRy11rakvjrbF9S9jKP+qiNyS1X2
      3LGyDNQlS7XymSUFz4PSiOVTEpkSoOuGM6PnOhzmdNgl/JPY2vVCFcejO+qDq2K+
      0EbLH6Ab0r7EiFQXufOSR0m6i3SXnfg66+ttiW5Olm2yfT0H05flvHUp93aeAoYf
      qOvnSR5nX4jzQaLyHBvSWlotNfAgLSgLVZlUSoShYjRm/4UuFShZn546ykEZ1vTZ
      rMU5PNvu8pqhCEneHnl7WEuxrlxt10vwtzWDUalaUZgNKXoIYDWISpVfzdOEuOu3
      xNaH1GwZuGEtGZbDwOzsdTkJC5OTRzkb5c0SF/wlCUaW6rWW0J1cc/PX3bi4euwH
      TdUe8v0KT2jX275FjpzvCQixduMrM9lm6vwOYSWplk6Au+v5ot2vaGob2ok5dMIP
      Ai2oopT87heuC/iPcL2DKES1TItiXbRvYYu6jB3qCxD2cQUFxXgYyTuAnS3uSnhx
      w89ElnO5qtr32gZ5+609hodFg8zrxZWxXxpNcIHfTgh17qHZuPg=
      =iSgt
      -----END PGP SIGNATURE-----"",
            ""message"": ""add rename.md
      "",
            ""parent"": Array [
              ""2584400512051e6cb07fda5ff7e8dde556fc3124"",
            ],
            ""tree"": ""8ad18556d7692aef283e7cf30a287b6010c362a4"",
          },
          ""oid"": ""01cd249eaaceb8572bee5b24d8ed728c95f61bd6"",
          ""payload"": ""tree 8ad18556d7692aef283e7cf30a287b6010c362a4
      parent 2584400512051e6cb07fda5ff7e8dde556fc3124
      author Riceball LEE <snowyu.lee@gmail.com> 1593510416 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593510416 +0800

      add rename.md
      "",
        },
      ]
    `)
  })",snuts
/__tests__/test-log-file.js,SubOptimalAssert,"{'startLine':743,'endLine':743}","it('a rename file forced without follow', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'a/rename1.md',
      force: true,
    })
    expect(commits.length).toBe(2)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510674,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510674,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77CxIACgkQEPFehIUs
      uGhgYg//c7Add1QPUgdVP11OSH9MGAyxjLes14+g6lyf+5raDa4bvQAgRVydiqbt
      yI9SKwDni7HkZUK9CrqDtGwivvDjNK7n0R+ebNXRa4LYPrm9v9Htd6AqFNpSU6LG
      Fvi/AQarINtnSt7prKAExgf4Dt9Q9tZrVLqNIxi/6AMq3yQHwcDb6hKubaAkXWdw
      fkjmkUKtSSzycUy2HdrDSWX04frjN9ostqZHWQRvEztI1DdStwMIGMWibDioJoi+
      xlT1I28NvRtF0hgGgjFUQoa5xN7WwVYpx2byXQdfFavhZxqfQjnR0MMyIouIBxGQ
      aQGQNNEAgzVCMcnbTynLyZuG31daIS55AuoHS73RlTn+cJey32oblvnWRje9x7Vo
      J52QpRJPu4CTWQM75vc43n9acZYxATNCr/tEW8SIb4PVR5q0lfh6M1+MyfHxNJrp
      iRLkZaOlSsXxdU+oV5rcFg7YlpDIaqHBWTHjffqSUvBQ26S0Wot5W/kNkua35qcl
      S4fomYCphl/zAxyp+O31MQYCS36MObIM3FXEGdfm1c6XWtrAhtMPTKtsk5YB2ltP
      7MmLM1OwKltT6b55+RUnmQ4GyN92xIop9JMgDNDQfln/TRW73DaDFZt7OyZOZxQm
      qkdT/ALm0qLz8iPf4q0zBbSd0e4RnYxD0FwfPQ7aVMAA77hzMoA=
      =1cFE
      -----END PGP SIGNATURE-----"",
            ""message"": ""update rename1
      "",
            ""parent"": Array [
              ""cc9bcf734480b44d2e884ae75a11805e42c938d8"",
            ],
            ""tree"": ""7ab59df3bfd122ef5d24c70f9c8977f03b35e720"",
          },
          ""oid"": ""1bc226bc219beea3fb177de96350d8ad2f4c57cd"",
          ""payload"": ""tree 7ab59df3bfd122ef5d24c70f9c8977f03b35e720
      parent cc9bcf734480b44d2e884ae75a11805e42c938d8
      author Riceball LEE <snowyu.lee@gmail.com> 1593510674 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593510674 +0800

      update rename1
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510498,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510498,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77CmIACgkQEPFehIUs
      uGi8fQ//VBw8UB5s5UvklkBbhhF/D6UsaH8ry1GU5fQoUZlf7ouBiKkdLv0Sqe7P
      dTsohbo1FGHK/+shXddsL9fsp9yQgySt0Zck7HcG2hM8TyeHycsHIZf2jdkfqWob
      3mjl2YoQLnht5z5+PoN7mHm6a4cNqFpKnQsHXuIMKjZLnvGDkgUOlxCiNrFsMmAx
      sho1ROVR+TCkSi8KrR66CvA6a8sIRVib7Y93WX7QgpFQgw24ZbpZvlDR0TjullLi
      df+9TBOEg89oZFtPBvpdURFSKltl6PMS7WnAoXgIFRAnwM5PnPZHkA37GanmSrj8
      awLBkCapWuTF4/K+Bhu5hfURRac6IPJi56ygQWKpThAwk3h2L/saKTJFqD9vb/Go
      +FM/fmex3lOGbVbZs1EtvkKwYIAb9pWKIcsnpzH6L6PrQE7DsLX2NP23hwMsXRt6
      9vQDUuY8Dd45ttM8XPcVP0bM5C4PqmCErxXVFLcuLUtkF98RaUNnEdkDCo0yfojF
      eQqn74zmQ0c3Q4WufxKM+4kQ1EflScv4uxOuBraj3hFcyac4u1CyLD0sv7InkdRB
      T0iS+pLIyaJQIHV4AximpRISitVGuYnNtSuTrJJDmjmGGSMyC/jCsDrr1t0lMxdb
      vdDuh3t+Ch9rvXHEPtnIokOW9U+hrVIeIGeiD0KM5QHD2CjcgwQ=
      =2hns
      -----END PGP SIGNATURE-----"",
            ""message"": ""rename it
      "",
            ""parent"": Array [
              ""b9a8e7ed4e394942ba0a45f19563e8ad90b94ea9"",
            ],
            ""tree"": ""641ca0a41cfbccf4fb5c366840270fd25ec48b4f"",
          },
          ""oid"": ""cc9bcf734480b44d2e884ae75a11805e42c938d8"",
          ""payload"": ""tree 641ca0a41cfbccf4fb5c366840270fd25ec48b4f
      parent b9a8e7ed4e394942ba0a45f19563e8ad90b94ea9
      author Riceball LEE <snowyu.lee@gmail.com> 1593510498 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593510498 +0800

      rename it
      "",
        },
      ]
    `)
  })",snuts
/__tests__/test-log-file.js,SubOptimalAssert,"{'startLine':850,'endLine':850}","it('a rename file with follow multi same content files', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'rename-2.md',
      follow: true,
    })
    expect(commits.length).toBe(2)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1594594854,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1594594854,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl8LliYACgkQEPFehIUs
      uGgGvBAAy4yXnK1dpMDe0x4fzWcNo9r5Ong/UFPBN8Wda0OMivmg7RbhmF1ZJxwS
      J+IuSSVyunnFGqJPE6kF+CdNlCVC/Ol7LJV2rYIi+R+EBVLjU+eW1i6lSRCzJlPt
      rwyWsLzvNWWsA8S88ndHMvNcr9NliSepsdXsF0dbbjru5aHct9Crvz9blb9q8WrN
      yc2HLtE7TliPCxfNBqz5I2aLYwfjcEQbdnMYXQfseJBI1md0qzupY5YKkYTA+Yuf
      1yEcPEOsACNrSalCTGooMgfKBC051HBnUVebAfdqUeR6XHjl6fVHTRsMKETsBQeH
      hIHuN+dKjdX1zvzXbq3IStXTvTLAnK5f5td866FRvkuuTki3BiWYq/AfpwchpKKt
      S3HkZnPhQXvOBSyYwI6fz+leZvpJDp+HjGDiNbB+H6iO1rDc7tVTzGKVniRsXVKJ
      /L/OkP0B5pt+ElSGrlQ38Mk5uN0xtnbGPGCA074Tgry/rC8G5E8x9a1ZbsO5lQ1g
      WuDwTuyzPlb6fxrctGPBI7yD+dxx/xIRjXkMRUo3GwcQSzTALl+x63SxOl4AfvmQ
      Hyh2/osfJh8YUd67QDSQOY0tagXodZhAT4YkfXhqehHOBQ1Sc4GZI5wT/7nn0NTy
      CP5jdSuA/wAIac/vGIQ89C71keAlKMgeEVrDOh6PISUGp4q8wy8=
      =dlF4
      -----END PGP SIGNATURE-----"",
            ""message"": ""rename rename2 to rename-2
      "",
            ""parent"": Array [
              ""c7a666607cd986eee187b3df2c4adef3b7e56c94"",
            ],
            ""tree"": ""2d8cf1942da4577aa3f205108c228e1a95b33940"",
          },
          ""oid"": ""18f202dfed5cb66a295dc57f1f4ba1b7f6b74f36"",
          ""payload"": ""tree 2d8cf1942da4577aa3f205108c228e1a95b33940
      parent c7a666607cd986eee187b3df2c4adef3b7e56c94
      author Riceball LEE <snowyu.lee@gmail.com> 1594594854 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1594594854 +0800

      rename rename2 to rename-2
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1594594440,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1594594440,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl8LlIgACgkQEPFehIUs
      uGjWiA/+Oda2OuPc7X9TFgDvnAwIWMRFThUebrGe2NaVstvtAAHte3Y/9FYqU062
      0IWLycCENb7EbSTlIb6Lew09KXibnB4E39WrIcWYJJx2zICETNW56yedkd+1UJKZ
      XwCewsgxyOVA960awxyLa2au06aHDF8U6128lHPZDVYIVgdYzhrn+18j+TXc4anB
      p1whk5vAq7nkdTS0yATbLvlbBgymKaDxsGM7RO1giFSVQxzULb0RyH1BfnvkV4Ox
      QxkyMPIYuziZXBpYBZmZOdIq1E5zOVkyoQIELpXy8NrLZ4Wj+r2P9RujdlA6zitA
      xaeihDikZNRQc1vPsb119psabrrgXY/dxW9+p60kSXsUGWhX5RBKuPodfmpRHJTD
      XKe5lckrPTUkCwbVMGXUx2nj9jCcF5FEMDQKEd/dBFKX9QPY6JnjaimIY1E8ulAX
      rwXN91oECmt5OvPI2icOYLCkPkbNMy8rW3hEu4QDj8bCfPBtgHhon9SIsWKE6Bh9
      sRLGU9cJWFPXNlyV9nj3G2w5MXrzm2SqJrxH/reuDdkB1Y2kYMM5pSNmlS1+IGk8
      mTkYjlsCT4WxHRyyMJUtGxvdTisyp2odP7BEcEjq97ZHKKgUDtTbsmD0tfo0k0eL
      KBa7eI7ag4KMAJ4MWk3X70f2qAeoaSNXAsYDSI+kt/rFgFsYSH0=
      =AaPG
      -----END PGP SIGNATURE-----"",
            ""message"": ""add rename2
      "",
            ""parent"": Array [
              ""9a4eb099547166c9cf28628a127cfc9e59fa4f29"",
            ],
            ""tree"": ""795c22aa0265ce8c2d1cd3d4bf2d62ac1605b5ca"",
          },
          ""oid"": ""f44bab8dd4229486c7f6acc448cfc158bcbe5cfd"",
          ""payload"": ""tree 795c22aa0265ce8c2d1cd3d4bf2d62ac1605b5ca
      parent 9a4eb099547166c9cf28628a127cfc9e59fa4f29
      author Riceball LEE <snowyu.lee@gmail.com> 1594594440 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1594594440 +0800

      add rename2
      "",
        },
      ]
    `)
  })",snuts
/__tests__/test-listTags.js,AnonymousTest,"{'startLine':7,'endLine':60}","it('listTags', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-listTags')
    // Test
    const refs = await listTags({
      fs,
      gitdir,
    })
    expect(refs).toMatchInlineSnapshot(`
      Array [
        ""local-tag"",
        ""test-tag"",
        ""v0.0.1"",
        ""v0.0.10"",
        ""v0.0.11"",
        ""v0.0.12"",
        ""v0.0.13"",
        ""v0.0.14"",
        ""v0.0.15"",
        ""v0.0.16"",
        ""v0.0.17"",
        ""v0.0.18"",
        ""v0.0.19"",
        ""v0.0.2"",
        ""v0.0.20"",
        ""v0.0.21"",
        ""v0.0.22"",
        ""v0.0.23"",
        ""v0.0.24"",
        ""v0.0.25"",
        ""v0.0.26"",
        ""v0.0.27"",
        ""v0.0.28"",
        ""v0.0.29"",
        ""v0.0.3"",
        ""v0.0.30"",
        ""v0.0.31"",
        ""v0.0.32"",
        ""v0.0.33"",
        ""v0.0.34"",
        ""v0.0.35"",
        ""v0.0.36"",
        ""v0.0.37"",
        ""v0.0.38"",
        ""v0.0.4"",
        ""v0.0.5"",
        ""v0.0.6"",
        ""v0.0.7"",
        ""v0.0.8"",
        ""v0.0.9"",
        ""v0.1.0"",
      ]
    `)
  })",snuts
/__tests__/test-listServerRefs.js,AnonymousTest,"{'startLine':15,'endLine':45}","it('protocol 1', async () => {
    const refs = await listServerRefs({
      http,
      url: `http://${localhost}:8888/test-listServerRefs.git`,
      protocolVersion: 1,
    })
    expect(refs).toMatchInlineSnapshot(`
      Array [
        Object {
          ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
          ""ref"": ""HEAD"",
        },
        Object {
          ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
          ""ref"": ""refs/heads/master"",
        },
        Object {
          ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
          ""ref"": ""refs/heads/symbol"",
        },
        Object {
          ""oid"": ""5a8905a02e181fe1821068b8c0f48cb6633d5b81"",
          ""ref"": ""refs/heads/test"",
        },
        Object {
          ""oid"": ""48424d105c9eac701cd734a0032fcc71505797e6"",
          ""ref"": ""refs/tags/test"",
        },
      ]
    `)
  })",snuts
/__tests__/test-listServerRefs.js,AnonymousTest,"{'startLine':172,'endLine':202}","it('protocol 2', async () => {
    const refs = await listServerRefs({
      http,
      url: `http://${localhost}:8888/test-listServerRefs.git`,
      protocolVersion: 2,
    })
    expect(refs).toMatchInlineSnapshot(`
      Array [
        Object {
          ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
          ""ref"": ""HEAD"",
        },
        Object {
          ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
          ""ref"": ""refs/heads/master"",
        },
        Object {
          ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
          ""ref"": ""refs/heads/symbol"",
        },
        Object {
          ""oid"": ""5a8905a02e181fe1821068b8c0f48cb6633d5b81"",
          ""ref"": ""refs/heads/test"",
        },
        Object {
          ""oid"": ""48424d105c9eac701cd734a0032fcc71505797e6"",
          ""ref"": ""refs/tags/test"",
        },
      ]
    `)
  })",snuts
/__tests__/test-listRemotes.js,AnonymousTest,"{'startLine':7,'endLine':16}","it('listRemotes', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-listRemotes')
    // Test
    const a = await listRemotes({ fs, dir, gitdir })
    expect(a).toEqual([
      { remote: 'foo', url: 'git@github.com:foo/foo.git' },
      { remote: 'bar', url: 'git@github.com:bar/bar.git' },
    ])
  })",snuts
/__tests__/test-listRefs.js,AnonymousTest,"{'startLine':7,'endLine':83}","it('listRefs', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-listRefs')
    // Test
    const refs = await listRefs({
      fs,
      gitdir,
      filepath: 'refs/tags',
    })
    expect(refs).toMatchInlineSnapshot(`
      Array [
        ""local-tag"",
        ""test-tag"",
        ""v0.0.1"",
        ""v0.0.10"",
        ""v0.0.10^{}"",
        ""v0.0.11"",
        ""v0.0.11^{}"",
        ""v0.0.12"",
        ""v0.0.12^{}"",
        ""v0.0.13"",
        ""v0.0.13^{}"",
        ""v0.0.14"",
        ""v0.0.14^{}"",
        ""v0.0.15"",
        ""v0.0.15^{}"",
        ""v0.0.16"",
        ""v0.0.16^{}"",
        ""v0.0.17"",
        ""v0.0.17^{}"",
        ""v0.0.18"",
        ""v0.0.18^{}"",
        ""v0.0.19"",
        ""v0.0.19^{}"",
        ""v0.0.2"",
        ""v0.0.20"",
        ""v0.0.20^{}"",
        ""v0.0.21"",
        ""v0.0.21^{}"",
        ""v0.0.22"",
        ""v0.0.22^{}"",
        ""v0.0.23"",
        ""v0.0.23^{}"",
        ""v0.0.24"",
        ""v0.0.24^{}"",
        ""v0.0.25"",
        ""v0.0.25^{}"",
        ""v0.0.26"",
        ""v0.0.26^{}"",
        ""v0.0.27"",
        ""v0.0.28"",
        ""v0.0.29"",
        ""v0.0.3"",
        ""v0.0.3^{}"",
        ""v0.0.30"",
        ""v0.0.31"",
        ""v0.0.32"",
        ""v0.0.33"",
        ""v0.0.34"",
        ""v0.0.35"",
        ""v0.0.36"",
        ""v0.0.37"",
        ""v0.0.38"",
        ""v0.0.4"",
        ""v0.0.4^{}"",
        ""v0.0.5"",
        ""v0.0.6"",
        ""v0.0.6^{}"",
        ""v0.0.7"",
        ""v0.0.8"",
        ""v0.0.8^{}"",
        ""v0.0.9"",
        ""v0.0.9^{}"",
        ""v0.1.0"",
      ]
    `)
  })",snuts
/__tests__/test-listRefs.js,ComplexSnapshots,"{'startLine':16,'endLine':82}","it('listRefs', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-listRefs')
    // Test
    const refs = await listRefs({
      fs,
      gitdir,
      filepath: 'refs/tags',
    })
    expect(refs).toMatchInlineSnapshot(`
      Array [
        ""local-tag"",
        ""test-tag"",
        ""v0.0.1"",
        ""v0.0.10"",
        ""v0.0.10^{}"",
        ""v0.0.11"",
        ""v0.0.11^{}"",
        ""v0.0.12"",
        ""v0.0.12^{}"",
        ""v0.0.13"",
        ""v0.0.13^{}"",
        ""v0.0.14"",
        ""v0.0.14^{}"",
        ""v0.0.15"",
        ""v0.0.15^{}"",
        ""v0.0.16"",
        ""v0.0.16^{}"",
        ""v0.0.17"",
        ""v0.0.17^{}"",
        ""v0.0.18"",
        ""v0.0.18^{}"",
        ""v0.0.19"",
        ""v0.0.19^{}"",
        ""v0.0.2"",
        ""v0.0.20"",
        ""v0.0.20^{}"",
        ""v0.0.21"",
        ""v0.0.21^{}"",
        ""v0.0.22"",
        ""v0.0.22^{}"",
        ""v0.0.23"",
        ""v0.0.23^{}"",
        ""v0.0.24"",
        ""v0.0.24^{}"",
        ""v0.0.25"",
        ""v0.0.25^{}"",
        ""v0.0.26"",
        ""v0.0.26^{}"",
        ""v0.0.27"",
        ""v0.0.28"",
        ""v0.0.29"",
        ""v0.0.3"",
        ""v0.0.3^{}"",
        ""v0.0.30"",
        ""v0.0.31"",
        ""v0.0.32"",
        ""v0.0.33"",
        ""v0.0.34"",
        ""v0.0.35"",
        ""v0.0.36"",
        ""v0.0.37"",
        ""v0.0.38"",
        ""v0.0.4"",
        ""v0.0.4^{}"",
        ""v0.0.5"",
        ""v0.0.6"",
        ""v0.0.6^{}"",
        ""v0.0.7"",
        ""v0.0.8"",
        ""v0.0.8^{}"",
        ""v0.0.9"",
        ""v0.0.9^{}"",
        ""v0.1.0"",
      ]
    `)
  })",snuts
/__tests__/test-listObjects.js,AnonymousTest,"{'startLine':7,'endLine':198}","it('listObjects', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-listObjects')
    // Test
    const objects = await listObjects({
      fs,
      cache: {},
      gitdir,
      oids: [
        'c60bbbe99e96578105c57c4b3f2b6ebdf863edbc',
        'e05547ea87ea55eff079de295ff56f483e5b4439',
        'ebdedf722a3ec938da3fd53eb74fdea55c48a19d',
        '0518502faba1c63489562641c36a989e0f574d95',
      ],
    })
    expect([...objects]).toMatchInlineSnapshot(`
      Array [
        ""c60bbbe99e96578105c57c4b3f2b6ebdf863edbc"",
        ""a8103169a3cb5fb457e5232a0e36728511e736b4"",
        ""1db939d41956405f755e69ab570296c7ed3cec99"",
        ""bbf3e21f43fa4fe25eb925bfcb7c0434f7c2dc7d"",
        ""4a58bdcdef3eb91264dfca0279959d98c16568d5"",
        ""eb1a0c5bb07374f97343010b019aeb3e6be472ee"",
        ""47967151a5ff9366ca5d86e261c9ceb835d7b722"",
        ""c675a17ccb1578bca836decf90205fdad743827d"",
        ""d7b25aab38d0772c4e0da5a88c84f369241e230e"",
        ""049041e4f5c2216806a69c78b3405d8882a6ce7a"",
        ""bf45c6a17356154e11e14325624e170201f3f875"",
        ""557574c5a4e2d6378c3b44e954790e2903a066b7"",
        ""c5059df27e646eca3c538fcb435bb5d3a5335e3d"",
        ""0dd30ed7ff2c698dec130d3451c99cdd9bbf1633"",
        ""60b63f5f7298f29033ec8b5fa19b689062282363"",
        ""e87c4acef861687deb2728c9f3667a0dc03a8958"",
        ""e965047ad7c57865823c7d992b1d046ea66edf78"",
        ""e5b8f9cece335aca583406109216173174068c73"",
        ""2e957a173810564d93efd6cc48f4149602e8dab0"",
        ""3830b74f75e13b734e117ac65d04fbd92d7ffa30"",
        ""51e632299486ed66ac253a467599cfbdfeb6b635"",
        ""cb089cd89a7d7686d284d8761201649346b5aa1c"",
        ""d545cdabdbddafca3501d2114506fc86e50e9824"",
        ""73003f80fc868def28485d20180318454614e9b5"",
        ""aa0a764f20a691959a981c60de223717d3ddeaa1"",
        ""699e0fe71ff254b1bec2320356657b024bb88657"",
        ""302013a7292bac15dd19b1d29049d69f4862561d"",
        ""9ac4f57c7d98020514ca2baebff511841baa9d93"",
        ""a003a3623c66cf6262db282d769574c556dafe1d"",
        ""be395f63b878f28a86a418ae0d6a291e6fa51de9"",
        ""6a41d6d49eec3593bee14ad19d0a0c0ac08be937"",
        ""651bd64f6c3716fc8a6e8ba6dcbad2d93337f279"",
        ""55158d43140549daee24c7d3534107723c0c056a"",
        ""64280b806c9760fb2313b29cc66dabbd0fe18e26"",
        ""6d925adc4818a513ae2683a12fe381269f45a7c7"",
        ""988c291502fc1acafede7f1ac3e913625ce665de"",
        ""ff53907ca9bd6d5f376188c57bcf1dd4650574c9"",
        ""a6a2b7186bf8001b510128be269870aac023271a"",
        ""fe9b7fecc60887755883b5d68fb706985d1f8667"",
        ""513b4a3e27ebf880868824240f0d294e7e128bdf"",
        ""fcba58ea4011b37731bba8b142b5d4a515f17839"",
        ""8dc4edaecb96a628b0d99e6e6ccc9bb2e13f2f54"",
        ""38e18cba8c86ec3a412c5d1360118e9d19f4042f"",
        ""c2ff4cb3f08a522ad4df96a664c39a697353e28e"",
        ""bd8f4c8e205694750d9f0c467accf0b9bb6b17eb"",
        ""1bc495d4e55ace48ae281ae1ec640e3a17eb443f"",
        ""2d1486375a20fd5d88290048f94e6f591f198dfc"",
        ""61107b1197fa6d0852f3460b496e945d7e4a9d83"",
        ""cf19438b68da32ad4966266b01b2982546fc75c0"",
        ""582558dc77d80d429fa473b67cedc6d56f1c201d"",
        ""546e375adc31e156ed6b497c944b7d48da5693bc"",
        ""7563df69fe82c944d0f6cf38890a4438af3ab8ee"",
        ""1a874199bec2f87134661592b628fb73a65c02de"",
        ""949af990f79e1bc45f4c5fbe83985cb81eebe6df"",
        ""4f95b6947580a4673c51453c5b5836785d987db5"",
        ""765de32d0e29d7fdc1c7ee597b90e942b9af23d6"",
        ""239bccdf526f72fd3e50993c91bac022d069e5ae"",
        ""d9b13df014743e24012795fe3ee07c57ce23326d"",
        ""8526dac4a73c678fb3d77f2bbbe9dba7c9bc73dd"",
        ""3debcd9ed0f762dd757d0426c1b7f41c7875e378"",
        ""cee0a86071305d3440f89da9fc57691ac1e934c9"",
        ""39989d7eed8a07022d06f3e5ea435ca55100b679"",
        ""d969fd286799af572eacb3b49c0881e1ea445ed3"",
        ""45165512f94f2cc9fb0259b6d1b8311cfda3928d"",
        ""612ee65b07c8a0e3d4f29be1ecc5f93ae26b6938"",
        ""90695c16a4f16741ddc792cf98d35fbafe0b5915"",
        ""9e922d7be75abba592701aec08117c1e023945ac"",
        ""68be1ea418b8a032adac85a15bffe15493be4607"",
        ""81dc4f14a323823a2a3a160a3d1e93de210b45ea"",
        ""8d37248c1e0b669d1f35d8cc23072a315eac51dc"",
        ""259426f84740e41182bbb63b7a2bb99f914c1bb6"",
        ""5da715b5521d883f4f67e39811c7ee392a28d31a"",
        ""35cd3a23c15e845849ebc397dd53a2f5692c52bf"",
        ""8796b53ec4f56869fb579d63ba88b369a8784d54"",
        ""1f01bbfeddb009fb49b1db0f192cb73d39c8f36d"",
        ""2c634e11f873c36e72e8415ceb5085de3d9ec507"",
        ""4f179be70e391c4b1b681dbdbd8126e10afd9800"",
        ""76ea0cb6ca47b3a49622d23037e8e7de24281ccf"",
        ""65ea841dbbff2244f144032ddd78d65d96093cb1"",
        ""79b998ff69792a63fa08d1f4c81bb8797c51d325"",
        ""9d88857c845dcecdf5628abbfdfb72c25bab9a1f"",
        ""6e9d67f2a308ca3d580b78c9f5894dde12fe981d"",
        ""38f6f3fe2ad90ede508cfdbd4c256e13d6bbfa1d"",
        ""e854a11f6df60bc01c75bebf046f01a0954ebafc"",
        ""b48ad49aac46081a38b501384b0364d10af9e2db"",
        ""8b3b108bb2f15275072b2479896d425700434754"",
        ""ba3a429b8bc8054427ee8209f1d725cc9bd0de3a"",
        ""7b7571cec88e81dbb74d9d923961d12a8a6e6fde"",
        ""3bfe1b6d98d0e263ba3bdf53a30766dac50a49a0"",
        ""4b3d47c6f13cceb2c789ae2c5d867b114d9e7fd3"",
        ""f79f954746fe5542f951401a43233e57ba959047"",
        ""d7e5d2d48a2ddf316d000fd6ff82b039a18e4489"",
        ""a1eb6dd53e364e03d2f51588decc4d64be7d6caa"",
        ""a3e4b3692cca9dad58987ed92792d283b0a0237d"",
        ""328e74b65839f7e5a8ae3b54e0b49180a5b7b82b"",
        ""7a0268b317ebc8deec82ff2481bd12c1d9640d05"",
        ""a4b2efea01e274f56744342bc9021fbab838f5fc"",
        ""c0585e66fee320a6d69c25248487464f8fe24dc6"",
        ""af2500de57708675419c4db313e654bf462e2d67"",
        ""5171f8a8291d7edc31a6670800d5967cfd6be830"",
        ""1f3134056c4ec8e09e12f8ce01853cb1ac697a06"",
        ""592075707f47b954553198633f0bfd57ae50e9e6"",
        ""92af21f1dc2c6568d473934950b59ae670c82e41"",
        ""5586cc035bd67b62124e24fcd0b60d7414909c9f"",
        ""f03ae7b490022507f83729b9227e723ab1587a38"",
        ""1b1b826853b6152b7e7ec4b39f47ecfb60143372"",
        ""0b583a1bd52bd7e5579a4f7e47624d990f6ba282"",
        ""34347c8ae54b8e84947f901d86761875364a9c5a"",
        ""cecbde44129b2b2537546d252176b49e986e9fda"",
        ""09df7e67ab764a5cb65a0826a3a0b2a3b3ebf621"",
        ""df2a3bdb4911011eddf4fa94c6f58857e0f120c7"",
        ""4605e706ad65f35fcc31b09d2d0d331eb6ae9a2a"",
        ""ce9f7fb173dc5846e37396df70003b389d311d1b"",
        ""38863b2030eae29b3efc81115f035a4c4cc95122"",
        ""20a1a5802c7abda8c76fb2771dbbe53458c8b37e"",
        ""174ca973d3b327276c73d0cf76698e7acb0f6bee"",
        ""021beda55a84b562e68610fedfae3b137e22416c"",
        ""291e89bcd9d3bdd72f11a5a53196151ceb063ba4"",
        ""2558e35095ac9323ff381c4488a9bb9f7df21486"",
        ""578c0a3a1363260575f1b1273eb28bd2c1b7dbac"",
        ""5d7ed63f6b79c3cd9f134f48be2521abfb9c6de1"",
        ""7c9c3ffd4d4a85bc927e7ea1165c48ab79a4fc81"",
        ""099fcd63a9a0387c1455717f9eaf50de058bdb5b"",
        ""72ed82e1d1ddb86e6577c80b8a4dfeb4f99c1975"",
        ""cc4322b0f6cbf8586f13a6bb8f8f12c51ce795e8"",
        ""ffa7d2f123658ad92b52d0f2e5198458b5d854d4"",
        ""39652652308646ebbd3f4291821a47754b1d6297"",
        ""32c1b1592175ea226ca22482fe7d32e1593d432b"",
        ""d938addbdc76f7de47775442ca045a2720d48be0"",
        ""6e31e029d051eb7bacfd86e93f7eab43d4730054"",
        ""a042f9c1c6de833686ae4a45f92515d028925df7"",
        ""bbcce901fa961f9df12681ba834c2f91ad4ba7b0"",
        ""986815d07b173ab7e8a9b40c843464cb52f0d86f"",
        ""09653a52077d5d747a9dfe64b3a8889c1c095c4d"",
        ""9d2fb91440d05039be549cd3ba21adad2823608a"",
        ""95ca9a4a8527d48de831b077dc3114173f125f62"",
        ""875870fdb5b991aa654783f1b2e6bd2b10b557e3"",
        ""9f5295803b5e1e8ac460656cb8ba57fef77099de"",
        ""bc9cf585a68cf44e2c5115ec3e9519c37d2c2e85"",
        ""b01f344da89c62977b1b4dc7d36cfaa546c630c8"",
        ""29d2fa6dbccd06134eb8832d1d942f4b29495f3d"",
        ""fa03bdcc920bdad46598cabd249a1f629cef010c"",
        ""d8db70567effb326c173b17b2b5b6df22f1c4cc6"",
        ""0681d1f146a390a27dcc628e982cadb5d7b500bc"",
        ""d6a0dd9c1c5e4df22b72979a097974ea3b7ba87b"",
        ""3946e7b3cfb83c71718dc4fab8d50ce6171f2443"",
        ""c0ef15bf5e38ba0221662569ee5a9aacc4cf6e2d"",
        ""598b7d6806c264d36776ff80635f95a0188d730d"",
        ""044b49d6fffc5cbb411784d6baa8b990d3856189"",
        ""cc8e98a7cfe36a74850eb52fbd2e0ca07a80a508"",
        ""6cea33858a30385a387c0704031c8be70b92cb4f"",
        ""e05547ea87ea55eff079de295ff56f483e5b4439"",
        ""86b9eff27444689c422fa9d3803c574dc402d0d0"",
        ""4510b2a983dc2253eb5f48a2bbe382b77a7a9be5"",
        ""6a8cb808568e67faf2f6d675a8738eb45131f787"",
        ""a7975f328539ded81f4453665bc578a5bd3e10a1"",
        ""14be9ce5a0358b0c002e3147e1fefa4c0d513926"",
        ""f2c6495f30d02e90ae465da3e1f5c48649dc77c4"",
        ""b4c3d831107de93e90405a275230aca61ac05099"",
        ""34d583663baf662b192a248adc8cca9702dc6dc5"",
        ""465d59659c40563765956e57d427262acbdc8485"",
        ""ebdedf722a3ec938da3fd53eb74fdea55c48a19d"",
        ""1f00cbefb9a1fafb3b3368d5dcc062b19e38db71"",
        ""0f9a58bfaf1f7808815bd9528d7af2de50dd1455"",
        ""045d9aa4358916d42ab896547ab21b6014606eb2"",
        ""992bede683598137b91ef6dae75cc125137c37e0"",
        ""0518502faba1c63489562641c36a989e0f574d95"",
        ""54d31620146af42375e0974c2ac2864218d2f197"",
        ""c3eb866fa2762e6abc36d226f2bb75017afb03e7"",
        ""fdba2ad440c231d15a2179f729b4b50ab5860df2"",
        ""018cb07aa9747e34bbd6b6f614a32f72d6e82d55"",
        ""549a20c0b0149a2a1a06ae433d7a29c95b800718"",
      ]
    `)
  })",snuts
/__tests__/test-listObjects.js,ComplexSnapshots,"{'startLine':22,'endLine':197}","it('listObjects', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-listObjects')
    // Test
    const objects = await listObjects({
      fs,
      cache: {},
      gitdir,
      oids: [
        'c60bbbe99e96578105c57c4b3f2b6ebdf863edbc',
        'e05547ea87ea55eff079de295ff56f483e5b4439',
        'ebdedf722a3ec938da3fd53eb74fdea55c48a19d',
        '0518502faba1c63489562641c36a989e0f574d95',
      ],
    })
    expect([...objects]).toMatchInlineSnapshot(`
      Array [
        ""c60bbbe99e96578105c57c4b3f2b6ebdf863edbc"",
        ""a8103169a3cb5fb457e5232a0e36728511e736b4"",
        ""1db939d41956405f755e69ab570296c7ed3cec99"",
        ""bbf3e21f43fa4fe25eb925bfcb7c0434f7c2dc7d"",
        ""4a58bdcdef3eb91264dfca0279959d98c16568d5"",
        ""eb1a0c5bb07374f97343010b019aeb3e6be472ee"",
        ""47967151a5ff9366ca5d86e261c9ceb835d7b722"",
        ""c675a17ccb1578bca836decf90205fdad743827d"",
        ""d7b25aab38d0772c4e0da5a88c84f369241e230e"",
        ""049041e4f5c2216806a69c78b3405d8882a6ce7a"",
        ""bf45c6a17356154e11e14325624e170201f3f875"",
        ""557574c5a4e2d6378c3b44e954790e2903a066b7"",
        ""c5059df27e646eca3c538fcb435bb5d3a5335e3d"",
        ""0dd30ed7ff2c698dec130d3451c99cdd9bbf1633"",
        ""60b63f5f7298f29033ec8b5fa19b689062282363"",
        ""e87c4acef861687deb2728c9f3667a0dc03a8958"",
        ""e965047ad7c57865823c7d992b1d046ea66edf78"",
        ""e5b8f9cece335aca583406109216173174068c73"",
        ""2e957a173810564d93efd6cc48f4149602e8dab0"",
        ""3830b74f75e13b734e117ac65d04fbd92d7ffa30"",
        ""51e632299486ed66ac253a467599cfbdfeb6b635"",
        ""cb089cd89a7d7686d284d8761201649346b5aa1c"",
        ""d545cdabdbddafca3501d2114506fc86e50e9824"",
        ""73003f80fc868def28485d20180318454614e9b5"",
        ""aa0a764f20a691959a981c60de223717d3ddeaa1"",
        ""699e0fe71ff254b1bec2320356657b024bb88657"",
        ""302013a7292bac15dd19b1d29049d69f4862561d"",
        ""9ac4f57c7d98020514ca2baebff511841baa9d93"",
        ""a003a3623c66cf6262db282d769574c556dafe1d"",
        ""be395f63b878f28a86a418ae0d6a291e6fa51de9"",
        ""6a41d6d49eec3593bee14ad19d0a0c0ac08be937"",
        ""651bd64f6c3716fc8a6e8ba6dcbad2d93337f279"",
        ""55158d43140549daee24c7d3534107723c0c056a"",
        ""64280b806c9760fb2313b29cc66dabbd0fe18e26"",
        ""6d925adc4818a513ae2683a12fe381269f45a7c7"",
        ""988c291502fc1acafede7f1ac3e913625ce665de"",
        ""ff53907ca9bd6d5f376188c57bcf1dd4650574c9"",
        ""a6a2b7186bf8001b510128be269870aac023271a"",
        ""fe9b7fecc60887755883b5d68fb706985d1f8667"",
        ""513b4a3e27ebf880868824240f0d294e7e128bdf"",
        ""fcba58ea4011b37731bba8b142b5d4a515f17839"",
        ""8dc4edaecb96a628b0d99e6e6ccc9bb2e13f2f54"",
        ""38e18cba8c86ec3a412c5d1360118e9d19f4042f"",
        ""c2ff4cb3f08a522ad4df96a664c39a697353e28e"",
        ""bd8f4c8e205694750d9f0c467accf0b9bb6b17eb"",
        ""1bc495d4e55ace48ae281ae1ec640e3a17eb443f"",
        ""2d1486375a20fd5d88290048f94e6f591f198dfc"",
        ""61107b1197fa6d0852f3460b496e945d7e4a9d83"",
        ""cf19438b68da32ad4966266b01b2982546fc75c0"",
        ""582558dc77d80d429fa473b67cedc6d56f1c201d"",
        ""546e375adc31e156ed6b497c944b7d48da5693bc"",
        ""7563df69fe82c944d0f6cf38890a4438af3ab8ee"",
        ""1a874199bec2f87134661592b628fb73a65c02de"",
        ""949af990f79e1bc45f4c5fbe83985cb81eebe6df"",
        ""4f95b6947580a4673c51453c5b5836785d987db5"",
        ""765de32d0e29d7fdc1c7ee597b90e942b9af23d6"",
        ""239bccdf526f72fd3e50993c91bac022d069e5ae"",
        ""d9b13df014743e24012795fe3ee07c57ce23326d"",
        ""8526dac4a73c678fb3d77f2bbbe9dba7c9bc73dd"",
        ""3debcd9ed0f762dd757d0426c1b7f41c7875e378"",
        ""cee0a86071305d3440f89da9fc57691ac1e934c9"",
        ""39989d7eed8a07022d06f3e5ea435ca55100b679"",
        ""d969fd286799af572eacb3b49c0881e1ea445ed3"",
        ""45165512f94f2cc9fb0259b6d1b8311cfda3928d"",
        ""612ee65b07c8a0e3d4f29be1ecc5f93ae26b6938"",
        ""90695c16a4f16741ddc792cf98d35fbafe0b5915"",
        ""9e922d7be75abba592701aec08117c1e023945ac"",
        ""68be1ea418b8a032adac85a15bffe15493be4607"",
        ""81dc4f14a323823a2a3a160a3d1e93de210b45ea"",
        ""8d37248c1e0b669d1f35d8cc23072a315eac51dc"",
        ""259426f84740e41182bbb63b7a2bb99f914c1bb6"",
        ""5da715b5521d883f4f67e39811c7ee392a28d31a"",
        ""35cd3a23c15e845849ebc397dd53a2f5692c52bf"",
        ""8796b53ec4f56869fb579d63ba88b369a8784d54"",
        ""1f01bbfeddb009fb49b1db0f192cb73d39c8f36d"",
        ""2c634e11f873c36e72e8415ceb5085de3d9ec507"",
        ""4f179be70e391c4b1b681dbdbd8126e10afd9800"",
        ""76ea0cb6ca47b3a49622d23037e8e7de24281ccf"",
        ""65ea841dbbff2244f144032ddd78d65d96093cb1"",
        ""79b998ff69792a63fa08d1f4c81bb8797c51d325"",
        ""9d88857c845dcecdf5628abbfdfb72c25bab9a1f"",
        ""6e9d67f2a308ca3d580b78c9f5894dde12fe981d"",
        ""38f6f3fe2ad90ede508cfdbd4c256e13d6bbfa1d"",
        ""e854a11f6df60bc01c75bebf046f01a0954ebafc"",
        ""b48ad49aac46081a38b501384b0364d10af9e2db"",
        ""8b3b108bb2f15275072b2479896d425700434754"",
        ""ba3a429b8bc8054427ee8209f1d725cc9bd0de3a"",
        ""7b7571cec88e81dbb74d9d923961d12a8a6e6fde"",
        ""3bfe1b6d98d0e263ba3bdf53a30766dac50a49a0"",
        ""4b3d47c6f13cceb2c789ae2c5d867b114d9e7fd3"",
        ""f79f954746fe5542f951401a43233e57ba959047"",
        ""d7e5d2d48a2ddf316d000fd6ff82b039a18e4489"",
        ""a1eb6dd53e364e03d2f51588decc4d64be7d6caa"",
        ""a3e4b3692cca9dad58987ed92792d283b0a0237d"",
        ""328e74b65839f7e5a8ae3b54e0b49180a5b7b82b"",
        ""7a0268b317ebc8deec82ff2481bd12c1d9640d05"",
        ""a4b2efea01e274f56744342bc9021fbab838f5fc"",
        ""c0585e66fee320a6d69c25248487464f8fe24dc6"",
        ""af2500de57708675419c4db313e654bf462e2d67"",
        ""5171f8a8291d7edc31a6670800d5967cfd6be830"",
        ""1f3134056c4ec8e09e12f8ce01853cb1ac697a06"",
        ""592075707f47b954553198633f0bfd57ae50e9e6"",
        ""92af21f1dc2c6568d473934950b59ae670c82e41"",
        ""5586cc035bd67b62124e24fcd0b60d7414909c9f"",
        ""f03ae7b490022507f83729b9227e723ab1587a38"",
        ""1b1b826853b6152b7e7ec4b39f47ecfb60143372"",
        ""0b583a1bd52bd7e5579a4f7e47624d990f6ba282"",
        ""34347c8ae54b8e84947f901d86761875364a9c5a"",
        ""cecbde44129b2b2537546d252176b49e986e9fda"",
        ""09df7e67ab764a5cb65a0826a3a0b2a3b3ebf621"",
        ""df2a3bdb4911011eddf4fa94c6f58857e0f120c7"",
        ""4605e706ad65f35fcc31b09d2d0d331eb6ae9a2a"",
        ""ce9f7fb173dc5846e37396df70003b389d311d1b"",
        ""38863b2030eae29b3efc81115f035a4c4cc95122"",
        ""20a1a5802c7abda8c76fb2771dbbe53458c8b37e"",
        ""174ca973d3b327276c73d0cf76698e7acb0f6bee"",
        ""021beda55a84b562e68610fedfae3b137e22416c"",
        ""291e89bcd9d3bdd72f11a5a53196151ceb063ba4"",
        ""2558e35095ac9323ff381c4488a9bb9f7df21486"",
        ""578c0a3a1363260575f1b1273eb28bd2c1b7dbac"",
        ""5d7ed63f6b79c3cd9f134f48be2521abfb9c6de1"",
        ""7c9c3ffd4d4a85bc927e7ea1165c48ab79a4fc81"",
        ""099fcd63a9a0387c1455717f9eaf50de058bdb5b"",
        ""72ed82e1d1ddb86e6577c80b8a4dfeb4f99c1975"",
        ""cc4322b0f6cbf8586f13a6bb8f8f12c51ce795e8"",
        ""ffa7d2f123658ad92b52d0f2e5198458b5d854d4"",
        ""39652652308646ebbd3f4291821a47754b1d6297"",
        ""32c1b1592175ea226ca22482fe7d32e1593d432b"",
        ""d938addbdc76f7de47775442ca045a2720d48be0"",
        ""6e31e029d051eb7bacfd86e93f7eab43d4730054"",
        ""a042f9c1c6de833686ae4a45f92515d028925df7"",
        ""bbcce901fa961f9df12681ba834c2f91ad4ba7b0"",
        ""986815d07b173ab7e8a9b40c843464cb52f0d86f"",
        ""09653a52077d5d747a9dfe64b3a8889c1c095c4d"",
        ""9d2fb91440d05039be549cd3ba21adad2823608a"",
        ""95ca9a4a8527d48de831b077dc3114173f125f62"",
        ""875870fdb5b991aa654783f1b2e6bd2b10b557e3"",
        ""9f5295803b5e1e8ac460656cb8ba57fef77099de"",
        ""bc9cf585a68cf44e2c5115ec3e9519c37d2c2e85"",
        ""b01f344da89c62977b1b4dc7d36cfaa546c630c8"",
        ""29d2fa6dbccd06134eb8832d1d942f4b29495f3d"",
        ""fa03bdcc920bdad46598cabd249a1f629cef010c"",
        ""d8db70567effb326c173b17b2b5b6df22f1c4cc6"",
        ""0681d1f146a390a27dcc628e982cadb5d7b500bc"",
        ""d6a0dd9c1c5e4df22b72979a097974ea3b7ba87b"",
        ""3946e7b3cfb83c71718dc4fab8d50ce6171f2443"",
        ""c0ef15bf5e38ba0221662569ee5a9aacc4cf6e2d"",
        ""598b7d6806c264d36776ff80635f95a0188d730d"",
        ""044b49d6fffc5cbb411784d6baa8b990d3856189"",
        ""cc8e98a7cfe36a74850eb52fbd2e0ca07a80a508"",
        ""6cea33858a30385a387c0704031c8be70b92cb4f"",
        ""e05547ea87ea55eff079de295ff56f483e5b4439"",
        ""86b9eff27444689c422fa9d3803c574dc402d0d0"",
        ""4510b2a983dc2253eb5f48a2bbe382b77a7a9be5"",
        ""6a8cb808568e67faf2f6d675a8738eb45131f787"",
        ""a7975f328539ded81f4453665bc578a5bd3e10a1"",
        ""14be9ce5a0358b0c002e3147e1fefa4c0d513926"",
        ""f2c6495f30d02e90ae465da3e1f5c48649dc77c4"",
        ""b4c3d831107de93e90405a275230aca61ac05099"",
        ""34d583663baf662b192a248adc8cca9702dc6dc5"",
        ""465d59659c40563765956e57d427262acbdc8485"",
        ""ebdedf722a3ec938da3fd53eb74fdea55c48a19d"",
        ""1f00cbefb9a1fafb3b3368d5dcc062b19e38db71"",
        ""0f9a58bfaf1f7808815bd9528d7af2de50dd1455"",
        ""045d9aa4358916d42ab896547ab21b6014606eb2"",
        ""992bede683598137b91ef6dae75cc125137c37e0"",
        ""0518502faba1c63489562641c36a989e0f574d95"",
        ""54d31620146af42375e0974c2ac2864218d2f197"",
        ""c3eb866fa2762e6abc36d226f2bb75017afb03e7"",
        ""fdba2ad440c231d15a2179f729b4b50ab5860df2"",
        ""018cb07aa9747e34bbd6b6f614a32f72d6e82d55"",
        ""549a20c0b0149a2a1a06ae433d7a29c95b800718"",
      ]
    `)
  })",snuts
/__tests__/test-listNotes.js,SubOptimalAssert,"{'startLine':15,'endLine':15}","it('from default branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-listNotes')
    // Test
    const notes = await listNotes({
      fs,
      gitdir,
    })
    expect(notes.length).toBe(3)
    expect(notes).toEqual([
      {
        note: '0bd2dc08e06dafbcdfe1c97fc64a99d0f206ef78',
        target: '199948939a0b95c6f27668689102496574b2c332',
      },
      {
        note: '6e2160d80f201db57a02415c47da5037ecc7c27f',
        target: '68aba62e560c0ebc3396e8ae9335232cd93a3f60',
      },
      {
        note: '40f0ba45e23b41630eabae9f4fc8d5007e37fcd6',
        target: 'f6d51b1f9a449079f6999be1fb249c359511f164',
      },
    ])
  })",snuts
/__tests__/test-listNotes.js,SubOptimalAssert,"{'startLine':40,'endLine':40}","it('from alternate branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-listNotes')
    // Test
    const notes = await listNotes({
      fs,
      gitdir,
      ref: 'refs/notes/alt',
    })
    expect(notes.length).toBe(1)
    expect(notes).toEqual([
      {
        note: '73ec9c00618d8ebb2648c47c9b05d78227569728',
        target: 'f6d51b1f9a449079f6999be1fb249c359511f164',
      },
    ])
  })",snuts
/__tests__/test-listNotes.js,SubOptimalAssert,"{'startLine':57,'endLine':57}","it('from non-existant branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-listNotes')
    // Test
    const notes = await listNotes({
      fs,
      gitdir,
      ref: 'refs/notes/alt2',
    })
    expect(notes.length).toBe(0)
    expect(notes).toEqual([])
  })",snuts
/__tests__/test-listFiles.js,AnonymousTest,"{'startLine':7,'endLine':48}","it('index', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-listFiles')
    // Test
    const files = await listFiles({ fs, gitdir })
    expect(files).toMatchInlineSnapshot(`
      Array [
        "".babelrc"",
        "".editorconfig"",
        "".flowconfig"",
        "".gitignore"",
        "".travis.yml"",
        ""LICENSE.md"",
        ""README.md"",
        ""package-lock.json"",
        ""package.json"",
        ""shrinkwrap.yaml"",
        ""src/commands/checkout.js"",
        ""src/commands/config.js"",
        ""src/commands/fetch.js"",
        ""src/commands/init.js"",
        ""src/index.js"",
        ""src/models/GitBlob.js"",
        ""src/models/GitCommit.js"",
        ""src/models/GitConfig.js"",
        ""src/models/GitObject.js"",
        ""src/models/GitTree.js"",
        ""src/utils/exists.js"",
        ""src/utils/mkdirs.js"",
        ""src/utils/read.js"",
        ""src/utils/resolveRef.js"",
        ""src/utils/write.js"",
        ""test/_helpers.js"",
        ""test/snapshots/test-resolveRef.js.md"",
        ""test/snapshots/test-resolveRef.js.snap"",
        ""test/test-clone.js"",
        ""test/test-config.js"",
        ""test/test-init.js"",
        ""test/test-resolveRef.js"",
      ]
    `)
  })",snuts
/__tests__/test-listFiles.js,AnonymousTest,"{'startLine':49,'endLine':88}","it('ref', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-checkout')
    // Test
    const files = await listFiles({ fs, gitdir, ref: 'test-branch' })
    expect(files).toMatchInlineSnapshot(`
      Array [
        "".babelrc"",
        "".editorconfig"",
        "".flowconfig"",
        "".gitignore"",
        ""LICENSE.md"",
        ""README.md"",
        ""package.json"",
        ""shrinkwrap.yaml"",
        ""src/commands/checkout.js"",
        ""src/commands/config.js"",
        ""src/commands/fetch.js"",
        ""src/commands/init.js"",
        ""src/index.js"",
        ""src/models/GitBlob.js"",
        ""src/models/GitCommit.js"",
        ""src/models/GitConfig.js"",
        ""src/models/GitTree.js"",
        ""src/utils/combinePayloadAndSignature.js"",
        ""src/utils/commitSha.js"",
        ""src/utils/exists.js"",
        ""src/utils/mkdirs.js"",
        ""src/utils/read.js"",
        ""src/utils/resolveRef.js"",
        ""src/utils/unwrapObject.js"",
        ""src/utils/wrapCommit.js"",
        ""src/utils/write.js"",
        ""test/resolveRef.js"",
        ""test/smoke.js"",
        ""test/snapshots/resolveRef.js.md"",
        ""test/snapshots/resolveRef.js.snap"",
      ]
    `)
  })",snuts
/__tests__/test-listCommitsAndTags.js,AnonymousTest,"{'startLine':7,'endLine':25}","it('listCommitsAndTags', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-listCommitsAndTags')
    // Test
    const commits = await listCommitsAndTags({
      fs,
      gitdir,
      start: ['c60bbbe99e96578105c57c4b3f2b6ebdf863edbc'],
      finish: ['c77052f99c33dbe3d2a120805fcebe9e2194b6f9'],
    })
    expect([...commits]).toMatchInlineSnapshot(`
      Array [
        ""c60bbbe99e96578105c57c4b3f2b6ebdf863edbc"",
        ""e05547ea87ea55eff079de295ff56f483e5b4439"",
        ""ebdedf722a3ec938da3fd53eb74fdea55c48a19d"",
        ""0518502faba1c63489562641c36a989e0f574d95"",
      ]
    `)
  })",snuts
/__tests__/test-listBranches.js,AnonymousTest,"{'startLine':7,'endLine':20}","it('listBranches', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-listBranches')
    // Test
    const commits = await listBranches({ fs, gitdir })
    expect(commits).toMatchInlineSnapshot(`
      Array [
        ""feature/supercool"",
        ""greenkeeper/initial"",
        ""master"",
        ""test-branch"",
      ]
    `)
  })",snuts
/__tests__/test-listBranches.js,AnonymousTest,"{'startLine':21,'endLine':36}","it('remote', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-listBranches')
    // Test
    const commits = await listBranches({
      fs,
      gitdir,
      remote: 'origin',
    })
    expect(commits).toMatchInlineSnapshot(`
      Array [
        ""HEAD"",
        ""master"",
      ]
    `)
  })",snuts
/__tests__/test-init.js,AnonymousTest,"{'startLine':9,'endLine':16}","it('init', async () => {
    const { fs, dir } = await makeFixture('test-init')
    await init({ fs, dir })
    expect(await fs.exists(dir)).toBe(true)
    expect(await fs.exists(`${dir}/.git/objects`)).toBe(true)
    expect(await fs.exists(`${dir}/.git/refs/heads`)).toBe(true)
    expect(await fs.exists(`${dir}/.git/HEAD`)).toBe(true)
  })",snuts
/__tests__/test-init.js,AnonymousTest,"{'startLine':17,'endLine':24}","it('init --bare', async () => {
    const { fs, dir } = await makeFixture('test-init')
    await init({ fs, dir, bare: true })
    expect(await fs.exists(dir)).toBe(true)
    expect(await fs.exists(`${dir}/objects`)).toBe(true)
    expect(await fs.exists(`${dir}/refs/heads`)).toBe(true)
    expect(await fs.exists(`${dir}/HEAD`)).toBe(true)
  })",snuts
/__tests__/test-hosting-providers.js,AnonymousTest,"{'startLine':26,'endLine':42}","it('fetch', async () => {
      // Setup
      const { fs, gitdir } = await makeFixture('test-hosting-providers')
      // Test
      const res = await fetch({
        fs,
        http,
        gitdir,
        corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
        remote: 'awscc',
        ref: 'master',
        onAuth: () => ({ username, password }),
      })
      expect(res).toBeTruthy()
      expect(res.defaultBranch).toBe('refs/heads/master')
      expect(res.fetchHead).toBe('c03e131196f43a78888415924bcdcbf3090f3316')
    })",snuts
/__tests__/test-hosting-providers.js,AnonymousTest,"{'startLine':43,'endLine':60}","it('push', async () => {
      // Setup
      const { fs, gitdir } = await makeFixture('test-hosting-providers')
      // Test
      const res = await push({
        fs,
        http,
        gitdir,
        corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
        remote: 'awscc',
        ref: 'master',
        force: true,
        onAuth: () => ({ username, password }),
      })
      expect(res).toBeTruthy()
      expect(res.ok).toBe(true)
      expect(res.refs['refs/heads/master'].ok).toBe(true)
    })",snuts
/__tests__/test-hosting-providers.js,AnonymousTest,"{'startLine':69,'endLine':85}","it('fetch', async () => {
      // Setup
      const { fs, gitdir } = await makeFixture('test-hosting-providers')
      // Test
      const res = await fetch({
        fs,
        http,
        gitdir,
        // corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
        remote: 'azure',
        ref: 'master',
        onAuth: () => ({ username, password }),
      })
      expect(res).toBeTruthy()
      expect(res.defaultBranch).toBe('refs/heads/master')
      expect(res.fetchHead).toBe('c03e131196f43a78888415924bcdcbf3090f3316')
    })",snuts
/__tests__/test-hosting-providers.js,AnonymousTest,"{'startLine':115,'endLine':132}","it('push', async () => {
      // Setup
      const { fs, gitdir } = await makeFixture('test-hosting-providers')
      // Test
      const res = await push({
        fs,
        http,
        gitdir,
        corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
        remote: 'bitbucket',
        ref: 'master',
        force: true,
        onAuth: () => ({ username, password }),
      })
      expect(res).toBeTruthy()
      expect(res.ok).toBe(true)
      expect(res.refs['refs/heads/master'].ok).toBe(true)
    })",snuts
/__tests__/test-hosting-providers.js,AnonymousTest,"{'startLine':133,'endLine':149}","it('fetch', async () => {
      // Setup
      const { fs, gitdir } = await makeFixture('test-hosting-providers')
      // Test
      const res = await fetch({
        fs,
        http,
        gitdir,
        corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
        remote: 'bitbucket',
        ref: 'master',
        onAuth: () => ({ username, password }),
      })
      expect(res).toBeTruthy()
      expect(res.defaultBranch).toBe('refs/heads/master')
      expect(res.fetchHead).toBe('c03e131196f43a78888415924bcdcbf3090f3316')
    })",snuts
/__tests__/test-hosting-providers.js,AnonymousTest,"{'startLine':159,'endLine':175}","it('fetch', async () => {
      // Setup
      const { fs, gitdir } = await makeFixture('test-hosting-providers')
      // Test
      const res = await fetch({
        fs,
        http,
        gitdir,
        corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
        remote: 'github',
        ref: 'master',
        onAuth: () => ({ username, password }),
      })
      expect(res).toBeTruthy()
      expect(res.defaultBranch).toBe('refs/heads/test')
      expect(res.fetchHead).toBe('c03e131196f43a78888415924bcdcbf3090f3316')
    })",snuts
/__tests__/test-hosting-providers.js,AnonymousTest,"{'startLine':176,'endLine':193}","it('push', async () => {
      // Setup
      const { fs, gitdir } = await makeFixture('test-hosting-providers')
      // Test
      const res = await push({
        fs,
        http,
        gitdir,
        corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
        remote: 'github',
        ref: 'master',
        force: true,
        onAuth: () => ({ username, password }),
      })
      expect(res).toBeTruthy()
      expect(res.ok).toBe(true)
      expect(res.refs['refs/heads/master'].ok).toBe(true)
    })",snuts
/__tests__/test-hosting-providers.js,AnonymousTest,"{'startLine':203,'endLine':219}","it('fetch', async () => {
      // Setup
      const { fs, gitdir } = await makeFixture('test-hosting-providers')
      // Test
      const res = await fetch({
        fs,
        http,
        gitdir,
        corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
        remote: 'gitlab',
        ref: 'master',
        onAuth: () => ({ username, password }),
      })
      expect(res).toBeTruthy()
      expect(res.defaultBranch).toBe('refs/heads/master')
      expect(res.fetchHead).toBe('c03e131196f43a78888415924bcdcbf3090f3316')
    })",snuts
/__tests__/test-hosting-providers.js,AnonymousTest,"{'startLine':220,'endLine':237}","it('push', async () => {
      // Setup
      const { fs, gitdir } = await makeFixture('test-hosting-providers')
      // Test
      const res = await push({
        fs,
        http,
        gitdir,
        corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
        remote: 'gitlab',
        ref: 'master',
        force: true,
        onAuth: () => ({ username, password }),
      })
      expect(res).toBeTruthy()
      expect(res.ok).toBe(true)
      expect(res.refs['refs/heads/master'].ok).toBe(true)
    })",snuts
/__tests__/test-hosting-providers.js,IdenticalTestDescription,"{'startLine':69,'endLine':85}","it('fetch', async () => {
      // Setup
      const { fs, gitdir } = await makeFixture('test-hosting-providers')
      // Test
      const res = await fetch({
        fs,
        http,
        gitdir,
        // corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
        remote: 'azure',
        ref: 'master',
        onAuth: () => ({ username, password }),
      })
      expect(res).toBeTruthy()
      expect(res.defaultBranch).toBe('refs/heads/master')
      expect(res.fetchHead).toBe('c03e131196f43a78888415924bcdcbf3090f3316')
    })",snuts
/__tests__/test-hosting-providers.js,IdenticalTestDescription,"{'startLine':115,'endLine':132}","it('push', async () => {
      // Setup
      const { fs, gitdir } = await makeFixture('test-hosting-providers')
      // Test
      const res = await push({
        fs,
        http,
        gitdir,
        corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
        remote: 'bitbucket',
        ref: 'master',
        force: true,
        onAuth: () => ({ username, password }),
      })
      expect(res).toBeTruthy()
      expect(res.ok).toBe(true)
      expect(res.refs['refs/heads/master'].ok).toBe(true)
    })",snuts
/__tests__/test-hosting-providers.js,IdenticalTestDescription,"{'startLine':133,'endLine':149}","it('fetch', async () => {
      // Setup
      const { fs, gitdir } = await makeFixture('test-hosting-providers')
      // Test
      const res = await fetch({
        fs,
        http,
        gitdir,
        corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
        remote: 'bitbucket',
        ref: 'master',
        onAuth: () => ({ username, password }),
      })
      expect(res).toBeTruthy()
      expect(res.defaultBranch).toBe('refs/heads/master')
      expect(res.fetchHead).toBe('c03e131196f43a78888415924bcdcbf3090f3316')
    })",snuts
/__tests__/test-hosting-providers.js,IdenticalTestDescription,"{'startLine':159,'endLine':175}","it('fetch', async () => {
      // Setup
      const { fs, gitdir } = await makeFixture('test-hosting-providers')
      // Test
      const res = await fetch({
        fs,
        http,
        gitdir,
        corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
        remote: 'github',
        ref: 'master',
        onAuth: () => ({ username, password }),
      })
      expect(res).toBeTruthy()
      expect(res.defaultBranch).toBe('refs/heads/test')
      expect(res.fetchHead).toBe('c03e131196f43a78888415924bcdcbf3090f3316')
    })",snuts
/__tests__/test-hosting-providers.js,IdenticalTestDescription,"{'startLine':176,'endLine':193}","it('push', async () => {
      // Setup
      const { fs, gitdir } = await makeFixture('test-hosting-providers')
      // Test
      const res = await push({
        fs,
        http,
        gitdir,
        corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
        remote: 'github',
        ref: 'master',
        force: true,
        onAuth: () => ({ username, password }),
      })
      expect(res).toBeTruthy()
      expect(res.ok).toBe(true)
      expect(res.refs['refs/heads/master'].ok).toBe(true)
    })",snuts
/__tests__/test-hosting-providers.js,IdenticalTestDescription,"{'startLine':203,'endLine':219}","it('fetch', async () => {
      // Setup
      const { fs, gitdir } = await makeFixture('test-hosting-providers')
      // Test
      const res = await fetch({
        fs,
        http,
        gitdir,
        corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
        remote: 'gitlab',
        ref: 'master',
        onAuth: () => ({ username, password }),
      })
      expect(res).toBeTruthy()
      expect(res.defaultBranch).toBe('refs/heads/master')
      expect(res.fetchHead).toBe('c03e131196f43a78888415924bcdcbf3090f3316')
    })",snuts
/__tests__/test-hosting-providers.js,IdenticalTestDescription,"{'startLine':220,'endLine':237}","it('push', async () => {
      // Setup
      const { fs, gitdir } = await makeFixture('test-hosting-providers')
      // Test
      const res = await push({
        fs,
        http,
        gitdir,
        corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
        remote: 'gitlab',
        ref: 'master',
        force: true,
        onAuth: () => ({ username, password }),
      })
      expect(res).toBeTruthy()
      expect(res.ok).toBe(true)
      expect(res.refs['refs/heads/master'].ok).toBe(true)
    })",snuts
/__tests__/test-hashBlob.js,SubOptimalAssert,"{'startLine':49,'endLine':49}","it('object as Uint8Array', async () => {
    // Test
    const { oid, object, format } = await hashBlob({
      object: buffer,
    })
    expect(oid).toEqual('4551a1856279dde6ae9d65862a1dff59a5f199d8')
    expect(format).toEqual('wrapped')
    expect(Buffer.compare(Buffer.from(object), wrapped) === 0).toBe(true)
  })",snuts
/__tests__/test-hashBlob.js,SubOptimalAssert,"{'startLine':59,'endLine':59}","it('object as String', async () => {
    // Test
    const { oid, object, format } = await hashBlob({
      object: string,
    })
    expect(oid).toEqual('4551a1856279dde6ae9d65862a1dff59a5f199d8')
    expect(format).toEqual('wrapped')
    expect(Buffer.compare(Buffer.from(object), wrapped) === 0).toBe(true)
  })",snuts
/__tests__/test-getRemoteInfo2.js,AnonymousTest,"{'startLine':11,'endLine':26}","it('protocol 2', async () => {
    const info = await getRemoteInfo2({
      http,
      url: `http://${localhost}:8888/test-dumb-http-server.git`,
      protocolVersion: 2,
    })
    expect(info).toBeDefined()
    expect(info.capabilities).toBeDefined()
    expect(info.protocolVersion).toBe(2)
    if (info.protocolVersion === 2) {
      // The actual capabilities reported will vary depending on what version of git is installed on the machine running the test suite,
      // but I think it is fair to assume at least these two commands will be reported.
      expect(info.capabilities['ls-refs']).toBeDefined()
      expect(info.capabilities.fetch).toBeDefined()
    }
  })",snuts
/__tests__/test-getRemoteInfo2.js,AnonymousTest,"{'startLine':28,'endLine':57}","it('protocol 1', async () => {
    const info = await getRemoteInfo2({
      http,
      url: `http://${localhost}:8888/test-dumb-http-server.git`,
      protocolVersion: 1,
    })
    expect(info).toBeDefined()
    expect(info.capabilities).toBeDefined()
    expect(info.protocolVersion).toBe(1)
    if (info.protocolVersion === 1) {
      expect(info.refs).toBeDefined()
      expect(info.refs).toMatchInlineSnapshot(`
        Array [
          Object {
            ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
            ""ref"": ""HEAD"",
            ""target"": ""refs/heads/master"",
          },
          Object {
            ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
            ""ref"": ""refs/heads/master"",
          },
          Object {
            ""oid"": ""5a8905a02e181fe1821068b8c0f48cb6633d5b81"",
            ""ref"": ""refs/heads/test"",
          },
        ]
      `)
    }
  })",snuts
/__tests__/test-getRemoteInfo2.js,ConditionalTestLogic,"{'startLine':20,'endLine':25}","it('protocol 2', async () => {
    const info = await getRemoteInfo2({
      http,
      url: `http://${localhost}:8888/test-dumb-http-server.git`,
      protocolVersion: 2,
    })
    expect(info).toBeDefined()
    expect(info.capabilities).toBeDefined()
    expect(info.protocolVersion).toBe(2)
    if (info.protocolVersion === 2) {
      // The actual capabilities reported will vary depending on what version of git is installed on the machine running the test suite,
      // but I think it is fair to assume at least these two commands will be reported.
      expect(info.capabilities['ls-refs']).toBeDefined()
      expect(info.capabilities.fetch).toBeDefined()
    }
  })",snuts
/__tests__/test-getRemoteInfo2.js,ConditionalTestLogic,"{'startLine':37,'endLine':56}","it('protocol 1', async () => {
    const info = await getRemoteInfo2({
      http,
      url: `http://${localhost}:8888/test-dumb-http-server.git`,
      protocolVersion: 1,
    })
    expect(info).toBeDefined()
    expect(info.capabilities).toBeDefined()
    expect(info.protocolVersion).toBe(1)
    if (info.protocolVersion === 1) {
      expect(info.refs).toBeDefined()
      expect(info.refs).toMatchInlineSnapshot(`
        Array [
          Object {
            ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
            ""ref"": ""HEAD"",
            ""target"": ""refs/heads/master"",
          },
          Object {
            ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
            ""ref"": ""refs/heads/master"",
          },
          Object {
            ""oid"": ""5a8905a02e181fe1821068b8c0f48cb6633d5b81"",
            ""ref"": ""refs/heads/test"",
          },
        ]
      `)
    }
  })",snuts
/__tests__/test-getRemoteInfo2.js,SubOptimalAssert,"{'startLine':71,'endLine':71}","describe('getRemoteInfo2', () => {
  it('protocol 2', async () => {
    const info = await getRemoteInfo2({
      http,
      url: `http://${localhost}:8888/test-dumb-http-server.git`,
      protocolVersion: 2,
    })
    expect(info).toBeDefined()
    expect(info.capabilities).toBeDefined()
    expect(info.protocolVersion).toBe(2)
    if (info.protocolVersion === 2) {
      // The actual capabilities reported will vary depending on what version of git is installed on the machine running the test suite,
      // but I think it is fair to assume at least these two commands will be reported.
      expect(info.capabilities['ls-refs']).toBeDefined()
      expect(info.capabilities.fetch).toBeDefined()
    }
  })

  it('protocol 1', async () => {
    const info = await getRemoteInfo2({
      http,
      url: `http://${localhost}:8888/test-dumb-http-server.git`,
      protocolVersion: 1,
    })
    expect(info).toBeDefined()
    expect(info.capabilities).toBeDefined()
    expect(info.protocolVersion).toBe(1)
    if (info.protocolVersion === 1) {
      expect(info.refs).toBeDefined()
      expect(info.refs).toMatchInlineSnapshot(`
        Array [
          Object {
            ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
            ""ref"": ""HEAD"",
            ""target"": ""refs/heads/master"",
          },
          Object {
            ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
            ""ref"": ""refs/heads/master"",
          },
          Object {
            ""oid"": ""5a8905a02e181fe1821068b8c0f48cb6633d5b81"",
            ""ref"": ""refs/heads/test"",
          },
        ]
      `)
    }
  })
  ;(process.browser ? it : xit)(
    'detects ""dumb"" HTTP server responses',
    async () => {
      let error = null
      try {
        await getRemoteInfo2({
          http,
          url: `http://${localhost}:9876/base/__tests__/__fixtures__/test-dumb-http-server.git`,
        })
      } catch (err) {
        error = err
      }
      expect(error).toBeDefined()
      expect(error instanceof Errors.SmartHttpError).toBe(true)
    }
  )

  it('throws UnknownTransportError if using shorter scp-like syntax', async () => {
    // Test
    let err
    try {
      await getRemoteInfo2({
        http,
        url: `git@github.com:isomorphic-git/isomorphic-git.git`,
      })
    } catch (e) {
      err = e
    }
    expect(err).toBeDefined()
    expect(err.code).toEqual(Errors.UnknownTransportError.code)
  })
})",snuts
/__tests__/test-getRemoteInfo.js,AnonymousTest,"{'startLine':11,'endLine':27}","it('getRemoteInfo', async () => {
    const info = await getRemoteInfo({
      http,
      url: `http://${localhost}:8888/test-dumb-http-server.git`,
    })
    expect(info).not.toBeNull()
    expect(info.capabilities).not.toBeNull()
    expect(info.refs).not.toBeNull()
    expect(info.refs).toMatchInlineSnapshot(`
      Object {
        ""heads"": Object {
          ""master"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
          ""test"": ""5a8905a02e181fe1821068b8c0f48cb6633d5b81"",
        },
      }
    `)
  })",snuts
/__tests__/test-getRemoteInfo.js,SubOptimalAssert,"{'startLine':41,'endLine':41}","describe('getRemoteInfo', () => {
  it('getRemoteInfo', async () => {
    const info = await getRemoteInfo({
      http,
      url: `http://${localhost}:8888/test-dumb-http-server.git`,
    })
    expect(info).not.toBeNull()
    expect(info.capabilities).not.toBeNull()
    expect(info.refs).not.toBeNull()
    expect(info.refs).toMatchInlineSnapshot(`
      Object {
        ""heads"": Object {
          ""master"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
          ""test"": ""5a8905a02e181fe1821068b8c0f48cb6633d5b81"",
        },
      }
    `)
  })
  ;(process.browser ? it : xit)(
    'detects ""dumb"" HTTP server responses',
    async () => {
      let error = null
      try {
        await getRemoteInfo({
          http,
          url: `http://${localhost}:9876/base/__tests__/__fixtures__/test-dumb-http-server.git`,
        })
      } catch (err) {
        error = err
      }
      expect(error).not.toBeNull()
      expect(error instanceof Errors.SmartHttpError).toBe(true)
    }
  )
  it('throws UnknownTransportError if using shorter scp-like syntax', async () => {
    // Test
    let err
    try {
      await getRemoteInfo({
        http,
        url: `git@github.com:isomorphic-git/isomorphic-git.git`,
      })
    } catch (e) {
      err = e
    }
    expect(err).toBeDefined()
    expect(err.code).toEqual(Errors.UnknownTransportError.code)
  })
})",snuts
/__tests__/test-flatFileListToDirectoryStructure.js,AnonymousTest,"{'startLine':7,'endLine':24}","it('simple', async () => {
    const inode = flatFileListToDirectoryStructure([
      { path: 'hello/there.txt' },
    ]).get('.')
    expect(inode.fullpath).toBe('.')
    expect(inode.type).toBe('tree')
    expect(inode.children.length).toBe(1)
    const hello = inode.children[0]
    expect(hello.type).toBe('tree')
    expect(hello.fullpath).toBe('hello')
    expect(hello.basename).toBe('hello')
    expect(hello.parent).toBe(inode)
    expect(hello.children.length).toBe(1)
    const there = hello.children[0]
    expect(there.type).toBe('blob')
    expect(there.fullpath).toBe('hello/there.txt')
    expect(there.basename).toBe('there.txt')
  })",snuts
/__tests__/test-flatFileListToDirectoryStructure.js,AnonymousTest,"{'startLine':26,'endLine':480}","it('advanced', async () => {
    const filelist = [
      '.babelrc',
      '.editorconfig',
      '.flowconfig',
      '.gitignore',
      '.travis.yml',
      'LICENSE.md',
      'README.md',
      'package-lock.json',
      'package.json',
      'shrinkwrap.yaml',
      'src/commands/checkout.js',
      'src/commands/config.js',
      'src/commands/fetch.js',
      'src/commands/init.js',
      'src/index.js',
      'src/models/GitBlob.js',
      'src/models/GitCommit.js',
      'src/models/GitConfig.js',
      'src/models/GitObject.js',
      'src/models/GitTree.js',
      'src/utils/exists.js',
      'src/utils/mkdirs.js',
      'src/utils/read.js',
      'src/utils/resolveRef.js',
      'src/utils/write.js',
      'test/_helpers.js',
      'test/snapshots/test-resolveRef.js.md',
      'test/snapshots/test-resolveRef.js.snap',
      'test/test-clone.js',
      'test/test-config.js',
      'test/test-init.js',
      'test/test-resolveRef.js',
    ]
    const files = filelist.map(f => ({ path: f, someMeta: f.length }))
    const inodes = flatFileListToDirectoryStructure(files)
    expect(inodes.get('.')).toMatchInlineSnapshot(`
      Object {
        ""basename"": ""."",
        ""children"": Array [
          Object {
            ""basename"": "".babelrc"",
            ""children"": Array [],
            ""fullpath"": "".babelrc"",
            ""metadata"": Object {
              ""path"": "".babelrc"",
              ""someMeta"": 8,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": "".editorconfig"",
            ""children"": Array [],
            ""fullpath"": "".editorconfig"",
            ""metadata"": Object {
              ""path"": "".editorconfig"",
              ""someMeta"": 13,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": "".flowconfig"",
            ""children"": Array [],
            ""fullpath"": "".flowconfig"",
            ""metadata"": Object {
              ""path"": "".flowconfig"",
              ""someMeta"": 11,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": "".gitignore"",
            ""children"": Array [],
            ""fullpath"": "".gitignore"",
            ""metadata"": Object {
              ""path"": "".gitignore"",
              ""someMeta"": 10,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": "".travis.yml"",
            ""children"": Array [],
            ""fullpath"": "".travis.yml"",
            ""metadata"": Object {
              ""path"": "".travis.yml"",
              ""someMeta"": 11,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": ""LICENSE.md"",
            ""children"": Array [],
            ""fullpath"": ""LICENSE.md"",
            ""metadata"": Object {
              ""path"": ""LICENSE.md"",
              ""someMeta"": 10,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": ""README.md"",
            ""children"": Array [],
            ""fullpath"": ""README.md"",
            ""metadata"": Object {
              ""path"": ""README.md"",
              ""someMeta"": 9,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": ""package-lock.json"",
            ""children"": Array [],
            ""fullpath"": ""package-lock.json"",
            ""metadata"": Object {
              ""path"": ""package-lock.json"",
              ""someMeta"": 17,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": ""package.json"",
            ""children"": Array [],
            ""fullpath"": ""package.json"",
            ""metadata"": Object {
              ""path"": ""package.json"",
              ""someMeta"": 12,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": ""shrinkwrap.yaml"",
            ""children"": Array [],
            ""fullpath"": ""shrinkwrap.yaml"",
            ""metadata"": Object {
              ""path"": ""shrinkwrap.yaml"",
              ""someMeta"": 15,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": ""src"",
            ""children"": Array [
              Object {
                ""basename"": ""commands"",
                ""children"": Array [
                  Object {
                    ""basename"": ""checkout.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/commands/checkout.js"",
                    ""metadata"": Object {
                      ""path"": ""src/commands/checkout.js"",
                      ""someMeta"": 24,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""config.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/commands/config.js"",
                    ""metadata"": Object {
                      ""path"": ""src/commands/config.js"",
                      ""someMeta"": 22,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""fetch.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/commands/fetch.js"",
                    ""metadata"": Object {
                      ""path"": ""src/commands/fetch.js"",
                      ""someMeta"": 21,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""init.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/commands/init.js"",
                    ""metadata"": Object {
                      ""path"": ""src/commands/init.js"",
                      ""someMeta"": 20,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                ],
                ""fullpath"": ""src/commands"",
                ""metadata"": Object {},
                ""parent"": [Circular],
                ""type"": ""tree"",
              },
              Object {
                ""basename"": ""index.js"",
                ""children"": Array [],
                ""fullpath"": ""src/index.js"",
                ""metadata"": Object {
                  ""path"": ""src/index.js"",
                  ""someMeta"": 12,
                },
                ""parent"": [Circular],
                ""type"": ""blob"",
              },
              Object {
                ""basename"": ""models"",
                ""children"": Array [
                  Object {
                    ""basename"": ""GitBlob.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/models/GitBlob.js"",
                    ""metadata"": Object {
                      ""path"": ""src/models/GitBlob.js"",
                      ""someMeta"": 21,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""GitCommit.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/models/GitCommit.js"",
                    ""metadata"": Object {
                      ""path"": ""src/models/GitCommit.js"",
                      ""someMeta"": 23,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""GitConfig.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/models/GitConfig.js"",
                    ""metadata"": Object {
                      ""path"": ""src/models/GitConfig.js"",
                      ""someMeta"": 23,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""GitObject.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/models/GitObject.js"",
                    ""metadata"": Object {
                      ""path"": ""src/models/GitObject.js"",
                      ""someMeta"": 23,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""GitTree.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/models/GitTree.js"",
                    ""metadata"": Object {
                      ""path"": ""src/models/GitTree.js"",
                      ""someMeta"": 21,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                ],
                ""fullpath"": ""src/models"",
                ""metadata"": Object {},
                ""parent"": [Circular],
                ""type"": ""tree"",
              },
              Object {
                ""basename"": ""utils"",
                ""children"": Array [
                  Object {
                    ""basename"": ""exists.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/utils/exists.js"",
                    ""metadata"": Object {
                      ""path"": ""src/utils/exists.js"",
                      ""someMeta"": 19,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""mkdirs.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/utils/mkdirs.js"",
                    ""metadata"": Object {
                      ""path"": ""src/utils/mkdirs.js"",
                      ""someMeta"": 19,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""read.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/utils/read.js"",
                    ""metadata"": Object {
                      ""path"": ""src/utils/read.js"",
                      ""someMeta"": 17,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""resolveRef.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/utils/resolveRef.js"",
                    ""metadata"": Object {
                      ""path"": ""src/utils/resolveRef.js"",
                      ""someMeta"": 23,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""write.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/utils/write.js"",
                    ""metadata"": Object {
                      ""path"": ""src/utils/write.js"",
                      ""someMeta"": 18,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                ],
                ""fullpath"": ""src/utils"",
                ""metadata"": Object {},
                ""parent"": [Circular],
                ""type"": ""tree"",
              },
            ],
            ""fullpath"": ""src"",
            ""metadata"": Object {},
            ""parent"": [Circular],
            ""type"": ""tree"",
          },
          Object {
            ""basename"": ""test"",
            ""children"": Array [
              Object {
                ""basename"": ""_helpers.js"",
                ""children"": Array [],
                ""fullpath"": ""test/_helpers.js"",
                ""metadata"": Object {
                  ""path"": ""test/_helpers.js"",
                  ""someMeta"": 16,
                },
                ""parent"": [Circular],
                ""type"": ""blob"",
              },
              Object {
                ""basename"": ""snapshots"",
                ""children"": Array [
                  Object {
                    ""basename"": ""test-resolveRef.js.md"",
                    ""children"": Array [],
                    ""fullpath"": ""test/snapshots/test-resolveRef.js.md"",
                    ""metadata"": Object {
                      ""path"": ""test/snapshots/test-resolveRef.js.md"",
                      ""someMeta"": 36,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""test-resolveRef.js.snap"",
                    ""children"": Array [],
                    ""fullpath"": ""test/snapshots/test-resolveRef.js.snap"",
                    ""metadata"": Object {
                      ""path"": ""test/snapshots/test-resolveRef.js.snap"",
                      ""someMeta"": 38,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                ],
                ""fullpath"": ""test/snapshots"",
                ""metadata"": Object {},
                ""parent"": [Circular],
                ""type"": ""tree"",
              },
              Object {
                ""basename"": ""test-clone.js"",
                ""children"": Array [],
                ""fullpath"": ""test/test-clone.js"",
                ""metadata"": Object {
                  ""path"": ""test/test-clone.js"",
                  ""someMeta"": 18,
                },
                ""parent"": [Circular],
                ""type"": ""blob"",
              },
              Object {
                ""basename"": ""test-config.js"",
                ""children"": Array [],
                ""fullpath"": ""test/test-config.js"",
                ""metadata"": Object {
                  ""path"": ""test/test-config.js"",
                  ""someMeta"": 19,
                },
                ""parent"": [Circular],
                ""type"": ""blob"",
              },
              Object {
                ""basename"": ""test-init.js"",
                ""children"": Array [],
                ""fullpath"": ""test/test-init.js"",
                ""metadata"": Object {
                  ""path"": ""test/test-init.js"",
                  ""someMeta"": 17,
                },
                ""parent"": [Circular],
                ""type"": ""blob"",
              },
              Object {
                ""basename"": ""test-resolveRef.js"",
                ""children"": Array [],
                ""fullpath"": ""test/test-resolveRef.js"",
                ""metadata"": Object {
                  ""path"": ""test/test-resolveRef.js"",
                  ""someMeta"": 23,
                },
                ""parent"": [Circular],
                ""type"": ""blob"",
              },
            ],
            ""fullpath"": ""test"",
            ""metadata"": Object {},
            ""parent"": [Circular],
            ""type"": ""tree"",
          },
        ],
        ""fullpath"": ""."",
        ""metadata"": Object {},
        ""parent"": [Circular],
        ""type"": ""tree"",
      }
    `)
  })",snuts
/__tests__/test-flatFileListToDirectoryStructure.js,ComplexSnapshots,"{'startLine':63,'endLine':479}","it('advanced', async () => {
    const filelist = [
      '.babelrc',
      '.editorconfig',
      '.flowconfig',
      '.gitignore',
      '.travis.yml',
      'LICENSE.md',
      'README.md',
      'package-lock.json',
      'package.json',
      'shrinkwrap.yaml',
      'src/commands/checkout.js',
      'src/commands/config.js',
      'src/commands/fetch.js',
      'src/commands/init.js',
      'src/index.js',
      'src/models/GitBlob.js',
      'src/models/GitCommit.js',
      'src/models/GitConfig.js',
      'src/models/GitObject.js',
      'src/models/GitTree.js',
      'src/utils/exists.js',
      'src/utils/mkdirs.js',
      'src/utils/read.js',
      'src/utils/resolveRef.js',
      'src/utils/write.js',
      'test/_helpers.js',
      'test/snapshots/test-resolveRef.js.md',
      'test/snapshots/test-resolveRef.js.snap',
      'test/test-clone.js',
      'test/test-config.js',
      'test/test-init.js',
      'test/test-resolveRef.js',
    ]
    const files = filelist.map(f => ({ path: f, someMeta: f.length }))
    const inodes = flatFileListToDirectoryStructure(files)
    expect(inodes.get('.')).toMatchInlineSnapshot(`
      Object {
        ""basename"": ""."",
        ""children"": Array [
          Object {
            ""basename"": "".babelrc"",
            ""children"": Array [],
            ""fullpath"": "".babelrc"",
            ""metadata"": Object {
              ""path"": "".babelrc"",
              ""someMeta"": 8,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": "".editorconfig"",
            ""children"": Array [],
            ""fullpath"": "".editorconfig"",
            ""metadata"": Object {
              ""path"": "".editorconfig"",
              ""someMeta"": 13,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": "".flowconfig"",
            ""children"": Array [],
            ""fullpath"": "".flowconfig"",
            ""metadata"": Object {
              ""path"": "".flowconfig"",
              ""someMeta"": 11,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": "".gitignore"",
            ""children"": Array [],
            ""fullpath"": "".gitignore"",
            ""metadata"": Object {
              ""path"": "".gitignore"",
              ""someMeta"": 10,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": "".travis.yml"",
            ""children"": Array [],
            ""fullpath"": "".travis.yml"",
            ""metadata"": Object {
              ""path"": "".travis.yml"",
              ""someMeta"": 11,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": ""LICENSE.md"",
            ""children"": Array [],
            ""fullpath"": ""LICENSE.md"",
            ""metadata"": Object {
              ""path"": ""LICENSE.md"",
              ""someMeta"": 10,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": ""README.md"",
            ""children"": Array [],
            ""fullpath"": ""README.md"",
            ""metadata"": Object {
              ""path"": ""README.md"",
              ""someMeta"": 9,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": ""package-lock.json"",
            ""children"": Array [],
            ""fullpath"": ""package-lock.json"",
            ""metadata"": Object {
              ""path"": ""package-lock.json"",
              ""someMeta"": 17,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": ""package.json"",
            ""children"": Array [],
            ""fullpath"": ""package.json"",
            ""metadata"": Object {
              ""path"": ""package.json"",
              ""someMeta"": 12,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": ""shrinkwrap.yaml"",
            ""children"": Array [],
            ""fullpath"": ""shrinkwrap.yaml"",
            ""metadata"": Object {
              ""path"": ""shrinkwrap.yaml"",
              ""someMeta"": 15,
            },
            ""parent"": [Circular],
            ""type"": ""blob"",
          },
          Object {
            ""basename"": ""src"",
            ""children"": Array [
              Object {
                ""basename"": ""commands"",
                ""children"": Array [
                  Object {
                    ""basename"": ""checkout.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/commands/checkout.js"",
                    ""metadata"": Object {
                      ""path"": ""src/commands/checkout.js"",
                      ""someMeta"": 24,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""config.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/commands/config.js"",
                    ""metadata"": Object {
                      ""path"": ""src/commands/config.js"",
                      ""someMeta"": 22,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""fetch.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/commands/fetch.js"",
                    ""metadata"": Object {
                      ""path"": ""src/commands/fetch.js"",
                      ""someMeta"": 21,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""init.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/commands/init.js"",
                    ""metadata"": Object {
                      ""path"": ""src/commands/init.js"",
                      ""someMeta"": 20,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                ],
                ""fullpath"": ""src/commands"",
                ""metadata"": Object {},
                ""parent"": [Circular],
                ""type"": ""tree"",
              },
              Object {
                ""basename"": ""index.js"",
                ""children"": Array [],
                ""fullpath"": ""src/index.js"",
                ""metadata"": Object {
                  ""path"": ""src/index.js"",
                  ""someMeta"": 12,
                },
                ""parent"": [Circular],
                ""type"": ""blob"",
              },
              Object {
                ""basename"": ""models"",
                ""children"": Array [
                  Object {
                    ""basename"": ""GitBlob.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/models/GitBlob.js"",
                    ""metadata"": Object {
                      ""path"": ""src/models/GitBlob.js"",
                      ""someMeta"": 21,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""GitCommit.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/models/GitCommit.js"",
                    ""metadata"": Object {
                      ""path"": ""src/models/GitCommit.js"",
                      ""someMeta"": 23,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""GitConfig.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/models/GitConfig.js"",
                    ""metadata"": Object {
                      ""path"": ""src/models/GitConfig.js"",
                      ""someMeta"": 23,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""GitObject.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/models/GitObject.js"",
                    ""metadata"": Object {
                      ""path"": ""src/models/GitObject.js"",
                      ""someMeta"": 23,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""GitTree.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/models/GitTree.js"",
                    ""metadata"": Object {
                      ""path"": ""src/models/GitTree.js"",
                      ""someMeta"": 21,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                ],
                ""fullpath"": ""src/models"",
                ""metadata"": Object {},
                ""parent"": [Circular],
                ""type"": ""tree"",
              },
              Object {
                ""basename"": ""utils"",
                ""children"": Array [
                  Object {
                    ""basename"": ""exists.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/utils/exists.js"",
                    ""metadata"": Object {
                      ""path"": ""src/utils/exists.js"",
                      ""someMeta"": 19,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""mkdirs.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/utils/mkdirs.js"",
                    ""metadata"": Object {
                      ""path"": ""src/utils/mkdirs.js"",
                      ""someMeta"": 19,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""read.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/utils/read.js"",
                    ""metadata"": Object {
                      ""path"": ""src/utils/read.js"",
                      ""someMeta"": 17,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""resolveRef.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/utils/resolveRef.js"",
                    ""metadata"": Object {
                      ""path"": ""src/utils/resolveRef.js"",
                      ""someMeta"": 23,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""write.js"",
                    ""children"": Array [],
                    ""fullpath"": ""src/utils/write.js"",
                    ""metadata"": Object {
                      ""path"": ""src/utils/write.js"",
                      ""someMeta"": 18,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                ],
                ""fullpath"": ""src/utils"",
                ""metadata"": Object {},
                ""parent"": [Circular],
                ""type"": ""tree"",
              },
            ],
            ""fullpath"": ""src"",
            ""metadata"": Object {},
            ""parent"": [Circular],
            ""type"": ""tree"",
          },
          Object {
            ""basename"": ""test"",
            ""children"": Array [
              Object {
                ""basename"": ""_helpers.js"",
                ""children"": Array [],
                ""fullpath"": ""test/_helpers.js"",
                ""metadata"": Object {
                  ""path"": ""test/_helpers.js"",
                  ""someMeta"": 16,
                },
                ""parent"": [Circular],
                ""type"": ""blob"",
              },
              Object {
                ""basename"": ""snapshots"",
                ""children"": Array [
                  Object {
                    ""basename"": ""test-resolveRef.js.md"",
                    ""children"": Array [],
                    ""fullpath"": ""test/snapshots/test-resolveRef.js.md"",
                    ""metadata"": Object {
                      ""path"": ""test/snapshots/test-resolveRef.js.md"",
                      ""someMeta"": 36,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                  Object {
                    ""basename"": ""test-resolveRef.js.snap"",
                    ""children"": Array [],
                    ""fullpath"": ""test/snapshots/test-resolveRef.js.snap"",
                    ""metadata"": Object {
                      ""path"": ""test/snapshots/test-resolveRef.js.snap"",
                      ""someMeta"": 38,
                    },
                    ""parent"": [Circular],
                    ""type"": ""blob"",
                  },
                ],
                ""fullpath"": ""test/snapshots"",
                ""metadata"": Object {},
                ""parent"": [Circular],
                ""type"": ""tree"",
              },
              Object {
                ""basename"": ""test-clone.js"",
                ""children"": Array [],
                ""fullpath"": ""test/test-clone.js"",
                ""metadata"": Object {
                  ""path"": ""test/test-clone.js"",
                  ""someMeta"": 18,
                },
                ""parent"": [Circular],
                ""type"": ""blob"",
              },
              Object {
                ""basename"": ""test-config.js"",
                ""children"": Array [],
                ""fullpath"": ""test/test-config.js"",
                ""metadata"": Object {
                  ""path"": ""test/test-config.js"",
                  ""someMeta"": 19,
                },
                ""parent"": [Circular],
                ""type"": ""blob"",
              },
              Object {
                ""basename"": ""test-init.js"",
                ""children"": Array [],
                ""fullpath"": ""test/test-init.js"",
                ""metadata"": Object {
                  ""path"": ""test/test-init.js"",
                  ""someMeta"": 17,
                },
                ""parent"": [Circular],
                ""type"": ""blob"",
              },
              Object {
                ""basename"": ""test-resolveRef.js"",
                ""children"": Array [],
                ""fullpath"": ""test/test-resolveRef.js"",
                ""metadata"": Object {
                  ""path"": ""test/test-resolveRef.js"",
                  ""someMeta"": 23,
                },
                ""parent"": [Circular],
                ""type"": ""blob"",
              },
            ],
            ""fullpath"": ""test"",
            ""metadata"": Object {},
            ""parent"": [Circular],
            ""type"": ""tree"",
          },
        ],
        ""fullpath"": ""."",
        ""metadata"": Object {},
        ""parent"": [Circular],
        ""type"": ""tree"",
      }
    `)
  })",snuts
/__tests__/test-flatFileListToDirectoryStructure.js,SubOptimalAssert,"{'startLine':13,'endLine':13}","it('simple', async () => {
    const inode = flatFileListToDirectoryStructure([
      { path: 'hello/there.txt' },
    ]).get('.')
    expect(inode.fullpath).toBe('.')
    expect(inode.type).toBe('tree')
    expect(inode.children.length).toBe(1)
    const hello = inode.children[0]
    expect(hello.type).toBe('tree')
    expect(hello.fullpath).toBe('hello')
    expect(hello.basename).toBe('hello')
    expect(hello.parent).toBe(inode)
    expect(hello.children.length).toBe(1)
    const there = hello.children[0]
    expect(there.type).toBe('blob')
    expect(there.fullpath).toBe('hello/there.txt')
    expect(there.basename).toBe('there.txt')
  })",snuts
/__tests__/test-flatFileListToDirectoryStructure.js,SubOptimalAssert,"{'startLine':19,'endLine':19}","it('simple', async () => {
    const inode = flatFileListToDirectoryStructure([
      { path: 'hello/there.txt' },
    ]).get('.')
    expect(inode.fullpath).toBe('.')
    expect(inode.type).toBe('tree')
    expect(inode.children.length).toBe(1)
    const hello = inode.children[0]
    expect(hello.type).toBe('tree')
    expect(hello.fullpath).toBe('hello')
    expect(hello.basename).toBe('hello')
    expect(hello.parent).toBe(inode)
    expect(hello.children.length).toBe(1)
    const there = hello.children[0]
    expect(there.type).toBe('blob')
    expect(there.fullpath).toBe('hello/there.txt')
    expect(there.basename).toBe('there.txt')
  })",snuts
/__tests__/test-flatFileListToDirectoryStructure.js,VerboseStatement,"{'startLine':7,'endLine':24}","it('simple', async () => {
    const inode = flatFileListToDirectoryStructure([
      { path: 'hello/there.txt' },
    ]).get('.')
    expect(inode.fullpath).toBe('.')
    expect(inode.type).toBe('tree')
    expect(inode.children.length).toBe(1)
    const hello = inode.children[0]
    expect(hello.type).toBe('tree')
    expect(hello.fullpath).toBe('hello')
    expect(hello.basename).toBe('hello')
    expect(hello.parent).toBe(inode)
    expect(hello.children.length).toBe(1)
    const there = hello.children[0]
    expect(there.type).toBe('blob')
    expect(there.fullpath).toBe('hello/there.txt')
    expect(there.basename).toBe('there.txt')
  })",snuts
/__tests__/test-findMergeBase.js,AnonymousTest,"{'startLine':45,'endLine':90}","it('fast-forward scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])
  })",snuts
/__tests__/test-findMergeBase.js,AnonymousTest,"{'startLine':91,'endLine':158}","it('diverging scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])
  })",snuts
/__tests__/test-findMergeBase.js,OvercommentedTest,"{'startLine':45,'endLine':90}","it('fast-forward scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])
  })",snuts
/__tests__/test-findMergeBase.js,OvercommentedTest,"{'startLine':91,'endLine':158}","it('diverging scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])
  })",snuts
/__tests__/test-findMergeBase.js,OvercommentedTest,"{'startLine':159,'endLine':214}","it('merge commit scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
      ],
    })
    expect(base).toEqual(['423489657e9529ecf285637eb21f40c8657ece3f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])
  })",snuts
/__tests__/test-findMergeBase.js,VerboseStatement,"{'startLine':91,'endLine':158}","it('diverging scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])
  })",snuts
/__tests__/test-fetch.js,SubOptimalAssert,"{'startLine':68,'endLine':68}","it('shallow fetch (from Github)', async () => {
    const { fs, gitdir } = await makeFixture('test-fetch-cors')
    await setConfig({
      fs,
      gitdir,
      path: 'http.corsProxy',
      value: `http://${localhost}:9999`,
    })
    const output = []
    const progress = []
    // Test
    await fetch({
      fs,
      http,
      gitdir,
      onMessage: async x => {
        output.push(x)
      },
      onProgress: async y => {
        progress.push(y)
      },
      depth: 1,
      singleBranch: true,
      remote: 'origin',
      ref: 'test-branch-shallow-clone',
    })
    await sleep(1000) // seems to be a problem spot
    expect(await fs.exists(`${gitdir}/shallow`)).toBe(true)
    // expect(output[0]).toEqual('Counting objects: 551, done.') // No longer reliable. New message seen was ""Enumerating objects: 551, done.""
    expect(output[output.length - 1].split(' ')[1]).toEqual('551')
    let shallow = (await fs.read(`${gitdir}/shallow`)).toString('utf8')
    expect(shallow === '92e7b4123fbf135f5ffa9b6fe2ec78d07bbc353e\n').toBe(true)
    // Now test deepen
    await fetch({
      fs,
      http,
      gitdir,
      depth: 2,
      singleBranch: true,
      remote: 'origin',
      ref: 'test-branch-shallow-clone',
    })
    await sleep(1000) // seems to be a problem spot
    shallow = (await fs.read(`${gitdir}/shallow`)).toString('utf8')
    expect(shallow === '86ec153c7b48e02f92930d07542680f60d104d31\n').toBe(true)
  })",snuts
/__tests__/test-fetch.js,SubOptimalAssert,"{'startLine':81,'endLine':81}","it('shallow fetch (from Github)', async () => {
    const { fs, gitdir } = await makeFixture('test-fetch-cors')
    await setConfig({
      fs,
      gitdir,
      path: 'http.corsProxy',
      value: `http://${localhost}:9999`,
    })
    const output = []
    const progress = []
    // Test
    await fetch({
      fs,
      http,
      gitdir,
      onMessage: async x => {
        output.push(x)
      },
      onProgress: async y => {
        progress.push(y)
      },
      depth: 1,
      singleBranch: true,
      remote: 'origin',
      ref: 'test-branch-shallow-clone',
    })
    await sleep(1000) // seems to be a problem spot
    expect(await fs.exists(`${gitdir}/shallow`)).toBe(true)
    // expect(output[0]).toEqual('Counting objects: 551, done.') // No longer reliable. New message seen was ""Enumerating objects: 551, done.""
    expect(output[output.length - 1].split(' ')[1]).toEqual('551')
    let shallow = (await fs.read(`${gitdir}/shallow`)).toString('utf8')
    expect(shallow === '92e7b4123fbf135f5ffa9b6fe2ec78d07bbc353e\n').toBe(true)
    // Now test deepen
    await fetch({
      fs,
      http,
      gitdir,
      depth: 2,
      singleBranch: true,
      remote: 'origin',
      ref: 'test-branch-shallow-clone',
    })
    await sleep(1000) // seems to be a problem spot
    shallow = (await fs.read(`${gitdir}/shallow`)).toString('utf8')
    expect(shallow === '86ec153c7b48e02f92930d07542680f60d104d31\n').toBe(true)
  })",snuts
/__tests__/test-fetch.js,SubOptimalAssert,"{'startLine':271,'endLine':271}","it('errors if missing refspec', async () => {
    const { fs, gitdir } = await makeFixture('test-issue-84')
    await setConfig({
      fs,
      gitdir,
      path: 'http.corsProxy',
      value: `http://${localhost}:9999`,
    })
    // Test
    let err = null
    try {
      await fetch({
        fs,
        http,
        gitdir,
        since: new Date(1506571200000),
        singleBranch: true,
        remote: 'origin',
        ref: 'test-branch-shallow-clone',
      })
    } catch (e) {
      err = e
    }
    expect(err).toBeDefined()
    expect(err instanceof Errors.NoRefspecError).toBe(true)
  })",snuts
/__tests__/test-fetch.js,VerboseStatement,"{'startLine':37,'endLine':82}","it('shallow fetch (from Github)', async () => {
    const { fs, gitdir } = await makeFixture('test-fetch-cors')
    await setConfig({
      fs,
      gitdir,
      path: 'http.corsProxy',
      value: `http://${localhost}:9999`,
    })
    const output = []
    const progress = []
    // Test
    await fetch({
      fs,
      http,
      gitdir,
      onMessage: async x => {
        output.push(x)
      },
      onProgress: async y => {
        progress.push(y)
      },
      depth: 1,
      singleBranch: true,
      remote: 'origin',
      ref: 'test-branch-shallow-clone',
    })
    await sleep(1000) // seems to be a problem spot
    expect(await fs.exists(`${gitdir}/shallow`)).toBe(true)
    // expect(output[0]).toEqual('Counting objects: 551, done.') // No longer reliable. New message seen was ""Enumerating objects: 551, done.""
    expect(output[output.length - 1].split(' ')[1]).toEqual('551')
    let shallow = (await fs.read(`${gitdir}/shallow`)).toString('utf8')
    expect(shallow === '92e7b4123fbf135f5ffa9b6fe2ec78d07bbc353e\n').toBe(true)
    // Now test deepen
    await fetch({
      fs,
      http,
      gitdir,
      depth: 2,
      singleBranch: true,
      remote: 'origin',
      ref: 'test-branch-shallow-clone',
    })
    await sleep(1000) // seems to be a problem spot
    shallow = (await fs.read(`${gitdir}/shallow`)).toString('utf8')
    expect(shallow === '86ec153c7b48e02f92930d07542680f60d104d31\n').toBe(true)
  })",snuts
/__tests__/test-exports.js,ComplexSnapshots,"{'startLine':7,'endLine':81}","it('exposes only the intended API functions', async () => {
    const names = Object.keys(git)
    expect(names.sort()).toMatchInlineSnapshot(`
      Array [
        ""Errors"",
        ""STAGE"",
        ""TREE"",
        ""WORKDIR"",
        ""abortMerge"",
        ""add"",
        ""addNote"",
        ""addRemote"",
        ""annotatedTag"",
        ""branch"",
        ""checkout"",
        ""clone"",
        ""commit"",
        ""currentBranch"",
        ""default"",
        ""deleteBranch"",
        ""deleteRef"",
        ""deleteRemote"",
        ""deleteTag"",
        ""expandOid"",
        ""expandRef"",
        ""fastForward"",
        ""fetch"",
        ""findMergeBase"",
        ""findRoot"",
        ""getConfig"",
        ""getConfigAll"",
        ""getRemoteInfo"",
        ""getRemoteInfo2"",
        ""hashBlob"",
        ""indexPack"",
        ""init"",
        ""isDescendent"",
        ""isIgnored"",
        ""listBranches"",
        ""listFiles"",
        ""listNotes"",
        ""listRefs"",
        ""listRemotes"",
        ""listServerRefs"",
        ""listTags"",
        ""log"",
        ""merge"",
        ""packObjects"",
        ""pull"",
        ""push"",
        ""readBlob"",
        ""readCommit"",
        ""readNote"",
        ""readObject"",
        ""readTag"",
        ""readTree"",
        ""remove"",
        ""removeNote"",
        ""renameBranch"",
        ""resetIndex"",
        ""resolveRef"",
        ""setConfig"",
        ""stash"",
        ""status"",
        ""statusMatrix"",
        ""tag"",
        ""updateIndex"",
        ""version"",
        ""walk"",
        ""writeBlob"",
        ""writeCommit"",
        ""writeObject"",
        ""writeRef"",
        ""writeTag"",
        ""writeTree"",
      ]
    `)
  })",snuts
/__tests__/test-expandOid.js,SubOptimalAssert,"{'startLine':28,'endLine':28}","it('expand short oid (not found)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-expandOid')
    const oid = '01234567'
    // Test
    let error = null
    try {
      await expandOid({ fs, gitdir, oid })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",snuts
/__tests__/test-expandOid.js,SubOptimalAssert,"{'startLine':43,'endLine':43}","it('expand short oid (ambiguous)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-expandOid')
    const oid = '033417a'
    // Test
    let error = null
    try {
      await expandOid({ fs, gitdir, oid })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.AmbiguousError).toBe(true)
  })",snuts
/__tests__/test-deleteTag.js,SubOptimalAssert,"{'startLine':35,'endLine':35}","it('missing ref argument', async () => {
    // Setup
    const { dir, gitdir } = await makeFixture('test-deleteTag')
    let error = null
    // Test
    try {
      // @ts-ignore
      await deleteTag({ dir, gitdir })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.MissingParameterError).toBe(true)
  })",snuts
/__tests__/test-deleteRemote.js,AnonymousTest,"{'startLine':7,'endLine':15}","it('deleteRemote', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-deleteRemote')
    const remote = 'foo'
    // Test
    await deleteRemote({ fs, dir, gitdir, remote })
    const a = await listRemotes({ fs, dir, gitdir })
    expect(a).toEqual([{ remote: 'bar', url: 'git@github.com:bar/bar.git' }])
  })",snuts
/__tests__/test-deleteRemote.js,AnonymousTest,"{'startLine':16,'endLine':29}","it('missing argument', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-addRemote')
    // Test
    let error = null
    try {
      // @ts-ignore
      await deleteRemote({ fs, dir, gitdir })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.MissingParameterError).toBe(true)
  })",snuts
/__tests__/test-deleteRemote.js,SubOptimalAssert,"{'startLine':28,'endLine':28}","it('missing argument', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-addRemote')
    // Test
    let error = null
    try {
      // @ts-ignore
      await deleteRemote({ fs, dir, gitdir })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.MissingParameterError).toBe(true)
  })",snuts
/__tests__/test-deleteBranch.js,AnonymousTest,"{'startLine':14,'endLine':21}","it('delete branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-deleteBranch')
    // Test
    await deleteBranch({ fs, gitdir, ref: 'test' })
    const branches = await listBranches({ fs, gitdir })
    expect(branches.includes('test')).toBe(false)
  })",snuts
/__tests__/test-deleteBranch.js,SubOptimalAssert,"{'startLine':45,'endLine':45}","it('branch not exist', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-deleteBranch')
    let error = null
    // Test
    try {
      await deleteBranch({ fs, gitdir, ref: 'branch-not-exist' })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",snuts
/__tests__/test-deleteBranch.js,SubOptimalAssert,"{'startLine':60,'endLine':60}","it('missing ref argument', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-deleteBranch')
    let error = null
    // Test
    try {
      // @ts-ignore
      await deleteBranch({ fs, gitdir })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.MissingParameterError).toBe(true)
  })",snuts
/__tests__/test-config.js,AnonymousTest,"{'startLine':7,'endLine':33}","it('getting', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-config')
    // Test
    const sym = await getConfig({ fs, gitdir, path: 'core.symlinks' })
    const rfv = await getConfig({
      fs,
      gitdir,
      path: 'core.repositoryformatversion',
    })
    const url = await getConfig({ fs, gitdir, path: 'remote.origin.url' })
    const fetch = await getConfig({ fs, gitdir, path: 'remote.upstream.fetch' })
    const fetches = await getConfigAll({
      fs,
      gitdir,
      path: 'remote.upstream.fetch',
    })
    expect(sym).toBe(false)
    expect(url).toBe('https://github.com/isomorphic-git/isomorphic-git')
    expect(rfv).toBe('0')
    expect(fetch).toBe('refs/heads/qa/*:refs/remotes/upstream/qa/*')
    expect(fetches).toEqual([
      '+refs/heads/master:refs/remotes/upstream/master',
      'refs/heads/develop:refs/remotes/upstream/develop',
      'refs/heads/qa/*:refs/remotes/upstream/qa/*',
    ])
  })",snuts
/__tests__/test-config.js,AnonymousTest,"{'startLine':35,'endLine':61}","it('setting', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-config')
    // Test
    let bare
    // set to true
    await setConfig({ fs, gitdir, path: 'core.bare', value: true })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(true)
    // set to false
    await setConfig({ fs, gitdir, path: 'core.bare', value: false })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(false)
    // set to undefined
    await setConfig({ fs, gitdir, path: 'core.bare', value: undefined })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(undefined)
    // change a remote
    await setConfig({
      fs,
      gitdir,
      path: 'remote.origin.url',
      value: 'https://github.com/isomorphic-git/isomorphic-git',
    })
    const url = await getConfig({ fs, gitdir, path: 'remote.origin.url' })
    expect(url).toBe('https://github.com/isomorphic-git/isomorphic-git')
  })",snuts
/__tests__/test-config.js,OvercommentedTest,"{'startLine':35,'endLine':61}","it('setting', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-config')
    // Test
    let bare
    // set to true
    await setConfig({ fs, gitdir, path: 'core.bare', value: true })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(true)
    // set to false
    await setConfig({ fs, gitdir, path: 'core.bare', value: false })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(false)
    // set to undefined
    await setConfig({ fs, gitdir, path: 'core.bare', value: undefined })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(undefined)
    // change a remote
    await setConfig({
      fs,
      gitdir,
      path: 'remote.origin.url',
      value: 'https://github.com/isomorphic-git/isomorphic-git',
    })
    const url = await getConfig({ fs, gitdir, path: 'remote.origin.url' })
    expect(url).toBe('https://github.com/isomorphic-git/isomorphic-git')
  })",snuts
/__tests__/test-config.js,SubOptimalAssert,"{'startLine':51,'endLine':51}","it('setting', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-config')
    // Test
    let bare
    // set to true
    await setConfig({ fs, gitdir, path: 'core.bare', value: true })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(true)
    // set to false
    await setConfig({ fs, gitdir, path: 'core.bare', value: false })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(false)
    // set to undefined
    await setConfig({ fs, gitdir, path: 'core.bare', value: undefined })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(undefined)
    // change a remote
    await setConfig({
      fs,
      gitdir,
      path: 'remote.origin.url',
      value: 'https://github.com/isomorphic-git/isomorphic-git',
    })
    const url = await getConfig({ fs, gitdir, path: 'remote.origin.url' })
    expect(url).toBe('https://github.com/isomorphic-git/isomorphic-git')
  })",snuts
/__tests__/test-config.js,VerboseStatement,"{'startLine':35,'endLine':61}","it('setting', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-config')
    // Test
    let bare
    // set to true
    await setConfig({ fs, gitdir, path: 'core.bare', value: true })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(true)
    // set to false
    await setConfig({ fs, gitdir, path: 'core.bare', value: false })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(false)
    // set to undefined
    await setConfig({ fs, gitdir, path: 'core.bare', value: undefined })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(undefined)
    // change a remote
    await setConfig({
      fs,
      gitdir,
      path: 'remote.origin.url',
      value: 'https://github.com/isomorphic-git/isomorphic-git',
    })
    const url = await getConfig({ fs, gitdir, path: 'remote.origin.url' })
    expect(url).toBe('https://github.com/isomorphic-git/isomorphic-git')
  })",snuts
/__tests__/test-commit.js,AnonymousTest,"{'startLine':40,'endLine':68}","it('commit', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    const { oid: originalOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    // Test
    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }
    const sha = await commit({
      fs,
      gitdir,
      author,
      message: 'Initial commit',
    })
    expect(sha).toBe('7a51c0b1181d738198ff21c4679d3aa32eb52fe0')
    // updates branch pointer
    const { oid: currentOid, commit: currentCommit } = (
      await log({ fs, gitdir, depth: 1 })
    )[0]
    expect(currentCommit.parent).toEqual([originalOid])
    expect(currentCommit.author).toEqual(author)
    expect(currentCommit.committer).toEqual(author)
    expect(currentCommit.message).toEqual('Initial commit\n')
    expect(currentOid).not.toEqual(originalOid)
    expect(currentOid).toEqual(sha)
  })",snuts
/__tests__/test-commit.js,AnonymousTest,"{'startLine':70,'endLine':96}","it('Initial commit', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-init')
    await init({ fs, dir })
    await fs.write(path.join(dir, 'hello.md'), 'Hello, World!')
    await add({ fs, dir, filepath: 'hello.md' })

    // Test
    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }

    await commit({
      fs,
      dir,
      author,
      message: 'Initial commit',
    })

    const commits = await log({ fs, dir })
    expect(commits.length).toBe(1)
    expect(commits[0].commit.parent).toEqual([])
    expect(await resolveRef({ fs, dir, ref: 'HEAD' })).toEqual(commits[0].oid)
  })",snuts
/__tests__/test-commit.js,AnonymousTest,"{'startLine':155,'endLine':183}","it('dry run', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    const { oid: originalOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    // Test
    const sha = await commit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      message: 'Initial commit',
      dryRun: true,
    })
    expect(sha).toBe('7a51c0b1181d738198ff21c4679d3aa32eb52fe0')
    // does NOT update branch pointer
    const { oid: currentOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    expect(currentOid).toEqual(originalOid)
    expect(currentOid).not.toEqual(sha)
    // and did NOT create commit object
    expect(
      await fs.exists(
        `${gitdir}/objects/7a/51c0b1181d738198ff21c4679d3aa32eb52fe0`
      )
    ).toBe(false)
  })",snuts
/__tests__/test-commit.js,AnonymousTest,"{'startLine':185,'endLine':217}","it('custom ref', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    const { oid: originalOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    // Test
    const sha = await commit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      message: 'Initial commit',
      ref: 'refs/heads/master-copy',
    })
    expect(sha).toBe('7a51c0b1181d738198ff21c4679d3aa32eb52fe0')
    // does NOT update master branch pointer
    const { oid: currentOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    expect(currentOid).toEqual(originalOid)
    expect(currentOid).not.toEqual(sha)
    // but DOES update master-copy
    const { oid: copyOid } = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'master-copy',
      })
    )[0]
    expect(sha).toEqual(copyOid)
  })",snuts
/__tests__/test-commit.js,AnonymousTest,"{'startLine':313,'endLine':375}","it('with timezone', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    let commits
    // Test
    await commit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      message: '-0 offset',
    })
    commits = await log({ fs, gitdir, depth: 1 })
    expect(Object.is(commits[0].commit.author.timezoneOffset, -0)).toBeTruthy()

    await commit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: 0,
      },
      message: '+0 offset',
    })
    commits = await log({ fs, gitdir, depth: 1 })
    expect(Object.is(commits[0].commit.author.timezoneOffset, 0)).toBeTruthy()

    await commit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: 240,
      },
      message: '+240 offset',
    })
    commits = await log({ fs, gitdir, depth: 1 })
    expect(Object.is(commits[0].commit.author.timezoneOffset, 240)).toBeTruthy()

    await commit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -240,
      },
      message: '-240 offset',
    })
    commits = await log({ fs, gitdir, depth: 1 })
    expect(
      Object.is(commits[0].commit.author.timezoneOffset, -240)
    ).toBeTruthy()
  })",snuts
/__tests__/test-commit.js,SubOptimalAssert,"{'startLine':93,'endLine':93}","it('Initial commit', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-init')
    await init({ fs, dir })
    await fs.write(path.join(dir, 'hello.md'), 'Hello, World!')
    await add({ fs, dir, filepath: 'hello.md' })

    // Test
    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }

    await commit({
      fs,
      dir,
      author,
      message: 'Initial commit',
    })

    const commits = await log({ fs, dir })
    expect(commits.length).toBe(1)
    expect(commits[0].commit.parent).toEqual([])
    expect(await resolveRef({ fs, dir, ref: 'HEAD' })).toEqual(commits[0].oid)
  })",snuts
/__tests__/test-commit.js,SubOptimalAssert,"{'startLine':122,'endLine':122}","it('Cannot commit without message', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    // Test
    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }

    let error = null

    try {
      await commit({
        fs,
        gitdir,
        author,
      })
    } catch (err) {
      error = err
    }

    expect(error).not.toBeNull()
    expect(error instanceof Errors.MissingParameterError).toBe(true)
  })",snuts
/__tests__/test-commit.js,SubOptimalAssert,"{'startLine':488,'endLine':488}","it('Cannot amend without an initial commit', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-init')
    await init({ fs, dir })
    await fs.write(path.join(dir, 'hello.md'), 'Hello, World!')
    await add({ fs, dir, filepath: 'hello.md' })

    // Test
    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }

    let error = null
    try {
      await commit({
        fs,
        dir,
        author,
        message: 'Initial commit',
        amend: true,
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NoCommitError).toBe(true)
  })",snuts
/__tests__/test-commit.js,VerboseStatement,"{'startLine':313,'endLine':375}","it('with timezone', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    let commits
    // Test
    await commit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      message: '-0 offset',
    })
    commits = await log({ fs, gitdir, depth: 1 })
    expect(Object.is(commits[0].commit.author.timezoneOffset, -0)).toBeTruthy()

    await commit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: 0,
      },
      message: '+0 offset',
    })
    commits = await log({ fs, gitdir, depth: 1 })
    expect(Object.is(commits[0].commit.author.timezoneOffset, 0)).toBeTruthy()

    await commit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: 240,
      },
      message: '+240 offset',
    })
    commits = await log({ fs, gitdir, depth: 1 })
    expect(Object.is(commits[0].commit.author.timezoneOffset, 240)).toBeTruthy()

    await commit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -240,
      },
      message: '-240 offset',
    })
    commits = await log({ fs, gitdir, depth: 1 })
    expect(
      Object.is(commits[0].commit.author.timezoneOffset, -240)
    ).toBeTruthy()
  })",snuts
/__tests__/test-clone.js,ConditionalTestLogic,"{'startLine':168,'endLine':194}","it('should throw error if server resets connection before reading packetlines', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-before-packetlines'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('shallow')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })",snuts
/__tests__/test-clone.js,ConditionalTestLogic,"{'startLine':185,'endLine':189}","it('should throw error if server resets connection before reading packetlines', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-before-packetlines'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('shallow')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })",snuts
/__tests__/test-clone.js,ConditionalTestLogic,"{'startLine':229,'endLine':256}","it('should throw error if server resets connection while reading packetlines', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-during-packetlines'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0037unshallow 1f6d22958fa079fc2205bb5ae1224d9677f1eaf9
0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('shallow')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })",snuts
/__tests__/test-clone.js,ConditionalTestLogic,"{'startLine':247,'endLine':251}","it('should throw error if server resets connection while reading packetlines', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-during-packetlines'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0037unshallow 1f6d22958fa079fc2205bb5ae1224d9677f1eaf9
0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('shallow')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })",snuts
/__tests__/test-clone.js,ConditionalTestLogic,"{'startLine':291,'endLine':317}","it('should throw error if server resets connection before reading packfile', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-before-packfile'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('PACK')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })",snuts
/__tests__/test-clone.js,ConditionalTestLogic,"{'startLine':308,'endLine':312}","it('should throw error if server resets connection before reading packfile', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-before-packfile'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('PACK')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })",snuts
/__tests__/test-clone.js,ConditionalTestLogic,"{'startLine':352,'endLine':358}","it('should not throw TypeError error if packfile is empty', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-empty-packfile'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            response.body = `0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.name).not.toEqual('TypeError')
    expect(error.name).toEqual('CommitNotFetchedError')
    expect(error.caller).toEqual('git.clone')
  })",snuts
/__tests__/test-checkout.js,AnonymousTest,"{'startLine':25,'endLine':97}","it('checkout', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-checkout')
    const onPostCheckout = []
    await checkout({
      fs,
      dir,
      gitdir,
      ref: 'test-branch',
      onPostCheckout: args => {
        onPostCheckout.push(args)
      },
    })
    const files = await fs.readdir(dir)
    expect(files.sort()).toMatchInlineSnapshot(`
      Array [
        "".babelrc"",
        "".editorconfig"",
        "".flowconfig"",
        "".gitignore"",
        ""LICENSE.md"",
        ""README.md"",
        ""package.json"",
        ""shrinkwrap.yaml"",
        ""src"",
        ""test"",
      ]
    `)
    const index = await listFiles({ fs, dir, gitdir })
    expect(index).toMatchInlineSnapshot(`
      Array [
        "".babelrc"",
        "".editorconfig"",
        "".flowconfig"",
        "".gitignore"",
        ""LICENSE.md"",
        ""README.md"",
        ""package.json"",
        ""shrinkwrap.yaml"",
        ""src/commands/checkout.js"",
        ""src/commands/config.js"",
        ""src/commands/fetch.js"",
        ""src/commands/init.js"",
        ""src/index.js"",
        ""src/models/GitBlob.js"",
        ""src/models/GitCommit.js"",
        ""src/models/GitConfig.js"",
        ""src/models/GitTree.js"",
        ""src/utils/combinePayloadAndSignature.js"",
        ""src/utils/commitSha.js"",
        ""src/utils/exists.js"",
        ""src/utils/mkdirs.js"",
        ""src/utils/read.js"",
        ""src/utils/resolveRef.js"",
        ""src/utils/unwrapObject.js"",
        ""src/utils/wrapCommit.js"",
        ""src/utils/write.js"",
        ""test/resolveRef.js"",
        ""test/smoke.js"",
        ""test/snapshots/resolveRef.js.md"",
        ""test/snapshots/resolveRef.js.snap"",
      ]
    `)
    const sha = await fs.read(gitdir + '/HEAD', 'utf8')
    expect(sha).toBe('ref: refs/heads/test-branch\n')
    expect(onPostCheckout).toEqual([
      {
        newHead: 'e10ebb90d03eaacca84de1af0a59b444232da99e',
        previousHead: '0f55956cbd50de80c2f86e6e565f00c92ce86631',
        type: 'branch',
      },
    ])
  })",snuts
/__tests__/test-checkout.js,OvercommentedTest,"{'startLine':680,'endLine':732}","it('checkout should not delete ignored files', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-checkout')

    // Checkout the test-branch
    await checkout({
      fs,
      dir,
      gitdir,
      ref: 'test-branch',
    })

    // Create a branch from test-branch
    await branch({
      fs,
      dir,
      gitdir,
      ref: 'branch-w-ignored-dir',
      checkout: true,
    })
    // Add a regular file to the ignored dir
    await fs.write(`${dir}/ignored/regular-file.txt`, 'regular file', {
      mode: 0o666,
    })

    // Add and commit a gitignore, ignoring everything but itself
    const gitignoreContent = `*
!.gitignore`
    await fs.write(`${dir}/ignored/.gitignore`, gitignoreContent, {
      mode: 0o666,
    })
    await add({ fs, dir, gitdir, filepath: 'ignored/.gitignore' })

    await commit({
      fs,
      dir,
      gitdir,
      author: { name: 'Git', email: 'git@example.org' },
      message: 'add gitignore',
    })

    // Checkout the test-branch, which does not contain the ignore/.gitignore
    // should not delete files from ignore, but leave them as untracked in the working tree
    await checkout({
      fs,
      dir,
      gitdir,
      ref: 'test-branch',
    })
    const files = await fs.readdir(`${dir}/ignored`)
    expect(files).toContain('regular-file.txt')
    expect(files).not.toContain('.gitignore')
  })",snuts
/__tests__/test-checkout.js,SubOptimalAssert,"{'startLine':388,'endLine':388}","it('checkout detects conflicts', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-checkout')
    await fs.write(`${dir}/README.md`, 'Hello world', 'utf8')
    // Test
    let error = null
    try {
      await checkout({
        fs,
        dir,
        gitdir,
        ref: 'test-branch',
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.CheckoutConflictError).toBe(true)
    expect(error.data.filepaths).toEqual(['README.md'])
  })",snuts
/__tests__/test-checkout.js,VerboseStatement,"{'startLine':252,'endLine':285}","it('checkout file permissions', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-checkout')
    await branch({ fs, dir, gitdir, ref: 'other', checkout: true })
    await checkout({ fs, dir, gitdir, ref: 'test-branch' })
    await fs.write(dir + '/regular-file.txt', 'regular file', {
      mode: 0o666,
    })
    await fs.write(dir + '/executable-file.sh', 'executable file', {
      mode: 0o777,
    })
    const expectedRegularFileMode = (await fs.lstat(dir + '/regular-file.txt'))
      .mode
    const expectedExecutableFileMode = (
      await fs.lstat(dir + '/executable-file.sh')
    ).mode
    await add({ fs, dir, gitdir, filepath: 'regular-file.txt' })
    await add({ fs, dir, gitdir, filepath: 'executable-file.sh' })
    await commit({
      fs,
      dir,
      gitdir,
      author: { name: 'Git', email: 'git@example.org' },
      message: 'add files',
    })
    await checkout({ fs, dir, gitdir, ref: 'other' })
    await checkout({ fs, dir, gitdir, ref: 'test-branch' })
    const actualRegularFileMode = (await fs.lstat(dir + '/regular-file.txt'))
      .mode
    const actualExecutableFileMode = (
      await fs.lstat(dir + '/executable-file.sh')
    ).mode
    expect(actualRegularFileMode).toEqual(expectedRegularFileMode)
    expect(actualExecutableFileMode).toEqual(expectedExecutableFileMode)
  })",snuts
/__tests__/test-branch.js,AnonymousTest,"{'startLine':15,'endLine':23}","it('branch', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-branch')
    // Test
    await branch({ fs, dir, gitdir, ref: 'test-branch' })
    const files = await fs.readdir(path.resolve(gitdir, 'refs', 'heads'))
    expect(files).toEqual(['master', 'test-branch'])
    expect(await currentBranch({ fs, dir, gitdir })).toEqual('master')
  })",snuts
/__tests__/test-branch.js,AnonymousTest,"{'startLine':52,'endLine':68}","it('branch force', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-branch')
    let error = null
    // Test
    await branch({ fs, dir, gitdir, ref: 'test-branch' })
    expect(await currentBranch({ fs, dir, gitdir })).toEqual('master')
    expect(
      await fs.exists(path.resolve(gitdir, 'refs/heads/test-branch'))
    ).toBeTruthy()
    try {
      await branch({ fs, dir, gitdir, ref: 'test-branch', force: true })
    } catch (err) {
      error = err
    }
    expect(error).toBeNull()
  })",snuts
/__tests__/test-branch.js,AnonymousTest,"{'startLine':91,'endLine':97}","it('branch --checkout', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-branch')
    // Test
    await branch({ fs, dir, gitdir, ref: 'test-branch', checkout: true })
    expect(await currentBranch({ fs, dir, gitdir })).toEqual('test-branch')
  })",snuts
/__tests__/test-branch.js,AnonymousTest,"{'startLine':128,'endLine':142}","it('empty repo', async () => {
    // Setup
    const { dir, fs, gitdir } = await makeFixture('test-branch-empty-repo')
    await init({ fs, dir, gitdir })
    let error = null
    // Test
    try {
      await branch({ fs, dir, gitdir, ref: 'test-branch', checkout: true })
    } catch (err) {
      error = err
    }
    expect(error).toBeNull()
    const file = await fs.read(path.resolve(gitdir, 'HEAD'), 'utf8')
    expect(file).toBe(`ref: refs/heads/test-branch\n`)
  })",snuts
/__tests__/test-branch.js,SubOptimalAssert,"{'startLine':110,'endLine':110}","it('invalid branch name', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-branch')
    let error = null
    // Test
    try {
      await branch({ fs, dir, gitdir, ref: 'inv@{id..branch.lock' })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidRefNameError).toBe(true)
  })",snuts
/__tests__/test-branch.js,SubOptimalAssert,"{'startLine':125,'endLine':125}","it('missing ref argument', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-branch')
    let error = null
    // Test
    try {
      // @ts-ignore
      await branch({ fs, dir, gitdir })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.MissingParameterError).toBe(true)
  })",snuts
/__tests__/test-addRemote.js,AnonymousTest,"{'startLine':7,'endLine':20}","it('addRemote', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-addRemote')
    const remote = 'baz'
    const url = 'git@github.com:baz/baz.git'
    // Test
    await addRemote({ fs, dir, gitdir, remote, url })
    const a = await listRemotes({ fs, dir, gitdir })
    expect(a).toEqual([
      { remote: 'foo', url: 'git@github.com:foo/foo.git' },
      { remote: 'bar', url: 'git@github.com:bar/bar.git' },
      { remote: 'baz', url: 'git@github.com:baz/baz.git' },
    ])
  })",snuts
/__tests__/test-addRemote.js,AnonymousTest,"{'startLine':21,'endLine':42}","it('missing argument', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-addRemote')
    const remote = 'baz'
    const url = undefined
    // Test
    let error = null
    try {
      await addRemote({
        fs,
        dir,
        gitdir,
        remote,
        // @ts-ignore
        url,
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.MissingParameterError).toBe(true)
  })",snuts
/__tests__/test-addRemote.js,SubOptimalAssert,"{'startLine':41,'endLine':41}","it('missing argument', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-addRemote')
    const remote = 'baz'
    const url = undefined
    // Test
    let error = null
    try {
      await addRemote({
        fs,
        dir,
        gitdir,
        remote,
        // @ts-ignore
        url,
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.MissingParameterError).toBe(true)
  })",snuts
/__tests__/test-addRemote.js,SubOptimalAssert,"{'startLine':56,'endLine':56}","it('invalid remote name', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-addRemote')
    const remote = '@{HEAD~1}'
    const url = 'git@github.com:baz/baz.git'
    // Test
    let error = null
    try {
      await addRemote({ fs, dir, gitdir, remote, url })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidRefNameError).toBe(true)
  })",snuts
/__tests__/test-addNote.js,SubOptimalAssert,"{'startLine':118,'endLine':118}","it('consecutive notes accumulate', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-addNote')
    // Test
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
        note: 'This is a note about a commit.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(1)
    }
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: '199948939a0b95c6f27668689102496574b2c332',
        note: 'This is a note about a tree.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(2)
    }
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: '68aba62e560c0ebc3396e8ae9335232cd93a3f60',
        note: 'This is a note about a blob.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(3)
    }
  })",snuts
/__tests__/test-addNote.js,SubOptimalAssert,"{'startLine':134,'endLine':134}","it('consecutive notes accumulate', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-addNote')
    // Test
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
        note: 'This is a note about a commit.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(1)
    }
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: '199948939a0b95c6f27668689102496574b2c332',
        note: 'This is a note about a tree.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(2)
    }
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: '68aba62e560c0ebc3396e8ae9335232cd93a3f60',
        note: 'This is a note about a blob.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(3)
    }
  })",snuts
/__tests__/test-addNote.js,SubOptimalAssert,"{'startLine':150,'endLine':150}","it('consecutive notes accumulate', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-addNote')
    // Test
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
        note: 'This is a note about a commit.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(1)
    }
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: '199948939a0b95c6f27668689102496574b2c332',
        note: 'This is a note about a tree.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(2)
    }
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: '68aba62e560c0ebc3396e8ae9335232cd93a3f60',
        note: 'This is a note about a blob.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(3)
    }
  })",snuts
/__tests__/test-addNote.js,SubOptimalAssert,"{'startLine':217,'endLine':217}","it('throws if note already exists', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-addNote')
    await addNote({
      fs,
      gitdir,
      author: {
        name: 'William Hilton',
        email: 'wmhilton@gmail.com',
        timestamp: 1578937310,
        timezoneOffset: 300,
      },
      oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
      note: 'This is a note about a commit.',
    })
    // Test
    let error = null
    try {
      await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
        note: 'This is a note about a commit.',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.AlreadyExistsError).toBe(true)
  })",snuts
/__tests__/test-add.js,AnonymousTest,"{'startLine':27,'endLine':40}","it('file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a-copy.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    await add({ fs, dir, filepath: 'b.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(3)
  })",snuts
/__tests__/test-add.js,AnonymousTest,"{'startLine':41,'endLine':48}","it('multiple files', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: ['a.txt', 'a-copy.txt', 'b.txt'] })
    expect((await listFiles({ fs, dir })).length).toEqual(3)
  })",snuts
/__tests__/test-add.js,AnonymousTest,"{'startLine':129,'endLine':158}","it('symlink', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // it's not currently possible to tests symlinks in the browser since there's no way to create them
    const symlinkCreated = await writeSymlink(fs, dir)
      .then(() => true)
      .catch(() => false)
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'c/e.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    if (!symlinkCreated) return
    await add({ fs, dir, filepath: 'e-link.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    const walkResult = await walk({
      fs,
      dir,
      trees: [STAGE()],
      map: async (filepath, [stage]) =>
        filepath === 'e-link.txt' && stage ? stage.oid() : undefined,
    })
    expect(walkResult.length).toEqual(1)
    const oid = walkResult[0]
    const { blob: symlinkTarget } = await readBlob({ fs, dir, oid })
    let symlinkTargetStr = Buffer.from(symlinkTarget).toString('utf8')
    if (symlinkTargetStr.startsWith('./')) {
      symlinkTargetStr = symlinkTargetStr.substr(2)
    }
    expect(symlinkTargetStr).toEqual('c/e.txt')
  })",snuts
/__tests__/test-add.js,AnonymousTest,"{'startLine':159,'endLine':167}","it('ignored file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'i.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
  })",snuts
/__tests__/test-add.js,AnonymousTest,"{'startLine':177,'endLine':189}","it('non-existant file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    let err = null
    try {
      await add({ fs, dir, filepath: 'asdf.txt' })
    } catch (e) {
      err = e
    }
    expect(err.caller).toEqual('git.add')
  })",snuts
/__tests__/test-add.js,AnonymousTest,"{'startLine':190,'endLine':198}","it('folder', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: 'c' })
    expect((await listFiles({ fs, dir })).length).toEqual(4)
  })",snuts
/__tests__/test-add.js,ConditionalTestLogic,"{'startLine':140,'endLine':140}","it('symlink', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // it's not currently possible to tests symlinks in the browser since there's no way to create them
    const symlinkCreated = await writeSymlink(fs, dir)
      .then(() => true)
      .catch(() => false)
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'c/e.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    if (!symlinkCreated) return
    await add({ fs, dir, filepath: 'e-link.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    const walkResult = await walk({
      fs,
      dir,
      trees: [STAGE()],
      map: async (filepath, [stage]) =>
        filepath === 'e-link.txt' && stage ? stage.oid() : undefined,
    })
    expect(walkResult.length).toEqual(1)
    const oid = walkResult[0]
    const { blob: symlinkTarget } = await readBlob({ fs, dir, oid })
    let symlinkTargetStr = Buffer.from(symlinkTarget).toString('utf8')
    if (symlinkTargetStr.startsWith('./')) {
      symlinkTargetStr = symlinkTargetStr.substr(2)
    }
    expect(symlinkTargetStr).toEqual('c/e.txt')
  })",snuts
/__tests__/test-add.js,ConditionalTestLogic,"{'startLine':154,'endLine':156}","it('symlink', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // it's not currently possible to tests symlinks in the browser since there's no way to create them
    const symlinkCreated = await writeSymlink(fs, dir)
      .then(() => true)
      .catch(() => false)
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'c/e.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    if (!symlinkCreated) return
    await add({ fs, dir, filepath: 'e-link.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    const walkResult = await walk({
      fs,
      dir,
      trees: [STAGE()],
      map: async (filepath, [stage]) =>
        filepath === 'e-link.txt' && stage ? stage.oid() : undefined,
    })
    expect(walkResult.length).toEqual(1)
    const oid = walkResult[0]
    const { blob: symlinkTarget } = await readBlob({ fs, dir, oid })
    let symlinkTargetStr = Buffer.from(symlinkTarget).toString('utf8')
    if (symlinkTargetStr.startsWith('./')) {
      symlinkTargetStr = symlinkTargetStr.substr(2)
    }
    expect(symlinkTargetStr).toEqual('c/e.txt')
  })",snuts
/__tests__/test-add.js,VerboseStatement,"{'startLine':129,'endLine':158}","it('symlink', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // it's not currently possible to tests symlinks in the browser since there's no way to create them
    const symlinkCreated = await writeSymlink(fs, dir)
      .then(() => true)
      .catch(() => false)
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'c/e.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    if (!symlinkCreated) return
    await add({ fs, dir, filepath: 'e-link.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    const walkResult = await walk({
      fs,
      dir,
      trees: [STAGE()],
      map: async (filepath, [stage]) =>
        filepath === 'e-link.txt' && stage ? stage.oid() : undefined,
    })
    expect(walkResult.length).toEqual(1)
    const oid = walkResult[0]
    const { blob: symlinkTarget } = await readBlob({ fs, dir, oid })
    let symlinkTargetStr = Buffer.from(symlinkTarget).toString('utf8')
    if (symlinkTargetStr.startsWith('./')) {
      symlinkTargetStr = symlinkTargetStr.substr(2)
    }
    expect(symlinkTargetStr).toEqual('c/e.txt')
  })",snuts
/__tests__/test-abortMerge.js,ConditionalTestLogic,"{'startLine':148,'endLine':148}","it('abort merge without touching anything', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await abortMerge({ fs, dir, gitdir })

    const trees = [TREE({ ref: 'HEAD' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (path === '.') return

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)

        // only since we didn't touch anything
        expect(await modified(workdir, head)).toBe(false)

        expect(await modified(index, workdir)).toBe(false)
      },
    })
  })",snuts
/__tests__/test-abortMerge.js,ConditionalTestLogic,"{'startLine':150,'endLine':153}","it('abort merge without touching anything', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await abortMerge({ fs, dir, gitdir })

    const trees = [TREE({ ref: 'HEAD' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (path === '.') return

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)

        // only since we didn't touch anything
        expect(await modified(workdir, head)).toBe(false)

        expect(await modified(index, workdir)).toBe(false)
      },
    })
  })",snuts
/__tests__/test-abortMerge.js,ConditionalTestLogic,"{'startLine':207,'endLine':207}","it('abort merge after modifying files in a directory', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'c',
        theirs: 'd',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.rm(`${dir}/a/a`)
    await fs.rmdir(`${dir}/a`)
    await fs.write(`${dir}/b/b`, 'new text for file b')
    await fs.write(`${dir}/c/c`, 'new text for file c')

    await abortMerge({ fs, dir, gitdir, commit: 'c' })

    const trees = [TREE({ ref: 'c' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (head && (await head.type()) === 'tree') return

        if (path === 'b') {
          expect(await modified(workdir, head)).toBe(false)
          expect(await modified(workdir, index)).toBe(false)
        }

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)
      },
    })
    const fileCContent = new TextDecoder().decode(await fs.read(`${dir}/c/c`))
    const fileBContent = new TextDecoder().decode(await fs.read(`${dir}/b/b`))
    expect(fileCContent).toEqual('new text for file c')
    expect(fileBContent).not.toEqual('new text for file b')
  })",snuts
/__tests__/test-abortMerge.js,ConditionalTestLogic,"{'startLine':209,'endLine':212}","it('abort merge after modifying files in a directory', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'c',
        theirs: 'd',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.rm(`${dir}/a/a`)
    await fs.rmdir(`${dir}/a`)
    await fs.write(`${dir}/b/b`, 'new text for file b')
    await fs.write(`${dir}/c/c`, 'new text for file c')

    await abortMerge({ fs, dir, gitdir, commit: 'c' })

    const trees = [TREE({ ref: 'c' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (head && (await head.type()) === 'tree') return

        if (path === 'b') {
          expect(await modified(workdir, head)).toBe(false)
          expect(await modified(workdir, index)).toBe(false)
        }

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)
      },
    })
    const fileCContent = new TextDecoder().decode(await fs.read(`${dir}/c/c`))
    const fileBContent = new TextDecoder().decode(await fs.read(`${dir}/b/b`))
    expect(fileCContent).toEqual('new text for file c')
    expect(fileBContent).not.toEqual('new text for file b')
  })",snuts
/__tests__/test-abortMerge.js,ConditionalTestLogic,"{'startLine':214,'endLine':217}","it('abort merge after modifying files in a directory', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'c',
        theirs: 'd',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.rm(`${dir}/a/a`)
    await fs.rmdir(`${dir}/a`)
    await fs.write(`${dir}/b/b`, 'new text for file b')
    await fs.write(`${dir}/c/c`, 'new text for file c')

    await abortMerge({ fs, dir, gitdir, commit: 'c' })

    const trees = [TREE({ ref: 'c' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (head && (await head.type()) === 'tree') return

        if (path === 'b') {
          expect(await modified(workdir, head)).toBe(false)
          expect(await modified(workdir, index)).toBe(false)
        }

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)
      },
    })
    const fileCContent = new TextDecoder().decode(await fs.read(`${dir}/c/c`))
    const fileBContent = new TextDecoder().decode(await fs.read(`${dir}/b/b`))
    expect(fileCContent).toEqual('new text for file c')
    expect(fileBContent).not.toEqual('new text for file b')
  })",snuts
/__tests__/test-abortMerge.js,ConditionalTestLogic,"{'startLine':269,'endLine':269}","it('abort merge after modifying files', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.rm(`${dir}/a`)
    await fs.write(`${dir}/b`, 'new text for file b')
    await fs.write(`${dir}/c`, 'new text for file c')

    await abortMerge({ fs, dir, gitdir })

    const trees = [TREE({ ref: 'HEAD' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (path === '.') return

        if (path === 'b') {
          expect(await modified(workdir, head)).toBe(false)
          expect(await modified(workdir, index)).toBe(false)
        }

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)
      },
    })
    const fileCContent = new TextDecoder().decode(await fs.read(`${dir}/c`))
    const fileBContent = new TextDecoder().decode(await fs.read(`${dir}/b`))
    expect(fileCContent).toEqual('new text for file c')
    expect(fileBContent).not.toEqual('new text for file b')
  })",snuts
/__tests__/test-abortMerge.js,ConditionalTestLogic,"{'startLine':271,'endLine':274}","it('abort merge after modifying files', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.rm(`${dir}/a`)
    await fs.write(`${dir}/b`, 'new text for file b')
    await fs.write(`${dir}/c`, 'new text for file c')

    await abortMerge({ fs, dir, gitdir })

    const trees = [TREE({ ref: 'HEAD' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (path === '.') return

        if (path === 'b') {
          expect(await modified(workdir, head)).toBe(false)
          expect(await modified(workdir, index)).toBe(false)
        }

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)
      },
    })
    const fileCContent = new TextDecoder().decode(await fs.read(`${dir}/c`))
    const fileBContent = new TextDecoder().decode(await fs.read(`${dir}/b`))
    expect(fileCContent).toEqual('new text for file c')
    expect(fileBContent).not.toEqual('new text for file b')
  })",snuts
/__tests__/test-abortMerge.js,ConditionalTestLogic,"{'startLine':276,'endLine':279}","it('abort merge after modifying files', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.rm(`${dir}/a`)
    await fs.write(`${dir}/b`, 'new text for file b')
    await fs.write(`${dir}/c`, 'new text for file c')

    await abortMerge({ fs, dir, gitdir })

    const trees = [TREE({ ref: 'HEAD' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (path === '.') return

        if (path === 'b') {
          expect(await modified(workdir, head)).toBe(false)
          expect(await modified(workdir, index)).toBe(false)
        }

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)
      },
    })
    const fileCContent = new TextDecoder().decode(await fs.read(`${dir}/c`))
    const fileBContent = new TextDecoder().decode(await fs.read(`${dir}/b`))
    expect(fileCContent).toEqual('new text for file c')
    expect(fileBContent).not.toEqual('new text for file b')
  })",snuts
/__tests__/test-abortMerge.js,SubOptimalAssert,"{'startLine':66,'endLine':66}","it('write conflicted files to index at different stages', async () => {
    // Setup
    const { gitdir, dir, fs } = await makeFixture('test-abortMerge')

    const branchA = await resolveRef({ fs, gitdir, ref: 'a' })
    const branchB = await resolveRef({ fs, gitdir, ref: 'b' })
    const ancestor = '2d7b1a9b82e52bd8648cf156aa559eff3a27a678' // common ancestor, hard coded, not ideal

    const fileAVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'a' }),
    ]

    const fileBVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'b' }),
    ]

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
      const fileAStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[3].oid,
        }),
      ]
      const fileBStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[3].oid,
        }),
      ]
      expect(fileAVersions).toEqual(fileAStages)
      expect(fileBVersions).toEqual(fileBStages)
    })
  })",snuts
/__tests__/test-abortMerge.js,SubOptimalAssert,"{'startLine':69,'endLine':69}","it('write conflicted files to index at different stages', async () => {
    // Setup
    const { gitdir, dir, fs } = await makeFixture('test-abortMerge')

    const branchA = await resolveRef({ fs, gitdir, ref: 'a' })
    const branchB = await resolveRef({ fs, gitdir, ref: 'b' })
    const ancestor = '2d7b1a9b82e52bd8648cf156aa559eff3a27a678' // common ancestor, hard coded, not ideal

    const fileAVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'a' }),
    ]

    const fileBVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'b' }),
    ]

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
      const fileAStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[3].oid,
        }),
      ]
      const fileBStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[3].oid,
        }),
      ]
      expect(fileAVersions).toEqual(fileAStages)
      expect(fileBVersions).toEqual(fileBStages)
    })
  })",snuts
/__tests__/test-abortMerge.js,SubOptimalAssert,"{'startLine':70,'endLine':70}","it('write conflicted files to index at different stages', async () => {
    // Setup
    const { gitdir, dir, fs } = await makeFixture('test-abortMerge')

    const branchA = await resolveRef({ fs, gitdir, ref: 'a' })
    const branchB = await resolveRef({ fs, gitdir, ref: 'b' })
    const ancestor = '2d7b1a9b82e52bd8648cf156aa559eff3a27a678' // common ancestor, hard coded, not ideal

    const fileAVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'a' }),
    ]

    const fileBVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'b' }),
    ]

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
      const fileAStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[3].oid,
        }),
      ]
      const fileBStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[3].oid,
        }),
      ]
      expect(fileAVersions).toEqual(fileAStages)
      expect(fileBVersions).toEqual(fileBStages)
    })
  })",snuts
/__tests__/test-abortMerge.js,SubOptimalAssert,"{'startLine':71,'endLine':71}","it('write conflicted files to index at different stages', async () => {
    // Setup
    const { gitdir, dir, fs } = await makeFixture('test-abortMerge')

    const branchA = await resolveRef({ fs, gitdir, ref: 'a' })
    const branchB = await resolveRef({ fs, gitdir, ref: 'b' })
    const ancestor = '2d7b1a9b82e52bd8648cf156aa559eff3a27a678' // common ancestor, hard coded, not ideal

    const fileAVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'a' }),
    ]

    const fileBVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'b' }),
    ]

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
      const fileAStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[3].oid,
        }),
      ]
      const fileBStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[3].oid,
        }),
      ]
      expect(fileAVersions).toEqual(fileAStages)
      expect(fileBVersions).toEqual(fileBStages)
    })
  })",snuts
/__tests__/test-abortMerge.js,SubOptimalAssert,"{'startLine':356,'endLine':356}","it('uncache a file that has changes in the workdir (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    fs.write(`${dir}/c`, 'new changes to file c')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      index.delete({ filepath: 'c' })
    })

    const fileAWorkdirVersion = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual(fileAWorkdirVersion)
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",snuts
/__tests__/test-abortMerge.js,SubOptimalAssert,"{'startLine':422,'endLine':422}","it('workdir != index && index != head [stage a file and them modify in workdir] (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.write(`${dir}/a`, 'text that is in the index')
    await add({ fs, dir, gitdir, filepath: 'a' })
    await fs.write(`${dir}/a`, 'text that is in the workdir')

    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual('text that is in the workdir')
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",snuts
/__tests__/test-abortMerge.js,SubOptimalAssert,"{'startLine':490,'endLine':490}","it('workdir != index && index === head (keep our changes)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    const head = await resolveRef({ fs, gitdir, ref: 'HEAD' })

    const fileAHeadVersion = await readBlob({
      fs,
      gitdir,
      oid: head,
      filepath: 'a',
    }).then(result => {
      return new TextDecoder().decode(result.blob)
    })
    const fileBHeadVersion = await readBlob({
      fs,
      gitdir,
      oid: head,
      filepath: 'b',
    }).then(result => {
      return new TextDecoder().decode(result.blob)
    })

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.write(`${dir}/c`, 'new text for file c')
    await abortMerge({ fs, dir, gitdir })

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual(fileAHeadVersion)
    expect(fileBContent).toEqual(fileBHeadVersion)
    expect(fileCContent).toEqual('new text for file c')
  })",snuts
/__tests__/test-abortMerge.js,VerboseStatement,"{'startLine':165,'endLine':226}","it('abort merge after modifying files in a directory', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'c',
        theirs: 'd',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.rm(`${dir}/a/a`)
    await fs.rmdir(`${dir}/a`)
    await fs.write(`${dir}/b/b`, 'new text for file b')
    await fs.write(`${dir}/c/c`, 'new text for file c')

    await abortMerge({ fs, dir, gitdir, commit: 'c' })

    const trees = [TREE({ ref: 'c' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (head && (await head.type()) === 'tree') return

        if (path === 'b') {
          expect(await modified(workdir, head)).toBe(false)
          expect(await modified(workdir, index)).toBe(false)
        }

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)
      },
    })
    const fileCContent = new TextDecoder().decode(await fs.read(`${dir}/c/c`))
    const fileBContent = new TextDecoder().decode(await fs.read(`${dir}/b/b`))
    expect(fileCContent).toEqual('new text for file c')
    expect(fileBContent).not.toEqual('new text for file b')
  })",snuts
/__tests__/test-abortMerge.js,VerboseStatement,"{'startLine':228,'endLine':288}","it('abort merge after modifying files', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.rm(`${dir}/a`)
    await fs.write(`${dir}/b`, 'new text for file b')
    await fs.write(`${dir}/c`, 'new text for file c')

    await abortMerge({ fs, dir, gitdir })

    const trees = [TREE({ ref: 'HEAD' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (path === '.') return

        if (path === 'b') {
          expect(await modified(workdir, head)).toBe(false)
          expect(await modified(workdir, index)).toBe(false)
        }

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)
      },
    })
    const fileCContent = new TextDecoder().decode(await fs.read(`${dir}/c`))
    const fileBContent = new TextDecoder().decode(await fs.read(`${dir}/b`))
    expect(fileCContent).toEqual('new text for file c')
    expect(fileBContent).not.toEqual('new text for file b')
  })",snuts
/__tests__/test-abortMerge.js,VerboseStatement,"{'startLine':290,'endLine':360}","it('uncache a file that has changes in the workdir (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    fs.write(`${dir}/c`, 'new changes to file c')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      index.delete({ filepath: 'c' })
    })

    const fileAWorkdirVersion = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual(fileAWorkdirVersion)
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",snuts
/__tests__/test-abortMerge.js,VerboseStatement,"{'startLine':362,'endLine':426}","it('workdir != index && index != head [stage a file and them modify in workdir] (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.write(`${dir}/a`, 'text that is in the index')
    await add({ fs, dir, gitdir, filepath: 'a' })
    await fs.write(`${dir}/a`, 'text that is in the workdir')

    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual('text that is in the workdir')
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",snuts
/__tests__/test-abortMerge.js,VerboseStatement,"{'startLine':428,'endLine':494}","it('workdir != index && index === head (keep our changes)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    const head = await resolveRef({ fs, gitdir, ref: 'HEAD' })

    const fileAHeadVersion = await readBlob({
      fs,
      gitdir,
      oid: head,
      filepath: 'a',
    }).then(result => {
      return new TextDecoder().decode(result.blob)
    })
    const fileBHeadVersion = await readBlob({
      fs,
      gitdir,
      oid: head,
      filepath: 'b',
    }).then(result => {
      return new TextDecoder().decode(result.blob)
    })

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.write(`${dir}/c`, 'new text for file c')
    await abortMerge({ fs, dir, gitdir })

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual(fileAHeadVersion)
    expect(fileBContent).toEqual(fileBHeadVersion)
    expect(fileCContent).toEqual('new text for file c')
  })",snuts
/__tests__/test-GitSideBand.js,ConditionalTestLogic,"{'startLine':18,'endLine':24}","it('demux - packetlines, packfile, and progress', async () => {
    const data = `001e# service=git-upload-pack
003dfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/main
000e\x01packfile
000e\x02hi there
0000`
    const expectedPacketlines = []
    const expectedProgress = []
    const expectedPackfile = []
    const lines = data.split(/\n/)
    const lastLineIdx = lines.length - 1
    lines.forEach((it, idx) => {
      it = it.slice(4) + (idx === lastLineIdx ? '' : '\n')
      if (it.startsWith('\x01')) {
        expectedPackfile.push(it.slice(1))
      } else if (it.startsWith('\x02')) {
        expectedProgress.push(it.slice(1))
      } else {
        expectedPacketlines.push(it)
      }
    })
    const stream = [Buffer.from(data)]
    const { packetlines, packfile, progress } = GitSideBand.demux(stream)
    const collectedPacketlines = await collect(packetlines)
    const collectedProgress = await collect(progress)
    const collectedPackfile = await collect(packfile)
    expect(collectedPacketlines.length > 0).toBe(true)
    expect(Buffer.from(collectedPacketlines).toString()).toEqual(
      expectedPacketlines.join('')
    )
    expect(collectedProgress.length > 0).toBe(true)
    expect(Buffer.from(collectedProgress).toString()).toEqual(
      expectedProgress.join('')
    )
    expect(collectedPackfile.length > 0).toBe(true)
    expect(Buffer.from(collectedPackfile).toString()).toEqual(
      expectedPackfile.join('')
    )
  })",snuts
/__tests__/test-GitSideBand.js,ConditionalTestLogic,"{'startLine':20,'endLine':24}","it('demux - packetlines, packfile, and progress', async () => {
    const data = `001e# service=git-upload-pack
003dfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/main
000e\x01packfile
000e\x02hi there
0000`
    const expectedPacketlines = []
    const expectedProgress = []
    const expectedPackfile = []
    const lines = data.split(/\n/)
    const lastLineIdx = lines.length - 1
    lines.forEach((it, idx) => {
      it = it.slice(4) + (idx === lastLineIdx ? '' : '\n')
      if (it.startsWith('\x01')) {
        expectedPackfile.push(it.slice(1))
      } else if (it.startsWith('\x02')) {
        expectedProgress.push(it.slice(1))
      } else {
        expectedPacketlines.push(it)
      }
    })
    const stream = [Buffer.from(data)]
    const { packetlines, packfile, progress } = GitSideBand.demux(stream)
    const collectedPacketlines = await collect(packetlines)
    const collectedProgress = await collect(progress)
    const collectedPackfile = await collect(packfile)
    expect(collectedPacketlines.length > 0).toBe(true)
    expect(Buffer.from(collectedPacketlines).toString()).toEqual(
      expectedPacketlines.join('')
    )
    expect(collectedProgress.length > 0).toBe(true)
    expect(Buffer.from(collectedProgress).toString()).toEqual(
      expectedProgress.join('')
    )
    expect(collectedPackfile.length > 0).toBe(true)
    expect(Buffer.from(collectedPackfile).toString()).toEqual(
      expectedPackfile.join('')
    )
  })",snuts
/__tests__/test-GitSideBand.js,ConditionalTestLogic,"{'startLine':55,'endLine':59}","it('demux - error line', async () => {
    const data = `001e# service=git-upload-pack
0015\x03error in stream
0000`
    const expectedPacketlines = []
    const expectedProgress = []
    const lines = data.split(/\n/)
    const lastLineIdx = lines.length - 1
    lines.forEach((it, idx) => {
      it = it.slice(4) + (idx === lastLineIdx ? '' : '\n')
      if (it.startsWith('\x03')) {
        expectedProgress.push(it.slice(1))
      } else {
        expectedPacketlines.push(it)
      }
    })
    const stream = [Buffer.from(data)]
    const { packetlines, packfile, progress } = GitSideBand.demux(stream)
    const collectedPacketlines = await collect(packetlines)
    const collectedProgress = await collect(progress)
    const collectedPackfile = await collect(packfile)
    expect(collectedPacketlines.length > 0).toBe(true)
    expect(Buffer.from(collectedPacketlines).toString()).toEqual(
      expectedPacketlines.join('')
    )
    expect(collectedProgress.length > 0).toBe(true)
    expect(Buffer.from(collectedProgress).toString()).toEqual(
      expectedProgress.join('')
    )
    expect(collectedPackfile.length === 0).toBe(true)
    expect('error' in packfile).toBe(true)
    expect(packfile.error.message).toEqual('error in stream\n')
  })",snuts
/__tests__/test-GitSideBand.js,SubOptimalAssert,"{'startLine':31,'endLine':31}","it('demux - packetlines, packfile, and progress', async () => {
    const data = `001e# service=git-upload-pack
003dfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/main
000e\x01packfile
000e\x02hi there
0000`
    const expectedPacketlines = []
    const expectedProgress = []
    const expectedPackfile = []
    const lines = data.split(/\n/)
    const lastLineIdx = lines.length - 1
    lines.forEach((it, idx) => {
      it = it.slice(4) + (idx === lastLineIdx ? '' : '\n')
      if (it.startsWith('\x01')) {
        expectedPackfile.push(it.slice(1))
      } else if (it.startsWith('\x02')) {
        expectedProgress.push(it.slice(1))
      } else {
        expectedPacketlines.push(it)
      }
    })
    const stream = [Buffer.from(data)]
    const { packetlines, packfile, progress } = GitSideBand.demux(stream)
    const collectedPacketlines = await collect(packetlines)
    const collectedProgress = await collect(progress)
    const collectedPackfile = await collect(packfile)
    expect(collectedPacketlines.length > 0).toBe(true)
    expect(Buffer.from(collectedPacketlines).toString()).toEqual(
      expectedPacketlines.join('')
    )
    expect(collectedProgress.length > 0).toBe(true)
    expect(Buffer.from(collectedProgress).toString()).toEqual(
      expectedProgress.join('')
    )
    expect(collectedPackfile.length > 0).toBe(true)
    expect(Buffer.from(collectedPackfile).toString()).toEqual(
      expectedPackfile.join('')
    )
  })",snuts
/__tests__/test-GitSideBand.js,SubOptimalAssert,"{'startLine':35,'endLine':35}","it('demux - packetlines, packfile, and progress', async () => {
    const data = `001e# service=git-upload-pack
003dfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/main
000e\x01packfile
000e\x02hi there
0000`
    const expectedPacketlines = []
    const expectedProgress = []
    const expectedPackfile = []
    const lines = data.split(/\n/)
    const lastLineIdx = lines.length - 1
    lines.forEach((it, idx) => {
      it = it.slice(4) + (idx === lastLineIdx ? '' : '\n')
      if (it.startsWith('\x01')) {
        expectedPackfile.push(it.slice(1))
      } else if (it.startsWith('\x02')) {
        expectedProgress.push(it.slice(1))
      } else {
        expectedPacketlines.push(it)
      }
    })
    const stream = [Buffer.from(data)]
    const { packetlines, packfile, progress } = GitSideBand.demux(stream)
    const collectedPacketlines = await collect(packetlines)
    const collectedProgress = await collect(progress)
    const collectedPackfile = await collect(packfile)
    expect(collectedPacketlines.length > 0).toBe(true)
    expect(Buffer.from(collectedPacketlines).toString()).toEqual(
      expectedPacketlines.join('')
    )
    expect(collectedProgress.length > 0).toBe(true)
    expect(Buffer.from(collectedProgress).toString()).toEqual(
      expectedProgress.join('')
    )
    expect(collectedPackfile.length > 0).toBe(true)
    expect(Buffer.from(collectedPackfile).toString()).toEqual(
      expectedPackfile.join('')
    )
  })",snuts
/__tests__/test-GitSideBand.js,SubOptimalAssert,"{'startLine':39,'endLine':39}","it('demux - packetlines, packfile, and progress', async () => {
    const data = `001e# service=git-upload-pack
003dfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/main
000e\x01packfile
000e\x02hi there
0000`
    const expectedPacketlines = []
    const expectedProgress = []
    const expectedPackfile = []
    const lines = data.split(/\n/)
    const lastLineIdx = lines.length - 1
    lines.forEach((it, idx) => {
      it = it.slice(4) + (idx === lastLineIdx ? '' : '\n')
      if (it.startsWith('\x01')) {
        expectedPackfile.push(it.slice(1))
      } else if (it.startsWith('\x02')) {
        expectedProgress.push(it.slice(1))
      } else {
        expectedPacketlines.push(it)
      }
    })
    const stream = [Buffer.from(data)]
    const { packetlines, packfile, progress } = GitSideBand.demux(stream)
    const collectedPacketlines = await collect(packetlines)
    const collectedProgress = await collect(progress)
    const collectedPackfile = await collect(packfile)
    expect(collectedPacketlines.length > 0).toBe(true)
    expect(Buffer.from(collectedPacketlines).toString()).toEqual(
      expectedPacketlines.join('')
    )
    expect(collectedProgress.length > 0).toBe(true)
    expect(Buffer.from(collectedProgress).toString()).toEqual(
      expectedProgress.join('')
    )
    expect(collectedPackfile.length > 0).toBe(true)
    expect(Buffer.from(collectedPackfile).toString()).toEqual(
      expectedPackfile.join('')
    )
  })",snuts
/__tests__/test-GitSideBand.js,SubOptimalAssert,"{'startLine':66,'endLine':66}","it('demux - error line', async () => {
    const data = `001e# service=git-upload-pack
0015\x03error in stream
0000`
    const expectedPacketlines = []
    const expectedProgress = []
    const lines = data.split(/\n/)
    const lastLineIdx = lines.length - 1
    lines.forEach((it, idx) => {
      it = it.slice(4) + (idx === lastLineIdx ? '' : '\n')
      if (it.startsWith('\x03')) {
        expectedProgress.push(it.slice(1))
      } else {
        expectedPacketlines.push(it)
      }
    })
    const stream = [Buffer.from(data)]
    const { packetlines, packfile, progress } = GitSideBand.demux(stream)
    const collectedPacketlines = await collect(packetlines)
    const collectedProgress = await collect(progress)
    const collectedPackfile = await collect(packfile)
    expect(collectedPacketlines.length > 0).toBe(true)
    expect(Buffer.from(collectedPacketlines).toString()).toEqual(
      expectedPacketlines.join('')
    )
    expect(collectedProgress.length > 0).toBe(true)
    expect(Buffer.from(collectedProgress).toString()).toEqual(
      expectedProgress.join('')
    )
    expect(collectedPackfile.length === 0).toBe(true)
    expect('error' in packfile).toBe(true)
    expect(packfile.error.message).toEqual('error in stream\n')
  })",snuts
/__tests__/test-GitSideBand.js,SubOptimalAssert,"{'startLine':70,'endLine':70}","it('demux - error line', async () => {
    const data = `001e# service=git-upload-pack
0015\x03error in stream
0000`
    const expectedPacketlines = []
    const expectedProgress = []
    const lines = data.split(/\n/)
    const lastLineIdx = lines.length - 1
    lines.forEach((it, idx) => {
      it = it.slice(4) + (idx === lastLineIdx ? '' : '\n')
      if (it.startsWith('\x03')) {
        expectedProgress.push(it.slice(1))
      } else {
        expectedPacketlines.push(it)
      }
    })
    const stream = [Buffer.from(data)]
    const { packetlines, packfile, progress } = GitSideBand.demux(stream)
    const collectedPacketlines = await collect(packetlines)
    const collectedProgress = await collect(progress)
    const collectedPackfile = await collect(packfile)
    expect(collectedPacketlines.length > 0).toBe(true)
    expect(Buffer.from(collectedPacketlines).toString()).toEqual(
      expectedPacketlines.join('')
    )
    expect(collectedProgress.length > 0).toBe(true)
    expect(Buffer.from(collectedProgress).toString()).toEqual(
      expectedProgress.join('')
    )
    expect(collectedPackfile.length === 0).toBe(true)
    expect('error' in packfile).toBe(true)
    expect(packfile.error.message).toEqual('error in stream\n')
  })",snuts
/__tests__/test-GitSideBand.js,SubOptimalAssert,"{'startLine':74,'endLine':74}","it('demux - error line', async () => {
    const data = `001e# service=git-upload-pack
0015\x03error in stream
0000`
    const expectedPacketlines = []
    const expectedProgress = []
    const lines = data.split(/\n/)
    const lastLineIdx = lines.length - 1
    lines.forEach((it, idx) => {
      it = it.slice(4) + (idx === lastLineIdx ? '' : '\n')
      if (it.startsWith('\x03')) {
        expectedProgress.push(it.slice(1))
      } else {
        expectedPacketlines.push(it)
      }
    })
    const stream = [Buffer.from(data)]
    const { packetlines, packfile, progress } = GitSideBand.demux(stream)
    const collectedPacketlines = await collect(packetlines)
    const collectedProgress = await collect(progress)
    const collectedPackfile = await collect(packfile)
    expect(collectedPacketlines.length > 0).toBe(true)
    expect(Buffer.from(collectedPacketlines).toString()).toEqual(
      expectedPacketlines.join('')
    )
    expect(collectedProgress.length > 0).toBe(true)
    expect(Buffer.from(collectedProgress).toString()).toEqual(
      expectedProgress.join('')
    )
    expect(collectedPackfile.length === 0).toBe(true)
    expect('error' in packfile).toBe(true)
    expect(packfile.error.message).toEqual('error in stream\n')
  })",snuts
/__tests__/test-GitSideBand.js,SubOptimalAssert,"{'startLine':75,'endLine':75}","it('demux - error line', async () => {
    const data = `001e# service=git-upload-pack
0015\x03error in stream
0000`
    const expectedPacketlines = []
    const expectedProgress = []
    const lines = data.split(/\n/)
    const lastLineIdx = lines.length - 1
    lines.forEach((it, idx) => {
      it = it.slice(4) + (idx === lastLineIdx ? '' : '\n')
      if (it.startsWith('\x03')) {
        expectedProgress.push(it.slice(1))
      } else {
        expectedPacketlines.push(it)
      }
    })
    const stream = [Buffer.from(data)]
    const { packetlines, packfile, progress } = GitSideBand.demux(stream)
    const collectedPacketlines = await collect(packetlines)
    const collectedProgress = await collect(progress)
    const collectedPackfile = await collect(packfile)
    expect(collectedPacketlines.length > 0).toBe(true)
    expect(Buffer.from(collectedPacketlines).toString()).toEqual(
      expectedPacketlines.join('')
    )
    expect(collectedProgress.length > 0).toBe(true)
    expect(Buffer.from(collectedProgress).toString()).toEqual(
      expectedProgress.join('')
    )
    expect(collectedPackfile.length === 0).toBe(true)
    expect('error' in packfile).toBe(true)
    expect(packfile.error.message).toEqual('error in stream\n')
  })",snuts
/__tests__/test-GitSideBand.js,VerboseStatement,"{'startLine':5,'endLine':43}","it('demux - packetlines, packfile, and progress', async () => {
    const data = `001e# service=git-upload-pack
003dfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/main
000e\x01packfile
000e\x02hi there
0000`
    const expectedPacketlines = []
    const expectedProgress = []
    const expectedPackfile = []
    const lines = data.split(/\n/)
    const lastLineIdx = lines.length - 1
    lines.forEach((it, idx) => {
      it = it.slice(4) + (idx === lastLineIdx ? '' : '\n')
      if (it.startsWith('\x01')) {
        expectedPackfile.push(it.slice(1))
      } else if (it.startsWith('\x02')) {
        expectedProgress.push(it.slice(1))
      } else {
        expectedPacketlines.push(it)
      }
    })
    const stream = [Buffer.from(data)]
    const { packetlines, packfile, progress } = GitSideBand.demux(stream)
    const collectedPacketlines = await collect(packetlines)
    const collectedProgress = await collect(progress)
    const collectedPackfile = await collect(packfile)
    expect(collectedPacketlines.length > 0).toBe(true)
    expect(Buffer.from(collectedPacketlines).toString()).toEqual(
      expectedPacketlines.join('')
    )
    expect(collectedProgress.length > 0).toBe(true)
    expect(Buffer.from(collectedProgress).toString()).toEqual(
      expectedProgress.join('')
    )
    expect(collectedPackfile.length > 0).toBe(true)
    expect(Buffer.from(collectedPackfile).toString()).toEqual(
      expectedPackfile.join('')
    )
  })",snuts
/__tests__/test-GitSideBand.js,VerboseStatement,"{'startLine':45,'endLine':77}","it('demux - error line', async () => {
    const data = `001e# service=git-upload-pack
0015\x03error in stream
0000`
    const expectedPacketlines = []
    const expectedProgress = []
    const lines = data.split(/\n/)
    const lastLineIdx = lines.length - 1
    lines.forEach((it, idx) => {
      it = it.slice(4) + (idx === lastLineIdx ? '' : '\n')
      if (it.startsWith('\x03')) {
        expectedProgress.push(it.slice(1))
      } else {
        expectedPacketlines.push(it)
      }
    })
    const stream = [Buffer.from(data)]
    const { packetlines, packfile, progress } = GitSideBand.demux(stream)
    const collectedPacketlines = await collect(packetlines)
    const collectedProgress = await collect(progress)
    const collectedPackfile = await collect(packfile)
    expect(collectedPacketlines.length > 0).toBe(true)
    expect(Buffer.from(collectedPacketlines).toString()).toEqual(
      expectedPacketlines.join('')
    )
    expect(collectedProgress.length > 0).toBe(true)
    expect(Buffer.from(collectedProgress).toString()).toEqual(
      expectedProgress.join('')
    )
    expect(collectedPackfile.length === 0).toBe(true)
    expect('error' in packfile).toBe(true)
    expect(packfile.error.message).toEqual('error in stream\n')
  })",snuts
/__tests__/test-GitRemoteManager.js,AnonymousTest,"{'startLine':9,'endLine':22}","it('getRemoteHelperFor (http)', async () => {
    // Test
    let helper = null
    let error = null
    try {
      helper = await GitRemoteManager.getRemoteHelperFor({
        url: 'http://github.com/isomorphic-git-isomorphic-git',
      })
    } catch (err) {
      error = err
    }
    expect(error).toBeNull()
    expect(helper).toBe(GitRemoteHTTP)
  })",snuts
/__tests__/test-GitRemoteManager.js,AnonymousTest,"{'startLine':39,'endLine':52}","it('getRemoteHelperFor (https)', async () => {
    // Test
    let helper = null
    let error = null
    try {
      helper = await GitRemoteManager.getRemoteHelperFor({
        url: 'https://github.com/isomorphic-git-isomorphic-git',
      })
    } catch (err) {
      error = err
    }
    expect(error).toBeNull()
    expect(helper).toBe(GitRemoteHTTP)
  })",snuts
/__tests__/test-GitRemoteManager.js,AnonymousTest,"{'startLine':54,'endLine':68}","it('getRemoteHelperFor (unknown)', async () => {
    // Test
    let helper = null
    let error = null
    try {
      helper = await GitRemoteManager.getRemoteHelperFor({
        url:
          'hypergit://5701a1c08ae15dba17e181b1a9a28bdfb8b95200d77a25be6051bb018e25439a',
      })
    } catch (err) {
      error = err
    }
    expect(helper).toBeNull()
    expect(error.code).toBe(Errors.UnknownTransportError.code)
  })",snuts
/__tests__/test-GitRemoteManager.js,AnonymousTest,"{'startLine':85,'endLine':98}","it('getRemoteHelperFor (unparseable)', async () => {
    // Test
    let helper = null
    let error = null
    try {
      helper = await GitRemoteManager.getRemoteHelperFor({
        url: 'oid:c3c2a92aa2bda58d667cb57493270b83bd14d1ed',
      })
    } catch (err) {
      error = err
    }
    expect(helper).toBeNull()
    expect(error.code).toBe(Errors.UrlParseError.code)
  })",snuts
/__tests__/test-GitRefManager.js,AnonymousTest,"{'startLine':7,'endLine':84}","it('packedRefs', async () => {
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    const refs = await GitRefManager.packedRefs({ fs, gitdir })
    expect(refs).toMatchInlineSnapshot(`
      Map {
        ""refs/remotes/origin/develop"" => ""dba5b92408549e55c36e16c89e2b4a4e4cbc8c8f"",
        ""refs/remotes/origin/dist"" => ""a2dd810e222b7b02fc53760037d9928cb97c645d"",
        ""refs/remotes/origin/gh-pages"" => ""1bfb4d0bce3fda5b26f189311dfef0a94390be38"",
        ""refs/remotes/origin/git-fetch"" => ""5741bed81a5e38744ec8ca88b5aa4f058467d4bf"",
        ""refs/remotes/origin/greenkeeper/semantic-release-11.0.2"" => ""665910e9294fe796499917c472b4ead573a11b06"",
        ""refs/remotes/origin/master"" => ""dba5b92408549e55c36e16c89e2b4a4e4cbc8c8f"",
        ""refs/remotes/origin/test-branch"" => ""e10ebb90d03eaacca84de1af0a59b444232da99e"",
        ""refs/remotes/origin/test-branch-shallow-clone"" => ""92e7b4123fbf135f5ffa9b6fe2ec78d07bbc353e"",
        ""refs/tags/test-tag"" => ""1e40fdfba1cf17f3c9f9f3d6b392b1865e5147b9"",
        ""refs/tags/v0.0.1"" => ""1a2149e96a9767b281a8f10fd014835322da2d14"",
        ""refs/tags/v0.0.10"" => ""0a117b8378f5e5323d15694c7eb8f62c4bea152b"",
        ""refs/tags/v0.0.10^{}"" => ""ce03143bd6567fc7063549c204e877834cda5645"",
        ""refs/tags/v0.0.11"" => ""acd8de39da34f0f05b07f0494675afa914fadbd9"",
        ""refs/tags/v0.0.11^{}"" => ""8388a3d4197bf9e02bb97dfdc920fe6b6353453d"",
        ""refs/tags/v0.0.12"" => ""9dba4bc0f13b98a21a9f8c41b9dcc174df6e8dd9"",
        ""refs/tags/v0.0.12^{}"" => ""8d74454009b9bf7bf1df39ad31c8191bd9ac591b"",
        ""refs/tags/v0.0.13"" => ""0d7c8bcac6c824e8a857eeceeab4416427314202"",
        ""refs/tags/v0.0.13^{}"" => ""af70a57e828aa1f7de829b1987915abe3aeeab85"",
        ""refs/tags/v0.0.14"" => ""1560793d9e6c08dddb9218ec7a58a96f55664f7f"",
        ""refs/tags/v0.0.14^{}"" => ""71cfcca36f2403662acf3390ae7654a0cb52fbfc"",
        ""refs/tags/v0.0.15"" => ""78bae74bb8d82877c703cca5da8a6ffd50facd17"",
        ""refs/tags/v0.0.15^{}"" => ""f531be257f90a5211ed5f63a417b1a3bc27ab2bb"",
        ""refs/tags/v0.0.16"" => ""8c2189d3745bb88f2e34d2dbb97028a9dead1a29"",
        ""refs/tags/v0.0.16^{}"" => ""252cb320650c604db9e504e0b04dea0e94922802"",
        ""refs/tags/v0.0.17"" => ""6f09d58133a791fc3a2493471d4b3d49f9e935d6"",
        ""refs/tags/v0.0.17^{}"" => ""5354394fb099b5713c60fe6be2350457d6d2d658"",
        ""refs/tags/v0.0.18"" => ""1739d0abdf493ad61caf11a10417dbf0f87bd2c9"",
        ""refs/tags/v0.0.18^{}"" => ""2359fff39771f72c94b8b034803c7722319a1405"",
        ""refs/tags/v0.0.19"" => ""180c9e01421744a307fb309f79b828ef71b47f4c"",
        ""refs/tags/v0.0.19^{}"" => ""9e4130538be3129100aecf9218a6be0fc35f9911"",
        ""refs/tags/v0.0.2"" => ""9e3ee22249ed50acccfd3996dadb5d27019a7dad"",
        ""refs/tags/v0.0.20"" => ""993509d291a58bc8c8dd8d23829d5294e057de22"",
        ""refs/tags/v0.0.20^{}"" => ""12cef164723a8ebcbbc2b9a48212a83bfcd9eecf"",
        ""refs/tags/v0.0.21"" => ""5b71480a0e679bf29cad790a78fd4df551a96097"",
        ""refs/tags/v0.0.21^{}"" => ""b25b4120b1ee4fc2ec4c2016268e1e42602b6a86"",
        ""refs/tags/v0.0.22"" => ""259ccc39944411d632189e4d7e009cd5d2485636"",
        ""refs/tags/v0.0.22^{}"" => ""eb95df88672e6f258ef6b759ab341f8b99dc477a"",
        ""refs/tags/v0.0.23"" => ""c0bc224f093f93d99c6e68b6b5ceedfeecf61bb9"",
        ""refs/tags/v0.0.23^{}"" => ""c81055a43f1691af59707076d78405b6d3235fea"",
        ""refs/tags/v0.0.24"" => ""463103b31c473c25e87288f564a8e73a9476777b"",
        ""refs/tags/v0.0.24^{}"" => ""d33eab687ba73b586239843dd8c3bc4267f1b358"",
        ""refs/tags/v0.0.25"" => ""79d7db0650cffe24e307dd4ba881ccbdf0011e6a"",
        ""refs/tags/v0.0.25^{}"" => ""b2c43af335e94255839aae1f2b1a97995040f389"",
        ""refs/tags/v0.0.26"" => ""e611dd73aeeef5add4bda82a00f7e9af7d17d9dd"",
        ""refs/tags/v0.0.26^{}"" => ""fae8a72f545106b2816641f5452bf7f7e99ea2a8"",
        ""refs/tags/v0.0.27"" => ""a233f65a609c07bc6e31bfc0bc051d98c8cfe18e"",
        ""refs/tags/v0.0.28"" => ""6398b5cb041d23de187f46c8888768d96b3cd01e"",
        ""refs/tags/v0.0.29"" => ""24ca84f16a4bcbf8b252eb0c4250a6c818cf00d3"",
        ""refs/tags/v0.0.3"" => ""3e6345233bb696737784f423ace943e0eaa2b30c"",
        ""refs/tags/v0.0.3^{}"" => ""b3ed1e3f15c9bcab23833dbb5ef6a8e2198ec4e2"",
        ""refs/tags/v0.0.30"" => ""c8ea7416948bdc19c1ca1b51b8897ed9201597dd"",
        ""refs/tags/v0.0.31"" => ""f754b0f027c72695cbfd37c990559bc61bf583b6"",
        ""refs/tags/v0.0.32"" => ""c2dcbda8dbe0fb614de6340b273e7bba9ab52a37"",
        ""refs/tags/v0.0.33"" => ""8411968f6359c8ae7e85b5da7e417002477263ea"",
        ""refs/tags/v0.0.34"" => ""dc887a60db904f58b558857ba7a6c39dd1d18f22"",
        ""refs/tags/v0.0.35"" => ""dd242320e5b0054c9468e4ab5cc3c4722051dd43"",
        ""refs/tags/v0.0.36"" => ""bc31c33f9b9dbaf6a2c15c118f9f8924600c6331"",
        ""refs/tags/v0.0.37"" => ""e723960dde1fa6dd1379642c80d09d2a1e5e2d16"",
        ""refs/tags/v0.0.38"" => ""e97c6ed41ae435991f2c4c1faaa0e72ad7b35c67"",
        ""refs/tags/v0.0.4"" => ""01509d00409c556c331bb278269c6ca770eb7c52"",
        ""refs/tags/v0.0.4^{}"" => ""3eb8f48d22cac58d8ba42237cb2227ef90bfce08"",
        ""refs/tags/v0.0.5"" => ""ff03e74259efab829557d0b3c15d6c76b9458262"",
        ""refs/tags/v0.0.6"" => ""20668e724eed5fffd23968793aee0592babac2ab"",
        ""refs/tags/v0.0.6^{}"" => ""641859e5e6bad88afab83a4a3e94903ed1d8e10b"",
        ""refs/tags/v0.0.7"" => ""6dedfbd21a0633055a93c05cc8b4b5cd89f2b708"",
        ""refs/tags/v0.0.8"" => ""4606f7652aba2b7e8d7c70eb0aa6cd75226f4d83"",
        ""refs/tags/v0.0.8^{}"" => ""025860fcfb6af84739a924ff49bcbda036855b1a"",
        ""refs/tags/v0.0.9"" => ""6e90dfd7573404a225888071ecaa572882b4e45c"",
        ""refs/tags/v0.0.9^{}"" => ""af4d84a6a9fa7a74acdad07fddf9f17ff3a974ae"",
        ""refs/tags/v0.1.0"" => ""dba5b92408549e55c36e16c89e2b4a4e4cbc8c8f"",
      }
    `)
  })",snuts
/__tests__/test-GitRefManager.js,AnonymousTest,"{'startLine':85,'endLine':176}","it('listRefs', async () => {
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    let refs = await GitRefManager.listRefs({
      fs,
      gitdir,
      filepath: 'refs/remotes/origin',
    })
    expect(refs).toMatchInlineSnapshot(`
      Array [
        ""develop"",
        ""dist"",
        ""gh-pages"",
        ""git-fetch"",
        ""greenkeeper/semantic-release-11.0.2"",
        ""master"",
        ""test-branch"",
        ""test-branch-shallow-clone"",
      ]
    `)
    refs = await GitRefManager.listRefs({
      fs,
      gitdir,
      filepath: 'refs/tags',
    })
    expect(refs).toMatchInlineSnapshot(`
      Array [
        ""local-tag"",
        ""test-tag"",
        ""v0.0.1"",
        ""v0.0.10"",
        ""v0.0.10^{}"",
        ""v0.0.11"",
        ""v0.0.11^{}"",
        ""v0.0.12"",
        ""v0.0.12^{}"",
        ""v0.0.13"",
        ""v0.0.13^{}"",
        ""v0.0.14"",
        ""v0.0.14^{}"",
        ""v0.0.15"",
        ""v0.0.15^{}"",
        ""v0.0.16"",
        ""v0.0.16^{}"",
        ""v0.0.17"",
        ""v0.0.17^{}"",
        ""v0.0.18"",
        ""v0.0.18^{}"",
        ""v0.0.19"",
        ""v0.0.19^{}"",
        ""v0.0.2"",
        ""v0.0.20"",
        ""v0.0.20^{}"",
        ""v0.0.21"",
        ""v0.0.21^{}"",
        ""v0.0.22"",
        ""v0.0.22^{}"",
        ""v0.0.23"",
        ""v0.0.23^{}"",
        ""v0.0.24"",
        ""v0.0.24^{}"",
        ""v0.0.25"",
        ""v0.0.25^{}"",
        ""v0.0.26"",
        ""v0.0.26^{}"",
        ""v0.0.27"",
        ""v0.0.28"",
        ""v0.0.29"",
        ""v0.0.3"",
        ""v0.0.3^{}"",
        ""v0.0.30"",
        ""v0.0.31"",
        ""v0.0.32"",
        ""v0.0.33"",
        ""v0.0.34"",
        ""v0.0.35"",
        ""v0.0.36"",
        ""v0.0.37"",
        ""v0.0.38"",
        ""v0.0.4"",
        ""v0.0.4^{}"",
        ""v0.0.5"",
        ""v0.0.6"",
        ""v0.0.6^{}"",
        ""v0.0.7"",
        ""v0.0.8"",
        ""v0.0.8^{}"",
        ""v0.0.9"",
        ""v0.0.9^{}"",
        ""v0.1.0"",
      ]
    `)
  })",snuts
/__tests__/test-GitRefManager.js,AnonymousTest,"{'startLine':177,'endLine':198}","it('listBranches', async () => {
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    let refs = await GitRefManager.listBranches({ fs, gitdir })
    expect(refs).toEqual([])
    refs = await GitRefManager.listBranches({
      fs,
      gitdir,
      remote: 'origin',
    })
    expect(refs).toMatchInlineSnapshot(`
      Array [
        ""develop"",
        ""dist"",
        ""gh-pages"",
        ""git-fetch"",
        ""greenkeeper/semantic-release-11.0.2"",
        ""master"",
        ""test-branch"",
        ""test-branch-shallow-clone"",
      ]
    `)
  })",snuts
/__tests__/test-GitRefManager.js,AnonymousTest,"{'startLine':199,'endLine':247}","it('listTags', async () => {
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    const refs = await GitRefManager.listTags({ fs, gitdir })
    expect(refs).toMatchInlineSnapshot(`
      Array [
        ""local-tag"",
        ""test-tag"",
        ""v0.0.1"",
        ""v0.0.10"",
        ""v0.0.11"",
        ""v0.0.12"",
        ""v0.0.13"",
        ""v0.0.14"",
        ""v0.0.15"",
        ""v0.0.16"",
        ""v0.0.17"",
        ""v0.0.18"",
        ""v0.0.19"",
        ""v0.0.2"",
        ""v0.0.20"",
        ""v0.0.21"",
        ""v0.0.22"",
        ""v0.0.23"",
        ""v0.0.24"",
        ""v0.0.25"",
        ""v0.0.26"",
        ""v0.0.27"",
        ""v0.0.28"",
        ""v0.0.29"",
        ""v0.0.3"",
        ""v0.0.30"",
        ""v0.0.31"",
        ""v0.0.32"",
        ""v0.0.33"",
        ""v0.0.34"",
        ""v0.0.35"",
        ""v0.0.36"",
        ""v0.0.37"",
        ""v0.0.38"",
        ""v0.0.4"",
        ""v0.0.5"",
        ""v0.0.6"",
        ""v0.0.7"",
        ""v0.0.8"",
        ""v0.0.9"",
        ""v0.1.0"",
      ]
    `)
  })",snuts
/__tests__/test-GitRefManager.js,OvercommentedTest,"{'startLine':248,'endLine':284}","it('concurrently reading/writing a ref should not cause a NotFoundError resolving it', async () => {
    // There are some expect() calls below, but as of 2023-03-15, if this test fails it will do so by logging instances
    // of 'NotFoundError: Could not find myRef', which should not happen.
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    const ref = 'myRef'
    const value = '1234567890123456789012345678901234567890'
    await GitRefManager.writeRef({ fs, gitdir, ref, value }) // Guarantee that the file for the ref exists on disk

    const writePromises = []
    const resolvePromises = []
    // Some arbitrary number of iterations that seems to guarantee that the error (pre-fix) is hit.
    // With 100 the test *mostly* failed but still passed every now and then.
    const iterations = 500

    for (let i = 0; i < iterations; i++) {
      // I was only able to cause the error to reproduce consistently by mixing awaited and non-awaited versions of the
      // calls to writeRef() and resolve(). I tried several variations of the combination but none of them caused the
      // error to happen as consistently.
      if (Math.random() < 0.5) {
        await GitRefManager.writeRef({ fs, gitdir, ref, value })
      } else {
        writePromises.push(GitRefManager.writeRef({ fs, gitdir, ref, value }))
      }
      if (Math.random() < 0.5) {
        const resolvedRef = await GitRefManager.resolve({ fs, gitdir, ref })
        expect(resolvedRef).toMatch(value)
      } else {
        resolvePromises.push(GitRefManager.resolve({ fs, gitdir, ref }))
      }
    }

    const resolvedRefs = await Promise.all(resolvePromises)
    for (const resolvedRef of resolvedRefs) {
      expect(resolvedRef).toMatch(value)
    }
    await Promise.all(writePromises)
  })",snuts
/__tests__/test-GitRefManager.js,ComplexSnapshots,"{'startLine':10,'endLine':83}","it('packedRefs', async () => {
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    const refs = await GitRefManager.packedRefs({ fs, gitdir })
    expect(refs).toMatchInlineSnapshot(`
      Map {
        ""refs/remotes/origin/develop"" => ""dba5b92408549e55c36e16c89e2b4a4e4cbc8c8f"",
        ""refs/remotes/origin/dist"" => ""a2dd810e222b7b02fc53760037d9928cb97c645d"",
        ""refs/remotes/origin/gh-pages"" => ""1bfb4d0bce3fda5b26f189311dfef0a94390be38"",
        ""refs/remotes/origin/git-fetch"" => ""5741bed81a5e38744ec8ca88b5aa4f058467d4bf"",
        ""refs/remotes/origin/greenkeeper/semantic-release-11.0.2"" => ""665910e9294fe796499917c472b4ead573a11b06"",
        ""refs/remotes/origin/master"" => ""dba5b92408549e55c36e16c89e2b4a4e4cbc8c8f"",
        ""refs/remotes/origin/test-branch"" => ""e10ebb90d03eaacca84de1af0a59b444232da99e"",
        ""refs/remotes/origin/test-branch-shallow-clone"" => ""92e7b4123fbf135f5ffa9b6fe2ec78d07bbc353e"",
        ""refs/tags/test-tag"" => ""1e40fdfba1cf17f3c9f9f3d6b392b1865e5147b9"",
        ""refs/tags/v0.0.1"" => ""1a2149e96a9767b281a8f10fd014835322da2d14"",
        ""refs/tags/v0.0.10"" => ""0a117b8378f5e5323d15694c7eb8f62c4bea152b"",
        ""refs/tags/v0.0.10^{}"" => ""ce03143bd6567fc7063549c204e877834cda5645"",
        ""refs/tags/v0.0.11"" => ""acd8de39da34f0f05b07f0494675afa914fadbd9"",
        ""refs/tags/v0.0.11^{}"" => ""8388a3d4197bf9e02bb97dfdc920fe6b6353453d"",
        ""refs/tags/v0.0.12"" => ""9dba4bc0f13b98a21a9f8c41b9dcc174df6e8dd9"",
        ""refs/tags/v0.0.12^{}"" => ""8d74454009b9bf7bf1df39ad31c8191bd9ac591b"",
        ""refs/tags/v0.0.13"" => ""0d7c8bcac6c824e8a857eeceeab4416427314202"",
        ""refs/tags/v0.0.13^{}"" => ""af70a57e828aa1f7de829b1987915abe3aeeab85"",
        ""refs/tags/v0.0.14"" => ""1560793d9e6c08dddb9218ec7a58a96f55664f7f"",
        ""refs/tags/v0.0.14^{}"" => ""71cfcca36f2403662acf3390ae7654a0cb52fbfc"",
        ""refs/tags/v0.0.15"" => ""78bae74bb8d82877c703cca5da8a6ffd50facd17"",
        ""refs/tags/v0.0.15^{}"" => ""f531be257f90a5211ed5f63a417b1a3bc27ab2bb"",
        ""refs/tags/v0.0.16"" => ""8c2189d3745bb88f2e34d2dbb97028a9dead1a29"",
        ""refs/tags/v0.0.16^{}"" => ""252cb320650c604db9e504e0b04dea0e94922802"",
        ""refs/tags/v0.0.17"" => ""6f09d58133a791fc3a2493471d4b3d49f9e935d6"",
        ""refs/tags/v0.0.17^{}"" => ""5354394fb099b5713c60fe6be2350457d6d2d658"",
        ""refs/tags/v0.0.18"" => ""1739d0abdf493ad61caf11a10417dbf0f87bd2c9"",
        ""refs/tags/v0.0.18^{}"" => ""2359fff39771f72c94b8b034803c7722319a1405"",
        ""refs/tags/v0.0.19"" => ""180c9e01421744a307fb309f79b828ef71b47f4c"",
        ""refs/tags/v0.0.19^{}"" => ""9e4130538be3129100aecf9218a6be0fc35f9911"",
        ""refs/tags/v0.0.2"" => ""9e3ee22249ed50acccfd3996dadb5d27019a7dad"",
        ""refs/tags/v0.0.20"" => ""993509d291a58bc8c8dd8d23829d5294e057de22"",
        ""refs/tags/v0.0.20^{}"" => ""12cef164723a8ebcbbc2b9a48212a83bfcd9eecf"",
        ""refs/tags/v0.0.21"" => ""5b71480a0e679bf29cad790a78fd4df551a96097"",
        ""refs/tags/v0.0.21^{}"" => ""b25b4120b1ee4fc2ec4c2016268e1e42602b6a86"",
        ""refs/tags/v0.0.22"" => ""259ccc39944411d632189e4d7e009cd5d2485636"",
        ""refs/tags/v0.0.22^{}"" => ""eb95df88672e6f258ef6b759ab341f8b99dc477a"",
        ""refs/tags/v0.0.23"" => ""c0bc224f093f93d99c6e68b6b5ceedfeecf61bb9"",
        ""refs/tags/v0.0.23^{}"" => ""c81055a43f1691af59707076d78405b6d3235fea"",
        ""refs/tags/v0.0.24"" => ""463103b31c473c25e87288f564a8e73a9476777b"",
        ""refs/tags/v0.0.24^{}"" => ""d33eab687ba73b586239843dd8c3bc4267f1b358"",
        ""refs/tags/v0.0.25"" => ""79d7db0650cffe24e307dd4ba881ccbdf0011e6a"",
        ""refs/tags/v0.0.25^{}"" => ""b2c43af335e94255839aae1f2b1a97995040f389"",
        ""refs/tags/v0.0.26"" => ""e611dd73aeeef5add4bda82a00f7e9af7d17d9dd"",
        ""refs/tags/v0.0.26^{}"" => ""fae8a72f545106b2816641f5452bf7f7e99ea2a8"",
        ""refs/tags/v0.0.27"" => ""a233f65a609c07bc6e31bfc0bc051d98c8cfe18e"",
        ""refs/tags/v0.0.28"" => ""6398b5cb041d23de187f46c8888768d96b3cd01e"",
        ""refs/tags/v0.0.29"" => ""24ca84f16a4bcbf8b252eb0c4250a6c818cf00d3"",
        ""refs/tags/v0.0.3"" => ""3e6345233bb696737784f423ace943e0eaa2b30c"",
        ""refs/tags/v0.0.3^{}"" => ""b3ed1e3f15c9bcab23833dbb5ef6a8e2198ec4e2"",
        ""refs/tags/v0.0.30"" => ""c8ea7416948bdc19c1ca1b51b8897ed9201597dd"",
        ""refs/tags/v0.0.31"" => ""f754b0f027c72695cbfd37c990559bc61bf583b6"",
        ""refs/tags/v0.0.32"" => ""c2dcbda8dbe0fb614de6340b273e7bba9ab52a37"",
        ""refs/tags/v0.0.33"" => ""8411968f6359c8ae7e85b5da7e417002477263ea"",
        ""refs/tags/v0.0.34"" => ""dc887a60db904f58b558857ba7a6c39dd1d18f22"",
        ""refs/tags/v0.0.35"" => ""dd242320e5b0054c9468e4ab5cc3c4722051dd43"",
        ""refs/tags/v0.0.36"" => ""bc31c33f9b9dbaf6a2c15c118f9f8924600c6331"",
        ""refs/tags/v0.0.37"" => ""e723960dde1fa6dd1379642c80d09d2a1e5e2d16"",
        ""refs/tags/v0.0.38"" => ""e97c6ed41ae435991f2c4c1faaa0e72ad7b35c67"",
        ""refs/tags/v0.0.4"" => ""01509d00409c556c331bb278269c6ca770eb7c52"",
        ""refs/tags/v0.0.4^{}"" => ""3eb8f48d22cac58d8ba42237cb2227ef90bfce08"",
        ""refs/tags/v0.0.5"" => ""ff03e74259efab829557d0b3c15d6c76b9458262"",
        ""refs/tags/v0.0.6"" => ""20668e724eed5fffd23968793aee0592babac2ab"",
        ""refs/tags/v0.0.6^{}"" => ""641859e5e6bad88afab83a4a3e94903ed1d8e10b"",
        ""refs/tags/v0.0.7"" => ""6dedfbd21a0633055a93c05cc8b4b5cd89f2b708"",
        ""refs/tags/v0.0.8"" => ""4606f7652aba2b7e8d7c70eb0aa6cd75226f4d83"",
        ""refs/tags/v0.0.8^{}"" => ""025860fcfb6af84739a924ff49bcbda036855b1a"",
        ""refs/tags/v0.0.9"" => ""6e90dfd7573404a225888071ecaa572882b4e45c"",
        ""refs/tags/v0.0.9^{}"" => ""af4d84a6a9fa7a74acdad07fddf9f17ff3a974ae"",
        ""refs/tags/v0.1.0"" => ""dba5b92408549e55c36e16c89e2b4a4e4cbc8c8f"",
      }
    `)
  })",snuts
/__tests__/test-GitRefManager.js,ComplexSnapshots,"{'startLine':109,'endLine':175}","it('listRefs', async () => {
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    let refs = await GitRefManager.listRefs({
      fs,
      gitdir,
      filepath: 'refs/remotes/origin',
    })
    expect(refs).toMatchInlineSnapshot(`
      Array [
        ""develop"",
        ""dist"",
        ""gh-pages"",
        ""git-fetch"",
        ""greenkeeper/semantic-release-11.0.2"",
        ""master"",
        ""test-branch"",
        ""test-branch-shallow-clone"",
      ]
    `)
    refs = await GitRefManager.listRefs({
      fs,
      gitdir,
      filepath: 'refs/tags',
    })
    expect(refs).toMatchInlineSnapshot(`
      Array [
        ""local-tag"",
        ""test-tag"",
        ""v0.0.1"",
        ""v0.0.10"",
        ""v0.0.10^{}"",
        ""v0.0.11"",
        ""v0.0.11^{}"",
        ""v0.0.12"",
        ""v0.0.12^{}"",
        ""v0.0.13"",
        ""v0.0.13^{}"",
        ""v0.0.14"",
        ""v0.0.14^{}"",
        ""v0.0.15"",
        ""v0.0.15^{}"",
        ""v0.0.16"",
        ""v0.0.16^{}"",
        ""v0.0.17"",
        ""v0.0.17^{}"",
        ""v0.0.18"",
        ""v0.0.18^{}"",
        ""v0.0.19"",
        ""v0.0.19^{}"",
        ""v0.0.2"",
        ""v0.0.20"",
        ""v0.0.20^{}"",
        ""v0.0.21"",
        ""v0.0.21^{}"",
        ""v0.0.22"",
        ""v0.0.22^{}"",
        ""v0.0.23"",
        ""v0.0.23^{}"",
        ""v0.0.24"",
        ""v0.0.24^{}"",
        ""v0.0.25"",
        ""v0.0.25^{}"",
        ""v0.0.26"",
        ""v0.0.26^{}"",
        ""v0.0.27"",
        ""v0.0.28"",
        ""v0.0.29"",
        ""v0.0.3"",
        ""v0.0.3^{}"",
        ""v0.0.30"",
        ""v0.0.31"",
        ""v0.0.32"",
        ""v0.0.33"",
        ""v0.0.34"",
        ""v0.0.35"",
        ""v0.0.36"",
        ""v0.0.37"",
        ""v0.0.38"",
        ""v0.0.4"",
        ""v0.0.4^{}"",
        ""v0.0.5"",
        ""v0.0.6"",
        ""v0.0.6^{}"",
        ""v0.0.7"",
        ""v0.0.8"",
        ""v0.0.8^{}"",
        ""v0.0.9"",
        ""v0.0.9^{}"",
        ""v0.1.0"",
      ]
    `)
  })",snuts
/__tests__/test-GitRefManager.js,ConditionalTestLogic,"{'startLine':266,'endLine':270}","it('concurrently reading/writing a ref should not cause a NotFoundError resolving it', async () => {
    // There are some expect() calls below, but as of 2023-03-15, if this test fails it will do so by logging instances
    // of 'NotFoundError: Could not find myRef', which should not happen.
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    const ref = 'myRef'
    const value = '1234567890123456789012345678901234567890'
    await GitRefManager.writeRef({ fs, gitdir, ref, value }) // Guarantee that the file for the ref exists on disk

    const writePromises = []
    const resolvePromises = []
    // Some arbitrary number of iterations that seems to guarantee that the error (pre-fix) is hit.
    // With 100 the test *mostly* failed but still passed every now and then.
    const iterations = 500

    for (let i = 0; i < iterations; i++) {
      // I was only able to cause the error to reproduce consistently by mixing awaited and non-awaited versions of the
      // calls to writeRef() and resolve(). I tried several variations of the combination but none of them caused the
      // error to happen as consistently.
      if (Math.random() < 0.5) {
        await GitRefManager.writeRef({ fs, gitdir, ref, value })
      } else {
        writePromises.push(GitRefManager.writeRef({ fs, gitdir, ref, value }))
      }
      if (Math.random() < 0.5) {
        const resolvedRef = await GitRefManager.resolve({ fs, gitdir, ref })
        expect(resolvedRef).toMatch(value)
      } else {
        resolvePromises.push(GitRefManager.resolve({ fs, gitdir, ref }))
      }
    }

    const resolvedRefs = await Promise.all(resolvePromises)
    for (const resolvedRef of resolvedRefs) {
      expect(resolvedRef).toMatch(value)
    }
    await Promise.all(writePromises)
  })",snuts
/__tests__/test-GitRefManager.js,ConditionalTestLogic,"{'startLine':271,'endLine':276}","it('concurrently reading/writing a ref should not cause a NotFoundError resolving it', async () => {
    // There are some expect() calls below, but as of 2023-03-15, if this test fails it will do so by logging instances
    // of 'NotFoundError: Could not find myRef', which should not happen.
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    const ref = 'myRef'
    const value = '1234567890123456789012345678901234567890'
    await GitRefManager.writeRef({ fs, gitdir, ref, value }) // Guarantee that the file for the ref exists on disk

    const writePromises = []
    const resolvePromises = []
    // Some arbitrary number of iterations that seems to guarantee that the error (pre-fix) is hit.
    // With 100 the test *mostly* failed but still passed every now and then.
    const iterations = 500

    for (let i = 0; i < iterations; i++) {
      // I was only able to cause the error to reproduce consistently by mixing awaited and non-awaited versions of the
      // calls to writeRef() and resolve(). I tried several variations of the combination but none of them caused the
      // error to happen as consistently.
      if (Math.random() < 0.5) {
        await GitRefManager.writeRef({ fs, gitdir, ref, value })
      } else {
        writePromises.push(GitRefManager.writeRef({ fs, gitdir, ref, value }))
      }
      if (Math.random() < 0.5) {
        const resolvedRef = await GitRefManager.resolve({ fs, gitdir, ref })
        expect(resolvedRef).toMatch(value)
      } else {
        resolvePromises.push(GitRefManager.resolve({ fs, gitdir, ref }))
      }
    }

    const resolvedRefs = await Promise.all(resolvePromises)
    for (const resolvedRef of resolvedRefs) {
      expect(resolvedRef).toMatch(value)
    }
    await Promise.all(writePromises)
  })",snuts
/__tests__/test-GitPktLine.js,AnonymousTest,"{'startLine':68,'endLine':74}","it('encode string', async () => {
    const foo = GitPktLine.encode('hello world\n')
    expect(foo).toBeTruthy()
    expect(Buffer.compare(foo, Buffer.from('0010hello world\n')) === 0).toBe(
      true
    )
  })",snuts
/__tests__/test-GitPktLine.js,AnonymousTest,"{'startLine':113,'endLine':117}","it('encode flush', async () => {
    const foo = GitPktLine.flush()
    expect(foo).toBeTruthy()
    expect(Buffer.compare(foo, Buffer.from('0000')) === 0).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SensitiveEquality,"{'startLine':9,'endLine':9}","it('read stream - simple', async () => {
    const stream = [Buffer.from('0010hello world\n')]
    const read = GitPktLine.streamReader(stream)
    expect(typeof read === 'function').toBe(true)
    expect((await read()).toString('utf8') === 'hello world\n').toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SensitiveEquality,"{'startLine':29,'endLine':29}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SensitiveEquality,"{'startLine':33,'endLine':34}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SensitiveEquality,"{'startLine':37,'endLine':38}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SensitiveEquality,"{'startLine':41,'endLine':42}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SensitiveEquality,"{'startLine':45,'endLine':46}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SensitiveEquality,"{'startLine':49,'endLine':50}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SensitiveEquality,"{'startLine':53,'endLine':54}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SensitiveEquality,"{'startLine':57,'endLine':58}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SensitiveEquality,"{'startLine':61,'endLine':62}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,ConditionalTestLogic,"{'startLine':87,'endLine':90}","it('read stream - with error', async () => {
    const hookStream = (subject, fn) => {
      const unhook = function(write) {
        this.write = write
      }.bind(subject, subject.write)
      subject.write = fn
      return unhook
    }
    let unhook
    try {
      const output = []
      if (!process.browser) {
        const onLog = chunk => output.push(chunk) && undefined
        unhook = hookStream(process.stdout, onLog)
      }
      let err
      const stream = {
        next() {
          throw (err = new Error('something went wrong'))
        },
      }
      const read = GitPktLine.streamReader(stream)
      const line = await read()
      expect(output.length === 0).toBe(true)
      expect(line).toBe(true)
      expect(stream.error === err).toBe(true)
    } finally {
      if (unhook) unhook()
    }
  })",snuts
/__tests__/test-GitPktLine.js,ConditionalTestLogic,"{'startLine':103,'endLine':103}","it('read stream - with error', async () => {
    const hookStream = (subject, fn) => {
      const unhook = function(write) {
        this.write = write
      }.bind(subject, subject.write)
      subject.write = fn
      return unhook
    }
    let unhook
    try {
      const output = []
      if (!process.browser) {
        const onLog = chunk => output.push(chunk) && undefined
        unhook = hookStream(process.stdout, onLog)
      }
      let err
      const stream = {
        next() {
          throw (err = new Error('something went wrong'))
        },
      }
      const read = GitPktLine.streamReader(stream)
      const line = await read()
      expect(output.length === 0).toBe(true)
      expect(line).toBe(true)
      expect(stream.error === err).toBe(true)
    } finally {
      if (unhook) unhook()
    }
  })",snuts
/__tests__/test-GitPktLine.js,SubOptimalAssert,"{'startLine':8,'endLine':8}","it('read stream - simple', async () => {
    const stream = [Buffer.from('0010hello world\n')]
    const read = GitPktLine.streamReader(stream)
    expect(typeof read === 'function').toBe(true)
    expect((await read()).toString('utf8') === 'hello world\n').toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SubOptimalAssert,"{'startLine':9,'endLine':9}","it('read stream - simple', async () => {
    const stream = [Buffer.from('0010hello world\n')]
    const read = GitPktLine.streamReader(stream)
    expect(typeof read === 'function').toBe(true)
    expect((await read()).toString('utf8') === 'hello world\n').toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SubOptimalAssert,"{'startLine':28,'endLine':30}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SubOptimalAssert,"{'startLine':31,'endLine':31}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SubOptimalAssert,"{'startLine':32,'endLine':35}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SubOptimalAssert,"{'startLine':36,'endLine':39}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SubOptimalAssert,"{'startLine':40,'endLine':43}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SubOptimalAssert,"{'startLine':44,'endLine':47}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SubOptimalAssert,"{'startLine':48,'endLine':51}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SubOptimalAssert,"{'startLine':52,'endLine':55}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SubOptimalAssert,"{'startLine':56,'endLine':59}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SubOptimalAssert,"{'startLine':60,'endLine':63}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SubOptimalAssert,"{'startLine':64,'endLine':64}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SubOptimalAssert,"{'startLine':71,'endLine':71}","it('encode string', async () => {
    const foo = GitPktLine.encode('hello world\n')
    expect(foo).toBeTruthy()
    expect(Buffer.compare(foo, Buffer.from('0010hello world\n')) === 0).toBe(
      true
    )
  })",snuts
/__tests__/test-GitPktLine.js,SubOptimalAssert,"{'startLine':99,'endLine':99}","it('read stream - with error', async () => {
    const hookStream = (subject, fn) => {
      const unhook = function(write) {
        this.write = write
      }.bind(subject, subject.write)
      subject.write = fn
      return unhook
    }
    let unhook
    try {
      const output = []
      if (!process.browser) {
        const onLog = chunk => output.push(chunk) && undefined
        unhook = hookStream(process.stdout, onLog)
      }
      let err
      const stream = {
        next() {
          throw (err = new Error('something went wrong'))
        },
      }
      const read = GitPktLine.streamReader(stream)
      const line = await read()
      expect(output.length === 0).toBe(true)
      expect(line).toBe(true)
      expect(stream.error === err).toBe(true)
    } finally {
      if (unhook) unhook()
    }
  })",snuts
/__tests__/test-GitPktLine.js,SubOptimalAssert,"{'startLine':101,'endLine':101}","it('read stream - with error', async () => {
    const hookStream = (subject, fn) => {
      const unhook = function(write) {
        this.write = write
      }.bind(subject, subject.write)
      subject.write = fn
      return unhook
    }
    let unhook
    try {
      const output = []
      if (!process.browser) {
        const onLog = chunk => output.push(chunk) && undefined
        unhook = hookStream(process.stdout, onLog)
      }
      let err
      const stream = {
        next() {
          throw (err = new Error('something went wrong'))
        },
      }
      const read = GitPktLine.streamReader(stream)
      const line = await read()
      expect(output.length === 0).toBe(true)
      expect(line).toBe(true)
      expect(stream.error === err).toBe(true)
    } finally {
      if (unhook) unhook()
    }
  })",snuts
/__tests__/test-GitPktLine.js,SubOptimalAssert,"{'startLine':110,'endLine':110}","it('encode empty string', async () => {
    const foo = GitPktLine.encode('')
    expect(foo).toBeTruthy()
    expect(Buffer.compare(foo, Buffer.from('0004')) === 0).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,SubOptimalAssert,"{'startLine':116,'endLine':116}","it('encode flush', async () => {
    const foo = GitPktLine.flush()
    expect(foo).toBeTruthy()
    expect(Buffer.compare(foo, Buffer.from('0000')) === 0).toBe(true)
  })",snuts
/__tests__/test-GitPktLine.js,VerboseStatement,"{'startLine':13,'endLine':66}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",snuts
/__tests__/test-GitPackIndex.js,AnonymousTest,"{'startLine':13,'endLine':42}","it('from .idx', async () => {
    const { fs, gitdir } = await makeFixture('test-GitPackIndex')
    const idx = await fs.read(
      path.join(
        gitdir,
        'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.idx'
      )
    )
    const p = await GitPackIndex.fromIdx({ idx })
    expect(
      await shasum(Buffer.from(JSON.stringify(p.hashes)))
    ).toMatchInlineSnapshot('""fd2404a29d1e5dc72066541366d5f75bc9d51c9b""')
    expect(p.packfileSha).toBe('1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888')
    // Test a handful of known offsets.
    expect(p.offsets.get('0b8faa11b353db846b40eb064dfb299816542a46')).toEqual(
      40077
    )
    expect(p.offsets.get('637c4e69d85e0dcc18898ec251377453d0891585')).toEqual(
      39860
    )
    expect(p.offsets.get('98e9fde3ee878fa985a143fc5fe05d4e6d8e637b')).toEqual(
      39036
    )
    expect(p.offsets.get('43c49edb213748626fc363c890c01a9e55a1b8da')).toEqual(
      38202
    )
    expect(p.offsets.get('5f1f014326b1d7e8079d00b87fa7a9913bd91324')).toEqual(
      20855
    )
  })",snuts
/__tests__/test-GitPackIndex.js,AnonymousTest,"{'startLine':43,'endLine':72}","it('from .pack', async () => {
    const { fs, gitdir } = await makeFixture('test-GitPackIndex')
    const pack = await fs.read(
      path.join(
        gitdir,
        'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
      )
    )
    const p = await GitPackIndex.fromPack({ pack })
    expect(
      await shasum(Buffer.from(JSON.stringify(p.hashes)))
    ).toMatchInlineSnapshot('""fd2404a29d1e5dc72066541366d5f75bc9d51c9b""')
    expect(p.packfileSha).toBe('1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888')
    // Test a handful of known offsets.
    expect(p.offsets.get('0b8faa11b353db846b40eb064dfb299816542a46')).toEqual(
      40077
    )
    expect(p.offsets.get('637c4e69d85e0dcc18898ec251377453d0891585')).toEqual(
      39860
    )
    expect(p.offsets.get('98e9fde3ee878fa985a143fc5fe05d4e6d8e637b')).toEqual(
      39036
    )
    expect(p.offsets.get('43c49edb213748626fc363c890c01a9e55a1b8da')).toEqual(
      38202
    )
    expect(p.offsets.get('5f1f014326b1d7e8079d00b87fa7a9913bd91324')).toEqual(
      20855
    )
  })",snuts
/__tests__/test-GitIndex.js,AnonymousTest,"{'startLine':22,'endLine':63}","it('GitIndex.from(buffer)', async () => {
    const { fs, dir } = await makeFixture('test-GitIndex')
    const buffer = await fs.read(path.join(dir, 'index'))
    const index = await GitIndex.from(buffer)
    const rendering = index.render()
    expect(rendering).toMatchInlineSnapshot(`
      ""100644 1db939d41956405f755e69ab570296c7ed3cec99    .babelrc
      100644 bbf3e21f43fa4fe25eb925bfcb7c0434f7c2dc7d    .editorconfig
      100644 4a58bdcdef3eb91264dfca0279959d98c16568d5    .flowconfig
      100644 48447164fc125691a3e77899190fcb8ab296b20a    .gitignore
      100644 47967151a5ff9366ca5d86e261c9ceb835d7b722    .travis.yml
      100644 c675a17ccb1578bca836decf90205fdad743827d    LICENSE.md
      100644 f5825f0700bc629db62fc2a2a3cc401095c38011    README.md
      100644 2856b7159ac064d8855da2089f342a785db99aec    package-lock.json
      100644 9784b15bb0d4610b633e1ebb7a6529e900ed1da0    package.json
      100644 6e9d67f2a308ca3d580b78c9f5894dde12fe981d    shrinkwrap.yaml
      100644 3a75c9b6600114dd88ff47bfd4c5e1f8f76be6db    src/commands/checkout.js
      100644 e69de29bb2d1d6434b8b29ae775ad8c2e48c5391    src/commands/config.js
      100644 5121e993645da48c428acfdd1970fbfe8bb9a6cc    src/commands/fetch.js
      100644 b439f8a7e95cd1c180238b1f2d1593ee329448ee    src/commands/init.js
      100644 ba6641a796752918bdfa2d3d1da8ccb5ec424b6c    src/index.js
      100644 cd2d01a0fe75d9e736ca623d124082225c97ec62    src/models/GitBlob.js
      100644 f598792ec4380d544ee0f7504e1a30d0ed0abebc    src/models/GitCommit.js
      100644 8657d296d07b4d76302519ac608752397c38cd39    src/models/GitConfig.js
      100644 1104999fec32f7a906cc64cb85c4de23daef7746    src/models/GitObject.js
      100644 467b38e29857cfc863a7be480ca739ef1edd553b    src/models/GitTree.js
      100644 4187b0591eb99fe023a5ead08af217901b938d72    src/utils/exists.js
      100644 1dbbf594d09fbc0fe257a0ed2fecca95b65bebe9    src/utils/mkdirs.js
      100644 b3f16d527a5d80b8893da03e1bf397689ebc06c3    src/utils/read.js
      100644 333191f116d625ba492527ce790fcabe12af33e5    src/utils/resolveRef.js
      100644 38f2a3e9a690581e249b789f2fbed5975d0b11e8    src/utils/write.js
      100644 72ed82e1d1ddb86e6577c80b8a4dfeb4f99c1975    test/_helpers.js
      100644 af8ac5cdb1dfe9415d75e08238c7f820d417fdee    test/snapshots/test-resolveRef.js.md
      100644 d0c8afd043a8887396f949240564fb3bc2a23798    test/snapshots/test-resolveRef.js.snap
      100644 7cc6aba8971d86ec3d306e80e3848b4fd8414ee3    test/test-clone.js
      100644 93f0002a2c0d2156aa15df908a984b2b2144b877    test/test-config.js
      100644 5345ffa5937c2591f96f4213934709b229a48b02    test/test-init.js
      100644 80708a513b7808becff0acfd70dbd3b66a4fb537    test/test-resolveRef.js""
    `)
    const buffer2 = await index.toObject()
    expect(buffer.slice(0, buffer2.length - 20)).toEqual(buffer2.slice(0, -20))
  })",snuts
/__tests__/test-GitIndex.js,SubOptimalAssert,"{'startLine':80,'endLine':80}","it('write unmerged index to disk and read it back', async () => {
    const { gitdir, fs } = await makeFixture('test-GitIndex')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(0)
      expect(index.entriesFlat.length).toBe(0)
      index.insert({ filepath: 'a', oid: '01', stage: 1 })
      index.insert({ filepath: 'a', oid: '10', stage: 2 })
      index.insert({ filepath: 'a', oid: '11', stage: 3 })
      expect(index.unmergedPaths).toContain('a')
    })
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(1)
      expect(index.entriesFlat.length).toBe(3)
      expect(index.unmergedPaths).toContain('a')

      const entryA = index.entriesMap.get('a')

      expect(entryA.stages.length).toBe(4)
      expect(entryA.stages[1]).toBe(index.entriesFlat[0])
      expect(entryA.stages[2]).toBe(index.entriesFlat[1])
      expect(entryA.stages[3]).toBe(index.entriesFlat[2])
    })
  })",snuts
/__tests__/test-GitIndex.js,SubOptimalAssert,"{'startLine':81,'endLine':81}","it('write unmerged index to disk and read it back', async () => {
    const { gitdir, fs } = await makeFixture('test-GitIndex')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(0)
      expect(index.entriesFlat.length).toBe(0)
      index.insert({ filepath: 'a', oid: '01', stage: 1 })
      index.insert({ filepath: 'a', oid: '10', stage: 2 })
      index.insert({ filepath: 'a', oid: '11', stage: 3 })
      expect(index.unmergedPaths).toContain('a')
    })
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(1)
      expect(index.entriesFlat.length).toBe(3)
      expect(index.unmergedPaths).toContain('a')

      const entryA = index.entriesMap.get('a')

      expect(entryA.stages.length).toBe(4)
      expect(entryA.stages[1]).toBe(index.entriesFlat[0])
      expect(entryA.stages[2]).toBe(index.entriesFlat[1])
      expect(entryA.stages[3]).toBe(index.entriesFlat[2])
    })
  })",snuts
/__tests__/test-GitIndex.js,SubOptimalAssert,"{'startLine':90,'endLine':90}","it('write unmerged index to disk and read it back', async () => {
    const { gitdir, fs } = await makeFixture('test-GitIndex')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(0)
      expect(index.entriesFlat.length).toBe(0)
      index.insert({ filepath: 'a', oid: '01', stage: 1 })
      index.insert({ filepath: 'a', oid: '10', stage: 2 })
      index.insert({ filepath: 'a', oid: '11', stage: 3 })
      expect(index.unmergedPaths).toContain('a')
    })
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(1)
      expect(index.entriesFlat.length).toBe(3)
      expect(index.unmergedPaths).toContain('a')

      const entryA = index.entriesMap.get('a')

      expect(entryA.stages.length).toBe(4)
      expect(entryA.stages[1]).toBe(index.entriesFlat[0])
      expect(entryA.stages[2]).toBe(index.entriesFlat[1])
      expect(entryA.stages[3]).toBe(index.entriesFlat[2])
    })
  })",snuts
/__tests__/test-GitIndex.js,SubOptimalAssert,"{'startLine':91,'endLine':91}","it('write unmerged index to disk and read it back', async () => {
    const { gitdir, fs } = await makeFixture('test-GitIndex')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(0)
      expect(index.entriesFlat.length).toBe(0)
      index.insert({ filepath: 'a', oid: '01', stage: 1 })
      index.insert({ filepath: 'a', oid: '10', stage: 2 })
      index.insert({ filepath: 'a', oid: '11', stage: 3 })
      expect(index.unmergedPaths).toContain('a')
    })
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(1)
      expect(index.entriesFlat.length).toBe(3)
      expect(index.unmergedPaths).toContain('a')

      const entryA = index.entriesMap.get('a')

      expect(entryA.stages.length).toBe(4)
      expect(entryA.stages[1]).toBe(index.entriesFlat[0])
      expect(entryA.stages[2]).toBe(index.entriesFlat[1])
      expect(entryA.stages[3]).toBe(index.entriesFlat[2])
    })
  })",snuts
/__tests__/test-GitIndex.js,SubOptimalAssert,"{'startLine':96,'endLine':96}","it('write unmerged index to disk and read it back', async () => {
    const { gitdir, fs } = await makeFixture('test-GitIndex')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(0)
      expect(index.entriesFlat.length).toBe(0)
      index.insert({ filepath: 'a', oid: '01', stage: 1 })
      index.insert({ filepath: 'a', oid: '10', stage: 2 })
      index.insert({ filepath: 'a', oid: '11', stage: 3 })
      expect(index.unmergedPaths).toContain('a')
    })
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(1)
      expect(index.entriesFlat.length).toBe(3)
      expect(index.unmergedPaths).toContain('a')

      const entryA = index.entriesMap.get('a')

      expect(entryA.stages.length).toBe(4)
      expect(entryA.stages[1]).toBe(index.entriesFlat[0])
      expect(entryA.stages[2]).toBe(index.entriesFlat[1])
      expect(entryA.stages[3]).toBe(index.entriesFlat[2])
    })
  })",snuts
/__tests__/test-GitIndex.js,SubOptimalAssert,"{'startLine':112,'endLine':112}","it('read existing unmerged index', async () => {
    // Setup
    const { gitdir, fs } = await makeFixture('test-GitIndex-unmerged')

    // Test
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
    })
  })",snuts
/__tests__/test-GitIndex.js,SubOptimalAssert,"{'startLine':115,'endLine':115}","it('read existing unmerged index', async () => {
    // Setup
    const { gitdir, fs } = await makeFixture('test-GitIndex-unmerged')

    // Test
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
    })
  })",snuts
/__tests__/test-GitIndex.js,SubOptimalAssert,"{'startLine':116,'endLine':116}","it('read existing unmerged index', async () => {
    // Setup
    const { gitdir, fs } = await makeFixture('test-GitIndex-unmerged')

    // Test
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
    })
  })",snuts
/__tests__/test-GitIndex.js,SubOptimalAssert,"{'startLine':117,'endLine':117}","it('read existing unmerged index', async () => {
    // Setup
    const { gitdir, fs } = await makeFixture('test-GitIndex-unmerged')

    // Test
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
    })
  })",snuts
/__tests__/test-GitError.js,SubOptimalAssert,"{'startLine':21,'endLine':21}","it('create a NotFoundError', async () => {
    let e = null
    try {
      throw new Errors.NotFoundError('foobar.txt')
    } catch (err) {
      e = err
    }
    expect(e).not.toBeNull()
    expect(e.code).toBe('NotFoundError')
    expect(e instanceof Error).toBe(true)
    expect(e instanceof Errors.NotFoundError).toBe(true)
    e = e.toJSON()
    delete e.stack
    expect(e).toMatchInlineSnapshot(`
      Object {
        ""caller"": """",
        ""code"": ""NotFoundError"",
        ""data"": Object {
          ""what"": ""foobar.txt"",
        },
        ""message"": ""Could not find foobar.txt."",
      }
    `)
  })",snuts
/__tests__/test-GitError.js,SubOptimalAssert,"{'startLine':22,'endLine':22}","it('create a NotFoundError', async () => {
    let e = null
    try {
      throw new Errors.NotFoundError('foobar.txt')
    } catch (err) {
      e = err
    }
    expect(e).not.toBeNull()
    expect(e.code).toBe('NotFoundError')
    expect(e instanceof Error).toBe(true)
    expect(e instanceof Errors.NotFoundError).toBe(true)
    e = e.toJSON()
    delete e.stack
    expect(e).toMatchInlineSnapshot(`
      Object {
        ""caller"": """",
        ""code"": ""NotFoundError"",
        ""data"": Object {
          ""what"": ""foobar.txt"",
        },
        ""message"": ""Could not find foobar.txt."",
      }
    `)
  })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':6,'endLine':13}","it('simple (foo)', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = valfoo
      [bar]
      keyaaa = valbar`)
      const a = await config.get('foo.keyaaa')
      expect(a).toEqual('valfoo')
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':15,'endLine':22}","it('simple (bar)', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = valfoo
      [bar]
      keyaaa = valbar`)
      const a = await config.get('bar.keyaaa')
      expect(a).toEqual('valbar')
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':65,'endLine':72}","it('multiple', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = valaaa
      keybbb = valbbb
      keybbb = valBBB`)
      const a = await config.getall('foo.keybbb')
      expect(a).toEqual(['valbbb', 'valBBB'])
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':85,'endLine':92}","it('subsection', async () => {
      const config = GitConfig.from(`[remote ""foo""]
      url = https://foo.com/project.git
      [remote ""bar""]
      url = https://bar.com/project.git`)
      const a = await config.get('remote.bar.url')
      expect(a).toEqual('https://bar.com/project.git')
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':144,'endLine':149}","it('simple', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = ""valaaa""`)
      const a = await config.get('foo.keyaaa')
      expect(a).toEqual('valaaa')
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':151,'endLine':156}","it('escaped', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = \\""valaaa`)
      const a = await config.get('foo.keyaaa')
      expect(a).toEqual('""valaaa')
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':158,'endLine':166}","it('multiple', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = ""val"" aaa
      keybbb = val ""a"" a""a""`)
      const a = await config.get('foo.keyaaa')
      expect(a).toEqual('val aaa')
      const b = await config.get('foo.keybbb')
      expect(b).toEqual('val a aa')
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':205,'endLine':228}","it('using schema', async () => {
      const config = GitConfig.from(`[core]
      repositoryformatversion = 0
      filemode = true
      bare = false
      logallrefupdates = true
      symlinks = false
      ignorecase = true
      bigFileThreshold = 2`)
      const a = await config.get('core.repositoryformatversion')
      const b = await config.get('core.filemode')
      const c = await config.get('core.bare')
      const d = await config.get('core.logallrefupdates')
      const e = await config.get('core.symlinks')
      const f = await config.get('core.ignorecase')
      const g = await config.get('core.bigFileThreshold')
      expect(a).toEqual('0')
      expect(b).toEqual(true)
      expect(c).toEqual(false)
      expect(d).toEqual(true)
      expect(e).toEqual(false)
      expect(f).toEqual(true)
      expect(g).toEqual(2)
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':230,'endLine':244}","it('special boolean', async () => {
      const config = GitConfig.from(`[core]
      filemode = off
      bare = on
      logallrefupdates = no
      symlinks = true`)
      const a = await config.get('core.filemode')
      const b = await config.get('core.bare')
      const c = await config.get('core.logallrefupdates')
      const d = await config.get('core.symlinks')
      expect(a).toEqual(false)
      expect(b).toEqual(true)
      expect(c).toEqual(false)
      expect(d).toEqual(true)
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':246,'endLine':259}","it('numeric suffix', async () => {
      const configA = GitConfig.from(`[core]
      bigFileThreshold = 2k`)
      const configB = GitConfig.from(`[core]
      bigFileThreshold = 2m`)
      const configC = GitConfig.from(`[core]
      bigFileThreshold = 2g`)
      const a = await configA.get('core.bigFileThreshold')
      const b = await configB.get('core.bigFileThreshold')
      const c = await configC.get('core.bigFileThreshold')
      expect(a).toEqual(2048)
      expect(b).toEqual(2097152)
      expect(c).toEqual(2147483648)
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':263,'endLine':270}","it('existing section', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = valaaa`)
      await config.set('foo.keybbb', 'valbbb')
      expect(config.toString()).toEqual(`[foo]
\tkeybbb = valbbb
      keyaaa = valaaa`)
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':281,'endLine':288}","it('existing subsection', async () => {
      const config = GitConfig.from(`[remote ""foo""]
      url = https://foo.com/project.git`)
      await config.set('remote.foo.fetch', 'foo')
      expect(config.toString()).toEqual(`[remote ""foo""]
\tfetch = foo
      url = https://foo.com/project.git`)
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':307,'endLine':315}","it('new section', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = valaaa`)
      await config.set('bar.keyaaa', 'valaaa')
      expect(config.toString()).toEqual(`[foo]
      keyaaa = valaaa
[bar]
\tkeyaaa = valaaa`)
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':317,'endLine':325}","it('new subsection', async () => {
      const config = GitConfig.from(`[remote ""foo""]
      url = https://foo.com/project.git`)
      await config.set('remote.bar.url', 'https://bar.com/project.git')
      expect(config.toString()).toEqual(`[remote ""foo""]
      url = https://foo.com/project.git
[remote ""bar""]
\turl = https://bar.com/project.git`)
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':357,'endLine':369}","it('simple', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = valfoo
      [bar]
      keyaaa = valbar
      keybbb = valbbb`)
      await config.set('bar.keyaaa', 'newvalbar')
      expect(config.toString()).toEqual(`[foo]
      keyaaa = valfoo
      [bar]
\tkeyaaa = newvalbar
      keybbb = valbbb`)
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':411,'endLine':421}","it('subsection', async () => {
      const config = GitConfig.from(`[remote ""foo""]
      url = https://foo.com/project.git
      [remote ""bar""]
      url = https://bar.com/project.git`)
      await config.set('remote.foo.url', 'https://foo.com/project-foo.git')
      expect(config.toString()).toEqual(`[remote ""foo""]
\turl = https://foo.com/project-foo.git
      [remote ""bar""]
      url = https://bar.com/project.git`)
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':425,'endLine':438}","it('simple', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = valfoo
      [bar]
      keyaaa = valbar
      keybbb = valbbb`)
      await config.append('bar.keyaaa', 'newvalbar')
      expect(config.toString()).toEqual(`[foo]
      keyaaa = valfoo
      [bar]
      keyaaa = valbar
\tkeyaaa = newvalbar
      keybbb = valbbb`)
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':455,'endLine':467}","it('subsection', async () => {
      const config = GitConfig.from(`[remote ""foo""]
      url = https://foo.com/project.git
      [remote ""bar""]
      url = https://bar.com/project.git`)
      await config.append('remote.baz.url', 'https://baz.com/project.git')
      expect(config.toString()).toEqual(`[remote ""foo""]
      url = https://foo.com/project.git
      [remote ""bar""]
      url = https://bar.com/project.git
[remote ""baz""]
\turl = https://baz.com/project.git`)
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':471,'endLine':478}","it('simple', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = valaaa
      keybbb = valbbb`)
      await config.set('foo.keyaaa')
      expect(config.toString()).toEqual(`[foo]
      keybbb = valbbb`)
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':498,'endLine':507}","it('subsection', async () => {
      const config = GitConfig.from(`[remote ""foo""]
      url = https://foo.com/project.git
      [remote ""bar""]
      url = https://bar.com/project.git`)
      await config.set('remote.foo.url')
      expect(config.toString()).toEqual(`[remote ""foo""]
      [remote ""bar""]
      url = https://bar.com/project.git`)
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':587,'endLine':601}","it('simple', async () => {
      const config = GitConfig.from(`[one]
      keyaaa = valaaa
          
      [remote ""foo""]
      url = https://foo.com/project.git

      [remote ""bar""]
      url = https://bar.com/project.git
            
      [two]
      keyaaa = valaaa`)
      const subsections = await config.getSubsections('remote')
      expect(subsections).toEqual(['foo', 'bar'])
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':605,'endLine':613}","it('simple', async () => {
      const config = GitConfig.from(`[one]
      keyaaa = valaaa
[two]
      keybbb = valbbb`)
      await config.deleteSection('one')
      expect(config.toString()).toEqual(`[two]
      keybbb = valbbb`)
    })",snuts
/__tests__/test-GitConfig.js,AnonymousTest,"{'startLine':615,'endLine':631}","it('subsection', async () => {
      const config = GitConfig.from(`[one]
      keyaaa = valaaa
      
      [remote ""foo""]
      url = https://foo.com/project.git
      ; this is a comment
      
      [remote ""bar""]
      url = https://bar.com/project.git`)
      await config.deleteSection('remote', 'foo')
      expect(config.toString()).toEqual(`[one]
      keyaaa = valaaa
      
      [remote ""bar""]
      url = https://bar.com/project.git`)
    })",snuts
/__tests__/test-GitConfig.js,IdenticalTestDescription,"{'startLine':158,'endLine':166}","it('multiple', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = ""val"" aaa
      keybbb = val ""a"" a""a""`)
      const a = await config.get('foo.keyaaa')
      expect(a).toEqual('val aaa')
      const b = await config.get('foo.keybbb')
      expect(b).toEqual('val a aa')
    })",snuts
/__tests__/test-GitConfig.js,IdenticalTestDescription,"{'startLine':357,'endLine':369}","it('simple', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = valfoo
      [bar]
      keyaaa = valbar
      keybbb = valbbb`)
      await config.set('bar.keyaaa', 'newvalbar')
      expect(config.toString()).toEqual(`[foo]
      keyaaa = valfoo
      [bar]
\tkeyaaa = newvalbar
      keybbb = valbbb`)
    })",snuts
/__tests__/test-GitConfig.js,IdenticalTestDescription,"{'startLine':399,'endLine':409}","it('last (when several)', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = valaaa
      keybbb = valbbb
      keybbb = valBBB`)
      await config.set('foo.keybbb', 'newvalBBB')
      expect(config.toString()).toEqual(`[foo]
      keyaaa = valaaa
      keybbb = valbbb
\tkeybbb = newvalBBB`)
    })",snuts
/__tests__/test-GitConfig.js,IdenticalTestDescription,"{'startLine':411,'endLine':421}","it('subsection', async () => {
      const config = GitConfig.from(`[remote ""foo""]
      url = https://foo.com/project.git
      [remote ""bar""]
      url = https://bar.com/project.git`)
      await config.set('remote.foo.url', 'https://foo.com/project-foo.git')
      expect(config.toString()).toEqual(`[remote ""foo""]
\turl = https://foo.com/project-foo.git
      [remote ""bar""]
      url = https://bar.com/project.git`)
    })",snuts
/__tests__/test-GitConfig.js,IdenticalTestDescription,"{'startLine':425,'endLine':438}","it('simple', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = valfoo
      [bar]
      keyaaa = valbar
      keybbb = valbbb`)
      await config.append('bar.keyaaa', 'newvalbar')
      expect(config.toString()).toEqual(`[foo]
      keyaaa = valfoo
      [bar]
      keyaaa = valbar
\tkeyaaa = newvalbar
      keybbb = valbbb`)
    })",snuts
/__tests__/test-GitConfig.js,IdenticalTestDescription,"{'startLine':440,'endLine':453}","it('simple (case insensitive)', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = valfoo
      [bar]
      keyaaa = valbar
      keybbb = valbbb`)
      await config.append('bar.KEYAAA', 'newvalbar')
      expect(config.toString()).toEqual(`[foo]
      keyaaa = valfoo
      [bar]
      keyaaa = valbar
\tKEYAAA = newvalbar
      keybbb = valbbb`)
    })",snuts
/__tests__/test-GitConfig.js,IdenticalTestDescription,"{'startLine':455,'endLine':467}","it('subsection', async () => {
      const config = GitConfig.from(`[remote ""foo""]
      url = https://foo.com/project.git
      [remote ""bar""]
      url = https://bar.com/project.git`)
      await config.append('remote.baz.url', 'https://baz.com/project.git')
      expect(config.toString()).toEqual(`[remote ""foo""]
      url = https://foo.com/project.git
      [remote ""bar""]
      url = https://bar.com/project.git
[remote ""baz""]
\turl = https://baz.com/project.git`)
    })",snuts
/__tests__/test-GitConfig.js,IdenticalTestDescription,"{'startLine':471,'endLine':478}","it('simple', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = valaaa
      keybbb = valbbb`)
      await config.set('foo.keyaaa')
      expect(config.toString()).toEqual(`[foo]
      keybbb = valbbb`)
    })",snuts
/__tests__/test-GitConfig.js,IdenticalTestDescription,"{'startLine':480,'endLine':487}","it('simple (case insensitive)', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = valaaa
      keybbb = valbbb`)
      await config.set('FOO.keyaaa')
      expect(config.toString()).toEqual(`[foo]
      keybbb = valbbb`)
    })",snuts
/__tests__/test-GitConfig.js,IdenticalTestDescription,"{'startLine':489,'endLine':496}","it('last (when several)', async () => {
      const config = GitConfig.from(`[foo]
      keyaaa = valone
      keyaaa = valtwo`)
      await config.set('foo.keyaaa')
      expect(config.toString()).toEqual(`[foo]
      keyaaa = valone`)
    })",snuts
/__tests__/test-GitConfig.js,IdenticalTestDescription,"{'startLine':498,'endLine':507}","it('subsection', async () => {
      const config = GitConfig.from(`[remote ""foo""]
      url = https://foo.com/project.git
      [remote ""bar""]
      url = https://bar.com/project.git`)
      await config.set('remote.foo.url')
      expect(config.toString()).toEqual(`[remote ""foo""]
      [remote ""bar""]
      url = https://bar.com/project.git`)
    })",snuts
/__tests__/test-GitConfig.js,IdenticalTestDescription,"{'startLine':587,'endLine':601}","it('simple', async () => {
      const config = GitConfig.from(`[one]
      keyaaa = valaaa
          
      [remote ""foo""]
      url = https://foo.com/project.git

      [remote ""bar""]
      url = https://bar.com/project.git
            
      [two]
      keyaaa = valaaa`)
      const subsections = await config.getSubsections('remote')
      expect(subsections).toEqual(['foo', 'bar'])
    })",snuts
/__tests__/test-GitConfig.js,IdenticalTestDescription,"{'startLine':605,'endLine':613}","it('simple', async () => {
      const config = GitConfig.from(`[one]
      keyaaa = valaaa
[two]
      keybbb = valbbb`)
      await config.deleteSection('one')
      expect(config.toString()).toEqual(`[two]
      keybbb = valbbb`)
    })",snuts
/__tests__/test-GitConfig.js,IdenticalTestDescription,"{'startLine':615,'endLine':631}","it('subsection', async () => {
      const config = GitConfig.from(`[one]
      keyaaa = valaaa
      
      [remote ""foo""]
      url = https://foo.com/project.git
      ; this is a comment
      
      [remote ""bar""]
      url = https://bar.com/project.git`)
      await config.deleteSection('remote', 'foo')
      expect(config.toString()).toEqual(`[one]
      keyaaa = valaaa
      
      [remote ""bar""]
      url = https://bar.com/project.git`)
    })",snuts
/__tests__/test-GitConfig.js,VerboseStatement,"{'startLine':205,'endLine':228}","it('using schema', async () => {
      const config = GitConfig.from(`[core]
      repositoryformatversion = 0
      filemode = true
      bare = false
      logallrefupdates = true
      symlinks = false
      ignorecase = true
      bigFileThreshold = 2`)
      const a = await config.get('core.repositoryformatversion')
      const b = await config.get('core.filemode')
      const c = await config.get('core.bare')
      const d = await config.get('core.logallrefupdates')
      const e = await config.get('core.symlinks')
      const f = await config.get('core.ignorecase')
      const g = await config.get('core.bigFileThreshold')
      expect(a).toEqual('0')
      expect(b).toEqual(true)
      expect(c).toEqual(false)
      expect(d).toEqual(true)
      expect(e).toEqual(false)
      expect(f).toEqual(true)
      expect(g).toEqual(2)
    })",snuts
/__tests__/test-GitAnnotatedTag.js,AnonymousTest,"{'startLine':61,'endLine':64}","it('parse', async () => {
    const tag = GitAnnotatedTag.from(tagString)
    expect(tag.parse()).toEqual(tagObject)
  })",snuts
/__tests__/test-GitAnnotatedTag.js,AnonymousTest,"{'startLine':66,'endLine':69}","it('render', async () => {
    const tag = GitAnnotatedTag.from(tagObject)
    expect(tag.render()).toEqual(tagString)
  })",snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':1,'endLine':1}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':1,'endLine':1}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':1,'endLine':1}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':1,'endLine':1}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':1,'endLine':1}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':1,'endLine':1}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':1,'endLine':1}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':1,'endLine':1}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':2,'endLine':2}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':2,'endLine':2}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':2,'endLine':2}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':2,'endLine':2}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':2,'endLine':2}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':2,'endLine':2}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':2,'endLine':2}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':2,'endLine':2}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':2,'endLine':2}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':2,'endLine':2}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':3,'endLine':3}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':3,'endLine':3}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':3,'endLine':3}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':3,'endLine':3}",Unknown,snuts
/website/static/js/object-inspector.min.js,NonFunctionalStatement,"{'startLine':3,'endLine':3}",Unknown,snuts
/__tests__/test-writeRef.js,Conditional Test Logic,"{'line': 40, 'column': 4, 'index': 1145}","it('sets current branch to another', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-writeRef')
    // Test
    await writeRef({
      fs,
      gitdir,
      ref: 'refs/heads/another',
      value: 'HEAD',
    })
    await writeRef({
      fs,
      gitdir,
      ref: 'HEAD',
      value: 'refs/heads/another',
      force: true,
      symbolic: true,
    })
    const newBranch = await currentBranch({ fs, gitdir, fullname: true })
    expect(newBranch).toBe('refs/heads/another')
    if (!newBranch) throw new Error('type error')
    const ref = await resolveRef({ fs, gitdir, ref: newBranch })
    expect(ref).toBe('cfc039a0acb68bee8bb4f3b13b6b211dbb8c1a69')
  })",steel
/__tests__/test-writeRef.js,Exception Handling,"{'line': 40, 'column': 20, 'index': 1161}","it('sets current branch to another', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-writeRef')
    // Test
    await writeRef({
      fs,
      gitdir,
      ref: 'refs/heads/another',
      value: 'HEAD',
    })
    await writeRef({
      fs,
      gitdir,
      ref: 'HEAD',
      value: 'refs/heads/another',
      force: true,
      symbolic: true,
    })
    const newBranch = await currentBranch({ fs, gitdir, fullname: true })
    expect(newBranch).toBe('refs/heads/another')
    if (!newBranch) throw new Error('type error')
    const ref = await resolveRef({ fs, gitdir, ref: newBranch })
    expect(ref).toBe('cfc039a0acb68bee8bb4f3b13b6b211dbb8c1a69')
  })",steel
/__tests__/test-wire.js,Exception Handling,"{'line': 216, 'column': 4, 'index': 12027}","it('parseRefsAdResponse bad service', async () => {
    const res = [
      Buffer.from(`001e# noservice=git-upload-pack
000001149ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/isomorphic-git@0.0.0-development
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`),
    ]
    try {
      await parseRefsAdResponse(res, {
        service: 'git-upload-pack',
      })
      fail('expected an error')
    } catch (error) {
      expect(error instanceof Errors.ParseError).toBe(true)
      expect(error.data).toEqual({
        expected: '# service=git-upload-pack\\n',
        actual: '# noservice=git-upload-pac',
      })
    }
  })",steel
/__tests__/test-wire.js,Exception Handling,"{'line': 237, 'column': 4, 'index': 12638}","it('parseRefsAdResponse bad null separated', async () => {
    const res = [
      Buffer.from(`001e# service=git-upload-pack
0072ERR Repository not found
The requested repository does not exist, or you do not have permission to
access it.
`),
    ]
    try {
      await parseRefsAdResponse(res, {
        service: 'git-upload-pack',
      })
      fail('expected an error')
    } catch (error) {
      expect(error instanceof Errors.ParseError).toBe(true)
      expect(error.data).toEqual({
        expected: `Two strings separated by '\\x00'`,
        actual: `ERR Repository not found
The requested repository does not exist, or you do not have permission to
access it.
`,
      })
    }
  })",steel
/__tests__/test-wire.js,Exception Handling,"{'line': 267, 'column': 4, 'index': 13987}","it('parseRefsAdResponse HEAD bad space separated', async () => {
    // two spaces instead of one
    const res = [
      Buffer.from(`001e# service=git-upload-pack
000001149ea43b479f5fedc679e3eb37803275d727bf51b7  HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/isomorphic-git@0.0.0-development
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`),
    ]
    try {
      await parseRefsAdResponse(res, {
        service: 'git-upload-pack',
      })
      fail('expected an error')
    } catch (error) {
      expect(error instanceof Errors.ParseError).toBe(true)
      expect(error.data).toEqual({
        expected: `Two strings separated by ' '`,
        actual: '9ea43b479f5fedc679e3eb37803275d727bf51b7  HEAD',
      })
    }
  })",steel
/__tests__/test-wire.js,Exception Handling,"{'line': 293, 'column': 4, 'index': 15233}","it('parseRefsAdResponse refs bad space separated', async () => {
    const res = [
      Buffer.from(`001e# service=git-upload-pack
000001149ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/isomorphic-git@0.0.0-development
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`),
    ]
    try {
      await parseRefsAdResponse(res, {
        service: 'git-upload-pack',
      })
      fail('expected an error')
    } catch (error) {
      expect(error instanceof Errors.ParseError).toBe(true)
      expect(error.data).toEqual({
        expected: `Two strings separated by ' '`,
        actual: 'fb74ea1a9b6a9601df18c38d3de751c51f064bf7refs/heads/js2\n0',
      })
    }
  })",steel
/__tests__/test-walk.js,Duplicate Assert,"{'line': 483, 'column': 4, 'index': 12175}","it('autocrlf respected when gitconfig changes', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-walk')
    // BrowserFS has a design quirk where HTTPRequestFS has a default mode of 555 for everything,
    // meaning that files have the executable bit set by default!

    const isBrowserFS = !!fs._original_unwrapped_fs.getRootFS
    const FILEMODE = isBrowserFS ? 0o100755 : 0o100644
    const SYMLINKMODE = isBrowserFS ? 0o100755 : 0o120000
    const toWalkerResult = async walker => {
      return {
        type: await walker.type(),
        mode: await walker.mode(),
        oid: await walker.oid(),
        content:
          (await walker.content()) &&
          Buffer.from(await walker.content()).toString('utf8'),
        hasStat: !!(await walker.stat()),
      }
    }

    // Test
    let matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    const expectedMatrix = [
      [
        '.',
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: undefined,
          hasStat: true,
        },
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: '49a23584c8bc3a928250e5fd164131f2eb0f2e4c',
          hasStat: false,
        },
        {
          type: 'tree',
          mode: undefined,
          content: undefined,
          oid: undefined,
          hasStat: false,
        },
      ],
      [
        'a.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'Hello\n',
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: 'Hello\n',
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: true,
        },
      ],
      [
        'b.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'world!!!',
          oid: '77787b8f756d76b1d470f0dbb919d5d35dc55ef8',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: 'world!',
          oid: 'c944ebc28f05731ef588ac6298485ba5e8bf3704',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'c944ebc28f05731ef588ac6298485ba5e8bf3704',
          hasStat: true,
        },
      ],
      [
        'c.txt',
        null,
        {
          type: 'blob',
          mode: 0o100644,
          content: '!!!',
          oid: '08faabdc782b92e1e8d371fdd13b30c0a3f54676',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: '08faabdc782b92e1e8d371fdd13b30c0a3f54676',
          hasStat: true,
        },
      ],
      [
        'd.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'Hello again',
          oid: '895a23b41a53a99670b5fd4092e4199e3a328e02',
          hasStat: true,
        },
        null,
        null,
      ],
      [
        'folder',
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: undefined,
          hasStat: true,
        },
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: '341e54913a3a43069f2927cc0f703e5a9f730df1',
          hasStat: false,
        },
        {
          type: 'tree',
          mode: undefined,
          content: undefined,
          oid: undefined,
          hasStat: false,
        },
      ],
      [
        'folder/1.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
      ],
      [
        'folder/2.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        null,
        null,
      ],
      [
        'folder/3.txt',
        {
          type: 'blob',
          mode: SYMLINKMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        null,
        {
          type: 'blob',
          mode: 0o120000,
          content: undefined,
          oid: '7999426c516ffbbae9136d93dc44e89091d35a13',
          hasStat: true,
        },
      ],
    ]
    expect(matrix).toEqual(expectedMatrix)

    // Check oid + content updates when changing autocrlf to true
    await setConfig({
      fs,
      gitdir,
      path: 'core.autocrlf',
      value: true,
    })
    await fs.write(dir + '/a.txt', 'Hello\r\nagain', {
      mode: 0o666,
    })

    matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    // core.autocrlf is true \r\n should be replaced with \n
    expectedMatrix[1][1] = {
      type: 'blob',
      mode: 0o100644,
      content: 'Hello\nagain',
      oid: 'e855bd8b67cc7ee321e4dec1b9e5b17e13aec8e1',
      hasStat: true,
    }
    expectedMatrix[1][3].mode = FILEMODE
    expectedMatrix[6][3].mode = FILEMODE
    expect(matrix).toEqual(expectedMatrix)

    // Check oid + content updates when changing autocrlf back to false
    await setConfig({
      fs,
      gitdir,
      path: 'core.autocrlf',
      value: false,
    })

    matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    // core.autocrlf is false \r\n should not be replaced with \n
    expectedMatrix[1][1] = {
      type: 'blob',
      mode: 0o100644,
      content: 'Hello\r\nagain',
      oid: '8d4f7af538be6af26291dc33eb1fde39b558dbea',
      hasStat: true,
    }
    expect(matrix).toEqual(expectedMatrix)
  })",steel
/__tests__/test-walk.js,Duplicate Assert,"{'line': 483, 'column': 4, 'index': 12175}","it('autocrlf respected when gitconfig changes', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-walk')
    // BrowserFS has a design quirk where HTTPRequestFS has a default mode of 555 for everything,
    // meaning that files have the executable bit set by default!

    const isBrowserFS = !!fs._original_unwrapped_fs.getRootFS
    const FILEMODE = isBrowserFS ? 0o100755 : 0o100644
    const SYMLINKMODE = isBrowserFS ? 0o100755 : 0o120000
    const toWalkerResult = async walker => {
      return {
        type: await walker.type(),
        mode: await walker.mode(),
        oid: await walker.oid(),
        content:
          (await walker.content()) &&
          Buffer.from(await walker.content()).toString('utf8'),
        hasStat: !!(await walker.stat()),
      }
    }

    // Test
    let matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    const expectedMatrix = [
      [
        '.',
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: undefined,
          hasStat: true,
        },
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: '49a23584c8bc3a928250e5fd164131f2eb0f2e4c',
          hasStat: false,
        },
        {
          type: 'tree',
          mode: undefined,
          content: undefined,
          oid: undefined,
          hasStat: false,
        },
      ],
      [
        'a.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'Hello\n',
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: 'Hello\n',
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: true,
        },
      ],
      [
        'b.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'world!!!',
          oid: '77787b8f756d76b1d470f0dbb919d5d35dc55ef8',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: 'world!',
          oid: 'c944ebc28f05731ef588ac6298485ba5e8bf3704',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'c944ebc28f05731ef588ac6298485ba5e8bf3704',
          hasStat: true,
        },
      ],
      [
        'c.txt',
        null,
        {
          type: 'blob',
          mode: 0o100644,
          content: '!!!',
          oid: '08faabdc782b92e1e8d371fdd13b30c0a3f54676',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: '08faabdc782b92e1e8d371fdd13b30c0a3f54676',
          hasStat: true,
        },
      ],
      [
        'd.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'Hello again',
          oid: '895a23b41a53a99670b5fd4092e4199e3a328e02',
          hasStat: true,
        },
        null,
        null,
      ],
      [
        'folder',
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: undefined,
          hasStat: true,
        },
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: '341e54913a3a43069f2927cc0f703e5a9f730df1',
          hasStat: false,
        },
        {
          type: 'tree',
          mode: undefined,
          content: undefined,
          oid: undefined,
          hasStat: false,
        },
      ],
      [
        'folder/1.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
      ],
      [
        'folder/2.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        null,
        null,
      ],
      [
        'folder/3.txt',
        {
          type: 'blob',
          mode: SYMLINKMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        null,
        {
          type: 'blob',
          mode: 0o120000,
          content: undefined,
          oid: '7999426c516ffbbae9136d93dc44e89091d35a13',
          hasStat: true,
        },
      ],
    ]
    expect(matrix).toEqual(expectedMatrix)

    // Check oid + content updates when changing autocrlf to true
    await setConfig({
      fs,
      gitdir,
      path: 'core.autocrlf',
      value: true,
    })
    await fs.write(dir + '/a.txt', 'Hello\r\nagain', {
      mode: 0o666,
    })

    matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    // core.autocrlf is true \r\n should be replaced with \n
    expectedMatrix[1][1] = {
      type: 'blob',
      mode: 0o100644,
      content: 'Hello\nagain',
      oid: 'e855bd8b67cc7ee321e4dec1b9e5b17e13aec8e1',
      hasStat: true,
    }
    expectedMatrix[1][3].mode = FILEMODE
    expectedMatrix[6][3].mode = FILEMODE
    expect(matrix).toEqual(expectedMatrix)

    // Check oid + content updates when changing autocrlf back to false
    await setConfig({
      fs,
      gitdir,
      path: 'core.autocrlf',
      value: false,
    })

    matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    // core.autocrlf is false \r\n should not be replaced with \n
    expectedMatrix[1][1] = {
      type: 'blob',
      mode: 0o100644,
      content: 'Hello\r\nagain',
      oid: '8d4f7af538be6af26291dc33eb1fde39b558dbea',
      hasStat: true,
    }
    expect(matrix).toEqual(expectedMatrix)
  })",steel
/__tests__/test-walk.js,Duplicate Assert,"{'line': 519, 'column': 4, 'index': 13152}","it('autocrlf respected when gitconfig changes', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-walk')
    // BrowserFS has a design quirk where HTTPRequestFS has a default mode of 555 for everything,
    // meaning that files have the executable bit set by default!

    const isBrowserFS = !!fs._original_unwrapped_fs.getRootFS
    const FILEMODE = isBrowserFS ? 0o100755 : 0o100644
    const SYMLINKMODE = isBrowserFS ? 0o100755 : 0o120000
    const toWalkerResult = async walker => {
      return {
        type: await walker.type(),
        mode: await walker.mode(),
        oid: await walker.oid(),
        content:
          (await walker.content()) &&
          Buffer.from(await walker.content()).toString('utf8'),
        hasStat: !!(await walker.stat()),
      }
    }

    // Test
    let matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    const expectedMatrix = [
      [
        '.',
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: undefined,
          hasStat: true,
        },
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: '49a23584c8bc3a928250e5fd164131f2eb0f2e4c',
          hasStat: false,
        },
        {
          type: 'tree',
          mode: undefined,
          content: undefined,
          oid: undefined,
          hasStat: false,
        },
      ],
      [
        'a.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'Hello\n',
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: 'Hello\n',
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: true,
        },
      ],
      [
        'b.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'world!!!',
          oid: '77787b8f756d76b1d470f0dbb919d5d35dc55ef8',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: 'world!',
          oid: 'c944ebc28f05731ef588ac6298485ba5e8bf3704',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'c944ebc28f05731ef588ac6298485ba5e8bf3704',
          hasStat: true,
        },
      ],
      [
        'c.txt',
        null,
        {
          type: 'blob',
          mode: 0o100644,
          content: '!!!',
          oid: '08faabdc782b92e1e8d371fdd13b30c0a3f54676',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: '08faabdc782b92e1e8d371fdd13b30c0a3f54676',
          hasStat: true,
        },
      ],
      [
        'd.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'Hello again',
          oid: '895a23b41a53a99670b5fd4092e4199e3a328e02',
          hasStat: true,
        },
        null,
        null,
      ],
      [
        'folder',
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: undefined,
          hasStat: true,
        },
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: '341e54913a3a43069f2927cc0f703e5a9f730df1',
          hasStat: false,
        },
        {
          type: 'tree',
          mode: undefined,
          content: undefined,
          oid: undefined,
          hasStat: false,
        },
      ],
      [
        'folder/1.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
      ],
      [
        'folder/2.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        null,
        null,
      ],
      [
        'folder/3.txt',
        {
          type: 'blob',
          mode: SYMLINKMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        null,
        {
          type: 'blob',
          mode: 0o120000,
          content: undefined,
          oid: '7999426c516ffbbae9136d93dc44e89091d35a13',
          hasStat: true,
        },
      ],
    ]
    expect(matrix).toEqual(expectedMatrix)

    // Check oid + content updates when changing autocrlf to true
    await setConfig({
      fs,
      gitdir,
      path: 'core.autocrlf',
      value: true,
    })
    await fs.write(dir + '/a.txt', 'Hello\r\nagain', {
      mode: 0o666,
    })

    matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    // core.autocrlf is true \r\n should be replaced with \n
    expectedMatrix[1][1] = {
      type: 'blob',
      mode: 0o100644,
      content: 'Hello\nagain',
      oid: 'e855bd8b67cc7ee321e4dec1b9e5b17e13aec8e1',
      hasStat: true,
    }
    expectedMatrix[1][3].mode = FILEMODE
    expectedMatrix[6][3].mode = FILEMODE
    expect(matrix).toEqual(expectedMatrix)

    // Check oid + content updates when changing autocrlf back to false
    await setConfig({
      fs,
      gitdir,
      path: 'core.autocrlf',
      value: false,
    })

    matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    // core.autocrlf is false \r\n should not be replaced with \n
    expectedMatrix[1][1] = {
      type: 'blob',
      mode: 0o100644,
      content: 'Hello\r\nagain',
      oid: '8d4f7af538be6af26291dc33eb1fde39b558dbea',
      hasStat: true,
    }
    expect(matrix).toEqual(expectedMatrix)
  })",steel
/__tests__/test-walk.js,Duplicate Assert,"{'line': 519, 'column': 4, 'index': 13152}","it('autocrlf respected when gitconfig changes', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-walk')
    // BrowserFS has a design quirk where HTTPRequestFS has a default mode of 555 for everything,
    // meaning that files have the executable bit set by default!

    const isBrowserFS = !!fs._original_unwrapped_fs.getRootFS
    const FILEMODE = isBrowserFS ? 0o100755 : 0o100644
    const SYMLINKMODE = isBrowserFS ? 0o100755 : 0o120000
    const toWalkerResult = async walker => {
      return {
        type: await walker.type(),
        mode: await walker.mode(),
        oid: await walker.oid(),
        content:
          (await walker.content()) &&
          Buffer.from(await walker.content()).toString('utf8'),
        hasStat: !!(await walker.stat()),
      }
    }

    // Test
    let matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    const expectedMatrix = [
      [
        '.',
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: undefined,
          hasStat: true,
        },
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: '49a23584c8bc3a928250e5fd164131f2eb0f2e4c',
          hasStat: false,
        },
        {
          type: 'tree',
          mode: undefined,
          content: undefined,
          oid: undefined,
          hasStat: false,
        },
      ],
      [
        'a.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'Hello\n',
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: 'Hello\n',
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: true,
        },
      ],
      [
        'b.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'world!!!',
          oid: '77787b8f756d76b1d470f0dbb919d5d35dc55ef8',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: 'world!',
          oid: 'c944ebc28f05731ef588ac6298485ba5e8bf3704',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'c944ebc28f05731ef588ac6298485ba5e8bf3704',
          hasStat: true,
        },
      ],
      [
        'c.txt',
        null,
        {
          type: 'blob',
          mode: 0o100644,
          content: '!!!',
          oid: '08faabdc782b92e1e8d371fdd13b30c0a3f54676',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: '08faabdc782b92e1e8d371fdd13b30c0a3f54676',
          hasStat: true,
        },
      ],
      [
        'd.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'Hello again',
          oid: '895a23b41a53a99670b5fd4092e4199e3a328e02',
          hasStat: true,
        },
        null,
        null,
      ],
      [
        'folder',
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: undefined,
          hasStat: true,
        },
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: '341e54913a3a43069f2927cc0f703e5a9f730df1',
          hasStat: false,
        },
        {
          type: 'tree',
          mode: undefined,
          content: undefined,
          oid: undefined,
          hasStat: false,
        },
      ],
      [
        'folder/1.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
      ],
      [
        'folder/2.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        null,
        null,
      ],
      [
        'folder/3.txt',
        {
          type: 'blob',
          mode: SYMLINKMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        null,
        {
          type: 'blob',
          mode: 0o120000,
          content: undefined,
          oid: '7999426c516ffbbae9136d93dc44e89091d35a13',
          hasStat: true,
        },
      ],
    ]
    expect(matrix).toEqual(expectedMatrix)

    // Check oid + content updates when changing autocrlf to true
    await setConfig({
      fs,
      gitdir,
      path: 'core.autocrlf',
      value: true,
    })
    await fs.write(dir + '/a.txt', 'Hello\r\nagain', {
      mode: 0o666,
    })

    matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    // core.autocrlf is true \r\n should be replaced with \n
    expectedMatrix[1][1] = {
      type: 'blob',
      mode: 0o100644,
      content: 'Hello\nagain',
      oid: 'e855bd8b67cc7ee321e4dec1b9e5b17e13aec8e1',
      hasStat: true,
    }
    expectedMatrix[1][3].mode = FILEMODE
    expectedMatrix[6][3].mode = FILEMODE
    expect(matrix).toEqual(expectedMatrix)

    // Check oid + content updates when changing autocrlf back to false
    await setConfig({
      fs,
      gitdir,
      path: 'core.autocrlf',
      value: false,
    })

    matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    // core.autocrlf is false \r\n should not be replaced with \n
    expectedMatrix[1][1] = {
      type: 'blob',
      mode: 0o100644,
      content: 'Hello\r\nagain',
      oid: '8d4f7af538be6af26291dc33eb1fde39b558dbea',
      hasStat: true,
    }
    expect(matrix).toEqual(expectedMatrix)
  })",steel
/__tests__/test-walk.js,Duplicate Assert,"{'line': 550, 'column': 4, 'index': 13980}","it('autocrlf respected when gitconfig changes', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-walk')
    // BrowserFS has a design quirk where HTTPRequestFS has a default mode of 555 for everything,
    // meaning that files have the executable bit set by default!

    const isBrowserFS = !!fs._original_unwrapped_fs.getRootFS
    const FILEMODE = isBrowserFS ? 0o100755 : 0o100644
    const SYMLINKMODE = isBrowserFS ? 0o100755 : 0o120000
    const toWalkerResult = async walker => {
      return {
        type: await walker.type(),
        mode: await walker.mode(),
        oid: await walker.oid(),
        content:
          (await walker.content()) &&
          Buffer.from(await walker.content()).toString('utf8'),
        hasStat: !!(await walker.stat()),
      }
    }

    // Test
    let matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    const expectedMatrix = [
      [
        '.',
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: undefined,
          hasStat: true,
        },
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: '49a23584c8bc3a928250e5fd164131f2eb0f2e4c',
          hasStat: false,
        },
        {
          type: 'tree',
          mode: undefined,
          content: undefined,
          oid: undefined,
          hasStat: false,
        },
      ],
      [
        'a.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'Hello\n',
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: 'Hello\n',
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: true,
        },
      ],
      [
        'b.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'world!!!',
          oid: '77787b8f756d76b1d470f0dbb919d5d35dc55ef8',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: 'world!',
          oid: 'c944ebc28f05731ef588ac6298485ba5e8bf3704',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'c944ebc28f05731ef588ac6298485ba5e8bf3704',
          hasStat: true,
        },
      ],
      [
        'c.txt',
        null,
        {
          type: 'blob',
          mode: 0o100644,
          content: '!!!',
          oid: '08faabdc782b92e1e8d371fdd13b30c0a3f54676',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: '08faabdc782b92e1e8d371fdd13b30c0a3f54676',
          hasStat: true,
        },
      ],
      [
        'd.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'Hello again',
          oid: '895a23b41a53a99670b5fd4092e4199e3a328e02',
          hasStat: true,
        },
        null,
        null,
      ],
      [
        'folder',
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: undefined,
          hasStat: true,
        },
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: '341e54913a3a43069f2927cc0f703e5a9f730df1',
          hasStat: false,
        },
        {
          type: 'tree',
          mode: undefined,
          content: undefined,
          oid: undefined,
          hasStat: false,
        },
      ],
      [
        'folder/1.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
      ],
      [
        'folder/2.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        null,
        null,
      ],
      [
        'folder/3.txt',
        {
          type: 'blob',
          mode: SYMLINKMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        null,
        {
          type: 'blob',
          mode: 0o120000,
          content: undefined,
          oid: '7999426c516ffbbae9136d93dc44e89091d35a13',
          hasStat: true,
        },
      ],
    ]
    expect(matrix).toEqual(expectedMatrix)

    // Check oid + content updates when changing autocrlf to true
    await setConfig({
      fs,
      gitdir,
      path: 'core.autocrlf',
      value: true,
    })
    await fs.write(dir + '/a.txt', 'Hello\r\nagain', {
      mode: 0o666,
    })

    matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    // core.autocrlf is true \r\n should be replaced with \n
    expectedMatrix[1][1] = {
      type: 'blob',
      mode: 0o100644,
      content: 'Hello\nagain',
      oid: 'e855bd8b67cc7ee321e4dec1b9e5b17e13aec8e1',
      hasStat: true,
    }
    expectedMatrix[1][3].mode = FILEMODE
    expectedMatrix[6][3].mode = FILEMODE
    expect(matrix).toEqual(expectedMatrix)

    // Check oid + content updates when changing autocrlf back to false
    await setConfig({
      fs,
      gitdir,
      path: 'core.autocrlf',
      value: false,
    })

    matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    // core.autocrlf is false \r\n should not be replaced with \n
    expectedMatrix[1][1] = {
      type: 'blob',
      mode: 0o100644,
      content: 'Hello\r\nagain',
      oid: '8d4f7af538be6af26291dc33eb1fde39b558dbea',
      hasStat: true,
    }
    expect(matrix).toEqual(expectedMatrix)
  })",steel
/__tests__/test-walk.js,Duplicate Assert,"{'line': 550, 'column': 4, 'index': 13980}","it('autocrlf respected when gitconfig changes', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-walk')
    // BrowserFS has a design quirk where HTTPRequestFS has a default mode of 555 for everything,
    // meaning that files have the executable bit set by default!

    const isBrowserFS = !!fs._original_unwrapped_fs.getRootFS
    const FILEMODE = isBrowserFS ? 0o100755 : 0o100644
    const SYMLINKMODE = isBrowserFS ? 0o100755 : 0o120000
    const toWalkerResult = async walker => {
      return {
        type: await walker.type(),
        mode: await walker.mode(),
        oid: await walker.oid(),
        content:
          (await walker.content()) &&
          Buffer.from(await walker.content()).toString('utf8'),
        hasStat: !!(await walker.stat()),
      }
    }

    // Test
    let matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    const expectedMatrix = [
      [
        '.',
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: undefined,
          hasStat: true,
        },
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: '49a23584c8bc3a928250e5fd164131f2eb0f2e4c',
          hasStat: false,
        },
        {
          type: 'tree',
          mode: undefined,
          content: undefined,
          oid: undefined,
          hasStat: false,
        },
      ],
      [
        'a.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'Hello\n',
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: 'Hello\n',
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'e965047ad7c57865823c7d992b1d046ea66edf78',
          hasStat: true,
        },
      ],
      [
        'b.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'world!!!',
          oid: '77787b8f756d76b1d470f0dbb919d5d35dc55ef8',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: 'world!',
          oid: 'c944ebc28f05731ef588ac6298485ba5e8bf3704',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'c944ebc28f05731ef588ac6298485ba5e8bf3704',
          hasStat: true,
        },
      ],
      [
        'c.txt',
        null,
        {
          type: 'blob',
          mode: 0o100644,
          content: '!!!',
          oid: '08faabdc782b92e1e8d371fdd13b30c0a3f54676',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: '08faabdc782b92e1e8d371fdd13b30c0a3f54676',
          hasStat: true,
        },
      ],
      [
        'd.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: 'Hello again',
          oid: '895a23b41a53a99670b5fd4092e4199e3a328e02',
          hasStat: true,
        },
        null,
        null,
      ],
      [
        'folder',
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: undefined,
          hasStat: true,
        },
        {
          type: 'tree',
          mode: 0o40000,
          content: undefined,
          oid: '341e54913a3a43069f2927cc0f703e5a9f730df1',
          hasStat: false,
        },
        {
          type: 'tree',
          mode: undefined,
          content: undefined,
          oid: undefined,
          hasStat: false,
        },
      ],
      [
        'folder/1.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: false,
        },
        {
          type: 'blob',
          mode: 0o100644,
          content: undefined,
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
      ],
      [
        'folder/2.txt',
        {
          type: 'blob',
          mode: FILEMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        null,
        null,
      ],
      [
        'folder/3.txt',
        {
          type: 'blob',
          mode: SYMLINKMODE,
          content: '',
          oid: 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391',
          hasStat: true,
        },
        null,
        {
          type: 'blob',
          mode: 0o120000,
          content: undefined,
          oid: '7999426c516ffbbae9136d93dc44e89091d35a13',
          hasStat: true,
        },
      ],
    ]
    expect(matrix).toEqual(expectedMatrix)

    // Check oid + content updates when changing autocrlf to true
    await setConfig({
      fs,
      gitdir,
      path: 'core.autocrlf',
      value: true,
    })
    await fs.write(dir + '/a.txt', 'Hello\r\nagain', {
      mode: 0o666,
    })

    matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    // core.autocrlf is true \r\n should be replaced with \n
    expectedMatrix[1][1] = {
      type: 'blob',
      mode: 0o100644,
      content: 'Hello\nagain',
      oid: 'e855bd8b67cc7ee321e4dec1b9e5b17e13aec8e1',
      hasStat: true,
    }
    expectedMatrix[1][3].mode = FILEMODE
    expectedMatrix[6][3].mode = FILEMODE
    expect(matrix).toEqual(expectedMatrix)

    // Check oid + content updates when changing autocrlf back to false
    await setConfig({
      fs,
      gitdir,
      path: 'core.autocrlf',
      value: false,
    })

    matrix = await walk({
      fs,
      dir,
      gitdir,
      trees: [WORKDIR(), TREE({ ref: 'HEAD' }), STAGE()],
      map: async (filepath, [workdir, tree, stage]) => [
        filepath,
        workdir && (await toWalkerResult(workdir)),
        tree && (await toWalkerResult(tree)),
        stage && (await toWalkerResult(stage)),
      ],
    })

    // core.autocrlf is false \r\n should not be replaced with \n
    expectedMatrix[1][1] = {
      type: 'blob',
      mode: 0o100644,
      content: 'Hello\r\nagain',
      oid: '8d4f7af538be6af26291dc33eb1fde39b558dbea',
      hasStat: true,
    }
    expect(matrix).toEqual(expectedMatrix)
  })",steel
/__tests__/test-validate.js,Exception Handling,"{'line': 20, 'column': 4, 'index': 559}","it('empty file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    const file = 'a.txt'

    await fs.write(path.join(dir, file), 'Hi', 'utf8')
    await add({ fs, dir, filepath: file })
    await fs.write(path.join(dir, '.git', 'index'), '', 'utf8')

    // Test
    let error = null
    try {
      await status({ fs, dir, filepath: file })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InternalError).toBe(true)
    expect(error.data.message).toEqual('Index file is empty (.git/index)')
  })",steel
/__tests__/test-validate.js,Exception Handling,"{'line': 41, 'column': 4, 'index': 1176}","it('no magic number', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    const file = 'a.txt'

    await fs.write(path.join(dir, file), 'Hi', 'utf8')
    await add({ fs, dir, filepath: file })
    await fs.write(path.join(dir, '.git', 'index'), 'no-magic-number', 'utf8')

    // Test
    let error = null
    try {
      await status({ fs, dir, filepath: file })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InternalError).toBe(true)
    expect(error.data.message).toContain('Invalid dircache magic file number')
  })",steel
/__tests__/test-validate.js,Exception Handling,"{'line': 62, 'column': 4, 'index': 1790}","it('wrong checksum', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    const file = 'a.txt'

    await fs.write(path.join(dir, file), 'Hi', 'utf8')
    await add({ fs, dir, filepath: file })
    await fs.write(path.join(dir, '.git', 'index'), 'DIRCxxxxx', 'utf8')

    // Test
    let error = null
    try {
      await status({ fs, dir, filepath: file })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InternalError).toBe(true)
    expect(error.data.message).toContain(
      'Invalid checksum in GitIndex buffer: expected 444952437878787878 but saw da39a3ee5e6b4b0d3255bfef95601890afd80709'
    )
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 45, 'column': 4, 'index': 1238}","it('should be possible to remove a file from the index which is not present in the workdir', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.write(path.join(dir, 'hello.md'), 'Hello, World!')
    await add({
      fs,
      dir,
      filepath: 'hello.md',
    })
    await fs.rm(path.join(dir, 'hello.md'))
    // Test
    let fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('*absent')
    await updateIndex({
      fs,
      dir,
      remove: true,
      filepath: 'hello.md',
    })
    fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('absent')
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 57, 'column': 4, 'index': 1465}","it('should be possible to remove a file from the index which is not present in the workdir', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.write(path.join(dir, 'hello.md'), 'Hello, World!')
    await add({
      fs,
      dir,
      filepath: 'hello.md',
    })
    await fs.rm(path.join(dir, 'hello.md'))
    // Test
    let fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('*absent')
    await updateIndex({
      fs,
      dir,
      remove: true,
      filepath: 'hello.md',
    })
    fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('absent')
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 75, 'column': 4, 'index': 1917}","it('should not remove file from index by default if file still exists in workdir', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.write(path.join(dir, 'hello.md'), 'Hello, World!')
    await add({
      fs,
      dir,
      filepath: 'hello.md',
    })
    // Test
    let fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('added')
    await updateIndex({
      fs,
      dir,
      remove: true,
      filepath: 'hello.md',
    })
    fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('added')
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 75, 'column': 4, 'index': 1917}","it('should not remove file from index by default if file still exists in workdir', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.write(path.join(dir, 'hello.md'), 'Hello, World!')
    await add({
      fs,
      dir,
      filepath: 'hello.md',
    })
    // Test
    let fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('added')
    await updateIndex({
      fs,
      dir,
      remove: true,
      filepath: 'hello.md',
    })
    fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('added')
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 87, 'column': 4, 'index': 2142}","it('should not remove file from index by default if file still exists in workdir', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.write(path.join(dir, 'hello.md'), 'Hello, World!')
    await add({
      fs,
      dir,
      filepath: 'hello.md',
    })
    // Test
    let fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('added')
    await updateIndex({
      fs,
      dir,
      remove: true,
      filepath: 'hello.md',
    })
    fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('added')
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 87, 'column': 4, 'index': 2142}","it('should not remove file from index by default if file still exists in workdir', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.write(path.join(dir, 'hello.md'), 'Hello, World!')
    await add({
      fs,
      dir,
      filepath: 'hello.md',
    })
    // Test
    let fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('added')
    await updateIndex({
      fs,
      dir,
      remove: true,
      filepath: 'hello.md',
    })
    fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('added')
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 105, 'column': 4, 'index': 2584}","it('should remove file from index which exists on disk if force is used', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.write(path.join(dir, 'hello.md'), 'Hello, World!')
    await add({
      fs,
      dir,
      filepath: 'hello.md',
    })
    // Test
    let fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('added')
    await updateIndex({
      fs,
      dir,
      remove: true,
      force: true,
      filepath: 'hello.md',
    })
    fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('*added')
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 118, 'column': 4, 'index': 2828}","it('should remove file from index which exists on disk if force is used', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.write(path.join(dir, 'hello.md'), 'Hello, World!')
    await add({
      fs,
      dir,
      filepath: 'hello.md',
    })
    // Test
    let fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('added')
    await updateIndex({
      fs,
      dir,
      remove: true,
      force: true,
      filepath: 'hello.md',
    })
    fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('*added')
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 162, 'column': 4, 'index': 3878}","it('should be possible to update a file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.write(path.join(dir, 'hello.md'), 'Hello, World!')
    await add({
      fs,
      dir,
      filepath: 'hello.md',
    })
    await fs.write(path.join(dir, 'hello.md'), 'Hello World')
    // Test
    let fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('*added')
    const oid = await updateIndex({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(oid).toBe('5e1c309dae7f45e0f39b1bf3ac3cd9db12e7d689')
    fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('added')
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 174, 'column': 4, 'index': 4161}","it('should be possible to update a file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.write(path.join(dir, 'hello.md'), 'Hello, World!')
    await add({
      fs,
      dir,
      filepath: 'hello.md',
    })
    await fs.write(path.join(dir, 'hello.md'), 'Hello World')
    // Test
    let fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('*added')
    const oid = await updateIndex({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(oid).toBe('5e1c309dae7f45e0f39b1bf3ac3cd9db12e7d689')
    fileStatus = await status({
      fs,
      dir,
      filepath: 'hello.md',
    })
    expect(fileStatus).toBe('added')
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 192, 'column': 4, 'index': 4600}","it('should throw if we try to update a new file without providing `add`', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.write(path.join(dir, 'hello.md'), 'Hello, World!')
    // Test
    let error = null
    try {
      await updateIndex({
        fs,
        dir,
        filepath: 'hello.md',
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.updateIndex')
    error = error.toJSON()
    delete error.stack
    expect(error).toMatchInlineSnapshot(`
      Object {
        ""caller"": ""git.updateIndex"",
        ""code"": ""NotFoundError"",
        ""data"": Object {
          ""what"": ""file at \\""hello.md\\"" in index and \\""add\\"" not set"",
        },
        ""message"": ""Could not find file at \\""hello.md\\"" in index and \\""add\\"" not set."",
      }
    `)
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 196, 'column': 4, 'index': 4735}","it('should throw if we try to update a new file without providing `add`', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.write(path.join(dir, 'hello.md'), 'Hello, World!')
    // Test
    let error = null
    try {
      await updateIndex({
        fs,
        dir,
        filepath: 'hello.md',
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.updateIndex')
    error = error.toJSON()
    delete error.stack
    expect(error).toMatchInlineSnapshot(`
      Object {
        ""caller"": ""git.updateIndex"",
        ""code"": ""NotFoundError"",
        ""data"": Object {
          ""what"": ""file at \\""hello.md\\"" in index and \\""add\\"" not set"",
        },
        ""message"": ""Could not find file at \\""hello.md\\"" in index and \\""add\\"" not set."",
      }
    `)
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 222, 'column': 4, 'index': 5419}","it('should throw if we try to update a file which does not exist on disk', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    // Test
    let error = null
    try {
      await updateIndex({
        fs,
        dir,
        filepath: 'hello.md',
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.updateIndex')
    error = error.toJSON()
    delete error.stack
    expect(error).toMatchInlineSnapshot(`
      Object {
        ""caller"": ""git.updateIndex"",
        ""code"": ""NotFoundError"",
        ""data"": Object {
          ""what"": ""file at \\""hello.md\\"" on disk and \\""remove\\"" not set"",
        },
        ""message"": ""Could not find file at \\""hello.md\\"" on disk and \\""remove\\"" not set."",
      }
    `)
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 226, 'column': 4, 'index': 5554}","it('should throw if we try to update a file which does not exist on disk', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    // Test
    let error = null
    try {
      await updateIndex({
        fs,
        dir,
        filepath: 'hello.md',
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.updateIndex')
    error = error.toJSON()
    delete error.stack
    expect(error).toMatchInlineSnapshot(`
      Object {
        ""caller"": ""git.updateIndex"",
        ""code"": ""NotFoundError"",
        ""data"": Object {
          ""what"": ""file at \\""hello.md\\"" on disk and \\""remove\\"" not set"",
        },
        ""message"": ""Could not find file at \\""hello.md\\"" on disk and \\""remove\\"" not set."",
      }
    `)
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 253, 'column': 4, 'index': 6268}","it('should throw if we try to add a directory', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.mkdir(path.join(dir, 'hello-world'))
    // Test
    let error = null
    try {
      await updateIndex({
        fs,
        dir,
        filepath: 'hello-world',
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.updateIndex')
    error = error.toJSON()
    delete error.stack
    expect(error).toMatchInlineSnapshot(`
      Object {
        ""caller"": ""git.updateIndex"",
        ""code"": ""InvalidFilepathError"",
        ""data"": Object {
          ""reason"": ""directory"",
        },
        ""message"": ""\\""filepath\\"" should not be a directory."",
      }
    `)
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 257, 'column': 4, 'index': 6403}","it('should throw if we try to add a directory', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.mkdir(path.join(dir, 'hello-world'))
    // Test
    let error = null
    try {
      await updateIndex({
        fs,
        dir,
        filepath: 'hello-world',
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.updateIndex')
    error = error.toJSON()
    delete error.stack
    expect(error).toMatchInlineSnapshot(`
      Object {
        ""caller"": ""git.updateIndex"",
        ""code"": ""InvalidFilepathError"",
        ""data"": Object {
          ""reason"": ""directory"",
        },
        ""message"": ""\\""filepath\\"" should not be a directory."",
      }
    `)
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 291, 'column': 4, 'index': 7209}","it('should throw if we try to remove a directory', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.mkdir(path.join(dir, 'hello-world'))
    await fs.write(path.join(dir, 'hello-world/a'), 'a')
    await add({
      fs,
      dir,
      filepath: 'hello-world/a',
    })
    // Test
    let error = null
    try {
      await updateIndex({
        fs,
        dir,
        remove: true,
        filepath: 'hello-world',
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.updateIndex')
    error = error.toJSON()
    delete error.stack
    expect(error).toMatchInlineSnapshot(`
      Object {
        ""caller"": ""git.updateIndex"",
        ""code"": ""InvalidFilepathError"",
        ""data"": Object {
          ""reason"": ""directory"",
        },
        ""message"": ""\\""filepath\\"" should not be a directory."",
      }
    `)
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 295, 'column': 4, 'index': 7344}","it('should throw if we try to remove a directory', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.mkdir(path.join(dir, 'hello-world'))
    await fs.write(path.join(dir, 'hello-world/a'), 'a')
    await add({
      fs,
      dir,
      filepath: 'hello-world/a',
    })
    // Test
    let error = null
    try {
      await updateIndex({
        fs,
        dir,
        remove: true,
        filepath: 'hello-world',
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.updateIndex')
    error = error.toJSON()
    delete error.stack
    expect(error).toMatchInlineSnapshot(`
      Object {
        ""caller"": ""git.updateIndex"",
        ""code"": ""InvalidFilepathError"",
        ""data"": Object {
          ""reason"": ""directory"",
        },
        ""message"": ""\\""filepath\\"" should not be a directory."",
      }
    `)
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 323, 'column': 4, 'index': 8064}","it('should not throw if we force remove a directory', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.mkdir(path.join(dir, 'hello-world'))
    await fs.write(path.join(dir, 'hello-world/a'), 'a')
    await add({
      fs,
      dir,
      filepath: 'hello-world/a',
    })
    // Test
    let fileStatus = await status({
      fs,
      dir,
      filepath: 'hello-world/a',
    })
    expect(fileStatus).toBe('added')
    await updateIndex({
      fs,
      dir,
      remove: true,
      force: true,
      filepath: 'hello-world',
    })
    fileStatus = await status({
      fs,
      dir,
      filepath: 'hello-world/a',
    })
    expect(fileStatus).toBe('added')
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 323, 'column': 4, 'index': 8064}","it('should not throw if we force remove a directory', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.mkdir(path.join(dir, 'hello-world'))
    await fs.write(path.join(dir, 'hello-world/a'), 'a')
    await add({
      fs,
      dir,
      filepath: 'hello-world/a',
    })
    // Test
    let fileStatus = await status({
      fs,
      dir,
      filepath: 'hello-world/a',
    })
    expect(fileStatus).toBe('added')
    await updateIndex({
      fs,
      dir,
      remove: true,
      force: true,
      filepath: 'hello-world',
    })
    fileStatus = await status({
      fs,
      dir,
      filepath: 'hello-world/a',
    })
    expect(fileStatus).toBe('added')
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 336, 'column': 4, 'index': 8316}","it('should not throw if we force remove a directory', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.mkdir(path.join(dir, 'hello-world'))
    await fs.write(path.join(dir, 'hello-world/a'), 'a')
    await add({
      fs,
      dir,
      filepath: 'hello-world/a',
    })
    // Test
    let fileStatus = await status({
      fs,
      dir,
      filepath: 'hello-world/a',
    })
    expect(fileStatus).toBe('added')
    await updateIndex({
      fs,
      dir,
      remove: true,
      force: true,
      filepath: 'hello-world',
    })
    fileStatus = await status({
      fs,
      dir,
      filepath: 'hello-world/a',
    })
    expect(fileStatus).toBe('added')
  })",steel
/__tests__/test-updateIndex.js,Duplicate Assert,"{'line': 336, 'column': 4, 'index': 8316}","it('should not throw if we force remove a directory', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.mkdir(path.join(dir, 'hello-world'))
    await fs.write(path.join(dir, 'hello-world/a'), 'a')
    await add({
      fs,
      dir,
      filepath: 'hello-world/a',
    })
    // Test
    let fileStatus = await status({
      fs,
      dir,
      filepath: 'hello-world/a',
    })
    expect(fileStatus).toBe('added')
    await updateIndex({
      fs,
      dir,
      remove: true,
      force: true,
      filepath: 'hello-world',
    })
    fileStatus = await status({
      fs,
      dir,
      filepath: 'hello-world/a',
    })
    expect(fileStatus).toBe('added')
  })",steel
/__tests__/test-updateIndex.js,Exception Handling,"{'line': 183, 'column': 4, 'index': 4460}","it('should throw if we try to update a new file without providing `add`', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.write(path.join(dir, 'hello.md'), 'Hello, World!')
    // Test
    let error = null
    try {
      await updateIndex({
        fs,
        dir,
        filepath: 'hello.md',
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.updateIndex')
    error = error.toJSON()
    delete error.stack
    expect(error).toMatchInlineSnapshot(`
      Object {
        ""caller"": ""git.updateIndex"",
        ""code"": ""NotFoundError"",
        ""data"": Object {
          ""what"": ""file at \\""hello.md\\"" in index and \\""add\\"" not set"",
        },
        ""message"": ""Could not find file at \\""hello.md\\"" in index and \\""add\\"" not set."",
      }
    `)
  })",steel
/__tests__/test-updateIndex.js,Exception Handling,"{'line': 213, 'column': 4, 'index': 5279}","it('should throw if we try to update a file which does not exist on disk', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    // Test
    let error = null
    try {
      await updateIndex({
        fs,
        dir,
        filepath: 'hello.md',
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.updateIndex')
    error = error.toJSON()
    delete error.stack
    expect(error).toMatchInlineSnapshot(`
      Object {
        ""caller"": ""git.updateIndex"",
        ""code"": ""NotFoundError"",
        ""data"": Object {
          ""what"": ""file at \\""hello.md\\"" on disk and \\""remove\\"" not set"",
        },
        ""message"": ""Could not find file at \\""hello.md\\"" on disk and \\""remove\\"" not set."",
      }
    `)
  })",steel
/__tests__/test-updateIndex.js,Exception Handling,"{'line': 244, 'column': 4, 'index': 6125}","it('should throw if we try to add a directory', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.mkdir(path.join(dir, 'hello-world'))
    // Test
    let error = null
    try {
      await updateIndex({
        fs,
        dir,
        filepath: 'hello-world',
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.updateIndex')
    error = error.toJSON()
    delete error.stack
    expect(error).toMatchInlineSnapshot(`
      Object {
        ""caller"": ""git.updateIndex"",
        ""code"": ""InvalidFilepathError"",
        ""data"": Object {
          ""reason"": ""directory"",
        },
        ""message"": ""\\""filepath\\"" should not be a directory."",
      }
    `)
  })",steel
/__tests__/test-updateIndex.js,Exception Handling,"{'line': 281, 'column': 4, 'index': 7044}","it('should throw if we try to remove a directory', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-empty')
    await fs.mkdir(path.join(dir, 'hello-world'))
    await fs.write(path.join(dir, 'hello-world/a'), 'a')
    await add({
      fs,
      dir,
      filepath: 'hello-world/a',
    })
    // Test
    let error = null
    try {
      await updateIndex({
        fs,
        dir,
        remove: true,
        filepath: 'hello-world',
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.updateIndex')
    error = error.toJSON()
    delete error.stack
    expect(error).toMatchInlineSnapshot(`
      Object {
        ""caller"": ""git.updateIndex"",
        ""code"": ""InvalidFilepathError"",
        ""data"": Object {
          ""reason"": ""directory"",
        },
        ""message"": ""\\""filepath\\"" should not be a directory."",
      }
    `)
  })",steel
/__tests__/test-unicode-paths.js,Magic Number,"{'line': 26, 'column': 63, 'index': 715}","it('write/read index ', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-unicode-paths')
    await init({ fs, dir, gitdir })
    // Test
    await add({ fs, dir, gitdir, filepath: '' })
    expect((await listFiles({ fs, dir, gitdir }))[0]).toBe('')
    await remove({ fs, dir, gitdir, filepath: '' })
    expect((await listFiles({ fs, dir, gitdir })).length).toBe(0)
  })",steel
/__tests__/test-unicode-paths.js,Magic Number,"{'line': 38, 'column': 63, 'index': 1249}","it('write/read index docs/', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-unicode-paths')
    await init({ fs, dir, gitdir })
    // Test
    await fs.mkdir(path.join(dir, 'docs'))
    await fs.write(path.join(dir, 'docs/'), '')
    await add({ fs, dir, gitdir, filepath: 'docs/' })
    expect((await listFiles({ fs, dir, gitdir }))[0]).toBe('docs/')
    await remove({ fs, dir, gitdir, filepath: 'docs/' })
    expect((await listFiles({ fs, dir, gitdir })).length).toBe(0)
  })",steel
/__tests__/test-tag.js,Exception Handling,"{'line': 20, 'column': 4, 'index': 677}","it('fails if tag already exists', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-tag')
    // Test
    let error = null
    try {
      await tag({ fs, gitdir, ref: 'existing-tag' })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.AlreadyExistsError).toBe(true)
  })",steel
/__tests__/test-tag.js,Exception Handling,"{'line': 33, 'column': 4, 'index': 1050}","it('fails if tag already exists (packed)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-tag')
    // Test
    let error = null
    try {
      await tag({ fs, gitdir, ref: 'packed-tag' })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.AlreadyExistsError).toBe(true)
  })",steel
/__tests__/test-tag.js,Exception Handling,"{'line': 46, 'column': 4, 'index': 1400}","it('force overwrite', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-tag')
    // Test
    let error = null
    try {
      await tag({ fs, gitdir, ref: 'existing-tag', force: true })
    } catch (err) {
      error = err
    }
    expect(error).toBeNull()
  })",steel
/__tests__/test-tag.js,Exception Handling,"{'line': 58, 'column': 4, 'index': 1704}","it('force overwrite (packed)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-tag')
    // Test
    let error = null
    try {
      await tag({ fs, gitdir, ref: 'packed-tag', force: true })
    } catch (err) {
      error = err
    }
    expect(error).toBeNull()
  })",steel
/__tests__/test-statusMatrix.js,Duplicate Assert,"{'line': 14, 'column': 4, 'index': 423}","it('statusMatrix', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-statusMatrix')
    // Test
    let matrix = await statusMatrix({ fs, dir, gitdir })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 1],
      ['c.txt', 1, 0, 1],
      ['d.txt', 0, 2, 0],
    ])

    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await add({ fs, dir, gitdir, filepath: 'b.txt' })
    await remove({ fs, dir, gitdir, filepath: 'c.txt' })
    await add({ fs, dir, gitdir, filepath: 'd.txt' })
    matrix = await statusMatrix({ fs, dir, gitdir })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 2],
      ['c.txt', 1, 0, 0],
      ['d.txt', 0, 2, 2],
    ])

    // And finally the weirdo cases
    const acontent = await fs.read(path.join(dir, 'a.txt'))
    await fs.write(path.join(dir, 'a.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await fs.write(path.join(dir, 'a.txt'), acontent)
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['a.txt'] })
    expect(matrix).toEqual([['a.txt', 1, 1, 3]])

    await remove({ fs, dir, gitdir, filepath: 'a.txt' })
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['a.txt'] })
    expect(matrix).toEqual([['a.txt', 1, 1, 0]])

    await fs.write(path.join(dir, 'e.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'e.txt' })
    await fs.rm(path.join(dir, 'e.txt'))
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['e.txt'] })
    expect(matrix).toEqual([['e.txt', 0, 0, 3]])
  })",steel
/__tests__/test-statusMatrix.js,Duplicate Assert,"{'line': 26, 'column': 4, 'index': 836}","it('statusMatrix', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-statusMatrix')
    // Test
    let matrix = await statusMatrix({ fs, dir, gitdir })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 1],
      ['c.txt', 1, 0, 1],
      ['d.txt', 0, 2, 0],
    ])

    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await add({ fs, dir, gitdir, filepath: 'b.txt' })
    await remove({ fs, dir, gitdir, filepath: 'c.txt' })
    await add({ fs, dir, gitdir, filepath: 'd.txt' })
    matrix = await statusMatrix({ fs, dir, gitdir })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 2],
      ['c.txt', 1, 0, 0],
      ['d.txt', 0, 2, 2],
    ])

    // And finally the weirdo cases
    const acontent = await fs.read(path.join(dir, 'a.txt'))
    await fs.write(path.join(dir, 'a.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await fs.write(path.join(dir, 'a.txt'), acontent)
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['a.txt'] })
    expect(matrix).toEqual([['a.txt', 1, 1, 3]])

    await remove({ fs, dir, gitdir, filepath: 'a.txt' })
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['a.txt'] })
    expect(matrix).toEqual([['a.txt', 1, 1, 0]])

    await fs.write(path.join(dir, 'e.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'e.txt' })
    await fs.rm(path.join(dir, 'e.txt'))
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['e.txt'] })
    expect(matrix).toEqual([['e.txt', 0, 0, 3]])
  })",steel
/__tests__/test-statusMatrix.js,Duplicate Assert,"{'line': 39, 'column': 4, 'index': 1306}","it('statusMatrix', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-statusMatrix')
    // Test
    let matrix = await statusMatrix({ fs, dir, gitdir })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 1],
      ['c.txt', 1, 0, 1],
      ['d.txt', 0, 2, 0],
    ])

    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await add({ fs, dir, gitdir, filepath: 'b.txt' })
    await remove({ fs, dir, gitdir, filepath: 'c.txt' })
    await add({ fs, dir, gitdir, filepath: 'd.txt' })
    matrix = await statusMatrix({ fs, dir, gitdir })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 2],
      ['c.txt', 1, 0, 0],
      ['d.txt', 0, 2, 2],
    ])

    // And finally the weirdo cases
    const acontent = await fs.read(path.join(dir, 'a.txt'))
    await fs.write(path.join(dir, 'a.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await fs.write(path.join(dir, 'a.txt'), acontent)
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['a.txt'] })
    expect(matrix).toEqual([['a.txt', 1, 1, 3]])

    await remove({ fs, dir, gitdir, filepath: 'a.txt' })
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['a.txt'] })
    expect(matrix).toEqual([['a.txt', 1, 1, 0]])

    await fs.write(path.join(dir, 'e.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'e.txt' })
    await fs.rm(path.join(dir, 'e.txt'))
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['e.txt'] })
    expect(matrix).toEqual([['e.txt', 0, 0, 3]])
  })",steel
/__tests__/test-statusMatrix.js,Duplicate Assert,"{'line': 43, 'column': 4, 'index': 1488}","it('statusMatrix', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-statusMatrix')
    // Test
    let matrix = await statusMatrix({ fs, dir, gitdir })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 1],
      ['c.txt', 1, 0, 1],
      ['d.txt', 0, 2, 0],
    ])

    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await add({ fs, dir, gitdir, filepath: 'b.txt' })
    await remove({ fs, dir, gitdir, filepath: 'c.txt' })
    await add({ fs, dir, gitdir, filepath: 'd.txt' })
    matrix = await statusMatrix({ fs, dir, gitdir })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 2],
      ['c.txt', 1, 0, 0],
      ['d.txt', 0, 2, 2],
    ])

    // And finally the weirdo cases
    const acontent = await fs.read(path.join(dir, 'a.txt'))
    await fs.write(path.join(dir, 'a.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await fs.write(path.join(dir, 'a.txt'), acontent)
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['a.txt'] })
    expect(matrix).toEqual([['a.txt', 1, 1, 3]])

    await remove({ fs, dir, gitdir, filepath: 'a.txt' })
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['a.txt'] })
    expect(matrix).toEqual([['a.txt', 1, 1, 0]])

    await fs.write(path.join(dir, 'e.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'e.txt' })
    await fs.rm(path.join(dir, 'e.txt'))
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['e.txt'] })
    expect(matrix).toEqual([['e.txt', 0, 0, 3]])
  })",steel
/__tests__/test-statusMatrix.js,Duplicate Assert,"{'line': 49, 'column': 4, 'index': 1758}","it('statusMatrix', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-statusMatrix')
    // Test
    let matrix = await statusMatrix({ fs, dir, gitdir })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 1],
      ['c.txt', 1, 0, 1],
      ['d.txt', 0, 2, 0],
    ])

    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await add({ fs, dir, gitdir, filepath: 'b.txt' })
    await remove({ fs, dir, gitdir, filepath: 'c.txt' })
    await add({ fs, dir, gitdir, filepath: 'd.txt' })
    matrix = await statusMatrix({ fs, dir, gitdir })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 2],
      ['c.txt', 1, 0, 0],
      ['d.txt', 0, 2, 2],
    ])

    // And finally the weirdo cases
    const acontent = await fs.read(path.join(dir, 'a.txt'))
    await fs.write(path.join(dir, 'a.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await fs.write(path.join(dir, 'a.txt'), acontent)
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['a.txt'] })
    expect(matrix).toEqual([['a.txt', 1, 1, 3]])

    await remove({ fs, dir, gitdir, filepath: 'a.txt' })
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['a.txt'] })
    expect(matrix).toEqual([['a.txt', 1, 1, 0]])

    await fs.write(path.join(dir, 'e.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'e.txt' })
    await fs.rm(path.join(dir, 'e.txt'))
    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['e.txt'] })
    expect(matrix).toEqual([['e.txt', 0, 0, 3]])
  })",steel
/__tests__/test-statusMatrix.js,Duplicate Assert,"{'line': 270, 'column': 4, 'index': 9171}","it('statusMatrix with filepaths', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-statusMatrix-filepath')
    // Test
    let matrix = await statusMatrix({ fs, dir, gitdir })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 1],
      ['c.txt', 1, 0, 1],
      ['d.txt', 0, 2, 0],
      ['g/g.txt', 0, 2, 0],
      ['h/h.txt', 0, 2, 0],
      ['i/.gitignore', 0, 2, 0],
      ['i/i.txt', 0, 2, 0],
    ])

    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['i'] })
    expect(matrix).toEqual([
      ['i/.gitignore', 0, 2, 0],
      ['i/i.txt', 0, 2, 0],
    ])

    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: [] })
    expect(matrix).toBeUndefined()

    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['i', 'h'] })
    expect(matrix).toEqual([
      ['h/h.txt', 0, 2, 0],
      ['i/.gitignore', 0, 2, 0],
      ['i/i.txt', 0, 2, 0],
    ])
  })",steel
/__tests__/test-statusMatrix.js,Duplicate Assert,"{'line': 282, 'column': 4, 'index': 9500}","it('statusMatrix with filepaths', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-statusMatrix-filepath')
    // Test
    let matrix = await statusMatrix({ fs, dir, gitdir })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 1],
      ['c.txt', 1, 0, 1],
      ['d.txt', 0, 2, 0],
      ['g/g.txt', 0, 2, 0],
      ['h/h.txt', 0, 2, 0],
      ['i/.gitignore', 0, 2, 0],
      ['i/i.txt', 0, 2, 0],
    ])

    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['i'] })
    expect(matrix).toEqual([
      ['i/.gitignore', 0, 2, 0],
      ['i/i.txt', 0, 2, 0],
    ])

    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: [] })
    expect(matrix).toBeUndefined()

    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['i', 'h'] })
    expect(matrix).toEqual([
      ['h/h.txt', 0, 2, 0],
      ['i/.gitignore', 0, 2, 0],
      ['i/i.txt', 0, 2, 0],
    ])
  })",steel
/__tests__/test-statusMatrix.js,Duplicate Assert,"{'line': 288, 'column': 4, 'index': 9666}","it('statusMatrix with filepaths', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-statusMatrix-filepath')
    // Test
    let matrix = await statusMatrix({ fs, dir, gitdir })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 1],
      ['c.txt', 1, 0, 1],
      ['d.txt', 0, 2, 0],
      ['g/g.txt', 0, 2, 0],
      ['h/h.txt', 0, 2, 0],
      ['i/.gitignore', 0, 2, 0],
      ['i/i.txt', 0, 2, 0],
    ])

    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['i'] })
    expect(matrix).toEqual([
      ['i/.gitignore', 0, 2, 0],
      ['i/i.txt', 0, 2, 0],
    ])

    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: [] })
    expect(matrix).toBeUndefined()

    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['i', 'h'] })
    expect(matrix).toEqual([
      ['h/h.txt', 0, 2, 0],
      ['i/.gitignore', 0, 2, 0],
      ['i/i.txt', 0, 2, 0],
    ])
  })",steel
/__tests__/test-statusMatrix.js,Duplicate Assert,"{'line': 291, 'column': 4, 'index': 9778}","it('statusMatrix with filepaths', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-statusMatrix-filepath')
    // Test
    let matrix = await statusMatrix({ fs, dir, gitdir })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 1],
      ['c.txt', 1, 0, 1],
      ['d.txt', 0, 2, 0],
      ['g/g.txt', 0, 2, 0],
      ['h/h.txt', 0, 2, 0],
      ['i/.gitignore', 0, 2, 0],
      ['i/i.txt', 0, 2, 0],
    ])

    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['i'] })
    expect(matrix).toEqual([
      ['i/.gitignore', 0, 2, 0],
      ['i/i.txt', 0, 2, 0],
    ])

    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: [] })
    expect(matrix).toBeUndefined()

    matrix = await statusMatrix({ fs, dir, gitdir, filepaths: ['i', 'h'] })
    expect(matrix).toEqual([
      ['h/h.txt', 0, 2, 0],
      ['i/.gitignore', 0, 2, 0],
      ['i/i.txt', 0, 2, 0],
    ])
  })",steel
/__tests__/test-statusMatrix.js,Duplicate Assert,"{'line': 308, 'column': 4, 'index': 10221}","it('statusMatrix with filter', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-statusMatrix-filepath')
    // Test
    let matrix = await statusMatrix({
      fs,
      dir,
      gitdir,
      filter: filepath => !filepath.includes('/') && filepath.endsWith('.txt'),
    })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 1],
      ['c.txt', 1, 0, 1],
      ['d.txt', 0, 2, 0],
    ])

    matrix = await statusMatrix({
      fs,
      dir,
      gitdir,
      filter: filepath => filepath.endsWith('.gitignore'),
    })
    expect(matrix).toEqual([['i/.gitignore', 0, 2, 0]])

    matrix = await statusMatrix({
      fs,
      dir,
      gitdir,
      filter: filepath => filepath.endsWith('.txt'),
      filepaths: ['i'],
    })
    expect(matrix).toEqual([['i/i.txt', 0, 2, 0]])
  })",steel
/__tests__/test-statusMatrix.js,Duplicate Assert,"{'line': 321, 'column': 4, 'index': 10497}","it('statusMatrix with filter', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-statusMatrix-filepath')
    // Test
    let matrix = await statusMatrix({
      fs,
      dir,
      gitdir,
      filter: filepath => !filepath.includes('/') && filepath.endsWith('.txt'),
    })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 1],
      ['c.txt', 1, 0, 1],
      ['d.txt', 0, 2, 0],
    ])

    matrix = await statusMatrix({
      fs,
      dir,
      gitdir,
      filter: filepath => filepath.endsWith('.gitignore'),
    })
    expect(matrix).toEqual([['i/.gitignore', 0, 2, 0]])

    matrix = await statusMatrix({
      fs,
      dir,
      gitdir,
      filter: filepath => filepath.endsWith('.txt'),
      filepaths: ['i'],
    })
    expect(matrix).toEqual([['i/i.txt', 0, 2, 0]])
  })",steel
/__tests__/test-statusMatrix.js,Duplicate Assert,"{'line': 330, 'column': 4, 'index': 10707}","it('statusMatrix with filter', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-statusMatrix-filepath')
    // Test
    let matrix = await statusMatrix({
      fs,
      dir,
      gitdir,
      filter: filepath => !filepath.includes('/') && filepath.endsWith('.txt'),
    })
    expect(matrix).toEqual([
      ['a.txt', 1, 1, 1],
      ['b.txt', 1, 2, 1],
      ['c.txt', 1, 0, 1],
      ['d.txt', 0, 2, 0],
    ])

    matrix = await statusMatrix({
      fs,
      dir,
      gitdir,
      filter: filepath => filepath.endsWith('.gitignore'),
    })
    expect(matrix).toEqual([['i/.gitignore', 0, 2, 0]])

    matrix = await statusMatrix({
      fs,
      dir,
      gitdir,
      filter: filepath => filepath.endsWith('.txt'),
      filepaths: ['i'],
    })
    expect(matrix).toEqual([['i/i.txt', 0, 2, 0]])
  })",steel
/__tests__/test-statusMatrix.js,Duplicate Assert,"{'line': 346, 'column': 4, 'index': 11166}","it('statusMatrix with removed folder and created file with same name', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-statusMatrix-tree-blob-collision'
    )
    // Test
    await fs.rmdir(path.join(dir, 'a'), { recursive: true })
    await fs.write(path.join(dir, 'a'), 'Hi')
    let matrix = await statusMatrix({
      fs,
      dir,
      gitdir,
    })
    expect(matrix).toEqual([
      ['a', 0, 2, 0],
      ['a/a.txt', 1, 0, 1],
      ['b', 1, 1, 1],
    ])
    await remove({ fs, dir, gitdir, filepath: 'a/a.txt' })
    await add({ fs, dir, gitdir, filepath: 'a' })
    matrix = await statusMatrix({
      fs,
      dir,
      gitdir,
    })
    expect(matrix).toEqual([
      ['a', 0, 2, 2],
      ['a/a.txt', 1, 0, 0],
      ['b', 1, 1, 1],
    ])
  })",steel
/__tests__/test-statusMatrix.js,Duplicate Assert,"{'line': 358, 'column': 4, 'index': 11459}","it('statusMatrix with removed folder and created file with same name', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-statusMatrix-tree-blob-collision'
    )
    // Test
    await fs.rmdir(path.join(dir, 'a'), { recursive: true })
    await fs.write(path.join(dir, 'a'), 'Hi')
    let matrix = await statusMatrix({
      fs,
      dir,
      gitdir,
    })
    expect(matrix).toEqual([
      ['a', 0, 2, 0],
      ['a/a.txt', 1, 0, 1],
      ['b', 1, 1, 1],
    ])
    await remove({ fs, dir, gitdir, filepath: 'a/a.txt' })
    await add({ fs, dir, gitdir, filepath: 'a' })
    matrix = await statusMatrix({
      fs,
      dir,
      gitdir,
    })
    expect(matrix).toEqual([
      ['a', 0, 2, 2],
      ['a/a.txt', 1, 0, 0],
      ['b', 1, 1, 1],
    ])
  })",steel
/__tests__/test-statusMatrix.js,Duplicate Assert,"{'line': 379, 'column': 4, 'index': 11997}","it('statusMatrix with removed file and created folder with same name', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-statusMatrix-blob-tree-collision'
    )
    // Test
    await fs.rm(path.join(dir, 'b'))
    await fs.mkdir(path.join(dir, 'b'))
    await fs.write(path.join(dir, 'b/b.txt'), 'Hi')
    let matrix = await statusMatrix({
      fs,
      dir,
      gitdir,
    })
    expect(matrix).toEqual([
      ['a/a.txt', 1, 1, 1],
      ['b', 1, 0, 1],
      ['b/b.txt', 0, 2, 0],
    ])
    await remove({ fs, dir, gitdir, filepath: 'b' })
    await add({ fs, dir, gitdir, filepath: 'b/b.txt' })
    matrix = await statusMatrix({
      fs,
      dir,
      gitdir,
    })
    expect(matrix).toEqual([
      ['a/a.txt', 1, 1, 1],
      ['b', 1, 0, 0],
      ['b/b.txt', 0, 2, 2],
    ])
  })",steel
/__tests__/test-statusMatrix.js,Duplicate Assert,"{'line': 391, 'column': 4, 'index': 12296}","it('statusMatrix with removed file and created folder with same name', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-statusMatrix-blob-tree-collision'
    )
    // Test
    await fs.rm(path.join(dir, 'b'))
    await fs.mkdir(path.join(dir, 'b'))
    await fs.write(path.join(dir, 'b/b.txt'), 'Hi')
    let matrix = await statusMatrix({
      fs,
      dir,
      gitdir,
    })
    expect(matrix).toEqual([
      ['a/a.txt', 1, 1, 1],
      ['b', 1, 0, 1],
      ['b/b.txt', 0, 2, 0],
    ])
    await remove({ fs, dir, gitdir, filepath: 'b' })
    await add({ fs, dir, gitdir, filepath: 'b/b.txt' })
    matrix = await statusMatrix({
      fs,
      dir,
      gitdir,
    })
    expect(matrix).toEqual([
      ['a/a.txt', 1, 1, 1],
      ['b', 1, 0, 0],
      ['b/b.txt', 0, 2, 2],
    ])
  })",steel
/__tests__/test-stash.js,Conditional Test Logic,"{'line': 19, 'column': 2, 'index': 369}",Unknown,steel
/__tests__/test-stash.js,Conditional Test Logic,"{'line': 23, 'column': 4, 'index': 573}",Unknown,steel
/__tests__/test-stash.js,Conditional Test Logic,"{'line': 31, 'column': 4, 'index': 893}",Unknown,steel
/__tests__/test-stash.js,Conditional Test Logic,"{'line': 78, 'column': 2, 'index': 2132}",Unknown,steel
/__tests__/test-stash.js,Conditional Test Logic,"{'line': 84, 'column': 4, 'index': 2371}",Unknown,steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 475, 'column': 4, 'index': 15643}","it('stash create with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createDeleted')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Files should remain deleted in working directory
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 475, 'column': 4, 'index': 15643}","it('stash create with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createDeleted')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Files should remain deleted in working directory
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 477, 'column': 4, 'index': 15750}","it('stash create with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createDeleted')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Files should remain deleted in working directory
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 477, 'column': 4, 'index': 15750}","it('stash create with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createDeleted')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Files should remain deleted in working directory
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 492, 'column': 4, 'index': 16158}","it('stash create with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createDeleted')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Files should remain deleted in working directory
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 492, 'column': 4, 'index': 16158}","it('stash create with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createDeleted')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Files should remain deleted in working directory
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 494, 'column': 4, 'index': 16261}","it('stash create with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createDeleted')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Files should remain deleted in working directory
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 494, 'column': 4, 'index': 16261}","it('stash create with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createDeleted')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Files should remain deleted in working directory
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 513, 'column': 4, 'index': 17004}","it('stash create with changes in nested folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createNested')
    await addUserConfig(fs, dir, gitdir)

    const cOriginalContent = 'staged changes - c'
    const dOriginalContent = 'staged changes - d'

    await fs.write(`${dir}/folder/c.txt`, cOriginalContent)
    await fs.write(`${dir}/folder/d.js`, dOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })

    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Verify files still exist in working directory
    const cContent = await fs.read(`${dir}/folder/c.txt`)
    expect(cContent.toString()).toEqual(cOriginalContent)
    const dContent = await fs.read(`${dir}/folder/d.js`)
    expect(dContent.toString()).toEqual(dOriginalContent)

    // Verify status remains unchanged
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 513, 'column': 4, 'index': 17004}","it('stash create with changes in nested folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createNested')
    await addUserConfig(fs, dir, gitdir)

    const cOriginalContent = 'staged changes - c'
    const dOriginalContent = 'staged changes - d'

    await fs.write(`${dir}/folder/c.txt`, cOriginalContent)
    await fs.write(`${dir}/folder/d.js`, dOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })

    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Verify files still exist in working directory
    const cContent = await fs.read(`${dir}/folder/c.txt`)
    expect(cContent.toString()).toEqual(cOriginalContent)
    const dContent = await fs.read(`${dir}/folder/d.js`)
    expect(dContent.toString()).toEqual(dOriginalContent)

    // Verify status remains unchanged
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 515, 'column': 4, 'index': 17115}","it('stash create with changes in nested folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createNested')
    await addUserConfig(fs, dir, gitdir)

    const cOriginalContent = 'staged changes - c'
    const dOriginalContent = 'staged changes - d'

    await fs.write(`${dir}/folder/c.txt`, cOriginalContent)
    await fs.write(`${dir}/folder/d.js`, dOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })

    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Verify files still exist in working directory
    const cContent = await fs.read(`${dir}/folder/c.txt`)
    expect(cContent.toString()).toEqual(cOriginalContent)
    const dContent = await fs.read(`${dir}/folder/d.js`)
    expect(dContent.toString()).toEqual(dOriginalContent)

    // Verify status remains unchanged
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 515, 'column': 4, 'index': 17115}","it('stash create with changes in nested folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createNested')
    await addUserConfig(fs, dir, gitdir)

    const cOriginalContent = 'staged changes - c'
    const dOriginalContent = 'staged changes - d'

    await fs.write(`${dir}/folder/c.txt`, cOriginalContent)
    await fs.write(`${dir}/folder/d.js`, dOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })

    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Verify files still exist in working directory
    const cContent = await fs.read(`${dir}/folder/c.txt`)
    expect(cContent.toString()).toEqual(cOriginalContent)
    const dContent = await fs.read(`${dir}/folder/d.js`)
    expect(dContent.toString()).toEqual(dOriginalContent)

    // Verify status remains unchanged
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 536, 'column': 4, 'index': 17795}","it('stash create with changes in nested folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createNested')
    await addUserConfig(fs, dir, gitdir)

    const cOriginalContent = 'staged changes - c'
    const dOriginalContent = 'staged changes - d'

    await fs.write(`${dir}/folder/c.txt`, cOriginalContent)
    await fs.write(`${dir}/folder/d.js`, dOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })

    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Verify files still exist in working directory
    const cContent = await fs.read(`${dir}/folder/c.txt`)
    expect(cContent.toString()).toEqual(cOriginalContent)
    const dContent = await fs.read(`${dir}/folder/d.js`)
    expect(dContent.toString()).toEqual(dOriginalContent)

    // Verify status remains unchanged
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 536, 'column': 4, 'index': 17795}","it('stash create with changes in nested folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createNested')
    await addUserConfig(fs, dir, gitdir)

    const cOriginalContent = 'staged changes - c'
    const dOriginalContent = 'staged changes - d'

    await fs.write(`${dir}/folder/c.txt`, cOriginalContent)
    await fs.write(`${dir}/folder/d.js`, dOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })

    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Verify files still exist in working directory
    const cContent = await fs.read(`${dir}/folder/c.txt`)
    expect(cContent.toString()).toEqual(cOriginalContent)
    const dContent = await fs.read(`${dir}/folder/d.js`)
    expect(dContent.toString()).toEqual(dOriginalContent)

    // Verify status remains unchanged
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 538, 'column': 4, 'index': 17902}","it('stash create with changes in nested folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createNested')
    await addUserConfig(fs, dir, gitdir)

    const cOriginalContent = 'staged changes - c'
    const dOriginalContent = 'staged changes - d'

    await fs.write(`${dir}/folder/c.txt`, cOriginalContent)
    await fs.write(`${dir}/folder/d.js`, dOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })

    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Verify files still exist in working directory
    const cContent = await fs.read(`${dir}/folder/c.txt`)
    expect(cContent.toString()).toEqual(cOriginalContent)
    const dContent = await fs.read(`${dir}/folder/d.js`)
    expect(dContent.toString()).toEqual(dOriginalContent)

    // Verify status remains unchanged
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 538, 'column': 4, 'index': 17902}","it('stash create with changes in nested folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createNested')
    await addUserConfig(fs, dir, gitdir)

    const cOriginalContent = 'staged changes - c'
    const dOriginalContent = 'staged changes - d'

    await fs.write(`${dir}/folder/c.txt`, cOriginalContent)
    await fs.write(`${dir}/folder/d.js`, dOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })

    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Verify files still exist in working directory
    const cContent = await fs.read(`${dir}/folder/c.txt`)
    expect(cContent.toString()).toEqual(cOriginalContent)
    const dContent = await fs.read(`${dir}/folder/d.js`)
    expect(dContent.toString()).toEqual(dOriginalContent)

    // Verify status remains unchanged
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 567, 'column': 4, 'index': 18597}","it('stash create multiple times returns different hashes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createMultiple')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/a.txt`, 'first change')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })

    const firstHash = await stash({
      fs,
      dir,
      gitdir,
      op: 'create',
      message: 'first',
    })

    await fs.write(`${dir}/a.txt`, 'second change')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })

    const secondHash = await stash({
      fs,
      dir,
      gitdir,
      op: 'create',
      message: 'second',
    })

    expect(firstHash).not.toBeNull()
    expect(secondHash).not.toBeNull()
    expect(firstHash).not.toEqual(secondHash)

    // Verify no stash refs were created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 569, 'column': 4, 'index': 18672}","it('stash create multiple times returns different hashes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createMultiple')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/a.txt`, 'first change')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })

    const firstHash = await stash({
      fs,
      dir,
      gitdir,
      op: 'create',
      message: 'first',
    })

    await fs.write(`${dir}/a.txt`, 'second change')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })

    const secondHash = await stash({
      fs,
      dir,
      gitdir,
      op: 'create',
      message: 'second',
    })

    expect(firstHash).not.toBeNull()
    expect(secondHash).not.toBeNull()
    expect(firstHash).not.toEqual(secondHash)

    // Verify no stash refs were created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 586, 'column': 4, 'index': 19358}","it('stash create does not interfere with existing stash list', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createWithExisting')
    await addUserConfig(fs, dir, gitdir)

    // Create a regular stash first
    await fs.write(`${dir}/a.txt`, 'first stash change')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })
    await stash({ fs, dir, gitdir, op: 'push', message: 'regular stash' })

    let stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)

    // Now use stash create
    await fs.write(`${dir}/b.js`, 'create change')
    await add({ fs, dir, gitdir, filepath: ['b.js'] })
    const createHash = await stash({
      fs,
      dir,
      gitdir,
      op: 'create',
      message: 'create stash',
    })

    expect(createHash).not.toBeNull()

    // Verify stash list is unchanged
    stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)
    expect(stashList[0]).toContain('regular stash')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 586, 'column': 4, 'index': 19358}","it('stash create does not interfere with existing stash list', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createWithExisting')
    await addUserConfig(fs, dir, gitdir)

    // Create a regular stash first
    await fs.write(`${dir}/a.txt`, 'first stash change')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })
    await stash({ fs, dir, gitdir, op: 'push', message: 'regular stash' })

    let stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)

    // Now use stash create
    await fs.write(`${dir}/b.js`, 'create change')
    await add({ fs, dir, gitdir, filepath: ['b.js'] })
    const createHash = await stash({
      fs,
      dir,
      gitdir,
      op: 'create',
      message: 'create stash',
    })

    expect(createHash).not.toBeNull()

    // Verify stash list is unchanged
    stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)
    expect(stashList[0]).toContain('regular stash')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 603, 'column': 4, 'index': 19799}","it('stash create does not interfere with existing stash list', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createWithExisting')
    await addUserConfig(fs, dir, gitdir)

    // Create a regular stash first
    await fs.write(`${dir}/a.txt`, 'first stash change')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })
    await stash({ fs, dir, gitdir, op: 'push', message: 'regular stash' })

    let stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)

    // Now use stash create
    await fs.write(`${dir}/b.js`, 'create change')
    await add({ fs, dir, gitdir, filepath: ['b.js'] })
    const createHash = await stash({
      fs,
      dir,
      gitdir,
      op: 'create',
      message: 'create stash',
    })

    expect(createHash).not.toBeNull()

    // Verify stash list is unchanged
    stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)
    expect(stashList[0]).toContain('regular stash')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 603, 'column': 4, 'index': 19799}","it('stash create does not interfere with existing stash list', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createWithExisting')
    await addUserConfig(fs, dir, gitdir)

    // Create a regular stash first
    await fs.write(`${dir}/a.txt`, 'first stash change')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })
    await stash({ fs, dir, gitdir, op: 'push', message: 'regular stash' })

    let stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)

    // Now use stash create
    await fs.write(`${dir}/b.js`, 'create change')
    await add({ fs, dir, gitdir, filepath: ['b.js'] })
    const createHash = await stash({
      fs,
      dir,
      gitdir,
      op: 'create',
      message: 'create stash',
    })

    expect(createHash).not.toBeNull()

    // Verify stash list is unchanged
    stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)
    expect(stashList[0]).toContain('regular stash')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 733, 'column': 4, 'index': 24451}","it('stash apply with staged changes under two folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFour')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/folder/c.txt`, 'staged changes - c')
    await fs.write(`${dir}/folder/d.js`, 'staged changes - d')

    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })
    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })
      aStatus = await status({
        fs,
        dir,
        gitdir,
        filepath: 'folder/c.txt',
      })
      expect(aStatus).toBe('absent')
      bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
      expect(bStatus).toBe('absent')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 733, 'column': 4, 'index': 24451}","it('stash apply with staged changes under two folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFour')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/folder/c.txt`, 'staged changes - c')
    await fs.write(`${dir}/folder/d.js`, 'staged changes - d')

    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })
    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })
      aStatus = await status({
        fs,
        dir,
        gitdir,
        filepath: 'folder/c.txt',
      })
      expect(aStatus).toBe('absent')
      bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
      expect(bStatus).toBe('absent')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 735, 'column': 4, 'index': 24562}","it('stash apply with staged changes under two folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFour')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/folder/c.txt`, 'staged changes - c')
    await fs.write(`${dir}/folder/d.js`, 'staged changes - d')

    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })
    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })
      aStatus = await status({
        fs,
        dir,
        gitdir,
        filepath: 'folder/c.txt',
      })
      expect(aStatus).toBe('absent')
      bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
      expect(bStatus).toBe('absent')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 735, 'column': 4, 'index': 24562}","it('stash apply with staged changes under two folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFour')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/folder/c.txt`, 'staged changes - c')
    await fs.write(`${dir}/folder/d.js`, 'staged changes - d')

    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })
    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })
      aStatus = await status({
        fs,
        dir,
        gitdir,
        filepath: 'folder/c.txt',
      })
      expect(aStatus).toBe('absent')
      bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
      expect(bStatus).toBe('absent')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 746, 'column': 6, 'index': 24796}","it('stash apply with staged changes under two folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFour')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/folder/c.txt`, 'staged changes - c')
    await fs.write(`${dir}/folder/d.js`, 'staged changes - d')

    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })
    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })
      aStatus = await status({
        fs,
        dir,
        gitdir,
        filepath: 'folder/c.txt',
      })
      expect(aStatus).toBe('absent')
      bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
      expect(bStatus).toBe('absent')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 748, 'column': 6, 'index': 24908}","it('stash apply with staged changes under two folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFour')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/folder/c.txt`, 'staged changes - c')
    await fs.write(`${dir}/folder/d.js`, 'staged changes - d')

    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })
    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })
      aStatus = await status({
        fs,
        dir,
        gitdir,
        filepath: 'folder/c.txt',
      })
      expect(aStatus).toBe('absent')
      bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
      expect(bStatus).toBe('absent')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 757, 'column': 4, 'index': 25140}","it('stash apply with staged changes under two folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFour')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/folder/c.txt`, 'staged changes - c')
    await fs.write(`${dir}/folder/d.js`, 'staged changes - d')

    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })
    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })
      aStatus = await status({
        fs,
        dir,
        gitdir,
        filepath: 'folder/c.txt',
      })
      expect(aStatus).toBe('absent')
      bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
      expect(bStatus).toBe('absent')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 757, 'column': 4, 'index': 25140}","it('stash apply with staged changes under two folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFour')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/folder/c.txt`, 'staged changes - c')
    await fs.write(`${dir}/folder/d.js`, 'staged changes - d')

    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })
    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })
      aStatus = await status({
        fs,
        dir,
        gitdir,
        filepath: 'folder/c.txt',
      })
      expect(aStatus).toBe('absent')
      bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
      expect(bStatus).toBe('absent')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 759, 'column': 4, 'index': 25247}","it('stash apply with staged changes under two folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFour')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/folder/c.txt`, 'staged changes - c')
    await fs.write(`${dir}/folder/d.js`, 'staged changes - d')

    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })
    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })
      aStatus = await status({
        fs,
        dir,
        gitdir,
        filepath: 'folder/c.txt',
      })
      expect(aStatus).toBe('absent')
      bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
      expect(bStatus).toBe('absent')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 759, 'column': 4, 'index': 25247}","it('stash apply with staged changes under two folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFour')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/folder/c.txt`, 'staged changes - c')
    await fs.write(`${dir}/folder/d.js`, 'staged changes - d')

    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })
    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })
      aStatus = await status({
        fs,
        dir,
        gitdir,
        filepath: 'folder/c.txt',
      })
      expect(aStatus).toBe('absent')
      bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
      expect(bStatus).toBe('absent')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 770, 'column': 4, 'index': 25585}","it('stash apply with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFive')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 770, 'column': 4, 'index': 25585}","it('stash apply with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFive')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 772, 'column': 4, 'index': 25692}","it('stash apply with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFive')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 772, 'column': 4, 'index': 25692}","it('stash apply with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFive')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 779, 'column': 6, 'index': 25884}","it('stash apply with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFive')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 781, 'column': 6, 'index': 25993}","it('stash apply with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFive')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 790, 'column': 4, 'index': 26222}","it('stash apply with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFive')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 790, 'column': 4, 'index': 26222}","it('stash apply with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFive')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 792, 'column': 4, 'index': 26325}","it('stash apply with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFive')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 792, 'column': 4, 'index': 26325}","it('stash apply with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFive')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 803, 'column': 4, 'index': 26709}","it('stash apply with deleted files and staged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySix')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.write(`${dir}/b.js`, 'staged changes - b')

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*modified')

    await add({ fs, dir, gitdir, filepath: ['b.js'] })

    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 803, 'column': 4, 'index': 26709}","it('stash apply with deleted files and staged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySix')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.write(`${dir}/b.js`, 'staged changes - b')

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*modified')

    await add({ fs, dir, gitdir, filepath: ['b.js'] })

    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 805, 'column': 4, 'index': 26816}","it('stash apply with deleted files and staged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySix')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.write(`${dir}/b.js`, 'staged changes - b')

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*modified')

    await add({ fs, dir, gitdir, filepath: ['b.js'] })

    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 810, 'column': 4, 'index': 26977}","it('stash apply with deleted files and staged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySix')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.write(`${dir}/b.js`, 'staged changes - b')

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*modified')

    await add({ fs, dir, gitdir, filepath: ['b.js'] })

    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 810, 'column': 4, 'index': 26977}","it('stash apply with deleted files and staged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySix')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.write(`${dir}/b.js`, 'staged changes - b')

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*modified')

    await add({ fs, dir, gitdir, filepath: ['b.js'] })

    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 817, 'column': 6, 'index': 27169}","it('stash apply with deleted files and staged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySix')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.write(`${dir}/b.js`, 'staged changes - b')

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*modified')

    await add({ fs, dir, gitdir, filepath: ['b.js'] })

    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 819, 'column': 6, 'index': 27278}","it('stash apply with deleted files and staged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySix')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.write(`${dir}/b.js`, 'staged changes - b')

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*modified')

    await add({ fs, dir, gitdir, filepath: ['b.js'] })

    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 828, 'column': 4, 'index': 27507}","it('stash apply with deleted files and staged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySix')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.write(`${dir}/b.js`, 'staged changes - b')

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*modified')

    await add({ fs, dir, gitdir, filepath: ['b.js'] })

    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 828, 'column': 4, 'index': 27507}","it('stash apply with deleted files and staged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySix')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.write(`${dir}/b.js`, 'staged changes - b')

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*modified')

    await add({ fs, dir, gitdir, filepath: ['b.js'] })

    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 830, 'column': 4, 'index': 27610}","it('stash apply with deleted files and staged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySix')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.write(`${dir}/b.js`, 'staged changes - b')

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*modified')

    await add({ fs, dir, gitdir, filepath: ['b.js'] })

    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 830, 'column': 4, 'index': 27610}","it('stash apply with deleted files and staged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySix')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.write(`${dir}/b.js`, 'staged changes - b')

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*modified')

    await add({ fs, dir, gitdir, filepath: ['b.js'] })

    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 852, 'column': 4, 'index': 28291}","it('stash apply with delete folder', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySeven')
    await addUserConfig(fs, dir, gitdir)

    await fs.mkdir(`${dir}/folder`)
    await fs.write(`${dir}/folder/e.js`, 'commited change - e')
    await add({ fs, dir, gitdir, filepath: ['folder', 'folder/e.js'] })
    await commit({
      fs,
      dir,
      gitdir,
      author: { name: 'author', email: 'author@test' },
      message: 'add folder',
    })

    // await fs.rmdir(`${dir}/folder`)
    await fs.rm(`${dir}/folder/e.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
    expect(aStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
      expect(aStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
    expect(aStatus).toBe('*deleted')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 852, 'column': 4, 'index': 28291}","it('stash apply with delete folder', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySeven')
    await addUserConfig(fs, dir, gitdir)

    await fs.mkdir(`${dir}/folder`)
    await fs.write(`${dir}/folder/e.js`, 'commited change - e')
    await add({ fs, dir, gitdir, filepath: ['folder', 'folder/e.js'] })
    await commit({
      fs,
      dir,
      gitdir,
      author: { name: 'author', email: 'author@test' },
      message: 'add folder',
    })

    // await fs.rmdir(`${dir}/folder`)
    await fs.rm(`${dir}/folder/e.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
    expect(aStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
      expect(aStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
    expect(aStatus).toBe('*deleted')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 859, 'column': 6, 'index': 28489}","it('stash apply with delete folder', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySeven')
    await addUserConfig(fs, dir, gitdir)

    await fs.mkdir(`${dir}/folder`)
    await fs.write(`${dir}/folder/e.js`, 'commited change - e')
    await add({ fs, dir, gitdir, filepath: ['folder', 'folder/e.js'] })
    await commit({
      fs,
      dir,
      gitdir,
      author: { name: 'author', email: 'author@test' },
      message: 'add folder',
    })

    // await fs.rmdir(`${dir}/folder`)
    await fs.rm(`${dir}/folder/e.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
    expect(aStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
      expect(aStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
    expect(aStatus).toBe('*deleted')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 868, 'column': 4, 'index': 28724}","it('stash apply with delete folder', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySeven')
    await addUserConfig(fs, dir, gitdir)

    await fs.mkdir(`${dir}/folder`)
    await fs.write(`${dir}/folder/e.js`, 'commited change - e')
    await add({ fs, dir, gitdir, filepath: ['folder', 'folder/e.js'] })
    await commit({
      fs,
      dir,
      gitdir,
      author: { name: 'author', email: 'author@test' },
      message: 'add folder',
    })

    // await fs.rmdir(`${dir}/folder`)
    await fs.rm(`${dir}/folder/e.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
    expect(aStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
      expect(aStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
    expect(aStatus).toBe('*deleted')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 868, 'column': 4, 'index': 28724}","it('stash apply with delete folder', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySeven')
    await addUserConfig(fs, dir, gitdir)

    await fs.mkdir(`${dir}/folder`)
    await fs.write(`${dir}/folder/e.js`, 'commited change - e')
    await add({ fs, dir, gitdir, filepath: ['folder', 'folder/e.js'] })
    await commit({
      fs,
      dir,
      gitdir,
      author: { name: 'author', email: 'author@test' },
      message: 'add folder',
    })

    // await fs.rmdir(`${dir}/folder`)
    await fs.rm(`${dir}/folder/e.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
    expect(aStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
      expect(aStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
    expect(aStatus).toBe('*deleted')
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 1254, 'column': 4, 'index': 40984}","it('should not lose stashes after stash pop followed by stash push', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('stashRegression')
    await addUserConfig(fs, dir, gitdir)

    // --- stash 1 ---
    await fs.write(dir + '/a.txt', 'change 1')
    await stash({ fs, dir, gitdir, message: 'stash 1', op: 'push' })
    // --- stash 2 ---
    await fs.write(dir + '/a.txt', 'change 2')
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    let stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)

    // Pop stash 2
    await stash({ fs, dir, gitdir, op: 'pop' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(1)
    // Push stash 2 again
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 1254, 'column': 4, 'index': 40984}","it('should not lose stashes after stash pop followed by stash push', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('stashRegression')
    await addUserConfig(fs, dir, gitdir)

    // --- stash 1 ---
    await fs.write(dir + '/a.txt', 'change 1')
    await stash({ fs, dir, gitdir, message: 'stash 1', op: 'push' })
    // --- stash 2 ---
    await fs.write(dir + '/a.txt', 'change 2')
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    let stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)

    // Pop stash 2
    await stash({ fs, dir, gitdir, op: 'pop' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(1)
    // Push stash 2 again
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 1260, 'column': 4, 'index': 41147}","it('should not lose stashes after stash pop followed by stash push', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('stashRegression')
    await addUserConfig(fs, dir, gitdir)

    // --- stash 1 ---
    await fs.write(dir + '/a.txt', 'change 1')
    await stash({ fs, dir, gitdir, message: 'stash 1', op: 'push' })
    // --- stash 2 ---
    await fs.write(dir + '/a.txt', 'change 2')
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    let stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)

    // Pop stash 2
    await stash({ fs, dir, gitdir, op: 'pop' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(1)
    // Push stash 2 again
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 1265, 'column': 4, 'index': 41337}","it('should not lose stashes after stash pop followed by stash push', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('stashRegression')
    await addUserConfig(fs, dir, gitdir)

    // --- stash 1 ---
    await fs.write(dir + '/a.txt', 'change 1')
    await stash({ fs, dir, gitdir, message: 'stash 1', op: 'push' })
    // --- stash 2 ---
    await fs.write(dir + '/a.txt', 'change 2')
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    let stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)

    // Pop stash 2
    await stash({ fs, dir, gitdir, op: 'pop' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(1)
    // Push stash 2 again
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 1265, 'column': 4, 'index': 41337}","it('should not lose stashes after stash pop followed by stash push', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('stashRegression')
    await addUserConfig(fs, dir, gitdir)

    // --- stash 1 ---
    await fs.write(dir + '/a.txt', 'change 1')
    await stash({ fs, dir, gitdir, message: 'stash 1', op: 'push' })
    // --- stash 2 ---
    await fs.write(dir + '/a.txt', 'change 2')
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    let stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)

    // Pop stash 2
    await stash({ fs, dir, gitdir, op: 'pop' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(1)
    // Push stash 2 again
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 1284, 'column': 4, 'index': 42043}","it('stash list order before and after stash drop', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('stashRegression')
    await addUserConfig(fs, dir, gitdir)

    // --- stash 1 ---
    await fs.write(dir + '/a.txt', 'change 1')
    await stash({ fs, dir, gitdir, message: 'stash 1', op: 'push' })
    // --- stash 2 ---
    await fs.write(dir + '/a.txt', 'change 2')
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    // --- stash 3 ---
    await fs.write(dir + '/a.txt', 'change 3')
    await stash({ fs, dir, gitdir, message: 'stash 3', op: 'push' })

    let stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes).toEqual([
      'stash@{0}: stash 3: 3ca31f1 initial commit',
      'stash@{1}: stash 2: 3ca31f1 initial commit',
      'stash@{2}: stash 1: 3ca31f1 initial commit',
    ])

    // drop stash 3
    await stash({ fs, dir, gitdir, op: 'drop' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes).toEqual([
      'stash@{0}: stash 2: 3ca31f1 initial commit',
      'stash@{1}: stash 1: 3ca31f1 initial commit',
    ])
  })",steel
/__tests__/test-stash.js,Duplicate Assert,"{'line': 1294, 'column': 4, 'index': 42366}","it('stash list order before and after stash drop', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('stashRegression')
    await addUserConfig(fs, dir, gitdir)

    // --- stash 1 ---
    await fs.write(dir + '/a.txt', 'change 1')
    await stash({ fs, dir, gitdir, message: 'stash 1', op: 'push' })
    // --- stash 2 ---
    await fs.write(dir + '/a.txt', 'change 2')
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    // --- stash 3 ---
    await fs.write(dir + '/a.txt', 'change 3')
    await stash({ fs, dir, gitdir, message: 'stash 3', op: 'push' })

    let stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes).toEqual([
      'stash@{0}: stash 3: 3ca31f1 initial commit',
      'stash@{1}: stash 2: 3ca31f1 initial commit',
      'stash@{2}: stash 1: 3ca31f1 initial commit',
    ])

    // drop stash 3
    await stash({ fs, dir, gitdir, op: 'drop' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes).toEqual([
      'stash@{0}: stash 2: 3ca31f1 initial commit',
      'stash@{1}: stash 1: 3ca31f1 initial commit',
    ])
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 118, 'column': 4, 'index': 3494}","it('stash without user', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('test-stash')

    let error = null
    try {
      await stash({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.stash')
    expect(error.code).toEqual(Errors.MissingNameError.code)
    expect(error.data.role).toEqual('author')
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 137, 'column': 4, 'index': 3979}","it('stash with no changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('test-stash')

    // add user to config
    await addUserConfig(fs, dir, gitdir)

    let error = null
    try {
      await stash({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.stash')
    expect(error.code).toEqual(Errors.NotFoundError.code)
    expect(error.data.what).toEqual('changes, nothing to stash')
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 160, 'column': 4, 'index': 4688}","it('stash with untracked files - no other changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('pushUntracked')

    const cContentBeforeStash = 'untracked file - c'
    const dContentBeforeStash = 'untracked file - d'

    // Create untracked files
    await fs.write(`${dir}/c.txt`, cContentBeforeStash)
    await fs.write(`${dir}/d.js`, dContentBeforeStash)

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })
    } catch (e) {
      error = e // should come here since no changes to stash
    }

    expect(error).not.toBeNull()
    const cContentAfterStash = await fs.read(`${dir}/c.txt`)
    const dContentAfterStash = await fs.read(`${dir}/d.js`)

    expect(cContentAfterStash.toString()).toEqual(cContentBeforeStash)
    expect(dContentAfterStash.toString()).toEqual(dContentBeforeStash)
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 208, 'column': 4, 'index': 6464}","it('stash with untracked files - with other changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('pushUntracked')

    await addUserConfig(fs, dir, gitdir)
    await fs.write(`${dir}/a.txt`, 'staged changes - a')
    await fs.write(`${dir}/b.js`, 'staged changes - b')

    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })

    const cContentBeforeStash = 'untracked file - c'
    const dContentBeforeStash = 'console.log(""untracked file - d"")'

    // Create untracked files
    await fs.write(`${dir}/c.txt`, cContentBeforeStash)
    await fs.write(`${dir}/d.js`, dContentBeforeStash)

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const cContentAfterStash = await fs.read(`${dir}/c.txt`)
    const dContentAfterStash = await fs.read(`${dir}/d.js`)

    expect(cContentAfterStash.toString()).toEqual(cContentBeforeStash)
    expect(dContentAfterStash.toString()).toEqual(dContentBeforeStash)
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 228, 'column': 4, 'index': 7047}","it('stash create without user', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('test-stash-create')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.stash')
    expect(error.code).toEqual(Errors.MissingNameError.code)
    expect(error.data.role).toEqual('author')
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 247, 'column': 4, 'index': 7560}","it('stash create with no changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('test-stash-create')

    // add user to config
    await addUserConfig(fs, dir, gitdir)

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.stash')
    expect(error.code).toEqual(Errors.NotFoundError.code)
    expect(error.data.what).toEqual('changes, nothing to stash')
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 277, 'column': 4, 'index': 8656}","it('stash create with staged changes - returns commit hash without modifying working dir', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createOne')
    await addUserConfig(fs, dir, gitdir)

    const aOriginalContent = 'staged changes - a'
    const bOriginalContent = 'staged changes - b'

    await fs.write(`${dir}/a.txt`, aOriginalContent)
    await fs.write(`${dir}/b.js`, bOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })

    const aStatusBefore = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatusBefore).toBe('modified')
    const bStatusBefore = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatusBefore).toBe('modified')

    let stashCommitHash = null
    let error = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()
    expect(typeof stashCommitHash).toBe('string')
    expect(stashCommitHash.length).toBe(40) // SHA-1 hash length

    // Verify working directory is NOT modified
    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual(aOriginalContent)
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual(bOriginalContent)

    // Verify status is still modified
    const aStatusAfter = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatusAfter).toBe('modified')
    const bStatusAfter = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatusAfter).toBe('modified')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 321, 'column': 4, 'index': 10269}","it('stash create with staged and unstaged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createTwo')
    await addUserConfig(fs, dir, gitdir)

    const aOriginalContent = 'staged changes - a'
    const bOriginalContent = 'staged changes - b'
    const mOriginalContent = '<unstaged>m</unstaged>'

    await fs.write(`${dir}/a.txt`, aOriginalContent)
    await fs.write(`${dir}/b.js`, bOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })

    await fs.write(`${dir}/m.xml`, mOriginalContent)

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({
        fs,
        dir,
        gitdir,
        op: 'create',
        message: 'custom message',
      })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()
    expect(typeof stashCommitHash).toBe('string')

    // Verify working directory is NOT modified
    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual(aOriginalContent)
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual(bOriginalContent)
    const mContent = await fs.read(`${dir}/m.xml`)
    expect(mContent.toString()).toEqual(mOriginalContent)

    // Verify status remains unchanged
    const aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('modified')
    const bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
    const mStatus = await status({ fs, dir, gitdir, filepath: 'm.xml' })
    expect(mStatus).toBe('*modified')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 375, 'column': 4, 'index': 12155}","it('stash create with staged and unstaged changes on same file', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createThree')
    await addUserConfig(fs, dir, gitdir)

    const aStagedContent = 'staged changes - a'
    const aUnstagedContent = 'unstaged changes - a - again'

    await fs.write(`${dir}/a.txt`, aStagedContent)
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })
    await fs.write(`${dir}/a.txt`, aUnstagedContent)

    const bOriginalContent = 'staged changes - b'
    await fs.write(`${dir}/b.js`, bOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['b.js'] })

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Verify working directory is NOT modified
    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual(aUnstagedContent)
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual(bOriginalContent)

    // Verify status remains unchanged
    const aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*modified')
    const bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 408, 'column': 4, 'index': 13301}","it('stash create with untracked files - no other changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createUntracked')

    const cContentBeforeStash = 'untracked file - c'
    const dContentBeforeStash = 'untracked file - d'

    // Create untracked files
    await fs.write(`${dir}/c.txt`, cContentBeforeStash)
    await fs.write(`${dir}/d.js`, dContentBeforeStash)

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e // should come here since no changes to stash
    }

    expect(error).not.toBeNull()
    const cContentAfterStash = await fs.read(`${dir}/c.txt`)
    const dContentAfterStash = await fs.read(`${dir}/d.js`)

    expect(cContentAfterStash.toString()).toEqual(cContentBeforeStash)
    expect(dContentAfterStash.toString()).toEqual(dContentBeforeStash)
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 444, 'column': 4, 'index': 14557}","it('stash create with untracked files - with other changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash(
      'createUntrackedWithChanges'
    )

    await addUserConfig(fs, dir, gitdir)
    const aOriginalContent = 'staged changes - a'
    const bOriginalContent = 'staged changes - b'

    await fs.write(`${dir}/a.txt`, aOriginalContent)
    await fs.write(`${dir}/b.js`, bOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })

    const cContentBeforeStash = 'untracked file - c'
    const dContentBeforeStash = 'console.log(""untracked file - d"")'

    // Create untracked files
    await fs.write(`${dir}/c.txt`, cContentBeforeStash)
    await fs.write(`${dir}/d.js`, dContentBeforeStash)

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Untracked files should remain unchanged
    const cContentAfterStash = await fs.read(`${dir}/c.txt`)
    const dContentAfterStash = await fs.read(`${dir}/d.js`)

    expect(cContentAfterStash.toString()).toEqual(cContentBeforeStash)
    expect(dContentAfterStash.toString()).toEqual(dContentBeforeStash)

    // Tracked files should remain in modified state
    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual(aOriginalContent)
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual(bOriginalContent)
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 481, 'column': 4, 'index': 15840}","it('stash create with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createDeleted')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Files should remain deleted in working directory
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 519, 'column': 4, 'index': 17202}","it('stash create with changes in nested folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createNested')
    await addUserConfig(fs, dir, gitdir)

    const cOriginalContent = 'staged changes - c'
    const dOriginalContent = 'staged changes - d'

    await fs.write(`${dir}/folder/c.txt`, cOriginalContent)
    await fs.write(`${dir}/folder/d.js`, dOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })

    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Verify files still exist in working directory
    const cContent = await fs.read(`${dir}/folder/c.txt`)
    expect(cContent.toString()).toEqual(cOriginalContent)
    const dContent = await fs.read(`${dir}/folder/d.js`)
    expect(dContent.toString()).toEqual(dOriginalContent)

    // Verify status remains unchanged
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 618, 'column': 4, 'index': 20276}","it('stash create with custom message', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createMessage')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/a.txt`, 'test content')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })

    const customMessage = 'my custom stash message'
    let stashCommitHash = null
    let error = null

    try {
      stashCommitHash = await stash({
        fs,
        dir,
        gitdir,
        op: 'create',
        message: customMessage,
      })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()
    expect(typeof stashCommitHash).toBe('string')
    expect(stashCommitHash.length).toBe(40)

    // Read the commit to verify message format
    const commitObj = await readCommit({
      fs,
      dir,
      gitdir,
      oid: stashCommitHash,
    })
    expect(commitObj.commit.message).toContain(customMessage)
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 653, 'column': 4, 'index': 21119}","it('stash apply with staged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyOne')

    await stashChanges(fs, dir, gitdir, false, false) // no unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual('staged changes - a') // make sure the staged changes are applied
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual('staged changes - b') // make sure the staged changes are applied

    expect(error).toBeNull()
    const aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('modified')
    const bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 677, 'column': 4, 'index': 22035}","it('stash apply with staged and unstaged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyTwo')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual('staged changes - a') // make sure the staged changes are applied
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual('staged changes - b') // make sure the staged changes are applied
    const mContent = await fs.read(`${dir}/m.xml`)
    expect(mContent.toString()).toEqual('<unstaged>m</unstaged>') // make sure the unstaged changes are applied

    expect(error).toBeNull()
    const aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('modified')
    const bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
    const mStatus = await status({ fs, dir, gitdir, filepath: 'm.xml' })
    expect(mStatus).toBe('*modified') // m.xml is not staged
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 705, 'column': 4, 'index': 23268}","it('stash apply with staged and unstaged changes, include same file', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyThree')

    await stashChanges(fs, dir, gitdir, true, true) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*modified') // a.txt has both staged and unstaged changes

    const againContent = await fs.read(`${dir}/a.txt`)
    expect(againContent.toString()).toEqual('unstaged changes - a - again') // make sure the unstaged changes are applied

    const bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
    const mStatus = await status({ fs, dir, gitdir, filepath: 'm.xml' })
    expect(mStatus).toBe('*modified') // m.xml is not staged
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 738, 'column': 4, 'index': 24618}","it('stash apply with staged changes under two folders', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFour')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/folder/c.txt`, 'staged changes - c')
    await fs.write(`${dir}/folder/d.js`, 'staged changes - d')

    await add({ fs, dir, gitdir, filepath: ['folder/c.txt', 'folder/d.js'] })
    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })
      aStatus = await status({
        fs,
        dir,
        gitdir,
        filepath: 'folder/c.txt',
      })
      expect(aStatus).toBe('absent')
      bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
      expect(bStatus).toBe('absent')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/c.txt' })
    expect(aStatus).toBe('added')
    bStatus = await status({ fs, dir, gitdir, filepath: 'folder/d.js' })
    expect(bStatus).toBe('added')
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 775, 'column': 4, 'index': 25751}","it('stash apply with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyFive')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 813, 'column': 4, 'index': 27036}","it('stash apply with deleted files and staged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySix')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.write(`${dir}/b.js`, 'staged changes - b')

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*modified')

    await add({ fs, dir, gitdir, filepath: ['b.js'] })

    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
      expect(aStatus).toBe('unmodified')
      bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
      expect(bStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 855, 'column': 4, 'index': 28350}","it('stash apply with delete folder', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applySeven')
    await addUserConfig(fs, dir, gitdir)

    await fs.mkdir(`${dir}/folder`)
    await fs.write(`${dir}/folder/e.js`, 'commited change - e')
    await add({ fs, dir, gitdir, filepath: ['folder', 'folder/e.js'] })
    await commit({
      fs,
      dir,
      gitdir,
      author: { name: 'author', email: 'author@test' },
      message: 'add folder',
    })

    // await fs.rmdir(`${dir}/folder`)
    await fs.rm(`${dir}/folder/e.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
    expect(aStatus).toBe('*deleted')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })

      aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
      expect(aStatus).toBe('unmodified')

      await stash({ fs, dir, gitdir, op: 'apply' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    aStatus = await status({ fs, dir, gitdir, filepath: 'folder/e.js' })
    expect(aStatus).toBe('*deleted')
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 885, 'column': 4, 'index': 29337}","it('stash apply with untracked files - with other staged and unstaged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyUntracked')

    await addUserConfig(fs, dir, gitdir)
    await fs.write(`${dir}/a.txt`, 'staged changes - a')
    await fs.write(`${dir}/b.js`, 'unstaged changes - b')

    await add({ fs, dir, gitdir, filepath: ['a.txt'] }) // only staged a.txt

    // Create untracked files
    await fs.write(`${dir}/c.txt`, 'untracked file - c')
    await fs.write(`${dir}/d.js`, 'untracked file - d')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'push' })
      const cContentBeforeApply = await fs.read(`${dir}/c.txt`)
      const dContentBeforeStash = await fs.read(`${dir}/d.js`)

      await stash({ fs, dir, gitdir, op: 'apply' })

      const cContentAfterApply = await fs.read(`${dir}/c.txt`)
      const dContentAfterStash = await fs.read(`${dir}/d.js`)

      expect(cContentAfterApply.toString()).toEqual(
        cContentBeforeApply.toString()
      )
      expect(dContentAfterStash.toString()).toEqual(
        dContentBeforeStash.toString()
      )
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 914, 'column': 4, 'index': 30224}","it('stash apply with invalid ref idx', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyInvalidRefIdx')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'apply', refIdx: 1 })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.stash')
    expect(error.code).toEqual(Errors.InvalidRefNameError.code)
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 941, 'column': 4, 'index': 31183}","it('stash apply with non-default ref idx', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('applyInvalidRefIdx')

    await stashChanges(fs, dir, gitdir, false, false, 'stash one') // no unstaged changes

    const aOriginalContent = 'stash two staged changes - aa'
    const bOriginalContent = 'console.log(""stash two staged changes - bb"")'
    await fs.write(`${dir}/a.txt`, aOriginalContent)
    await fs.write(`${dir}/b.js`, bOriginalContent)

    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })
    await stash({ fs, dir, gitdir, op: 'push', message: 'stash two' })

    await stashChanges(fs, dir, gitdir, true, true, 'stash three')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'apply', refIdx: 1 })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual(aOriginalContent) // make sure the 2nd staged changes are applied
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual(bOriginalContent) // make sure the 2nd staged changes are applied
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 1014, 'column': 4, 'index': 33791}","it('stash drop with no stash', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('dropWithNoStash')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'drop' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 1029, 'column': 4, 'index': 34152}","it('stash drop with stash', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('test-stash')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'drop' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 1046, 'column': 4, 'index': 34623}","it('stash drop with invalid ref idx', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('dropInvalidRefIdx')

    await stashChanges(fs, dir, gitdir, false, false) // no unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'drop', refIdx: 1 })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.stash')
    expect(error.code).toEqual(Errors.InvalidRefNameError.code)
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 1071, 'column': 4, 'index': 35468}","it('stash drop with non-default ref idx', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('dropValidRefIdx')

    await stashChanges(fs, dir, gitdir, false, false, 'stash one') // no unstaged changes

    await fs.write(`${dir}/a.txt`, 'stash two staged changes - a')
    await fs.write(`${dir}/b.js`, 'stash two staged changes - b')

    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })
    await stash({ fs, dir, gitdir, op: 'push', message: 'stash two' })

    await stashChanges(fs, dir, gitdir, true, true, 'stash three')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'drop', refIdx: 1 })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()

    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList).toEqual([
      'stash@{0}: stash three: 3ca31f1 initial commit',
      'stash@{1}: stash one: 3ca31f1 initial commit',
    ])
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 1092, 'column': 4, 'index': 36007}","it('stash clear with no stash', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('test-stash')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'clear' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 1107, 'column': 4, 'index': 36370}","it('stash clear with stash', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('test-stash')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'clear' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 1125, 'column': 4, 'index': 36929}","it('stash clear with 2 stashes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('test-stash')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes
    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'clear' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 1142, 'column': 4, 'index': 37337}","it('stash pop with no stash', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('popOne')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'pop' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 1157, 'column': 4, 'index': 37694}","it('stash pop with 1 stash', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('popTwo')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'pop' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 1175, 'column': 4, 'index': 38247}","it('stash pop with 2 stashes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('popThree')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes
    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'pop' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 1193, 'column': 4, 'index': 38793}","it('stash pop with invalid ref idx', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('popInvalidRefIdx')

    await stashChanges(fs, dir, gitdir, false, false) // no unstaged changes
    await stashChanges(fs, dir, gitdir, true, false) // plus unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'pop', refIdx: 2 })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.stash')
    expect(error.code).toEqual(Errors.InvalidRefNameError.code)
  })",steel
/__tests__/test-stash.js,Exception Handling,"{'line': 1221, 'column': 4, 'index': 39728}","it('stash pop with non-default ref idx', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('dropValidRefIdx')

    await stashChanges(fs, dir, gitdir, false, false, 'stash one') // no unstaged changes

    const aNewContent = 'stash two staged changes - aaa'
    const bNewContent = 'console.log(""stash two staged changes - bbb"")'

    await fs.write(`${dir}/a.txt`, aNewContent)
    await fs.write(`${dir}/b.js`, bNewContent)

    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })
    await stash({ fs, dir, gitdir, op: 'push', message: 'stash two' })

    await stashChanges(fs, dir, gitdir, true, true, 'stash three')

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'pop', refIdx: 1 })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()

    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList).toEqual([
      'stash@{0}: stash three: 3ca31f1 initial commit',
      'stash@{1}: stash one: 3ca31f1 initial commit',
    ])
    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual(aNewContent) // make sure the 2nd staged changes are applied
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual(bNewContent) // make sure the 2nd staged changes are applied
  })",steel
/__tests__/test-stash.js,Magic Number,"{'line': 286, 'column': 40, 'index': 8936}","it('stash create with staged changes - returns commit hash without modifying working dir', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createOne')
    await addUserConfig(fs, dir, gitdir)

    const aOriginalContent = 'staged changes - a'
    const bOriginalContent = 'staged changes - b'

    await fs.write(`${dir}/a.txt`, aOriginalContent)
    await fs.write(`${dir}/b.js`, bOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })

    const aStatusBefore = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatusBefore).toBe('modified')
    const bStatusBefore = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatusBefore).toBe('modified')

    let stashCommitHash = null
    let error = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()
    expect(typeof stashCommitHash).toBe('string')
    expect(stashCommitHash.length).toBe(40) // SHA-1 hash length

    // Verify working directory is NOT modified
    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual(aOriginalContent)
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual(bOriginalContent)

    // Verify status is still modified
    const aStatusAfter = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatusAfter).toBe('modified')
    const bStatusAfter = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatusAfter).toBe('modified')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Magic Number,"{'line': 302, 'column': 34, 'index': 9647}","it('stash create with staged changes - returns commit hash without modifying working dir', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createOne')
    await addUserConfig(fs, dir, gitdir)

    const aOriginalContent = 'staged changes - a'
    const bOriginalContent = 'staged changes - b'

    await fs.write(`${dir}/a.txt`, aOriginalContent)
    await fs.write(`${dir}/b.js`, bOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })

    const aStatusBefore = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatusBefore).toBe('modified')
    const bStatusBefore = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatusBefore).toBe('modified')

    let stashCommitHash = null
    let error = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()
    expect(typeof stashCommitHash).toBe('string')
    expect(stashCommitHash.length).toBe(40) // SHA-1 hash length

    // Verify working directory is NOT modified
    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual(aOriginalContent)
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual(bOriginalContent)

    // Verify status is still modified
    const aStatusAfter = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatusAfter).toBe('modified')
    const bStatusAfter = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatusAfter).toBe('modified')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Magic Number,"{'line': 355, 'column': 34, 'index': 11469}","it('stash create with staged and unstaged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createTwo')
    await addUserConfig(fs, dir, gitdir)

    const aOriginalContent = 'staged changes - a'
    const bOriginalContent = 'staged changes - b'
    const mOriginalContent = '<unstaged>m</unstaged>'

    await fs.write(`${dir}/a.txt`, aOriginalContent)
    await fs.write(`${dir}/b.js`, bOriginalContent)
    await add({ fs, dir, gitdir, filepath: ['a.txt', 'b.js'] })

    await fs.write(`${dir}/m.xml`, mOriginalContent)

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({
        fs,
        dir,
        gitdir,
        op: 'create',
        message: 'custom message',
      })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()
    expect(typeof stashCommitHash).toBe('string')

    // Verify working directory is NOT modified
    const aContent = await fs.read(`${dir}/a.txt`)
    expect(aContent.toString()).toEqual(aOriginalContent)
    const bContent = await fs.read(`${dir}/b.js`)
    expect(bContent.toString()).toEqual(bOriginalContent)
    const mContent = await fs.read(`${dir}/m.xml`)
    expect(mContent.toString()).toEqual(mOriginalContent)

    // Verify status remains unchanged
    const aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('modified')
    const bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('modified')
    const mStatus = await status({ fs, dir, gitdir, filepath: 'm.xml' })
    expect(mStatus).toBe('*modified')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Magic Number,"{'line': 498, 'column': 34, 'index': 16435}","it('stash create with deleted files', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createDeleted')
    await addUserConfig(fs, dir, gitdir)

    await fs.rm(`${dir}/a.txt`)
    await fs.rm(`${dir}/b.js`)

    let aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    let bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    let error = null
    let stashCommitHash = null
    try {
      stashCommitHash = await stash({ fs, dir, gitdir, op: 'create' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()

    // Files should remain deleted in working directory
    aStatus = await status({ fs, dir, gitdir, filepath: 'a.txt' })
    expect(aStatus).toBe('*deleted')
    bStatus = await status({ fs, dir, gitdir, filepath: 'b.js' })
    expect(bStatus).toBe('*deleted')

    // Verify stash ref is NOT created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Magic Number,"{'line': 573, 'column': 34, 'index': 18857}","it('stash create multiple times returns different hashes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createMultiple')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/a.txt`, 'first change')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })

    const firstHash = await stash({
      fs,
      dir,
      gitdir,
      op: 'create',
      message: 'first',
    })

    await fs.write(`${dir}/a.txt`, 'second change')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })

    const secondHash = await stash({
      fs,
      dir,
      gitdir,
      op: 'create',
      message: 'second',
    })

    expect(firstHash).not.toBeNull()
    expect(secondHash).not.toBeNull()
    expect(firstHash).not.toEqual(secondHash)

    // Verify no stash refs were created
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Magic Number,"{'line': 586, 'column': 34, 'index': 19388}","it('stash create does not interfere with existing stash list', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createWithExisting')
    await addUserConfig(fs, dir, gitdir)

    // Create a regular stash first
    await fs.write(`${dir}/a.txt`, 'first stash change')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })
    await stash({ fs, dir, gitdir, op: 'push', message: 'regular stash' })

    let stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)

    // Now use stash create
    await fs.write(`${dir}/b.js`, 'create change')
    await add({ fs, dir, gitdir, filepath: ['b.js'] })
    const createHash = await stash({
      fs,
      dir,
      gitdir,
      op: 'create',
      message: 'create stash',
    })

    expect(createHash).not.toBeNull()

    // Verify stash list is unchanged
    stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)
    expect(stashList[0]).toContain('regular stash')
  })",steel
/__tests__/test-stash.js,Magic Number,"{'line': 603, 'column': 34, 'index': 19829}","it('stash create does not interfere with existing stash list', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createWithExisting')
    await addUserConfig(fs, dir, gitdir)

    // Create a regular stash first
    await fs.write(`${dir}/a.txt`, 'first stash change')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })
    await stash({ fs, dir, gitdir, op: 'push', message: 'regular stash' })

    let stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)

    // Now use stash create
    await fs.write(`${dir}/b.js`, 'create change')
    await add({ fs, dir, gitdir, filepath: ['b.js'] })
    const createHash = await stash({
      fs,
      dir,
      gitdir,
      op: 'create',
      message: 'create stash',
    })

    expect(createHash).not.toBeNull()

    // Verify stash list is unchanged
    stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)
    expect(stashList[0]).toContain('regular stash')
  })",steel
/__tests__/test-stash.js,Magic Number,"{'line': 633, 'column': 40, 'index': 20627}","it('stash create with custom message', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('createMessage')
    await addUserConfig(fs, dir, gitdir)

    await fs.write(`${dir}/a.txt`, 'test content')
    await add({ fs, dir, gitdir, filepath: ['a.txt'] })

    const customMessage = 'my custom stash message'
    let stashCommitHash = null
    let error = null

    try {
      stashCommitHash = await stash({
        fs,
        dir,
        gitdir,
        op: 'create',
        message: customMessage,
      })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    expect(stashCommitHash).not.toBeNull()
    expect(typeof stashCommitHash).toBe('string')
    expect(stashCommitHash.length).toBe(40)

    // Read the commit to verify message format
    const commitObj = await readCommit({
      fs,
      dir,
      gitdir,
      oid: stashCommitHash,
    })
    expect(commitObj.commit.message).toContain(customMessage)
  })",steel
/__tests__/test-stash.js,Magic Number,"{'line': 969, 'column': 34, 'index': 32212}","it('stash list with 1 stash', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('test-stash')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged 3 file changes

    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)
  })",steel
/__tests__/test-stash.js,Magic Number,"{'line': 979, 'column': 34, 'index': 32617}","it('stash list with 2 stashes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('test-stash')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes
    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(2)
  })",steel
/__tests__/test-stash.js,Magic Number,"{'line': 1037, 'column': 34, 'index': 34380}","it('stash drop with stash', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('test-stash')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'drop' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Magic Number,"{'line': 1115, 'column': 34, 'index': 36599}","it('stash clear with stash', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('test-stash')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'clear' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Magic Number,"{'line': 1133, 'column': 34, 'index': 37158}","it('stash clear with 2 stashes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('test-stash')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes
    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'clear' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Magic Number,"{'line': 1165, 'column': 34, 'index': 37921}","it('stash pop with 1 stash', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('popTwo')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'pop' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(0)
  })",steel
/__tests__/test-stash.js,Magic Number,"{'line': 1183, 'column': 34, 'index': 38474}","it('stash pop with 2 stashes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('popThree')

    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes
    await stashChanges(fs, dir, gitdir, true, false) // staged and non-unstaged changes

    let error = null
    try {
      await stash({ fs, dir, gitdir, op: 'pop' })
    } catch (e) {
      error = e
    }

    expect(error).toBeNull()
    const stashList = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashList.length).toBe(1)
  })",steel
/__tests__/test-stash.js,Magic Number,"{'line': 1254, 'column': 32, 'index': 41012}","it('should not lose stashes after stash pop followed by stash push', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('stashRegression')
    await addUserConfig(fs, dir, gitdir)

    // --- stash 1 ---
    await fs.write(dir + '/a.txt', 'change 1')
    await stash({ fs, dir, gitdir, message: 'stash 1', op: 'push' })
    // --- stash 2 ---
    await fs.write(dir + '/a.txt', 'change 2')
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    let stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)

    // Pop stash 2
    await stash({ fs, dir, gitdir, op: 'pop' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(1)
    // Push stash 2 again
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)
  })",steel
/__tests__/test-stash.js,Magic Number,"{'line': 1260, 'column': 32, 'index': 41175}","it('should not lose stashes after stash pop followed by stash push', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('stashRegression')
    await addUserConfig(fs, dir, gitdir)

    // --- stash 1 ---
    await fs.write(dir + '/a.txt', 'change 1')
    await stash({ fs, dir, gitdir, message: 'stash 1', op: 'push' })
    // --- stash 2 ---
    await fs.write(dir + '/a.txt', 'change 2')
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    let stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)

    // Pop stash 2
    await stash({ fs, dir, gitdir, op: 'pop' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(1)
    // Push stash 2 again
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)
  })",steel
/__tests__/test-stash.js,Magic Number,"{'line': 1265, 'column': 32, 'index': 41365}","it('should not lose stashes after stash pop followed by stash push', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('stashRegression')
    await addUserConfig(fs, dir, gitdir)

    // --- stash 1 ---
    await fs.write(dir + '/a.txt', 'change 1')
    await stash({ fs, dir, gitdir, message: 'stash 1', op: 'push' })
    // --- stash 2 ---
    await fs.write(dir + '/a.txt', 'change 2')
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    let stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)

    // Pop stash 2
    await stash({ fs, dir, gitdir, op: 'pop' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(1)
    // Push stash 2 again
    await stash({ fs, dir, gitdir, message: 'stash 2', op: 'push' })

    stashes = await stash({ fs, dir, gitdir, op: 'list' })
    expect(stashes.length).toBe(2)
  })",steel
/__tests__/test-stash.js,Unknown Test,"{'column': 2, 'line': 176}","it('stash with staged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('pushOne')
    await stashChanges(fs, dir, gitdir, false, false) // no unstaged changes
  })",steel
/__tests__/test-stash.js,Unknown Test,"{'column': 2, 'line': 181}","it('stash with staged and unstaged changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('pushTwo')
    await stashChanges(fs, dir, gitdir, true, false) // with unstaged changes
  })",steel
/__tests__/test-stash.js,Unknown Test,"{'column': 2, 'line': 186}","it('stash with staged and unstaged changes plus same file changes', async () => {
    const { fs, dir, gitdir } = await makeFixtureStash('pushThree')
    await stashChanges(fs, dir, gitdir, true, true) // with unstaged changes
  })",steel
/__tests__/test-resolveRef.js,Exception Handling,"{'line': 90, 'column': 4, 'index': 2346}","it('non-existant refs', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-resolveRef')
    // Test
    let error = {}
    try {
      await resolveRef({
        fs,
        gitdir,
        ref: 'this-is-not-a-ref',
      })
    } catch (err) {
      error = err
    }
    expect(error.message).toBeDefined()
    expect(error.caller).toEqual('git.resolveRef')
  })",steel
/__tests__/test-renameBranch.js,Duplicate Assert,"{'line': 141, 'column': 4, 'index': 3562}","it('rename current branch', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-renameBranch')
    // Test
    await renameBranch({
      fs,
      dir,
      gitdir,
      oldref: 'master',
      ref: 'other-branch',
    })
    expect(await currentBranch({ fs, dir, gitdir })).toEqual('other-branch')

    await renameBranch({
      fs,
      dir,
      gitdir,
      oldref: 'other-branch',
      ref: 'master',
    })
    expect(await currentBranch({ fs, dir, gitdir })).toEqual('master')
  })",steel
/__tests__/test-renameBranch.js,Duplicate Assert,"{'line': 150, 'column': 4, 'index': 3758}","it('rename current branch', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-renameBranch')
    // Test
    await renameBranch({
      fs,
      dir,
      gitdir,
      oldref: 'master',
      ref: 'other-branch',
    })
    expect(await currentBranch({ fs, dir, gitdir })).toEqual('other-branch')

    await renameBranch({
      fs,
      dir,
      gitdir,
      oldref: 'other-branch',
      ref: 'master',
    })
    expect(await currentBranch({ fs, dir, gitdir })).toEqual('master')
  })",steel
/__tests__/test-renameBranch.js,Exception Handling,"{'line': 14, 'column': 4, 'index': 406}","it('branch already exists', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-renameBranch')
    let error = null
    // Test
    try {
      await renameBranch({
        fs,
        dir,
        gitdir,
        oldref: 'test-branch',
        ref: 'existing-branch',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.AlreadyExistsError).toBe(true)
  })",steel
/__tests__/test-renameBranch.js,Exception Handling,"{'line': 34, 'column': 4, 'index': 868}","it('invalid new branch name', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-renameBranch')
    let error = null
    // Test
    try {
      await renameBranch({
        fs,
        dir,
        gitdir,
        oldref: 'test-branch',
        ref: 'inv@{id..branch.lock',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidRefNameError).toBe(true)
  })",steel
/__tests__/test-renameBranch.js,Exception Handling,"{'line': 54, 'column': 4, 'index': 1336}","it('invalid old branch name', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-renameBranch')
    let error = null
    // Test
    try {
      await renameBranch({
        fs,
        dir,
        gitdir,
        ref: 'other-branch',
        oldref: 'inv@{id..branch.lock',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidRefNameError).toBe(true)
  })",steel
/__tests__/test-renameBranch.js,Exception Handling,"{'line': 74, 'column': 4, 'index': 1802}","it('missing ref argument', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-renameBranch')
    let error = null
    // Test
    try {
      // @ts-ignore
      await renameBranch({ fs, dir, gitdir, oldref: 'test-branch' })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.MissingParameterError).toBe(true)
  })",steel
/__tests__/test-renameBranch.js,Exception Handling,"{'line': 89, 'column': 4, 'index': 2216}","it('missing oldref argument', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-renameBranch')
    let error = null
    // Test
    try {
      // @ts-ignore
      await renameBranch({ fs, dir, gitdir, ref: 'other-branch' })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.MissingParameterError).toBe(true)
  })",steel
/__tests__/test-removeNote.js,Duplicate Assert,"{'line': 15, 'column': 4, 'index': 395}","it('from default branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-removeNote')
    // Test
    let notes = await listNotes({
      fs,
      gitdir,
    })
    expect(notes.length).toBe(3)
    const oid = await removeNote({
      fs,
      gitdir,
      author: {
        name: 'William Hilton',
        email: 'wmhilton@gmail.com',
        timestamp: 1578937310,
        timezoneOffset: 300,
      },
      oid: '199948939a0b95c6f27668689102496574b2c332',
    })
    notes = await listNotes({
      fs,
      gitdir,
    })
    expect(notes.length).toBe(2)
    expect(oid).toBe('96cc0598c9f2eaac733d0817981039596c0c410f')
  })",steel
/__tests__/test-removeNote.js,Duplicate Assert,"{'line': 31, 'column': 4, 'index': 764}","it('from default branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-removeNote')
    // Test
    let notes = await listNotes({
      fs,
      gitdir,
    })
    expect(notes.length).toBe(3)
    const oid = await removeNote({
      fs,
      gitdir,
      author: {
        name: 'William Hilton',
        email: 'wmhilton@gmail.com',
        timestamp: 1578937310,
        timezoneOffset: 300,
      },
      oid: '199948939a0b95c6f27668689102496574b2c332',
    })
    notes = await listNotes({
      fs,
      gitdir,
    })
    expect(notes.length).toBe(2)
    expect(oid).toBe('96cc0598c9f2eaac733d0817981039596c0c410f')
  })",steel
/__tests__/test-removeNote.js,Duplicate Assert,"{'line': 43, 'column': 4, 'index': 1094}","it('from alternate branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-removeNote')
    // Test
    let notes = await listNotes({
      fs,
      gitdir,
      ref: 'refs/notes/alt',
    })
    expect(notes.length).toBe(1)
    const oid = await removeNote({
      fs,
      gitdir,
      author: {
        name: 'William Hilton',
        email: 'wmhilton@gmail.com',
        timestamp: 1578937310,
        timezoneOffset: 300,
      },
      ref: 'refs/notes/alt',
      oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
    })
    notes = await listNotes({
      fs,
      gitdir,
      ref: 'refs/notes/alt',
    })
    expect(notes.length).toBe(0)
    expect(oid).toBe('cfab6e154843d83173626d8d39d1dbe0f603921b')
  })",steel
/__tests__/test-removeNote.js,Duplicate Assert,"{'line': 61, 'column': 4, 'index': 1521}","it('from alternate branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-removeNote')
    // Test
    let notes = await listNotes({
      fs,
      gitdir,
      ref: 'refs/notes/alt',
    })
    expect(notes.length).toBe(1)
    const oid = await removeNote({
      fs,
      gitdir,
      author: {
        name: 'William Hilton',
        email: 'wmhilton@gmail.com',
        timestamp: 1578937310,
        timezoneOffset: 300,
      },
      ref: 'refs/notes/alt',
      oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
    })
    notes = await listNotes({
      fs,
      gitdir,
      ref: 'refs/notes/alt',
    })
    expect(notes.length).toBe(0)
    expect(oid).toBe('cfab6e154843d83173626d8d39d1dbe0f603921b')
  })",steel
/__tests__/test-removeNote.js,Magic Number,"{'line': 15, 'column': 30, 'index': 421}","it('from default branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-removeNote')
    // Test
    let notes = await listNotes({
      fs,
      gitdir,
    })
    expect(notes.length).toBe(3)
    const oid = await removeNote({
      fs,
      gitdir,
      author: {
        name: 'William Hilton',
        email: 'wmhilton@gmail.com',
        timestamp: 1578937310,
        timezoneOffset: 300,
      },
      oid: '199948939a0b95c6f27668689102496574b2c332',
    })
    notes = await listNotes({
      fs,
      gitdir,
    })
    expect(notes.length).toBe(2)
    expect(oid).toBe('96cc0598c9f2eaac733d0817981039596c0c410f')
  })",steel
/__tests__/test-removeNote.js,Magic Number,"{'line': 31, 'column': 30, 'index': 790}","it('from default branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-removeNote')
    // Test
    let notes = await listNotes({
      fs,
      gitdir,
    })
    expect(notes.length).toBe(3)
    const oid = await removeNote({
      fs,
      gitdir,
      author: {
        name: 'William Hilton',
        email: 'wmhilton@gmail.com',
        timestamp: 1578937310,
        timezoneOffset: 300,
      },
      oid: '199948939a0b95c6f27668689102496574b2c332',
    })
    notes = await listNotes({
      fs,
      gitdir,
    })
    expect(notes.length).toBe(2)
    expect(oid).toBe('96cc0598c9f2eaac733d0817981039596c0c410f')
  })",steel
/__tests__/test-removeNote.js,Magic Number,"{'line': 43, 'column': 30, 'index': 1120}","it('from alternate branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-removeNote')
    // Test
    let notes = await listNotes({
      fs,
      gitdir,
      ref: 'refs/notes/alt',
    })
    expect(notes.length).toBe(1)
    const oid = await removeNote({
      fs,
      gitdir,
      author: {
        name: 'William Hilton',
        email: 'wmhilton@gmail.com',
        timestamp: 1578937310,
        timezoneOffset: 300,
      },
      ref: 'refs/notes/alt',
      oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
    })
    notes = await listNotes({
      fs,
      gitdir,
      ref: 'refs/notes/alt',
    })
    expect(notes.length).toBe(0)
    expect(oid).toBe('cfab6e154843d83173626d8d39d1dbe0f603921b')
  })",steel
/__tests__/test-removeNote.js,Magic Number,"{'line': 61, 'column': 30, 'index': 1547}","it('from alternate branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-removeNote')
    // Test
    let notes = await listNotes({
      fs,
      gitdir,
      ref: 'refs/notes/alt',
    })
    expect(notes.length).toBe(1)
    const oid = await removeNote({
      fs,
      gitdir,
      author: {
        name: 'William Hilton',
        email: 'wmhilton@gmail.com',
        timestamp: 1578937310,
        timezoneOffset: 300,
      },
      ref: 'refs/notes/alt',
      oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
    })
    notes = await listNotes({
      fs,
      gitdir,
      ref: 'refs/notes/alt',
    })
    expect(notes.length).toBe(0)
    expect(oid).toBe('cfab6e154843d83173626d8d39d1dbe0f603921b')
  })",steel
/__tests__/test-readTree.js,Exception Handling,"{'line': 512, 'column': 4, 'index': 14829}","it('with erroneous filepath (directory is a file)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readTree')
    // Test
    let error = null
    try {
      await readTree({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        filepath: 'src/commands/clone.js/isntafolder.txt',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.ObjectTypeError).toBe(true)
  })",steel
/__tests__/test-readTree.js,Exception Handling,"{'line': 530, 'column': 4, 'index': 15334}","it('with erroneous filepath (no such directory)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readTree')
    // Test
    let error = null
    try {
      await readTree({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        filepath: 'src/isntafolder',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",steel
/__tests__/test-readTree.js,Exception Handling,"{'line': 548, 'column': 4, 'index': 15811}","it('with erroneous filepath (leading slash)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readTree')
    // Test
    let error = null
    try {
      await readTree({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        filepath: '/src',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidFilepathError).toBe(true)
    expect(error.data.reason).toBe('leading-slash')
  })",steel
/__tests__/test-readTree.js,Exception Handling,"{'line': 567, 'column': 4, 'index': 16337}","it('with erroneous filepath (trailing slash)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readTree')
    // Test
    let error = null
    try {
      await readTree({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        filepath: 'src/',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidFilepathError).toBe(true)
    expect(error.data.reason).toBe('trailing-slash')
  })",steel
/__tests__/test-readObject.js,Conditional Test Logic,"{'line': 94, 'column': 4, 'index': 3230}","it('content', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'e10ebb90d03eaacca84de1af0a59b444232da99e',
      format: 'content',
    })
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('commit')
    expect(ref.source).toBe('objects/e1/0ebb90d03eaacca84de1af0a59b444232da99e')
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      '""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""'
    )
  })",steel
/__tests__/test-readObject.js,Conditional Test Logic,"{'line': 112, 'column': 4, 'index': 6045}","it('wrapped', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'e10ebb90d03eaacca84de1af0a59b444232da99e',
      format: 'wrapped',
    })
    expect(ref.format).toEqual('wrapped')
    expect(ref.type).toEqual('wrapped')
    expect(ref.source).toBe('objects/e1/0ebb90d03eaacca84de1af0a59b444232da99e')
    if (ref.format !== 'wrapped') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      '""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""'
    )
  })",steel
/__tests__/test-readObject.js,Conditional Test Logic,"{'line': 130, 'column': 4, 'index': 8888}","it('deflated', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'e10ebb90d03eaacca84de1af0a59b444232da99e',
      format: 'deflated',
    })
    expect(ref.format).toEqual('deflated')
    expect(ref.type).toEqual('deflated')
    expect(ref.source).toBe('objects/e1/0ebb90d03eaacca84de1af0a59b444232da99e')
    if (ref.format !== 'deflated') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      '""78019d93c9cea3481084e7cc53d4ddea76010586d1cc68001b0cde30fc06ec1b4b4161966237e6e9dbd373ed53e729158a487d522a625a55f9005896e5ff183a8c01869194f2c206411162cc210c798cc294976431158524e1a0148a308e9926ec703d8008a51207c544c6bc2023568c60ca238e97e2084708c274938492248712138e03a11df0f3b204fbbc1c680dfe7a55e4e7f66f568579f93da6d53f8015208724c44108bec1cf05e6a37e1007fc3bd9acc9fa3c03dffe1b75679867601b36704de3ac7cdd9cdd4f9d011eeefa9cd67f02a31e6d034c2c0318905fcd58551455c91443bd5a8f2789a8a2506b67ddadf1e0bbb9180a9e70b3d71f4837c595c5f2b6a306fdc0615590b39e013cb1674ede3a0795e8c354ac467725091cbf26b7b47b7314fb7e22de9d22ae8b79566e835aa78b5798b2923966cc9ebf4e0c2042301c4fd731d294c34bb2fcc99b68b0fb5a5e9e72d956493569c877afda715cd1866271ed6f9ca9e8beb6b0898ad71eed18700a280905b937fdc75a0fe34720aaef7b4bf477915a4729d3f4c9719767deaa66d4db9ba0e54e043d0be5702f8565f6f89101ad567022a9c971b52a5e69508edc3d3106555e954fbe29d833f65b87dfc88bb31064b3509f038b955a778e97a850f4cb9d012215c8265c9fda923db4be2aef74756cb4e6f94eaa46196c2a96ecad47215fe6aa70b4268dc873e670fbc1250e8ae4cd8501b5d90436aab3375ae4dbbb0b82796ef2ebb55e175ebd1e0fd930198d545ff49c5291b5b55c7ef6dcb5bace713faa177c5931609be8ad5070f6e9fc38bef26540b6b43352cfa2767424c9dd46d4cf4fda78f7d65c7a26902ee5ba6537e2dee89732ed0afcf926cf3d60155abc22cca6f384d16672ce7b4f529452de124cf963df3c319d6c2e7fc7da5eb7219fb98d76488e8eea68e88b01010b5555df4a35d54e813547428beb2e5de183934809ca36d610bf97d6cb0af52a4a8669480879bea3d2f2b2cc487d0b0c8895f0b576efe6c3e01dda2931cbe68f4d3f85f0a99b2e7e56bbc5c4d1a8117749fc0b77b9f88e379d12f27ebcb6c75ba6440cb8e633e1a2cace3a9ec8f5dc72dbaa66c0df68b53d33ffd76477defeaa248c59351d9d30e8704fcb093b3805030524ac9312838a761814799df480a61f4bda7f074a928001f743cffc00fa8263c9""'
    )
  })",steel
/__tests__/test-readObject.js,Conditional Test Logic,"{'line': 151, 'column': 4, 'index': 11285}","it('from packfile deflated', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: '0b8faa11b353db846b40eb064dfb299816542a46',
      format: 'deflated',
    })
    // packed objects will always be returned as 'content' format
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('commit')
    expect(ref.source).toBe(
      'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
    )
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      `""7472656520346431363665323666636639666537623231383633343336313337633434613339613231613930660a706172656e7420666264353662343964343030613139656531383561653733353431376264623334633038343632310a617574686f722057696c6c69616d2048696c746f6e203c776d68696c746f6e40676d61696c2e636f6d3e2031353038323034303133202d303430300a636f6d6d69747465722057696c6c69616d2048696c746f6e203c776d68696c746f6e40676d61696c2e636f6d3e2031353038323034303133202d303430300a0a696e646578206f6e206d61737465723a2066626435366234204164642027756e706b6727206b657920746f207061636b6167652e6a736f6e0a""`
    )
  })",steel
/__tests__/test-readObject.js,Conditional Test Logic,"{'line': 172, 'column': 4, 'index': 12529}","it('from packfile wrapped', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: '0b8faa11b353db846b40eb064dfb299816542a46',
      format: 'wrapped',
    })
    // packed objects will always be returned as 'content' format
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('commit')
    expect(ref.source).toBe(
      'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
    )
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      `""7472656520346431363665323666636639666537623231383633343336313337633434613339613231613930660a706172656e7420666264353662343964343030613139656531383561653733353431376264623334633038343632310a617574686f722057696c6c69616d2048696c746f6e203c776d68696c746f6e40676d61696c2e636f6d3e2031353038323034303133202d303430300a636f6d6d69747465722057696c6c69616d2048696c746f6e203c776d68696c746f6e40676d61696c2e636f6d3e2031353038323034303133202d303430300a0a696e646578206f6e206d61737465723a2066626435366234204164642027756e706b6727206b657920746f207061636b6167652e6a736f6e0a""`
    )
  })",steel
/__tests__/test-readObject.js,Conditional Test Logic,"{'line': 192, 'column': 4, 'index': 13707}","it('from packfile content', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: '0b8faa11b353db846b40eb064dfb299816542a46',
      format: 'content',
    })
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('commit')
    expect(ref.source).toBe(
      'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
    )
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      `""7472656520346431363665323666636639666537623231383633343336313337633434613339613231613930660a706172656e7420666264353662343964343030613139656531383561653733353431376264623334633038343632310a617574686f722057696c6c69616d2048696c746f6e203c776d68696c746f6e40676d61696c2e636f6d3e2031353038323034303133202d303430300a636f6d6d69747465722057696c6c69616d2048696c746f6e203c776d68696c746f6e40676d61696c2e636f6d3e2031353038323034303133202d303430300a0a696e646578206f6e206d61737465723a2066626435366234204164642027756e706b6727206b657920746f207061636b6167652e6a736f6e0a""`
    )
  })",steel
/__tests__/test-readObject.js,Conditional Test Logic,"{'line': 261, 'column': 4, 'index': 16599}","it('with simple filepath to blob', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'be1e63da44b26de8877a184359abace1cddcb739',
      format: 'parsed',
      filepath: 'cli.js',
    })
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('blob')
    expect(ref.source).toBe(
      'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
    )
    expect(ref.oid).toEqual('4551a1856279dde6ae9d65862a1dff59a5f199d8')
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      '""23212f7573722f62696e2f656e76206e6f64650a636f6e7374206d696e696d6973746564203d207265717569726528276d696e696d697374656427290a636f6e737420676974203d207265717569726528272e27290a0a2f2f2054686973207265616c6c792069736e2774206d756368206f66206120434c492e2049742773206d6f73746c7920666f722074657374696e672e0a2f2f204275742069742773207665727920766572736174696c6520616e6420776f726b732073757270726973696e676c792077656c6c2e0a0a6d696e696d6973746564286173796e632066756e6374696f6e20287b205f3a205b636f6d6d616e642c202e2e2e617267735d2c202e2e2e6f707473207d29207b0a2020636f6e737420646972203d2070726f636573732e63776428290a2020636f6e7374207265706f203d2067697428646972290a20206c657420636d64203d20606769742827247b6469727d2729600a2020666f7220286c6574206b6579206f66204f626a6563742e6b657973286f7074732929207b0a202020202f2f205468697320697320686f7720796f7520636865636b20666f7220616e2061727261792c2072696768743f0a20202020696620286f7074735b6b65795d2e6c656e677468203d3d3d20756e646566696e656429207b0a2020202020207265706f5b6b65795d286f7074735b6b65795d290a202020202020636d64202b3d20602e247b6b65797d2827247b6f7074735b6b65795d7d2729600a202020207d20656c7365207b0a2020202020207265706f5b6b65795d282e2e2e6f7074735b6b65795d290a202020202020636d64202b3d20602e247b6b65797d28247b6f7074735b6b65795d2e6d61702878203d3e206027247b787d2760292e6a6f696e28272c2027297d29600a202020207d0a20207d0a2020636d64202b3d20602e247b636f6d6d616e647d28247b617267732e6d61702878203d3e206027247b787d2760292e6a6f696e28272c2027297d29600a2020636f6e736f6c652e6c6f6728636d64290a20206c657420726573756c74203d206177616974207265706f5b636f6d6d616e645d282e2e2e61726773290a202069662028726573756c74203d3d3d20756e646566696e6564292072657475726e0a2020636f6e736f6c652e6c6f67284a534f4e2e737472696e6769667928726573756c742c206e756c6c2c203229290a7d290a""'
    )
  })",steel
/__tests__/test-readObject.js,Conditional Test Logic,"{'line': 280, 'column': 4, 'index': 18989}","it('with deep filepath to blob', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'be1e63da44b26de8877a184359abace1cddcb739',
      format: 'parsed',
      filepath: 'src/commands/clone.js',
    })
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('blob')
    expect(ref.oid).toEqual('5264f23285d8be3ce45f95c102001ffa1d5391d3')
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      '""696d706f7274207b20696e6974207d2066726f6d20272e2f696e6974270a696d706f7274207b20636f6e666967207d2066726f6d20272e2f636f6e666967270a696d706f7274207b206665746368207d2066726f6d20272e2f6665746368270a696d706f7274207b20636865636b6f7574207d2066726f6d20272e2f636865636b6f7574270a0a6578706f7274206173796e632066756e6374696f6e20636c6f6e6520287b0a2020776f726b6469722c0a20206769746469722c0a202075726c2c0a202072656d6f74652c0a20207265662c0a202061757468557365726e616d652c0a20206175746850617373776f72642c0a202064657074682c0a202073696e63652c0a20206578636c7564652c0a202072656c61746976652c0a20206f6e70726f67726573730a7d29207b0a202072656d6f7465203d2072656d6f7465207c7c20276f726967696e270a2020617761697420696e6974287b20676974646972207d290a20202f2f204164642072656d6f74650a2020617761697420636f6e666967287b0a202020206769746469722c0a20202020706174683a206072656d6f74652e247b72656d6f74657d2e75726c602c0a2020202076616c75653a2075726c0a20207d290a20202f2f20466574636820636f6d6d6974730a20206177616974206665746368287b0a202020206769746469722c0a202020207265662c0a2020202072656d6f74652c0a2020202061757468557365726e616d652c0a202020206175746850617373776f72642c0a2020202064657074682c0a2020202073696e63652c0a202020206578636c7564652c0a2020202072656c61746976652c0a202020206f6e70726f67726573730a20207d290a20202f2f20436865636b6f7574206272616e63680a2020617761697420636865636b6f7574287b0a20202020776f726b6469722c0a202020206769746469722c0a202020207265662c0a2020202072656d6f74650a20207d290a7d0a""'
    )
  })",steel
/__tests__/test-readObject.js,Exception Handling,"{'line': 12, 'column': 4, 'index': 341}","it('test missing', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    let error = null
    try {
      await readObject({
        fs,
        gitdir,
        oid: 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",steel
/__tests__/test-readObject.js,Exception Handling,"{'line': 94, 'column': 34, 'index': 3260}","it('content', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'e10ebb90d03eaacca84de1af0a59b444232da99e',
      format: 'content',
    })
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('commit')
    expect(ref.source).toBe('objects/e1/0ebb90d03eaacca84de1af0a59b444232da99e')
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      '""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""'
    )
  })",steel
/__tests__/test-readObject.js,Exception Handling,"{'line': 112, 'column': 34, 'index': 6075}","it('wrapped', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'e10ebb90d03eaacca84de1af0a59b444232da99e',
      format: 'wrapped',
    })
    expect(ref.format).toEqual('wrapped')
    expect(ref.type).toEqual('wrapped')
    expect(ref.source).toBe('objects/e1/0ebb90d03eaacca84de1af0a59b444232da99e')
    if (ref.format !== 'wrapped') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      '""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""'
    )
  })",steel
/__tests__/test-readObject.js,Exception Handling,"{'line': 130, 'column': 35, 'index': 8919}","it('deflated', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'e10ebb90d03eaacca84de1af0a59b444232da99e',
      format: 'deflated',
    })
    expect(ref.format).toEqual('deflated')
    expect(ref.type).toEqual('deflated')
    expect(ref.source).toBe('objects/e1/0ebb90d03eaacca84de1af0a59b444232da99e')
    if (ref.format !== 'deflated') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      '""78019d93c9cea3481084e7cc53d4ddea76010586d1cc68001b0cde30fc06ec1b4b4161966237e6e9dbd373ed53e729158a487d522a625a55f9005896e5ff183a8c01869194f2c206411162cc210c798cc294976431158524e1a0148a308e9926ec703d8008a51207c544c6bc2023568c60ca238e97e2084708c274938492248712138e03a11df0f3b204fbbc1c680dfe7a55e4e7f66f568579f93da6d53f8015208724c44108bec1cf05e6a37e1007fc3bd9acc9fa3c03dffe1b75679867601b36704de3ac7cdd9cdd4f9d011eeefa9cd67f02a31e6d034c2c0318905fcd58551455c91443bd5a8f2789a8a2506b67ddadf1e0bbb9180a9e70b3d71f4837c595c5f2b6a306fdc0615590b39e013cb1674ede3a0795e8c354ac467725091cbf26b7b47b7314fb7e22de9d22ae8b79566e835aa78b5798b2923966cc9ebf4e0c2042301c4fd731d294c34bb2fcc99b68b0fb5a5e9e72d956493569c877afda715cd1866271ed6f9ca9e8beb6b0898ad71eed18700a280905b937fdc75a0fe34720aaef7b4bf477915a4729d3f4c9719767deaa66d4db9ba0e54e043d0be5702f8565f6f89101ad567022a9c971b52a5e69508edc3d3106555e954fbe29d833f65b87dfc88bb31064b3509f038b955a778e97a850f4cb9d012215c8265c9fda923db4be2aef74756cb4e6f94eaa46196c2a96ecad47215fe6aa70b4268dc873e670fbc1250e8ae4cd8501b5d90436aab3375ae4dbbb0b82796ef2ebb55e175ebd1e0fd930198d545ff49c5291b5b55c7ef6dcb5bace713faa177c5931609be8ad5070f6e9fc38bef26540b6b43352cfa2767424c9dd46d4cf4fda78f7d65c7a26902ee5ba6537e2dee89732ed0afcf926cf3d60155abc22cca6f384d16672ce7b4f529452de124cf963df3c319d6c2e7fc7da5eb7219fb98d76488e8eea68e88b01010b5555df4a35d54e813547428beb2e5de183934809ca36d610bf97d6cb0af52a4a8669480879bea3d2f2b2cc487d0b0c8895f0b576efe6c3e01dda2931cbe68f4d3f85f0a99b2e7e56bbc5c4d1a8117749fc0b77b9f88e379d12f27ebcb6c75ba6440cb8e633e1a2cace3a9ec8f5dc72dbaa66c0df68b53d33ffd76477defeaa248c59351d9d30e8704fcb093b3805030524ac9312838a761814799df480a61f4bda7f074a928001f743cffc00fa8263c9""'
    )
  })",steel
/__tests__/test-readObject.js,Exception Handling,"{'line': 151, 'column': 34, 'index': 11315}","it('from packfile deflated', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: '0b8faa11b353db846b40eb064dfb299816542a46',
      format: 'deflated',
    })
    // packed objects will always be returned as 'content' format
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('commit')
    expect(ref.source).toBe(
      'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
    )
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      `""7472656520346431363665323666636639666537623231383633343336313337633434613339613231613930660a706172656e7420666264353662343964343030613139656531383561653733353431376264623334633038343632310a617574686f722057696c6c69616d2048696c746f6e203c776d68696c746f6e40676d61696c2e636f6d3e2031353038323034303133202d303430300a636f6d6d69747465722057696c6c69616d2048696c746f6e203c776d68696c746f6e40676d61696c2e636f6d3e2031353038323034303133202d303430300a0a696e646578206f6e206d61737465723a2066626435366234204164642027756e706b6727206b657920746f207061636b6167652e6a736f6e0a""`
    )
  })",steel
/__tests__/test-readObject.js,Exception Handling,"{'line': 172, 'column': 34, 'index': 12559}","it('from packfile wrapped', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: '0b8faa11b353db846b40eb064dfb299816542a46',
      format: 'wrapped',
    })
    // packed objects will always be returned as 'content' format
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('commit')
    expect(ref.source).toBe(
      'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
    )
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      `""7472656520346431363665323666636639666537623231383633343336313337633434613339613231613930660a706172656e7420666264353662343964343030613139656531383561653733353431376264623334633038343632310a617574686f722057696c6c69616d2048696c746f6e203c776d68696c746f6e40676d61696c2e636f6d3e2031353038323034303133202d303430300a636f6d6d69747465722057696c6c69616d2048696c746f6e203c776d68696c746f6e40676d61696c2e636f6d3e2031353038323034303133202d303430300a0a696e646578206f6e206d61737465723a2066626435366234204164642027756e706b6727206b657920746f207061636b6167652e6a736f6e0a""`
    )
  })",steel
/__tests__/test-readObject.js,Exception Handling,"{'line': 192, 'column': 34, 'index': 13737}","it('from packfile content', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: '0b8faa11b353db846b40eb064dfb299816542a46',
      format: 'content',
    })
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('commit')
    expect(ref.source).toBe(
      'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
    )
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      `""7472656520346431363665323666636639666537623231383633343336313337633434613339613231613930660a706172656e7420666264353662343964343030613139656531383561653733353431376264623334633038343632310a617574686f722057696c6c69616d2048696c746f6e203c776d68696c746f6e40676d61696c2e636f6d3e2031353038323034303133202d303430300a636f6d6d69747465722057696c6c69616d2048696c746f6e203c776d68696c746f6e40676d61696c2e636f6d3e2031353038323034303133202d303430300a0a696e646578206f6e206d61737465723a2066626435366234204164642027756e706b6727206b657920746f207061636b6167652e6a736f6e0a""`
    )
  })",steel
/__tests__/test-readObject.js,Exception Handling,"{'line': 261, 'column': 34, 'index': 16629}","it('with simple filepath to blob', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'be1e63da44b26de8877a184359abace1cddcb739',
      format: 'parsed',
      filepath: 'cli.js',
    })
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('blob')
    expect(ref.source).toBe(
      'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
    )
    expect(ref.oid).toEqual('4551a1856279dde6ae9d65862a1dff59a5f199d8')
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      '""23212f7573722f62696e2f656e76206e6f64650a636f6e7374206d696e696d6973746564203d207265717569726528276d696e696d697374656427290a636f6e737420676974203d207265717569726528272e27290a0a2f2f2054686973207265616c6c792069736e2774206d756368206f66206120434c492e2049742773206d6f73746c7920666f722074657374696e672e0a2f2f204275742069742773207665727920766572736174696c6520616e6420776f726b732073757270726973696e676c792077656c6c2e0a0a6d696e696d6973746564286173796e632066756e6374696f6e20287b205f3a205b636f6d6d616e642c202e2e2e617267735d2c202e2e2e6f707473207d29207b0a2020636f6e737420646972203d2070726f636573732e63776428290a2020636f6e7374207265706f203d2067697428646972290a20206c657420636d64203d20606769742827247b6469727d2729600a2020666f7220286c6574206b6579206f66204f626a6563742e6b657973286f7074732929207b0a202020202f2f205468697320697320686f7720796f7520636865636b20666f7220616e2061727261792c2072696768743f0a20202020696620286f7074735b6b65795d2e6c656e677468203d3d3d20756e646566696e656429207b0a2020202020207265706f5b6b65795d286f7074735b6b65795d290a202020202020636d64202b3d20602e247b6b65797d2827247b6f7074735b6b65795d7d2729600a202020207d20656c7365207b0a2020202020207265706f5b6b65795d282e2e2e6f7074735b6b65795d290a202020202020636d64202b3d20602e247b6b65797d28247b6f7074735b6b65795d2e6d61702878203d3e206027247b787d2760292e6a6f696e28272c2027297d29600a202020207d0a20207d0a2020636d64202b3d20602e247b636f6d6d616e647d28247b617267732e6d61702878203d3e206027247b787d2760292e6a6f696e28272c2027297d29600a2020636f6e736f6c652e6c6f6728636d64290a20206c657420726573756c74203d206177616974207265706f5b636f6d6d616e645d282e2e2e61726773290a202069662028726573756c74203d3d3d20756e646566696e6564292072657475726e0a2020636f6e736f6c652e6c6f67284a534f4e2e737472696e6769667928726573756c742c206e756c6c2c203229290a7d290a""'
    )
  })",steel
/__tests__/test-readObject.js,Exception Handling,"{'line': 280, 'column': 34, 'index': 19019}","it('with deep filepath to blob', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    const ref = await readObject({
      fs,
      gitdir,
      oid: 'be1e63da44b26de8877a184359abace1cddcb739',
      format: 'parsed',
      filepath: 'src/commands/clone.js',
    })
    expect(ref.format).toEqual('content')
    expect(ref.type).toEqual('blob')
    expect(ref.oid).toEqual('5264f23285d8be3ce45f95c102001ffa1d5391d3')
    if (ref.format !== 'content') throw new Error('wrong type')
    expect(Buffer.from(ref.object).toString('hex')).toMatchInlineSnapshot(
      '""696d706f7274207b20696e6974207d2066726f6d20272e2f696e6974270a696d706f7274207b20636f6e666967207d2066726f6d20272e2f636f6e666967270a696d706f7274207b206665746368207d2066726f6d20272e2f6665746368270a696d706f7274207b20636865636b6f7574207d2066726f6d20272e2f636865636b6f7574270a0a6578706f7274206173796e632066756e6374696f6e20636c6f6e6520287b0a2020776f726b6469722c0a20206769746469722c0a202075726c2c0a202072656d6f74652c0a20207265662c0a202061757468557365726e616d652c0a20206175746850617373776f72642c0a202064657074682c0a202073696e63652c0a20206578636c7564652c0a202072656c61746976652c0a20206f6e70726f67726573730a7d29207b0a202072656d6f7465203d2072656d6f7465207c7c20276f726967696e270a2020617761697420696e6974287b20676974646972207d290a20202f2f204164642072656d6f74650a2020617761697420636f6e666967287b0a202020206769746469722c0a20202020706174683a206072656d6f74652e247b72656d6f74657d2e75726c602c0a2020202076616c75653a2075726c0a20207d290a20202f2f20466574636820636f6d6d6974730a20206177616974206665746368287b0a202020206769746469722c0a202020207265662c0a2020202072656d6f74652c0a2020202061757468557365726e616d652c0a202020206175746850617373776f72642c0a2020202064657074682c0a2020202073696e63652c0a202020206578636c7564652c0a2020202072656c61746976652c0a202020206f6e70726f67726573730a20207d290a20202f2f20436865636b6f7574206272616e63680a2020617761697420636865636b6f7574287b0a20202020776f726b6469722c0a202020206769746469722c0a202020207265662c0a2020202072656d6f74650a20207d290a7d0a""'
    )
  })",steel
/__tests__/test-readObject.js,Exception Handling,"{'line': 553, 'column': 4, 'index': 28428}","it('with erroneous filepath (directory is a file)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    let error = null
    try {
      await readObject({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        format: 'parsed',
        filepath: 'src/commands/clone.js/isntafolder.txt',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.ObjectTypeError).toBe(true)
  })",steel
/__tests__/test-readObject.js,Exception Handling,"{'line': 572, 'column': 4, 'index': 28963}","it('with erroneous filepath (no such directory)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    let error = null
    try {
      await readObject({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        format: 'parsed',
        filepath: 'src/isntafolder',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",steel
/__tests__/test-readObject.js,Exception Handling,"{'line': 591, 'column': 4, 'index': 29470}","it('with erroneous filepath (leading slash)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    let error = null
    try {
      await readObject({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        format: 'parsed',
        filepath: '/src',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidFilepathError).toBe(true)
    expect(error.data.reason).toBe('leading-slash')
  })",steel
/__tests__/test-readObject.js,Exception Handling,"{'line': 611, 'column': 4, 'index': 30026}","it('with erroneous filepath (trailing slash)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readObject')
    // Test
    let error = null
    try {
      await readObject({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        format: 'parsed',
        filepath: 'src/',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidFilepathError).toBe(true)
    expect(error.data.reason).toBe('trailing-slash')
  })",steel
/__tests__/test-readCommit.js,Exception Handling,"{'line': 12, 'column': 4, 'index': 341}","it('test missing', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readCommit')
    // Test
    let error = null
    try {
      await readCommit({
        fs,
        gitdir,
        oid: 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",steel
/__tests__/test-readBlob.js,Exception Handling,"{'line': 12, 'column': 4, 'index': 335}","it('test missing', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readBlob')
    // Test
    let error = null
    try {
      await readBlob({
        fs,
        gitdir,
        oid: 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",steel
/__tests__/test-readBlob.js,Exception Handling,"{'line': 110, 'column': 4, 'index': 6580}","it('with simple filepath to tree', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readBlob')
    // Test
    let error = null
    try {
      await readBlob({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        filepath: '',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.ObjectTypeError).toBe(true)
  })",steel
/__tests__/test-readBlob.js,Exception Handling,"{'line': 128, 'column': 4, 'index': 7050}","it('with erroneous filepath (directory is a file)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readBlob')
    // Test
    let error = null
    try {
      await readBlob({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        filepath: 'src/commands/clone.js/isntafolder.txt',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.ObjectTypeError).toBe(true)
  })",steel
/__tests__/test-readBlob.js,Exception Handling,"{'line': 146, 'column': 4, 'index': 7555}","it('with erroneous filepath (no such directory)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readBlob')
    // Test
    let error = null
    try {
      await readBlob({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        filepath: 'src/isntafolder',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",steel
/__tests__/test-readBlob.js,Exception Handling,"{'line': 164, 'column': 4, 'index': 8032}","it('with erroneous filepath (leading slash)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readBlob')
    // Test
    let error = null
    try {
      await readBlob({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        filepath: '/src',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidFilepathError).toBe(true)
    expect(error.data.reason).toBe('leading-slash')
  })",steel
/__tests__/test-readBlob.js,Exception Handling,"{'line': 183, 'column': 4, 'index': 8558}","it('with erroneous filepath (trailing slash)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-readBlob')
    // Test
    let error = null
    try {
      await readBlob({
        fs,
        gitdir,
        oid: 'be1e63da44b26de8877a184359abace1cddcb739',
        filepath: 'src/',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidFilepathError).toBe(true)
    expect(error.data.reason).toBe('trailing-slash')
  })",steel
/__tests__/test-push.js,Conditional Test Logic,"{'line': 503, 'column': 10, 'index': 12571}","it('onAuthFailure', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-push')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.auth.url',
      value: `http://${localhost}:8888/test-push-server-auth.git`,
    })
    // Test
    let err
    const onAuthArgs = []
    const onAuthSuccessArgs = []
    const onAuthFailureArgs = []
    try {
      await push({
        fs,
        http,
        gitdir,
        remote: 'auth',
        ref: 'master',
        async onAuth(...args) {
          onAuthArgs.push(args)
          return {
            username: 'testuser',
            password: 'NoT_rIgHt',
          }
        },
        async onAuthSuccess(...args) {
          onAuthSuccessArgs.push(args)
        },
        async onAuthFailure(...args) {
          onAuthFailureArgs.push(args)
          switch (onAuthFailureArgs.length) {
            case 1:
              return {
                username: 'testuser',
                password: 'St1ll_NoT_rIgHt',
              }
            case 2:
              return {
                headers: {
                  Authorization: 'Bearer Big Bear',
                  'X-Authorization': 'supersecret',
                },
              }
          }
        },
      })
    } catch (e) {
      err = e
    }
    expect(err).toBeDefined()
    expect(err.code).toBe(Errors.HttpError.code)
    expect(err.data.response).toBeTruthy()
    expect(onAuthArgs).toEqual([
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          headers: {},
        },
      ],
    ])
    expect(onAuthSuccessArgs).toEqual([])
    expect(onAuthFailureArgs).toEqual([
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          headers: {
            Authorization: 'Basic dGVzdHVzZXI6Tm9UX3JJZ0h0',
          },
          username: 'testuser',
          password: 'NoT_rIgHt',
        },
      ],
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          headers: {
            Authorization: 'Basic dGVzdHVzZXI6U3QxbGxfTm9UX3JJZ0h0',
          },
          username: 'testuser',
          password: 'St1ll_NoT_rIgHt',
        },
      ],
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          headers: {
            Authorization: 'Bearer Big Bear',
            'X-Authorization': 'supersecret',
          },
        },
      ],
    ])
  })",steel
/__tests__/test-push.js,Conditional Test Logic,"{'line': 598, 'column': 8, 'index': 14971}","it('onAuthFailure then onAuthSuccess', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-push')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.auth.url',
      value: `http://${localhost}:8888/test-push-server-auth.git`,
    })
    // Test
    const onAuthArgs = []
    const onAuthSuccessArgs = []
    const onAuthFailureArgs = []
    await push({
      fs,
      http,
      gitdir,
      remote: 'auth',
      ref: 'master',
      async onAuth(...args) {
        onAuthArgs.push(args)
        return {
          username: 'testuser',
          password: 'NoT_rIgHt',
        }
      },
      async onAuthSuccess(...args) {
        onAuthSuccessArgs.push(args)
      },
      async onAuthFailure(...args) {
        onAuthFailureArgs.push(args)
        switch (onAuthFailureArgs.length) {
          case 1:
            return {
              username: 'testuser',
              password: 'St1ll_NoT_rIgHt',
            }
          case 2:
            return {
              username: 'testuser',
              password: 'testpassword',
            }
        }
      },
    })
    expect(onAuthArgs).toEqual([
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          headers: {},
        },
      ],
    ])
    expect(onAuthSuccessArgs).toEqual([
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          username: 'testuser',
          password: 'testpassword',
        },
      ],
    ])
    expect(onAuthFailureArgs).toEqual([
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          headers: {
            Authorization: 'Basic dGVzdHVzZXI6Tm9UX3JJZ0h0',
          },
          username: 'testuser',
          password: 'NoT_rIgHt',
        },
      ],
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          headers: {
            Authorization: 'Basic dGVzdHVzZXI6U3QxbGxfTm9UX3JJZ0h0',
          },
          username: 'testuser',
          password: 'St1ll_NoT_rIgHt',
        },
      ],
    ])
  })",steel
/__tests__/test-push.js,Duplicate Assert,"{'line': 83, 'column': 4, 'index': 1923}","it('push', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-push')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.karma.url',
      value: `http://${localhost}:8888/test-push-server.git`,
    })
    const output = []
    const onPrePush = []
    // Test
    const res = await push({
      fs,
      http,
      gitdir,
      onMessage: async m => {
        output.push(m)
      },
      remote: 'karma',
      ref: 'refs/heads/master',
      onPrePush: args => {
        onPrePush.push(args)
        return true
      },
    })
    expect(res).toBeTruthy()
    expect(res.ok).toBe(true)
    expect(res.refs['refs/heads/master'].ok).toBe(true)
    expect(output).toMatchInlineSnapshot(`
      Array [
        ""build started...
      "",
        ""build completed...
      "",
        ""tests started...
      "",
        ""tests completed...
      "",
        ""starting server...
      "",
        ""server running
      "",
        ""Here is a message from 'post-receive' hook.
      "",
      ]
    `)
    expect(onPrePush).toEqual([
      {
        localRef: {
          oid: 'c03e131196f43a78888415924bcdcbf3090f3316',
          ref: 'refs/heads/master',
        },
        remote: 'karma',
        remoteRef: {
          oid: '5a8905a02e181fe1821068b8c0f48cb6633d5b81',
          ref: 'refs/heads/master',
        },
        url: `http://${localhost}:8888/test-push-server.git`,
      },
    ])

    // Test that remote ref is updated
    expect(
      await resolveRef({ fs, gitdir, ref: 'refs/remotes/karma/master' })
    ).toEqual(await resolveRef({ fs, gitdir, ref: 'refs/heads/master' }))
    expect(
      await resolveRef({ fs, gitdir, ref: 'refs/remotes/karma/master' })
    ).toEqual('c03e131196f43a78888415924bcdcbf3090f3316')
  })",steel
/__tests__/test-push.js,Duplicate Assert,"{'line': 86, 'column': 4, 'index': 2082}","it('push', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-push')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.karma.url',
      value: `http://${localhost}:8888/test-push-server.git`,
    })
    const output = []
    const onPrePush = []
    // Test
    const res = await push({
      fs,
      http,
      gitdir,
      onMessage: async m => {
        output.push(m)
      },
      remote: 'karma',
      ref: 'refs/heads/master',
      onPrePush: args => {
        onPrePush.push(args)
        return true
      },
    })
    expect(res).toBeTruthy()
    expect(res.ok).toBe(true)
    expect(res.refs['refs/heads/master'].ok).toBe(true)
    expect(output).toMatchInlineSnapshot(`
      Array [
        ""build started...
      "",
        ""build completed...
      "",
        ""tests started...
      "",
        ""tests completed...
      "",
        ""starting server...
      "",
        ""server running
      "",
        ""Here is a message from 'post-receive' hook.
      "",
      ]
    `)
    expect(onPrePush).toEqual([
      {
        localRef: {
          oid: 'c03e131196f43a78888415924bcdcbf3090f3316',
          ref: 'refs/heads/master',
        },
        remote: 'karma',
        remoteRef: {
          oid: '5a8905a02e181fe1821068b8c0f48cb6633d5b81',
          ref: 'refs/heads/master',
        },
        url: `http://${localhost}:8888/test-push-server.git`,
      },
    ])

    // Test that remote ref is updated
    expect(
      await resolveRef({ fs, gitdir, ref: 'refs/remotes/karma/master' })
    ).toEqual(await resolveRef({ fs, gitdir, ref: 'refs/heads/master' }))
    expect(
      await resolveRef({ fs, gitdir, ref: 'refs/remotes/karma/master' })
    ).toEqual('c03e131196f43a78888415924bcdcbf3090f3316')
  })",steel
/__tests__/test-push.js,Duplicate Assert,"{'line': 260, 'column': 4, 'index': 6592}","it('push delete', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-push')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.karma.url',
      value: `http://${localhost}:8888/test-push-server.git`,
    })
    await push({
      fs,
      http,
      gitdir,
      remote: 'karma',
      ref: 'master',
      remoteRef: 'foobar',
    })
    expect(await listBranches({ fs, gitdir, remote: 'karma' })).toContain(
      'foobar'
    )
    // Test
    const onPrePush = []
    const res = await push({
      fs,
      http,
      gitdir,
      remote: 'karma',
      remoteRef: 'foobar',
      delete: true,
      onPrePush: args => {
        onPrePush.push(args)
        return true
      },
    })
    expect(res).toBeTruthy()
    expect(res.ok).toBe(true)
    expect(res.refs['refs/heads/foobar'].ok).toBe(true)
    expect(await listBranches({ fs, gitdir, remote: 'karma' })).not.toContain(
      'foobar'
    )
    expect(onPrePush).toEqual([
      {
        localRef: {
          oid: '0000000000000000000000000000000000000000',
          ref: '(delete)',
        },
        remote: 'karma',
        remoteRef: {
          oid: '0000000000000000000000000000000000000000', // This is OK: mock server threw away information about newly created branch
          ref: 'refs/heads/foobar',
        },
        url: `http://${localhost}:8888/test-push-server.git`,
      },
    ])
  })",steel
/__tests__/test-push.js,Duplicate Assert,"{'line': 280, 'column': 4, 'index': 7067}","it('push delete', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-push')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.karma.url',
      value: `http://${localhost}:8888/test-push-server.git`,
    })
    await push({
      fs,
      http,
      gitdir,
      remote: 'karma',
      ref: 'master',
      remoteRef: 'foobar',
    })
    expect(await listBranches({ fs, gitdir, remote: 'karma' })).toContain(
      'foobar'
    )
    // Test
    const onPrePush = []
    const res = await push({
      fs,
      http,
      gitdir,
      remote: 'karma',
      remoteRef: 'foobar',
      delete: true,
      onPrePush: args => {
        onPrePush.push(args)
        return true
      },
    })
    expect(res).toBeTruthy()
    expect(res.ok).toBe(true)
    expect(res.refs['refs/heads/foobar'].ok).toBe(true)
    expect(await listBranches({ fs, gitdir, remote: 'karma' })).not.toContain(
      'foobar'
    )
    expect(onPrePush).toEqual([
      {
        localRef: {
          oid: '0000000000000000000000000000000000000000',
          ref: '(delete)',
        },
        remote: 'karma',
        remoteRef: {
          oid: '0000000000000000000000000000000000000000', // This is OK: mock server threw away information about newly created branch
          ref: 'refs/heads/foobar',
        },
        url: `http://${localhost}:8888/test-push-server.git`,
      },
    ])
  })",steel
/__tests__/test-push.js,Exception Handling,"{'line': 309, 'column': 4, 'index': 7957}","it('throws UnknownTransportError if using shorter scp-like syntax', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-push')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.ssh.url',
      value: `git@${localhost}:8888/test-push-server.git`,
    })
    // Test
    let err
    try {
      await push({
        fs,
        http,
        gitdir,
        remote: 'ssh',
        ref: 'master',
      })
    } catch (e) {
      err = e
    }
    expect(err).toBeDefined()
    expect(err.code).toEqual(Errors.UnknownTransportError.code)
  })",steel
/__tests__/test-push.js,Exception Handling,"{'line': 378, 'column': 4, 'index': 9682}","it('throws an Error if no credentials supplied', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-push')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.auth.url',
      value: `http://${localhost}:8888/test-push-server-auth.git`,
    })
    // Test
    let error = null
    try {
      await push({
        fs,
        http,
        gitdir,
        remote: 'auth',
        ref: 'master',
      })
    } catch (err) {
      error = err.message
    }
    expect(error).toContain('401')
  })",steel
/__tests__/test-push.js,Exception Handling,"{'line': 402, 'column': 4, 'index': 10226}","it('throws an Error if invalid credentials supplied', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-push')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.auth.url',
      value: `http://${localhost}:8888/test-push-server-auth.git`,
    })
    // Test
    let error = null
    try {
      await push({
        fs,
        http,
        gitdir,
        remote: 'auth',
        ref: 'master',
        onAuth: () => ({ username: 'test', password: 'test' }),
      })
    } catch (err) {
      error = err.message
    }
    expect(error).toContain('401')
  })",steel
/__tests__/test-push.js,Exception Handling,"{'line': 484, 'column': 4, 'index': 12105}","it('onAuthFailure', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-push')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.auth.url',
      value: `http://${localhost}:8888/test-push-server-auth.git`,
    })
    // Test
    let err
    const onAuthArgs = []
    const onAuthSuccessArgs = []
    const onAuthFailureArgs = []
    try {
      await push({
        fs,
        http,
        gitdir,
        remote: 'auth',
        ref: 'master',
        async onAuth(...args) {
          onAuthArgs.push(args)
          return {
            username: 'testuser',
            password: 'NoT_rIgHt',
          }
        },
        async onAuthSuccess(...args) {
          onAuthSuccessArgs.push(args)
        },
        async onAuthFailure(...args) {
          onAuthFailureArgs.push(args)
          switch (onAuthFailureArgs.length) {
            case 1:
              return {
                username: 'testuser',
                password: 'St1ll_NoT_rIgHt',
              }
            case 2:
              return {
                headers: {
                  Authorization: 'Bearer Big Bear',
                  'X-Authorization': 'supersecret',
                },
              }
          }
        },
      })
    } catch (e) {
      err = e
    }
    expect(err).toBeDefined()
    expect(err.code).toBe(Errors.HttpError.code)
    expect(err.data.response).toBeTruthy()
    expect(onAuthArgs).toEqual([
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          headers: {},
        },
      ],
    ])
    expect(onAuthSuccessArgs).toEqual([])
    expect(onAuthFailureArgs).toEqual([
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          headers: {
            Authorization: 'Basic dGVzdHVzZXI6Tm9UX3JJZ0h0',
          },
          username: 'testuser',
          password: 'NoT_rIgHt',
        },
      ],
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          headers: {
            Authorization: 'Basic dGVzdHVzZXI6U3QxbGxfTm9UX3JJZ0h0',
          },
          username: 'testuser',
          password: 'St1ll_NoT_rIgHt',
        },
      ],
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          headers: {
            Authorization: 'Bearer Big Bear',
            'X-Authorization': 'supersecret',
          },
        },
      ],
    ])
  })",steel
/__tests__/test-push.js,Exception Handling,"{'line': 667, 'column': 4, 'index': 16639}","it('onAuth + cancel', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-push')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.auth.url',
      value: `http://${localhost}:8888/test-push-server-auth.git`,
    })
    // Test
    let err
    const onAuthArgs = []
    const onAuthSuccessArgs = []
    const onAuthFailureArgs = []
    try {
      await push({
        fs,
        http,
        gitdir,
        remote: 'auth',
        ref: 'master',
        async onAuth(...args) {
          onAuthArgs.push(args)
          return {
            cancel: true,
          }
        },
        async onAuthSuccess(...args) {
          onAuthSuccessArgs.push(args)
        },
        async onAuthFailure(...args) {
          onAuthFailureArgs.push(args)
        },
      })
    } catch (e) {
      err = e
    }
    expect(err).toBeDefined()
    expect(err instanceof Errors.UserCanceledError).toBe(true)
    expect(err.code).toBe('UserCanceledError')
    expect(onAuthArgs).toEqual([
      [
        `http://${localhost}:8888/test-push-server-auth.git`,
        {
          headers: {},
        },
      ],
    ])
    expect(onAuthSuccessArgs).toEqual([])
    expect(onAuthFailureArgs).toEqual([])
  })",steel
/__tests__/test-push.js,Exception Handling,"{'line': 717, 'column': 4, 'index': 17786}","it('onPrePush abort', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-fetch-server')
    await clone({
      fs,
      http,
      dir,
      gitdir,
      url: `http://${localhost}:8888/test-fetch-server.git`,
    })
    // Test
    let err
    try {
      await push({
        fs,
        http,
        gitdir,
        onPrePush: args => {
          return false
        },
      })
    } catch (e) {
      err = e
    }

    expect(err).toBeDefined()
    expect(err instanceof Errors.UserCanceledError).toBe(true)
    expect(err.code).toBe('UserCanceledError')
  })",steel
/__tests__/test-pull.js,Duplicate Assert,"{'line': 26, 'column': 4, 'index': 783}","it('pull', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-pull')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.origin.url',
      value: `http://${localhost}:8888/test-pull-server.git`,
    })
    // Test
    let logs = await log({ fs, gitdir, dir, ref: 'refs/heads/master' })
    expect(logs.map(({ commit }) => commit.message)).toEqual([
      'Initial commit\n',
    ])
    await pull({
      fs,
      http,
      gitdir,
      dir,
      remote: 'origin',
      ref: 'refs/heads/master',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
    })
    logs = await log({ fs, gitdir, dir, ref: 'refs/heads/master' })
    expect(logs.map(({ commit }) => commit.message)).toEqual([
      'Added c.txt\n',
      'Added b.txt\n',
      'Initial commit\n',
    ])
  })",steel
/__tests__/test-pull.js,Duplicate Assert,"{'line': 44, 'column': 4, 'index': 1221}","it('pull', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-pull')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.origin.url',
      value: `http://${localhost}:8888/test-pull-server.git`,
    })
    // Test
    let logs = await log({ fs, gitdir, dir, ref: 'refs/heads/master' })
    expect(logs.map(({ commit }) => commit.message)).toEqual([
      'Initial commit\n',
    ])
    await pull({
      fs,
      http,
      gitdir,
      dir,
      remote: 'origin',
      ref: 'refs/heads/master',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
    })
    logs = await log({ fs, gitdir, dir, ref: 'refs/heads/master' })
    expect(logs.map(({ commit }) => commit.message)).toEqual([
      'Added c.txt\n',
      'Added b.txt\n',
      'Initial commit\n',
    ])
  })",steel
/__tests__/test-pull.js,Exception Handling,"{'line': 75, 'column': 4, 'index': 2182}","it('pull fast-forward only', async () => {
    // Setup
    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }
    const { fs, gitdir, dir } = await makeFixture('test-pull-no-ff')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.origin.url',
      value: `http://${localhost}:8888/test-pull-server.git`,
    })
    // Test
    await fs.write(path.join(dir, 'z.txt'), 'Hi')
    await add({ fs, dir, gitdir, filepath: 'z.txt' })
    await commit({ fs, dir, gitdir, message: 'Added z.txt', author })
    const logs = await log({ fs, gitdir, dir, ref: 'refs/heads/master' })
    expect(logs.map(({ commit }) => commit.message)).toEqual([
      'Added z.txt\n',
      'Initial commit\n',
    ])
    let err = null
    try {
      await pull({
        fs,
        http,
        gitdir,
        dir,
        remote: 'origin',
        ref: 'refs/heads/master',
        fastForwardOnly: true,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      err = e
    }
    expect(err.caller).toBe('git.pull')
    expect(err.code).toBe(Errors.FastForwardError.code)
  })",steel
/__tests__/test-packObjects.js,Conditional Test Logic,"{'line': 31, 'column': 4, 'index': 1162}","it('makes a packfile', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-packObjects')
    const { filename, packfile } = await packObjects({
      fs,
      gitdir,
      oids: [
        '5a9da3272badb2d3c8dbab463aed5741acb15a33',
        '0bfe8fa3764089465235461624f2ede1533e74ec',
        '414a0afa7e20452d90ab52de1c024182531c5c52',
        '97b32c43e96acc7873a1990e409194cb92421522',
        '328e74b65839f7e5a8ae3b54e0b49180a5b7b82b',
        'fdba2ad440c231d15a2179f729b4b50ab5860df2',
        '5171f8a8291d7edc31a6670800d5967cfd6be830',
        '7983b4770a894a068152dfe6f347ea9b5ae561c5',
        'f03ae7b490022507f83729b9227e723ab1587a38',
        'a59efbcd7640e659ec81887a2599711f8d9ef801',
        'e5abf40a5b37382c700f51ac5c2aeefdadb8e184',
        '5477471ab5a6a8f2c217023532475044117a8f2c',
      ],
    })
    if (!packfile) throw new Error('type error')
    expect(await fs.exists(path.join(gitdir, `objects/pack/${filename}`))).toBe(
      false
    )
  })",steel
/__tests__/test-packObjects.js,Exception Handling,"{'line': 31, 'column': 19, 'index': 1177}","it('makes a packfile', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-packObjects')
    const { filename, packfile } = await packObjects({
      fs,
      gitdir,
      oids: [
        '5a9da3272badb2d3c8dbab463aed5741acb15a33',
        '0bfe8fa3764089465235461624f2ede1533e74ec',
        '414a0afa7e20452d90ab52de1c024182531c5c52',
        '97b32c43e96acc7873a1990e409194cb92421522',
        '328e74b65839f7e5a8ae3b54e0b49180a5b7b82b',
        'fdba2ad440c231d15a2179f729b4b50ab5860df2',
        '5171f8a8291d7edc31a6670800d5967cfd6be830',
        '7983b4770a894a068152dfe6f347ea9b5ae561c5',
        'f03ae7b490022507f83729b9227e723ab1587a38',
        'a59efbcd7640e659ec81887a2599711f8d9ef801',
        'e5abf40a5b37382c700f51ac5c2aeefdadb8e184',
        '5477471ab5a6a8f2c217023532475044117a8f2c',
      ],
    })
    if (!packfile) throw new Error('type error')
    expect(await fs.exists(path.join(gitdir, `objects/pack/${filename}`))).toBe(
      false
    )
  })",steel
/__tests__/test-merge.js,Conditional Test Logic,"{'line': 381, 'column': 4, 'index': 8885}","it(""merge 'delete-first-half' and 'delete-second-half' (dryRun)"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')
    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'delete-first-half-merge-delete-second-half',
      })
    )[0]
    const originalCommit = (
      await log({
        fs,
        gitdir,
        ref: 'delete-first-half',
        depth: 1,
      })
    )[0]
    // Test
    const report = await merge({
      fs,
      gitdir,
      ours: 'delete-first-half',
      theirs: 'delete-second-half',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      dryRun: true,
    })
    expect(report.tree).toBe(commit.commit.tree)
    // make sure branch hasn't been moved
    const notMergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'delete-first-half',
        depth: 1,
      })
    )[0]
    expect(notMergeCommit.oid).toEqual(originalCommit.oid)
    if (!report.oid) throw new Error('type error')
    // make sure no commit object was created
    expect(
      await fs.exists(
        `${gitdir}/objects/${report.oid.slice(0, 2)}/${report.oid.slice(2)}`
      )
    ).toBe(false)
  })",steel
/__tests__/test-merge.js,Conditional Test Logic,"{'line': 434, 'column': 4, 'index': 10210}","it(""merge 'delete-first-half' and 'delete-second-half' (noUpdateBranch)"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')
    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'delete-first-half-merge-delete-second-half',
      })
    )[0]
    const originalCommit = (
      await log({
        fs,
        gitdir,
        ref: 'delete-first-half',
        depth: 1,
      })
    )[0]
    // Test
    const report = await merge({
      fs,
      gitdir,
      ours: 'delete-first-half',
      theirs: 'delete-second-half',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      noUpdateBranch: true,
    })
    expect(report.tree).toBe(commit.commit.tree)
    // make sure branch hasn't been moved
    const notMergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'delete-first-half',
        depth: 1,
      })
    )[0]
    expect(notMergeCommit.oid).toEqual(originalCommit.oid)
    if (!report.oid) throw new Error('type error')
    // but make sure the commit object exists
    expect(
      await fs.exists(
        `${gitdir}/objects/${report.oid.slice(0, 2)}/${report.oid.slice(2)}`
      )
    ).toBe(true)
  })",steel
/__tests__/test-merge.js,Conditional Test Logic,"{'line': 755, 'column': 8, 'index': 18278}","it(""merge two branches that modified the same file, custom conflict resolver (prefer our changes)'"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')

    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'a-merge-c-recursive-ours',
      })
    )[0].commit
    // Test
    const report = await merge({
      fs,
      gitdir,
      ours: 'a',
      theirs: 'c',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      mergeDriver: ({ branches, contents }) => {
        const baseContent = contents[0]
        const ourContent = contents[1]
        const theirContent = contents[2]

        const LINEBREAKS = /^.*(\r?\n|$)/gm
        const ours = ourContent.match(LINEBREAKS)
        const base = baseContent.match(LINEBREAKS)
        const theirs = theirContent.match(LINEBREAKS)
        const result = diff3Merge(ours, base, theirs)
        let mergedText = ''
        for (const item of result) {
          if (item.ok) {
            mergedText += item.ok.join('')
          }
          if (item.conflict) {
            mergedText += item.conflict.a.join('')
          }
        }
        return { cleanMerge: true, mergedText }
      },
    })
    const mergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'a',
        depth: 1,
      })
    )[0].commit
    expect(report.tree).toBe(commit.tree)
    expect(mergeCommit.tree).toEqual(commit.tree)
    expect(mergeCommit.message).toEqual(commit.message)
    expect(mergeCommit.parent).toEqual(commit.parent)
  })",steel
/__tests__/test-merge.js,Conditional Test Logic,"{'line': 756, 'column': 10, 'index': 18317}","it(""merge two branches that modified the same file, custom conflict resolver (prefer our changes)'"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')

    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'a-merge-c-recursive-ours',
      })
    )[0].commit
    // Test
    const report = await merge({
      fs,
      gitdir,
      ours: 'a',
      theirs: 'c',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      mergeDriver: ({ branches, contents }) => {
        const baseContent = contents[0]
        const ourContent = contents[1]
        const theirContent = contents[2]

        const LINEBREAKS = /^.*(\r?\n|$)/gm
        const ours = ourContent.match(LINEBREAKS)
        const base = baseContent.match(LINEBREAKS)
        const theirs = theirContent.match(LINEBREAKS)
        const result = diff3Merge(ours, base, theirs)
        let mergedText = ''
        for (const item of result) {
          if (item.ok) {
            mergedText += item.ok.join('')
          }
          if (item.conflict) {
            mergedText += item.conflict.a.join('')
          }
        }
        return { cleanMerge: true, mergedText }
      },
    })
    const mergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'a',
        depth: 1,
      })
    )[0].commit
    expect(report.tree).toBe(commit.tree)
    expect(mergeCommit.tree).toEqual(commit.tree)
    expect(mergeCommit.message).toEqual(commit.message)
    expect(mergeCommit.parent).toEqual(commit.parent)
  })",steel
/__tests__/test-merge.js,Conditional Test Logic,"{'line': 759, 'column': 10, 'index': 18397}","it(""merge two branches that modified the same file, custom conflict resolver (prefer our changes)'"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')

    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'a-merge-c-recursive-ours',
      })
    )[0].commit
    // Test
    const report = await merge({
      fs,
      gitdir,
      ours: 'a',
      theirs: 'c',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      mergeDriver: ({ branches, contents }) => {
        const baseContent = contents[0]
        const ourContent = contents[1]
        const theirContent = contents[2]

        const LINEBREAKS = /^.*(\r?\n|$)/gm
        const ours = ourContent.match(LINEBREAKS)
        const base = baseContent.match(LINEBREAKS)
        const theirs = theirContent.match(LINEBREAKS)
        const result = diff3Merge(ours, base, theirs)
        let mergedText = ''
        for (const item of result) {
          if (item.ok) {
            mergedText += item.ok.join('')
          }
          if (item.conflict) {
            mergedText += item.conflict.a.join('')
          }
        }
        return { cleanMerge: true, mergedText }
      },
    })
    const mergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'a',
        depth: 1,
      })
    )[0].commit
    expect(report.tree).toBe(commit.tree)
    expect(mergeCommit.tree).toEqual(commit.tree)
    expect(mergeCommit.message).toEqual(commit.message)
    expect(mergeCommit.parent).toEqual(commit.parent)
  })",steel
/__tests__/test-merge.js,Conditional Test Logic,"{'line': 814, 'column': 8, 'index': 19951}","it(""merge two branches that modified the same file, custom conflict resolver (prefer their changes)'"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')

    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'a-merge-c-recursive-theirs',
      })
    )[0].commit
    // Test
    const report = await merge({
      fs,
      gitdir,
      ours: 'a',
      theirs: 'c',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      mergeDriver: ({ branches, contents }) => {
        const baseContent = contents[0]
        const ourContent = contents[1]
        const theirContent = contents[2]

        const LINEBREAKS = /^.*(\r?\n|$)/gm
        const ours = ourContent.match(LINEBREAKS)
        const base = baseContent.match(LINEBREAKS)
        const theirs = theirContent.match(LINEBREAKS)
        const result = diff3Merge(ours, base, theirs)
        let mergedText = ''
        for (const item of result) {
          if (item.ok) {
            mergedText += item.ok.join('')
          }
          if (item.conflict) {
            mergedText += item.conflict.b.join('')
          }
        }
        return { cleanMerge: true, mergedText }
      },
    })
    const mergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'a',
        depth: 1,
      })
    )[0].commit
    expect(report.tree).toBe(commit.tree)
    expect(mergeCommit.tree).toEqual(commit.tree)
    expect(mergeCommit.message).toEqual(commit.message)
    expect(mergeCommit.parent).toEqual(commit.parent)
  })",steel
/__tests__/test-merge.js,Conditional Test Logic,"{'line': 815, 'column': 10, 'index': 19990}","it(""merge two branches that modified the same file, custom conflict resolver (prefer their changes)'"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')

    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'a-merge-c-recursive-theirs',
      })
    )[0].commit
    // Test
    const report = await merge({
      fs,
      gitdir,
      ours: 'a',
      theirs: 'c',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      mergeDriver: ({ branches, contents }) => {
        const baseContent = contents[0]
        const ourContent = contents[1]
        const theirContent = contents[2]

        const LINEBREAKS = /^.*(\r?\n|$)/gm
        const ours = ourContent.match(LINEBREAKS)
        const base = baseContent.match(LINEBREAKS)
        const theirs = theirContent.match(LINEBREAKS)
        const result = diff3Merge(ours, base, theirs)
        let mergedText = ''
        for (const item of result) {
          if (item.ok) {
            mergedText += item.ok.join('')
          }
          if (item.conflict) {
            mergedText += item.conflict.b.join('')
          }
        }
        return { cleanMerge: true, mergedText }
      },
    })
    const mergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'a',
        depth: 1,
      })
    )[0].commit
    expect(report.tree).toBe(commit.tree)
    expect(mergeCommit.tree).toEqual(commit.tree)
    expect(mergeCommit.message).toEqual(commit.message)
    expect(mergeCommit.parent).toEqual(commit.parent)
  })",steel
/__tests__/test-merge.js,Conditional Test Logic,"{'line': 818, 'column': 10, 'index': 20070}","it(""merge two branches that modified the same file, custom conflict resolver (prefer their changes)'"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')

    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'a-merge-c-recursive-theirs',
      })
    )[0].commit
    // Test
    const report = await merge({
      fs,
      gitdir,
      ours: 'a',
      theirs: 'c',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      mergeDriver: ({ branches, contents }) => {
        const baseContent = contents[0]
        const ourContent = contents[1]
        const theirContent = contents[2]

        const LINEBREAKS = /^.*(\r?\n|$)/gm
        const ours = ourContent.match(LINEBREAKS)
        const base = baseContent.match(LINEBREAKS)
        const theirs = theirContent.match(LINEBREAKS)
        const result = diff3Merge(ours, base, theirs)
        let mergedText = ''
        for (const item of result) {
          if (item.ok) {
            mergedText += item.ok.join('')
          }
          if (item.conflict) {
            mergedText += item.conflict.b.join('')
          }
        }
        return { cleanMerge: true, mergedText }
      },
    })
    const mergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'a',
        depth: 1,
      })
    )[0].commit
    expect(report.tree).toBe(commit.tree)
    expect(mergeCommit.tree).toEqual(commit.tree)
    expect(mergeCommit.message).toEqual(commit.message)
    expect(mergeCommit.parent).toEqual(commit.parent)
  })",steel
/__tests__/test-merge.js,Conditional Test Logic,"{'line': 994, 'column': 6, 'index': 24582}","it(""merge two branches that modified the same file, manual conflict resolution'"", async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-merge')

    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'a-merge-c-manual-resolve',
      })
    )[0].commit
    // Test
    await merge({
      fs,
      dir,
      gitdir,
      ours: 'a',
      theirs: 'c',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      abortOnConflict: false,
    }).catch(e => {
      if (!(e instanceof Errors.MergeConflictError)) throw e
    })
    await add({
      fs,
      dir,
      gitdir,
      filepath: '.',
    })
    await gitCommit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      ref: 'a',
      message: ""Merge branch 'c' into a"",
      parent: ['a', 'c'],
    })
    const mergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'a',
        depth: 1,
      })
    )[0].commit

    expect(mergeCommit.tree).toEqual(commit.tree)
    expect(mergeCommit.message).toEqual(commit.message)
    expect(mergeCommit.parent).toEqual(commit.parent)
  })",steel
/__tests__/test-merge.js,Exception Handling,"{'line': 22, 'column': 4, 'index': 509}","it('prevent merge if index has unmerged paths', async () => {
    // Setup
    const { gitdir, dir, fs } = await makeFixture('test-GitIndex-unmerged')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.UnmergedPathsError.code)
  })",steel
/__tests__/test-merge.js,Exception Handling,"{'line': 322, 'column': 4, 'index': 7518}","it(""merge 'delete-first-half' and 'delete-second-half' (dryRun, missing author)"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')
    // Test
    let error = null
    try {
      await merge({
        fs,
        gitdir,
        ours: 'delete-first-half',
        theirs: 'delete-second-half',
        dryRun: true,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBe(null)
    expect(error.code).toBe(Errors.MissingNameError.code)
  })",steel
/__tests__/test-merge.js,Exception Handling,"{'line': 381, 'column': 21, 'index': 8902}","it(""merge 'delete-first-half' and 'delete-second-half' (dryRun)"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')
    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'delete-first-half-merge-delete-second-half',
      })
    )[0]
    const originalCommit = (
      await log({
        fs,
        gitdir,
        ref: 'delete-first-half',
        depth: 1,
      })
    )[0]
    // Test
    const report = await merge({
      fs,
      gitdir,
      ours: 'delete-first-half',
      theirs: 'delete-second-half',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      dryRun: true,
    })
    expect(report.tree).toBe(commit.commit.tree)
    // make sure branch hasn't been moved
    const notMergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'delete-first-half',
        depth: 1,
      })
    )[0]
    expect(notMergeCommit.oid).toEqual(originalCommit.oid)
    if (!report.oid) throw new Error('type error')
    // make sure no commit object was created
    expect(
      await fs.exists(
        `${gitdir}/objects/${report.oid.slice(0, 2)}/${report.oid.slice(2)}`
      )
    ).toBe(false)
  })",steel
/__tests__/test-merge.js,Exception Handling,"{'line': 434, 'column': 21, 'index': 10227}","it(""merge 'delete-first-half' and 'delete-second-half' (noUpdateBranch)"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')
    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'delete-first-half-merge-delete-second-half',
      })
    )[0]
    const originalCommit = (
      await log({
        fs,
        gitdir,
        ref: 'delete-first-half',
        depth: 1,
      })
    )[0]
    // Test
    const report = await merge({
      fs,
      gitdir,
      ours: 'delete-first-half',
      theirs: 'delete-second-half',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      noUpdateBranch: true,
    })
    expect(report.tree).toBe(commit.commit.tree)
    // make sure branch hasn't been moved
    const notMergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'delete-first-half',
        depth: 1,
      })
    )[0]
    expect(notMergeCommit.oid).toEqual(originalCommit.oid)
    if (!report.oid) throw new Error('type error')
    // but make sure the commit object exists
    expect(
      await fs.exists(
        `${gitdir}/objects/${report.oid.slice(0, 2)}/${report.oid.slice(2)}`
      )
    ).toBe(true)
  })",steel
/__tests__/test-merge.js,Exception Handling,"{'line': 486, 'column': 4, 'index': 11570}","it(""merge 'a-file' and 'a-folder'"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')
    // Test
    let error = null
    try {
      await merge({
        fs,
        gitdir,
        ours: 'a-file',
        theirs: 'a-folder',
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeNotSupportedError.code)
  })",steel
/__tests__/test-merge.js,Exception Handling,"{'line': 511, 'column': 4, 'index': 12167}","it(""merge 'g' and 'g-delete-file' (delete by theirs)"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')
    // Test
    let error = null
    try {
      await merge({
        fs,
        gitdir,
        ours: 'g',
        theirs: 'g-delete-file',
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)
  })",steel
/__tests__/test-merge.js,Exception Handling,"{'line': 536, 'column': 4, 'index': 12756}","it(""merge 'g-delete-file' and 'g' (delete by us)"", async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-merge')
    // Test
    let error = null
    try {
      await merge({
        fs,
        gitdir,
        ours: 'g-delete-file',
        theirs: 'g',
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)
  })",steel
/__tests__/test-merge.js,Exception Handling,"{'line': 662, 'column': 4, 'index': 15858}","it(""merge two branches that modified the same file, no conflict resolver (should conflict)'"", async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-merge')
    // Test
    const testFile = `${gitdir}/o.conflict.example`
    const outFile = `${dir}/o.txt`
    const cache = {}

    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'c',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
        cache,
      })
    } catch (e) {
      error = e
    }

    expect(await fs.read(outFile, 'utf-8')).toBe(
      await fs.read(testFile, 'utf-8')
    )
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)
  })",steel
/__tests__/test-merge.js,Exception Handling,"{'line': 696, 'column': 4, 'index': 16680}","it(""merge two branches that modified the same file, no conflict resolver, don't update worktree'"", async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-merge')
    // Test
    const outFile = `${dir}/o.txt`

    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'c',
        abortOnConflict: true,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }
    expect(await fs.read(outFile, 'utf-8')).toBeNull()
    expect(await fs.readdir(dir)).toEqual([])
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)
  })",steel
/__tests__/test-merge.js,Exception Handling,"{'line': 994, 'column': 53, 'index': 24629}","it(""merge two branches that modified the same file, manual conflict resolution'"", async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-merge')

    const commit = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'a-merge-c-manual-resolve',
      })
    )[0].commit
    // Test
    await merge({
      fs,
      dir,
      gitdir,
      ours: 'a',
      theirs: 'c',
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      abortOnConflict: false,
    }).catch(e => {
      if (!(e instanceof Errors.MergeConflictError)) throw e
    })
    await add({
      fs,
      dir,
      gitdir,
      filepath: '.',
    })
    await gitCommit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      ref: 'a',
      message: ""Merge branch 'c' into a"",
      parent: ['a', 'c'],
    })
    const mergeCommit = (
      await log({
        fs,
        gitdir,
        ref: 'a',
        depth: 1,
      })
    )[0].commit

    expect(mergeCommit.tree).toEqual(commit.tree)
    expect(mergeCommit.message).toEqual(commit.message)
    expect(mergeCommit.parent).toEqual(commit.parent)
  })",steel
/__tests__/test-merge.js,Exception Handling,"{'line': 1282, 'column': 4, 'index': 31762}","it('merge two branches with unrelated histories where they add 2 files having same name', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-empty')
    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }

    // First root commit on master adding same.txt
    await fs.write(`${dir}/same.txt`, 'content from master')
    await add({ fs, dir, gitdir, filepath: 'same.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'master',
      message: 'Add same.txt on master',
      author,
    })

    // Second unrelated root commit on branch 'other' adding same.txt with different content
    await fs.write(`${dir}/same.txt`, 'content from other')
    await add({ fs, dir, gitdir, filepath: 'same.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'other',
      parent: [],
      message: 'Add same.txt on other',
      author,
    })

    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'master',
        theirs: 'other',
        abortOnConflict: false,
        allowUnrelatedHistories: true,
        author,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)
    const resultText = await fs.read(`${dir}/same.txt`, 'utf8')
    expect(resultText).toContain('<<<<<<<')

    const matrix = await statusMatrix({ fs, dir, gitdir })
    const trackedFiles = matrix.map(row => row[0])
    expect(trackedFiles.join()).toEqual(['same.txt'].join())

    const history = await log({ fs, gitdir, ref: 'master', depth: 3 })
    const messages = history.map(entry =>
      entry.commit.message.replace('\n', '')
    )
    expect(messages.join()).toEqual(['Add same.txt on master'].join())
  })",steel
/__tests__/test-merge.js,Exception Handling,"{'line': 1424, 'column': 4, 'index': 36139}","it('merge two branches with unrelated histories where they add files with same path in nested directories', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-empty')
    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }

    // First root commit on master adding nested file
    await fs.mkdir(`${dir}/shared`)
    await fs.mkdir(`${dir}/shared/path`)
    await fs.write(`${dir}/shared/path/conflict.txt`, 'content from master')
    await add({ fs, dir, gitdir, filepath: 'shared/path/conflict.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'master',
      message: 'Add nested file on master',
      author,
    })

    // Second unrelated root commit on branch 'other' adding same nested file with different content
    await fs.mkdir(`${dir}/shared`)
    await fs.mkdir(`${dir}/shared/path`)
    await fs.write(`${dir}/shared/path/conflict.txt`, 'content from other')
    await add({ fs, dir, gitdir, filepath: 'shared/path/conflict.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'other',
      parent: [],
      message: 'Add nested file on other',
      author,
    })

    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'master',
        theirs: 'other',
        abortOnConflict: false,
        allowUnrelatedHistories: true,
        author,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)
    const resultText = await fs.read(`${dir}/shared/path/conflict.txt`, 'utf8')
    expect(resultText).toContain('<<<<<<<')

    const matrix = await statusMatrix({ fs, dir, gitdir })
    const trackedFiles = matrix.map(row => row[0])
    expect(trackedFiles.join()).toEqual(['shared/path/conflict.txt'].join())

    const history = await log({ fs, gitdir, ref: 'master', depth: 3 })
    const messages = history.map(entry =>
      entry.commit.message.replace('\n', '')
    )
    expect(messages.join()).toEqual(['Add nested file on master'].join())
  })",steel
/__tests__/test-merge.js,Magic Number,"{'line': 1232, 'column': 41, 'index': 30277}","it('merge two branches with unrelated histories where they add 2 files having different name', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-empty')

    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }

    // First root commit on 'master'
    await fs.write(`${dir}/a.txt`, 'hello a')
    await add({ fs, dir, gitdir, filepath: 'a.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'master',
      message: 'Add a.txt',
      author,
    })

    // Second root commit on unrelated branch 'other'
    await fs.write(`${dir}/b.txt`, 'hello b')
    await add({ fs, dir, gitdir, filepath: 'b.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'other',
      message: 'Add b.txt',
      author,
    })

    const report = await merge({
      fs,
      gitdir,
      ours: 'master',
      theirs: 'other',
      abortOnConflict: false,
      allowUnrelatedHistories: true,
      author,
    })

    expect(report).toBeTruthy()
    expect(report.mergeCommit).toBeTruthy()
    const mergeHead = (await log({ fs, gitdir, ref: 'master', depth: 1 }))[0]
      .commit
    expect(mergeHead.parent.length).toBe(2)

    const matrix = await statusMatrix({ fs, dir, gitdir })
    const trackedFiles = matrix.map(row => row[0])
    expect(trackedFiles.join()).toEqual(['a.txt', 'b.txt'].join())

    const history = await log({ fs, gitdir, ref: 'master', depth: 3 })
    const messages = history.map(entry =>
      entry.commit.message.replace('\n', '')
    )
    expect(messages.join()).toEqual(
      [`Merge branch 'other' into master`, 'Add b.txt', 'Add a.txt'].join()
    )
  })",steel
/__tests__/test-merge.js,Magic Number,"{'line': 1364, 'column': 41, 'index': 34255}","it('merge two branches with unrelated histories where they add files in nested directories', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-empty')

    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }

    // First root commit on 'master' with nested directory
    await fs.mkdir(`${dir}/dir1`)
    await fs.mkdir(`${dir}/dir1/subdir1`)
    await fs.write(`${dir}/dir1/subdir1/file1.txt`, 'content from master')
    await add({ fs, dir, gitdir, filepath: 'dir1/subdir1/file1.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'master',
      message: 'Add file in nested directory on master',
      author,
    })

    // Second root commit on unrelated branch 'other' with different nested directory
    await fs.mkdir(`${dir}/dir2`)
    await fs.mkdir(`${dir}/dir2/subdir2`)
    await fs.write(`${dir}/dir2/subdir2/file2.txt`, 'content from other')
    await add({ fs, dir, gitdir, filepath: 'dir2/subdir2/file2.txt' })
    await gitCommit({
      fs,
      dir,
      gitdir,
      ref: 'other',
      message: 'Add file in different nested directory on other',
      author,
    })

    const report = await merge({
      fs,
      gitdir,
      ours: 'master',
      theirs: 'other',
      abortOnConflict: false,
      allowUnrelatedHistories: true,
      author,
    })

    expect(report).toBeTruthy()
    expect(report.mergeCommit).toBeTruthy()
    const mergeHead = (await log({ fs, gitdir, ref: 'master', depth: 1 }))[0]
      .commit
    expect(mergeHead.parent.length).toBe(2)

    const matrix = await statusMatrix({ fs, dir, gitdir })
    const trackedFiles = matrix.map(row => row[0])
    expect(trackedFiles.join()).toEqual(
      ['dir1/subdir1/file1.txt', 'dir2/subdir2/file2.txt'].join()
    )

    const history = await log({ fs, gitdir, ref: 'master', depth: 3 })
    const messages = history.map(entry =>
      entry.commit.message.replace('\n', '')
    )
    expect(messages.join()).toEqual(
      [
        `Merge branch 'other' into master`,
        'Add file in different nested directory on other',
        'Add file in nested directory on master',
      ].join()
    )
  })",steel
/__tests__/test-log.js,Conditional Test Logic,"{'line': 326, 'column': 4, 'index': 13500}","it('has correct payloads and gpgsig', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-log')
    // Test
    const commits = await log({ fs, gitdir, ref: 'HEAD' })
    expect(commits.length).toBe(5)
    // Verify
    for (const commit of commits) {
      const { valid } = await pgp.verify({
        payload: commit.payload,
        publicKey: `-----BEGIN PGP PUBLIC KEY BLOCK-----
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=QSo+
-----END PGP PUBLIC KEY BLOCK-----`,
        signature: commit.commit.gpgsig,
      })
      expect(valid).toEqual(['9609b8a5928ba6b9'])
    }
  })",steel
/__tests__/test-log.js,Magic Number,"{'line': 11, 'column': 32, 'index': 399}","it('HEAD', async () => {
    const { fs, gitdir } = await makeFixture('test-log')
    const commits = await log({ fs, gitdir, ref: 'HEAD' })
    expect(commits.length).toBe(5)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501475810,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501475810,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfrPiAAoJEJYJuKWSi6a5r7AP/0iG5t9oO4OFkvxCbhUd5fra
      Q2Z/ujck0yJFW3xF/2/Rzi/4PZ93RPhwB/JUVa8I9zPi5mVJMV6+ZoqiRLmgMb8g
      RJyw5Umi2JxtkpssaVfd7RUzjPiXBl9fb0lYgZttGf/sUXoEAUtX0hCwFqN/jALZ
      R+x6DqQy4XPkRpLJtQ/ABIL6dpRWflQVsONE7a4M/PA/dON4JaoCl9NTEsOPDs+J
      uY/dus3C8DTa2cdeb5OCxpjG7uQEzhMF7PfO/j+uAMNh96HVLvZGQcomxDzfglph
      EbEYm21QnpfmYCddnrM2TM3CsYnLutnk85nfz8JcaO40H2uBoxXf6iJguTUDeDWx
      eUDoQNpegfWf2VqoHqsAPamqEDnKt5sWDfx5GLhM7tkbmCDZYKiCIc6YZX2lySlu
      plaAg/NuAETtnHknDABWlVz9TQUrW6VG+iseS/rN+ZvxFQHZQvX3pNLigAa5Ey4T
      bYTU2r/JAajb+e91tEV52+ZzF7QO5URhDBQkiSurFV830HfBFBel/TcOvzWvsW8l
      gaESl+Pz8194Z/fEfIVec8IeLPURpSfOKzRZRbu80qBwgE6IBbhbiveVKE5TmaLO
      OgA2QgYxLNoaP6fR0mzBa/XqVZeTTGUrgPpGprP/AktZdl+8hPT2s8TkeO9wAVL2
      PwpokxoC+HRjO+bEBAs5
      =n8ff
      -----END PGP SIGNATURE-----"",
            ""message"": ""Update gitignore
      "",
            ""parent"": Array [
              ""ae054080bcfd04c84e0820e0cf74b31f4a422d7c"",
            ],
            ""tree"": ""24224c8f5d4cb40dc61f4210e7eb2c964f7e2407"",
          },
          ""oid"": ""3c945912219e6fc27a9100bf099687c69c88afed"",
          ""payload"": ""tree 24224c8f5d4cb40dc61f4210e7eb2c964f7e2407
      parent ae054080bcfd04c84e0820e0cf74b31f4a422d7c
      author Will Hilton <wmhilton@gmail.com> 1501475810 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501475810 -0400
      
      Update gitignore
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501475755,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501475755,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfrOrAAoJEJYJuKWSi6a5VWMP/il3myaUFoxh2DaM/1+F5GFC
      OdS+jUheAMak+M8s87kGrH8Fhv+q46RpSIrrQoz9COYM0tBFDygn2xiIdoMgqwP+
      uSXVRWzawZS+0T0nYIVCZLAN41iniL6um3XopNExpOF6rzsgi5t4s+Ch2fksOhBz
      Ze7jVtFOrmd2O9QlofgM9ICXJDJcrFRd9tPSQO9Nu4sJPpZjcYUfIfOcSIvwrB6p
      ySR4Kyh9zrNRxxY8LEbcXZGvet2wvmhBV6oQo1Xh++E5xINvcHHNo0frZl+/wSSm
      QpVE4ErEOBKYnjFqrtsdra9fmAa30/gl0pC3kBbAYdqbB1k0LgWeBfZ08Lmw5qON
      ZEDzm2jV9PFCuDs6DTk20dguyhIQIvSetpM8LEWUpVSUiXMJkJs48TZ5nTry79me
      QHf3gGNTZ6TQ9Wnjj7QXplVHFMbUc/9TJkXwQ1yYiRCY4z6g9j75qEZmhmWcUg5G
      1wHb2xcx5uNysb8gFJT4Anb1GL9VdNAy82uaEt7OgpaFozLnqS/ZqZljnM4VUY+e
      A0/Fw1cirSCuVCboA3pPNFyD5vrQcYU+RYEyxdMCf9BBO1/Zuf2qfsVOcIr3hGB6
      EaqfZgz3hL/6DRoaira+wo6vQWDLDfbkKmJTSVTXO/p9gWhOGo2J1w75fJmmwbte
      DW9rcJWg376XhOdUJYjl
      =kq+d
      -----END PGP SIGNATURE-----"",
            ""message"": ""Finished implementing fetching trees and blobs from Github API, even if we can't push to it.
      "",
            ""parent"": Array [
              ""3e80cede3c2a753a5272ed4d93496b67bb65cb0d"",
            ],
            ""tree"": ""6b858a95cc8e87677aff79a645ae178923caa5f5"",
          },
          ""oid"": ""ae054080bcfd04c84e0820e0cf74b31f4a422d7c"",
          ""payload"": ""tree 6b858a95cc8e87677aff79a645ae178923caa5f5
      parent 3e80cede3c2a753a5272ed4d93496b67bb65cb0d
      author Will Hilton <wmhilton@gmail.com> 1501475755 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501475755 -0400
      
      Finished implementing fetching trees and blobs from Github API, even if we can't push to it.
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501462174,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501462174,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfn6eAAoJEJYJuKWSi6a5H/wP/0iG/chGZyd1b0ZIpI43saW9
      GzGZsKMgUmCmy+CWPIUDJ5p6p045xBDwRrMqdKPvDsJrpDmcUvV8usbL3nQWKvZj
      oeSeOvC4C6yw6k66Zr0YtCrcAjqfAUAsyEdiZ+7JNigDB9MqUufw2sYurlulYtBu
      2zv22QIep5AYG0pDhSWFbeNuzesL+uk1sxoGTqQN7ER/qnKPWPQwMBNezpA65a3O
      WgH2lnPpyDPc6S356Nkr8f9fvQMxx66vXdR07cIw9gsA6dzgW+aUC9w4rAZ9Afk2
      SPsARmm8DH1vwwQMbiVzcKuvZ5/yWpy2XJjR2v/IhtD8dtYZDAlUbq+5jIpS9eoa
      046xp7GJ5cawOXhoWJfpvmj9ozFkQA8yZvNQ/DmUX7mrknR3pvOuxKFd/WAHZ0R/
      M696r6MIbAWWmy6/g76qcj//oEhlTWiaoxqBL5HNxRIAJzhM8gGBmtv7L+mSxKtb
      b5foIdbQZ/s890Cnm632KxTQdPkVwInP7oratrYsvpXoe+X6/EOYvhPZYaFARm+C
      KS0bq7XbfGxgswD7/6rOjOL4G3WNs0eBBf4KTOZQ4HLM72cjgcMsSSgHMUarLfCo
      KLW+2DEuHJhzF4yBcR9uSUdT0t/BbqXpRwNL0QI8nOKmvbuZqMkDHJZHOCqbjn+8
      hkMXWZGGpdRSNcNY9Hw8
      =VFL/
      -----END PGP SIGNATURE-----"",
            ""message"": ""My oh shit moment
      "",
            ""parent"": Array [
              ""1c04ba2c3b7c61cdfc0ddc3f9515116bc0e06863"",
            ],
            ""tree"": ""d1a3e8c5371d481b54e32916da162e08a87ad294"",
          },
          ""oid"": ""3e80cede3c2a753a5272ed4d93496b67bb65cb0d"",
          ""payload"": ""tree d1a3e8c5371d481b54e32916da162e08a87ad294
      parent 1c04ba2c3b7c61cdfc0ddc3f9515116bc0e06863
      author Will Hilton <wmhilton@gmail.com> 1501462174 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501462174 -0400
      
      My oh shit moment
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501454660,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501454660,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfmFEAAoJEJYJuKWSi6a5UeUP/3H2AdaOG5g1awkyHSC7sax9
      ZAQZhHumcufXoe4jNlKNogk0SUNud7H9dbhG3D7pbpujrLfjPPQ5rrQ5k2RdbuzR
      /YRuPPv9fdukWSCX3tXp63BzeNF18i/scIODgX2tT3RmihRldSWopgGpfRnks9o1
      cTAhmhjEIOH2wNki7u0M9WT6ntSUw99kglZ2vQGlExp97NFuVS68LsGjdlOpL/Lx
      kYxZUap5NVU1CFQZRgeSKZYKGVanuAbSFrGp5dHdY33YXxUQ2POzzH/sZIRRvnFZ
      T11K4AN4O7NhO0nujJS9VDrNgU20Kxwxl9FsVMwjSDdlf8ZROVbkse1U/pGjchwN
      V+1j3wMzbu0AHCcqkMB5zny/6fLrZigclOTXgq/zFiwh4FjMYwraGIKIYpTWYQ65
      d+BfM3nb7j6otAQvrxiIyNe7dwWPI39OZeFk6krAQNg1Lm1cxWwqWiWgXpZAmQwd
      yNlgQ9WLjZqiKUI8uxYJB3IznpDjIvO7t8Fq2EmDF0L4/t2LTD4JIGPOlKBx0Abr
      5J9lI+2GLTk1ZRPpDk/7w/UJpSxoeGyo5+bI9RaWQRgzkpSLyPTlvipuBLgZefj2
      njEC13b2FdnupU2qhjTqptwh1t5qrOQ4COYehMFJyhHllu/S1gV53pdBQ3N1sw35
      R4YVFfBN+FJiRwiGq3vn
      =zxDV
      -----END PGP SIGNATURE-----"",
            ""message"": ""Git init, and parts of git fetch
      "",
            ""parent"": Array [
              ""1e40fdfba1cf17f3c9f9f3d6b392b1865e5147b9"",
            ],
            ""tree"": ""dd92ed7e55ddc0c74f467a8899cc281d909c6bb9"",
          },
          ""oid"": ""1c04ba2c3b7c61cdfc0ddc3f9515116bc0e06863"",
          ""payload"": ""tree dd92ed7e55ddc0c74f467a8899cc281d909c6bb9
      parent 1e40fdfba1cf17f3c9f9f3d6b392b1865e5147b9
      author Will Hilton <wmhilton@gmail.com> 1501454660 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501454660 -0400
      
      Git init, and parts of git fetch
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501381894,
              ""timezoneOffset"": 240,
            },
            ""committer"": Object {
              ""email"": ""wmhilton@gmail.com"",
              ""name"": ""Will Hilton"",
              ""timestamp"": 1501381894,
              ""timezoneOffset"": 240,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----
      Version: GnuPG v1
      
      iQIcBAABAgAGBQJZfUUGAAoJEJYJuKWSi6a51VIQAJPwVk7bFWbNoLbi9Hi931k3
      E6kGW8JnWwcT6Y7fpm0oNpoXt+UzqJdUhVTi+79ws3yKc0u1cA23nVXDUQYmNBT7
      3YkzXP2b6OE8i7n0ffzWbOIwHqWPn7lm0RlssSEYMAwGzDTP4fj2isRCFBqQ2lb3
      dqp7ZbzikvkkQONs9AKpE7LpWYTVuyElBwO2RtlIcZQrs29fBxZg4q4fkF+mqOhp
      DMWMIvTNeCa35sjmWh4+iPXO2CtoYVKXfCzZStzleeCuwQGRhfCLxrxtcuXOREjG
      DilGnCZ0iM9+ClzD4wDUf/aY3F5exyq2oqktIq78EhFvIIozY+gUaTn6zXicr5ud
      30QQP063Tf8wC3Cy95aEq9QqLYkMXhOYBDym5fWawEWo7ssmOIW1o0ISfSI8pTVZ
      bZr5f9gQZETlTWhSPh5IGqqdHrI2fw5pkmO1N/OEn4L8D7R8josty28V4+wk2gsO
      wUSPyBv7EpVx2JtO+9Wu941fZK2qOBBmTjcTYys9PQeY9UHtrTQ3y/1r/qdLpdUH
      9HK/x5yNHqpnSATHpRiZnfkvKfaxxwIbaOLBPV8khPa/zu9dD+0WxDXStLVBWfXg
      MvYAu4q+mQSgON1Qu+kWg67lNhx//kRH0K+vUMJMIvc8M+yUgkJhRqH/HIEzEcJV
      ee4fN2IIWX0CTNr8Fs8a
      =0Txp
      -----END PGP SIGNATURE-----"",
            ""message"": ""Initial commit
      "",
            ""parent"": Array [],
            ""tree"": ""421909592ea5e22c6dda69d1cc85118240478444"",
          },
          ""oid"": ""1e40fdfba1cf17f3c9f9f3d6b392b1865e5147b9"",
          ""payload"": ""tree 421909592ea5e22c6dda69d1cc85118240478444
      author Will Hilton <wmhilton@gmail.com> 1501381894 -0400
      committer Will Hilton <wmhilton@gmail.com> 1501381894 -0400
      
      Initial commit
      "",
        },
      ]
    `)
  })",steel
/__tests__/test-log.js,Magic Number,"{'line': 252, 'column': 32, 'index': 10673}","it('HEAD depth', async () => {
    const { fs, gitdir } = await makeFixture('test-log')
    const commits = await log({ fs, gitdir, ref: 'HEAD', depth: 1 })
    expect(commits.length).toBe(1)
  })",steel
/__tests__/test-log.js,Magic Number,"{'line': 262, 'column': 32, 'index': 10923}","it('HEAD since', async () => {
    const { fs, gitdir } = await makeFixture('test-log')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      since: new Date(1501462174000),
    })
    expect(commits.length).toBe(2)
  })",steel
/__tests__/test-log.js,Magic Number,"{'line': 324, 'column': 32, 'index': 13479}","it('has correct payloads and gpgsig', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-log')
    // Test
    const commits = await log({ fs, gitdir, ref: 'HEAD' })
    expect(commits.length).toBe(5)
    // Verify
    for (const commit of commits) {
      const { valid } = await pgp.verify({
        payload: commit.payload,
        publicKey: `-----BEGIN PGP PUBLIC KEY BLOCK-----
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=QSo+
-----END PGP PUBLIC KEY BLOCK-----`,
        signature: commit.commit.gpgsig,
      })
      expect(valid).toEqual(['9609b8a5928ba6b9'])
    }
  })",steel
/__tests__/test-log-file.js,Exception Handling,"{'line': 234, 'column': 4, 'index': 9031}","it('a deleted file without force should throw error', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    let err
    try {
      await log({
        fs,
        gitdir,
        ref: 'HEAD',
        filepath: 'a/b/rm.md',
      })
    } catch (error) {
      err = error
    }
    expect(err).toBeDefined()
    expect(err.message).toMatch('Could not find')
  })",steel
/__tests__/test-log-file.js,Magic Number,"{'line': 16, 'column': 32, 'index': 474}","it('a newly added file', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'newfile.md',
    })
    expect(commits.length).toBe(2)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""araknast@protonmail.com"",
              ""name"": ""araknast"",
              ""timestamp"": 1653969605,
              ""timezoneOffset"": 420,
            },
            ""committer"": Object {
              ""email"": ""araknast@protonmail.com"",
              ""name"": ""araknast"",
              ""timestamp"": 1653969605,
              ""timezoneOffset"": 420,
            },
            ""message"": ""update newfile
      "",
            ""parent"": Array [
              ""dcb1c5fe6cc28e7757c4bc4d7dbf5b061c38ec48"",
            ],
            ""tree"": ""331f342f6e9b38c45e17189691134cb4a72189d2"",
          },
          ""oid"": ""04833cdb10e0f8fa81800cafa98e1381a1c6c58e"",
          ""payload"": ""tree 331f342f6e9b38c45e17189691134cb4a72189d2
      parent dcb1c5fe6cc28e7757c4bc4d7dbf5b061c38ec48
      author araknast <araknast@protonmail.com> 1653969605 -0700
      committer araknast <araknast@protonmail.com> 1653969605 -0700
      
      update newfile
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""araknast@protonmail.com"",
              ""name"": ""araknast"",
              ""timestamp"": 1653969041,
              ""timezoneOffset"": 420,
            },
            ""committer"": Object {
              ""email"": ""araknast@protonmail.com"",
              ""name"": ""araknast"",
              ""timestamp"": 1653969041,
              ""timezoneOffset"": 420,
            },
            ""message"": ""add newfile
      "",
            ""parent"": Array [
              ""18f202dfed5cb66a295dc57f1f4ba1b7f6b74f36"",
            ],
            ""tree"": ""59c1caba006bb27077d11f1c0ff7ad3ff4b2b422"",
          },
          ""oid"": ""dcb1c5fe6cc28e7757c4bc4d7dbf5b061c38ec48"",
          ""payload"": ""tree 59c1caba006bb27077d11f1c0ff7ad3ff4b2b422
      parent 18f202dfed5cb66a295dc57f1f4ba1b7f6b74f36
      author araknast <araknast@protonmail.com> 1653969041 -0700
      committer araknast <araknast@protonmail.com> 1653969041 -0700
      
      add newfile
      "",
        },
      ]
    `)
  })",steel
/__tests__/test-log-file.js,Magic Number,"{'line': 90, 'column': 32, 'index': 2894}","it('a file only', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'README.md',
    })
    expect(commits.length).toBe(3)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509836,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509836,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77B8wACgkQEPFehIUs
      uGi0CQ//ciB5DDcHppFv1caaOiEYUos8oc871eMMbXtl+y9eTfzN6VEwpXY8matE
      3hxMpe4YAUpivfQ3a75d5MEy5iEpF/U9rCkWBlGpdqG3+rvmrvpQXo+PZEzdP84E
      7rz1Ue2PnfivXCzo2zvDoyMLWqFbNgxXIwr0ST2SxuBTsVIwF/6y80uXa/8VQXfK
      MBCFKKcBK03ruZAWiLIwMNvYTxDIMvupRIN2rzyRpOb8lCSWmyw1/eqzF5soVy62
      HraCZlK1iyv9XaL0qn+SlAGYYsJylp8sfLUmU0y2qeEtLYdRLS25yRAK9h7l5RD2
      qTmQwPb5vx1ldFALr90qgVZc3j7xI5xnL6UtiMGSoZM+HuJ3eioOisXf0aAaxr6U
      ImY98WAIPuAAx6rUhHP27r0w0hDABFZmrMtO7FkH6wcqM2LJIweLGFZtKXePmR14
      CH4cQw4ylSjtrcQFguUF7rvz0sX69IeDTTF2ppaH9uQclL+3F0Bj78XiH9Dflx4E
      6+HfY98tdLPcjGfcdAguLBbKZslmYz7uUeqvHyrgVER6xMFcrGR7IUPLI0IWjtqY
      CL+5+gxD2O4FIUhY2hwISLHx+cWsCsAmiBZKx5OhQeW9nn4D8ex4WQK/go7iCrEe
      LnuTba+0qmNBTF7f7a+U0x1ReeipUk19bEuP7P1K7Ppc1C+BYT4=
      =nAWS
      -----END PGP SIGNATURE-----"",
            ""message"": ""feat: update to readme and hi.md
      "",
            ""parent"": Array [
              ""8e98db35c3e3e01014f78a60786b1b3b96a49960"",
            ],
            ""tree"": ""281d4cba64e37323777e7f3ee222d504ed8fa0ea"",
          },
          ""oid"": ""bba48a582aaa7e572c844cf7f42f3cd03eab81f0"",
          ""payload"": ""tree 281d4cba64e37323777e7f3ee222d504ed8fa0ea
      parent 8e98db35c3e3e01014f78a60786b1b3b96a49960
      author Riceball LEE <snowyu.lee@gmail.com> 1593509836 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509836 +0800

      feat: update to readme and hi.md
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509669,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509669,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77ByUACgkQEPFehIUs
      uGjJYQ/9HNh4TJO/V+ckTyMDzf+Z4Aih6ytn63ispZnfbKb5hPEV+eG1HRuPthF4
      kNilem8w//QYbllbih9bbw3tKvh2SaWYHIOEDI6eA/1k5Bd0nYLi5HNWZG+bOZNR
      XdDI+yPBAQSl4607S2xGeOH7HrSzVSVbheDjNhwYBiRDOvbFxhx3Sc/G+vO8IfdU
      MCLzVhwizNNclKIMWKaUSpBpJuqxsRK4oINT8wJQLB4LRQ/M2CXgjSjZt0e9NtFl
      +6OxGKBbgioNMg6TXzvmqFJ4eqGk1tgMz/qYX1zjCRR2jZ1g/anht8OJRppdz2/0
      k87EN+lLpN5H/Z2tSJMrKBHaCJWo72vrcyQzpLjtVUVdHNdOB66+60yqSDZiz7pc
      1ou/9jM3cbtEwtvaD+W/JJvG7ctFOM7efM3iGghW2jccJ7Ku/DIlxwCXE6HNCjDf
      azPFqO0Y9fw7ZoJl+D7sotea2xaWMhxspUoHxtnYxah6tzJ6KQ8eZ4GR8FoMw2dj
      szUaHVtLRg+Nx/G5YWimOFNUrgA3lQYjh9+fgvodxhIQvd9KVW/qCdX6ZQM9vDXU
      o9d+QEdd/hzkMrOEHscT3nqKgeIEj6JSBg27kDraM6L0dAP4wCN/9h2dbR2ke0j2
      im+CRYtkgJz5EpJ4uN1B7SDUvdBrjYIzC2Aqiohh6M2ehP1in7g=
      =IvVn
      -----END PGP SIGNATURE-----"",
            ""message"": ""feat: update to README
      "",
            ""parent"": Array [
              ""533131624898bb8ff588b48c77b26d63e7eb180f"",
            ],
            ""tree"": ""2ed69fff23ee6e239744c7277ab80bf40a644ece"",
          },
          ""oid"": ""37c51dcbe78dd2fbdca15cf74c6c540f879a5bbb"",
          ""payload"": ""tree 2ed69fff23ee6e239744c7277ab80bf40a644ece
      parent 533131624898bb8ff588b48c77b26d63e7eb180f
      author Riceball LEE <snowyu.lee@gmail.com> 1593509669 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509669 +0800

      feat: update to README
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509547,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509547,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77BqsACgkQEPFehIUs
      uGj/oRAAmOMhskEjKwcFaEnC7InU/UMd4PHAy3XlKwqUCiQVEJWWi6B81n5IYsWi
      mDOKXGYenlYOAf0HFqs7nPBeINDRFQp03d01wZT7JgacpERCvvu53IHLH8ndJehL
      MQaRtWV/SpScj4OZH4Wzm6tjB4IBB/agZWM67tU4KKI2i6TOhQw8ktBoXbXGWO9g
      OwjHW4mZn5eggIhyNzNKWRwzImopYlcBGqtYil5l4LWXADBfxAYfBCA296HkiD1N
      sFzsi5mak7bKyW5/dFI9uP27BQSLLbGdbJIJlkYXi8XIo/sLPJGA0BHuiNLAVXUn
      E/CO4hBH/tZtJNk3jg0TPLey4Lh34d3Tw8+6z6CvMKQtZ9JUXy8rAWMvAXg0+YVp
      IvT+xA6HxECuBZ6UAYLU1ZHAvQtZch6XhJTirOJ5SMklTNKSiGaCLfDP/iuRWOYo
      4x52uwkInIuintkcIZocjwEQ5DsG6jO4ylbwmEaWgpzEuR7xOuIBx38dsCoSDD+D
      kyZF7ijammlt5Wc6A2u7ewEgCEy/GMEMJ+hUXqhJJ9Gi2uYU/WmC9GJDqD12JsEa
      m6FFvEd+zCH/9K+O5eBUS9WFpiwXPP+amaXGBWkXnlbEYf/j9QemZXi/dkn1qCE7
      yM9yzr8Tb0dJWqvovK42AlCuYsZ9BYOBM3zz+pGhpSdES9OYO08=
      =/hmk
      -----END PGP SIGNATURE-----"",
            ""message"": ""first commit
      "",
            ""parent"": Array [],
            ""tree"": ""5640888e247e986136d36b1d52a9881abc7170f6"",
          },
          ""oid"": ""8651dcc28c58d96439e99aa2bf239bf2ab238b73"",
          ""payload"": ""tree 5640888e247e986136d36b1d52a9881abc7170f6
      author Riceball LEE <snowyu.lee@gmail.com> 1593509547 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509547 +0800

      first commit
      "",
        },
      ]
    `)
  })",steel
/__tests__/test-log-file.js,Magic Number,"{'line': 256, 'column': 32, 'index': 9543}","it('a deleted file forced', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'a/b/rm.md',
      force: true,
    })
    expect(commits.length).toBe(6)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593652995,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593652995,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl79NwMACgkQEPFehIUs
      uGh+EA//f+cNby3i8IhD5LL5elmR6qp+KFNLQMEa7nvcUmYQX2Ffx4QAN0WtPQ+O
      y6PmrQg5MLfCPzANthY3oKnkvjIYbpnBF2JTeN2HA8mF8/HtGakMfeykkeuaGP6V
      Kdk4I2jiXC22g/Zy7VAzbYdJTk96yWw71lpufQa1voy8ykCCu/YgeO4EjQME2RYn
      82W9+X4Qxx5bu0C0lKMwfdhAcR/MDTye0jbu33krwnuXsNyA+6OKBIOfIAWK8PWY
      iTwvkfQ+61T0dGFAdi8tJCfGZ6JRBf482KHR/gSwmwq59g7quS/snnybB6kGwrqZ
      tScHZ6Sy08xHYRbibV8HmOAyIBKZr1ZPtEjBx5Aj6Q4qKsTkZ3Q5ZTTi8Ayhm1SM
      y1mJ20d3B0WM9F48w0a8qbKxNn7zefW88QHq3PB6wdGechkZ/Wq0xN2z/h3Sl5W3
      ZSmJcvgMFJwc/p7ci2spkR+ibVnFNdvn0xinUvrJGftFuiEqlZfHwo1t6KkmX9st
      X7+30WwKmotxgeBfV0g1Br4YpaZTKJc5V2JkU+gtjnIlb/7XU6eWm+vCInad5QdL
      NeiYCPsrT9ejboKghAIteNNfiuauiRnpZ/06H5gi2OVeyChA1urD/pKjJyaNllbh
      XZTv9Wqzt6oQzR6FV0HH5H9ACqOnCJXsTUoydzt843MFHmPDL0Y=
      =77Yr
      -----END PGP SIGNATURE-----"",
            ""message"": ""redel rm.md
      "",
            ""parent"": Array [
              ""91e66ded3cee73f5f181fbd0e7a4703f1c12bb9f"",
            ],
            ""tree"": ""7ab59df3bfd122ef5d24c70f9c8977f03b35e720"",
          },
          ""oid"": ""9a4eb099547166c9cf28628a127cfc9e59fa4f29"",
          ""payload"": ""tree 7ab59df3bfd122ef5d24c70f9c8977f03b35e720
      parent 91e66ded3cee73f5f181fbd0e7a4703f1c12bb9f
      author Riceball LEE <snowyu.lee@gmail.com> 1593652995 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593652995 +0800

      redel rm.md
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593652652,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593652652,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl79NawACgkQEPFehIUs
      uGj7BRAAjZjpjaP6Kl++qtsHS5GdzMCVyocVOE+UCOWU55ImjJI9g2ajlnWfIUuM
      oZTFCG123eY0vGtXTCpcrNUPO3QvVtkIlZybMMFcJJMoENWjQ1rWZEVX4UK/skkM
      kKt1ZFVJHfgLnqsFGcyR5Fmr9omm3faVinyIxQhhdNxIYV44x4Uj5IszZul4yeQr
      NBdrPpmChT53ST3+WNp1/c7iSeMjUpXO+CVkmmG0kieThJgKBqkBTlholwYrVCgS
      B5MTgVzLh9NGoJHs+9Qd5pze41tIPNJbCWtWimoOdWJTo91L29qT747tNC14v6zh
      dkemZgUsO81lq96WiTekDS2E9PDWVWk1mi2XAXrsQ8OqDKYDwkLQa4GvlxjQrNEU
      1FG0btHD0ddYYEwBN4uK5wsXA60i1qDetggGT+CcYi2yX4MqFCI4GJgf4Oj0htht
      ltX7fMFZu5sKSOd1vLE8RxS2c4IgNQZ4ZFCAW1mfBAV31RLXG4BH1f/4laKvMrKO
      5EUufJcPIW4vKAXVVGyPMgenkEUrXL/ImYt1kuSAMx2pffahWQzaF7rTXAWO2YK+
      bqajFbubxMPbDPW70pnYQJLwuLve2IqBbPsMghx+B30F0PzCajg3XvJv7ZdqodSE
      wKn2DCea/8Rj7O/GYRPJJtJ8ITwhGMLxRC5s7j6mJAxj5IdB2fw=
      =z3mu
      -----END PGP SIGNATURE-----"",
            ""message"": ""feat: readd the rm.md
      "",
            ""parent"": Array [
              ""1bc226bc219beea3fb177de96350d8ad2f4c57cd"",
            ],
            ""tree"": ""e7bd10ca01b3377fa6fbe633ce104698b5d7dd29"",
          },
          ""oid"": ""91e66ded3cee73f5f181fbd0e7a4703f1c12bb9f"",
          ""payload"": ""tree e7bd10ca01b3377fa6fbe633ce104698b5d7dd29
      parent 1bc226bc219beea3fb177de96350d8ad2f4c57cd
      author Riceball LEE <snowyu.lee@gmail.com> 1593652652 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593652652 +0800

      feat: readd the rm.md
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509970,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509970,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77CFIACgkQEPFehIUs
      uGicBhAAr9NDElwaYSoKk8ayUnlO00E/Kr555Xr+/U0wgfXBoVJoDbVSsIi3IhzZ
      vkWJXVeb1puUyyhYR4o2gdySJ3u3kcpj1xLIeXp+gvNftJyOaCN04m6Hnay2eMXS
      9vZX55PppFXS0B1lB9L95k6ciJEVnoKjEVT1mDunmo1G932qrs6QkU0smKJ7M6fm
      cEonSzi+VCpcACs4toN4PMhrFdPvFEvYK0iG8LXxLkKV+bhmKPeD45TKhJTAfjvV
      86SltUU1ftyJTu2FxsuWeMzxAw57bI/xET4eHVboOnWp3cSPAWX2Mc5H5yWBzRZy
      cPwDIwwvj0WSOtXOWJMW743O+29sNSKZZjoLjrSpwrYWnNYT4ThzdGvKvl2XD9uM
      vzZWgQihdT+My0qXLVuDMAnH56jeUN/fdiBw2oxK+sDMiwssD4Y3GulTQ7o067aU
      dqVCeV0LXTXmLUCvkbSwbKnxRRRxdA/OowH0NDbaYyjMoZ7UqBYiF5M9W1bcB9Op
      RCAfWVB7U7gwgu0PO70g6+LUr1lS+1UnszIvopwsqo301O1qTQBzM4ftuBwQa57P
      SHDxCpZ7bBObayNmW+PLkZSwc/Ak+uGzJdJkVrOA0kq2rlsLxnbysj1XxohIQsnQ
      +RZMMYcW8eev2DeDB+vtr94O8bxQZOH3cfx5gbxvRX5ixG5dn44=
      =8VVM
      -----END PGP SIGNATURE-----"",
            ""message"": ""fix: remove rm.md
      "",
            ""parent"": Array [
              ""58aa7508ff84bc25552b4576b1b5ab0ddc5e41dd"",
            ],
            ""tree"": ""b0904e4ea2e2548d0ebc5c9401b8a0390c0888cd"",
          },
          ""oid"": ""2584400512051e6cb07fda5ff7e8dde556fc3124"",
          ""payload"": ""tree b0904e4ea2e2548d0ebc5c9401b8a0390c0888cd
      parent 58aa7508ff84bc25552b4576b1b5ab0ddc5e41dd
      author Riceball LEE <snowyu.lee@gmail.com> 1593509970 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509970 +0800

      fix: remove rm.md
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509879,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509879,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77B/cACgkQEPFehIUs
      uGj+hxAAhidyrgiKXUdOh038Wvho48rd0opD2b+1C5kUpjSIrnd+7zKAS34Grveo
      wjdUsk4/Ao/qNLrZHuMwdca9KMt2bywc6X8AToNZXIapXvow3wj/1w9wtxeLyuaR
      7HFFVxBtVHZ9pntMvr5GXUMLqvm8sxXyOQVFxCjXgBCkFku+9Hi9PdTlt5PIvQ5C
      8ORynFVcdl8JPGYe510+lPSZVdgB/lrfDpyFwa1cnpVzXiefQFGSbNDYvh5DUnxv
      5cDmXLS79HFJg+9tnkOeMqKiSPvJU9giPE/Thrq1RYBk+rvEJA8yfl/QdFQBiFp0
      gOetxGoaJestpWNDh5qaCNdgyH3UwP1eR17WUFwR6f9wTaRwUlY8KkDbELjOn5IP
      jD7QopZPCbhSiEcC+5aER6Cfcae1DtQnftG3A/PpNlVRYAdZY/Ls8rxFsac1tdeg
      Q/0a6fpOG9WtsTXyzIvwk+b8ddJshXVslxLWj8Zw5F/PH27p4yRfZT0UscApO3Gf
      xX/nh+4Rs8/BDu8jmUMpJmqR3RVO1WnyShNgB2ONGaDc17bcGNwSz7IKnN5MXOZ6
      HCTNCtysIkl6uKAHq5TydZxz6LVwq+d62AVy1dKnVUqqLySOb7PLiWwZ06Qsvyfq
      iKPeOnlFPUrRBvNdtTfXpRpb4gJ1OJBxsvuxsApr2+vh1be8PCA=
      =Vmf5
      -----END PGP SIGNATURE-----"",
            ""message"": ""feat: update to rm.md
      "",
            ""parent"": Array [
              ""bba48a582aaa7e572c844cf7f42f3cd03eab81f0"",
            ],
            ""tree"": ""996a1c302a71aeeb3ba865c1a8720bbec39657b9"",
          },
          ""oid"": ""58aa7508ff84bc25552b4576b1b5ab0ddc5e41dd"",
          ""payload"": ""tree 996a1c302a71aeeb3ba865c1a8720bbec39657b9
      parent bba48a582aaa7e572c844cf7f42f3cd03eab81f0
      author Riceball LEE <snowyu.lee@gmail.com> 1593509879 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509879 +0800

      feat: update to rm.md
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509597,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509597,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77Bt0ACgkQEPFehIUs
      uGjwEhAAt+YBPtElFAv+hs5ybANPDKncpDdzYwJ+55aVG/RiWtN51BLj19pGm7Wg
      lxw2NUPPaFkeMvsula7sS8kgDeuEnpapkoBAnPDUUon5KtLR77qn6JGAvdl6EGDN
      x1Vyb3eOTjM0bW34gNTaAS6cHGhjmFFvX+w1Q1i0/kXBzn+/Gzy9IJTxYpoPYm0R
      IIZ+FI34hb7/UV6UjEqT9JqbRq8NQMr4nV5IQeEFBkBW3k9lPkoJvKAk585nGcaG
      NrqFCYI+S1RGChW1JO9dK9iNagvcEp5q1qs3R0Qag5ddf4502gQrHwIrvJBhiRXf
      kg5SBYae+C+UedUEAMI7kEDvzJY2n3s/l2T69HcrCL/0Uzay9hHF7+uQUoXMz+og
      u8kPJSMxEa5Ay2qThFL425d0bv7fm99kv8tVZrgDGAORF7F6cEj+0zAXrG66q7+C
      3zby8ZOtBo5m9lEXhKWfkg3qjHBWSIEzFSf2sIsHZwMwaP/UX4bHc2+gsU4ZuSV9
      ERuEM5rIcbUywNtVDCvRgyABNf+R9u1+OlbEE2gHkso1DiWzVhJl8OgoohNeQ6ve
      usuE81K6Hl0RXFPZEGiP9+VvBKegZr+TpChj/U9Xxg5Xo8h1IJofq+pcM7szyiW+
      XjQ2JObzauS9s+vlQZ3k01acgUxXF+izIb3JLWgZPo8ZQW57evA=
      =8Fqf
      -----END PGP SIGNATURE-----"",
            ""message"": ""feat: add content to rm.md
      "",
            ""parent"": Array [
              ""8651dcc28c58d96439e99aa2bf239bf2ab238b73"",
            ],
            ""tree"": ""c8a2583e243cfdd458a6ff40ff6f7a2d57fbaa96"",
          },
          ""oid"": ""533131624898bb8ff588b48c77b26d63e7eb180f"",
          ""payload"": ""tree c8a2583e243cfdd458a6ff40ff6f7a2d57fbaa96
      parent 8651dcc28c58d96439e99aa2bf239bf2ab238b73
      author Riceball LEE <snowyu.lee@gmail.com> 1593509597 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509597 +0800

      feat: add content to rm.md
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509547,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593509547,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77BqsACgkQEPFehIUs
      uGj/oRAAmOMhskEjKwcFaEnC7InU/UMd4PHAy3XlKwqUCiQVEJWWi6B81n5IYsWi
      mDOKXGYenlYOAf0HFqs7nPBeINDRFQp03d01wZT7JgacpERCvvu53IHLH8ndJehL
      MQaRtWV/SpScj4OZH4Wzm6tjB4IBB/agZWM67tU4KKI2i6TOhQw8ktBoXbXGWO9g
      OwjHW4mZn5eggIhyNzNKWRwzImopYlcBGqtYil5l4LWXADBfxAYfBCA296HkiD1N
      sFzsi5mak7bKyW5/dFI9uP27BQSLLbGdbJIJlkYXi8XIo/sLPJGA0BHuiNLAVXUn
      E/CO4hBH/tZtJNk3jg0TPLey4Lh34d3Tw8+6z6CvMKQtZ9JUXy8rAWMvAXg0+YVp
      IvT+xA6HxECuBZ6UAYLU1ZHAvQtZch6XhJTirOJ5SMklTNKSiGaCLfDP/iuRWOYo
      4x52uwkInIuintkcIZocjwEQ5DsG6jO4ylbwmEaWgpzEuR7xOuIBx38dsCoSDD+D
      kyZF7ijammlt5Wc6A2u7ewEgCEy/GMEMJ+hUXqhJJ9Gi2uYU/WmC9GJDqD12JsEa
      m6FFvEd+zCH/9K+O5eBUS9WFpiwXPP+amaXGBWkXnlbEYf/j9QemZXi/dkn1qCE7
      yM9yzr8Tb0dJWqvovK42AlCuYsZ9BYOBM3zz+pGhpSdES9OYO08=
      =/hmk
      -----END PGP SIGNATURE-----"",
            ""message"": ""first commit
      "",
            ""parent"": Array [],
            ""tree"": ""5640888e247e986136d36b1d52a9881abc7170f6"",
          },
          ""oid"": ""8651dcc28c58d96439e99aa2bf239bf2ab238b73"",
          ""payload"": ""tree 5640888e247e986136d36b1d52a9881abc7170f6
      author Riceball LEE <snowyu.lee@gmail.com> 1593509547 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593509547 +0800

      first commit
      "",
        },
      ]
    `)
  })",steel
/__tests__/test-log-file.js,Magic Number,"{'line': 544, 'column': 32, 'index': 21793}","it('a rename file with follow', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'a/rename1.md',
      follow: true,
    })
    expect(commits.length).toBe(4)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510674,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510674,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77CxIACgkQEPFehIUs
      uGhgYg//c7Add1QPUgdVP11OSH9MGAyxjLes14+g6lyf+5raDa4bvQAgRVydiqbt
      yI9SKwDni7HkZUK9CrqDtGwivvDjNK7n0R+ebNXRa4LYPrm9v9Htd6AqFNpSU6LG
      Fvi/AQarINtnSt7prKAExgf4Dt9Q9tZrVLqNIxi/6AMq3yQHwcDb6hKubaAkXWdw
      fkjmkUKtSSzycUy2HdrDSWX04frjN9ostqZHWQRvEztI1DdStwMIGMWibDioJoi+
      xlT1I28NvRtF0hgGgjFUQoa5xN7WwVYpx2byXQdfFavhZxqfQjnR0MMyIouIBxGQ
      aQGQNNEAgzVCMcnbTynLyZuG31daIS55AuoHS73RlTn+cJey32oblvnWRje9x7Vo
      J52QpRJPu4CTWQM75vc43n9acZYxATNCr/tEW8SIb4PVR5q0lfh6M1+MyfHxNJrp
      iRLkZaOlSsXxdU+oV5rcFg7YlpDIaqHBWTHjffqSUvBQ26S0Wot5W/kNkua35qcl
      S4fomYCphl/zAxyp+O31MQYCS36MObIM3FXEGdfm1c6XWtrAhtMPTKtsk5YB2ltP
      7MmLM1OwKltT6b55+RUnmQ4GyN92xIop9JMgDNDQfln/TRW73DaDFZt7OyZOZxQm
      qkdT/ALm0qLz8iPf4q0zBbSd0e4RnYxD0FwfPQ7aVMAA77hzMoA=
      =1cFE
      -----END PGP SIGNATURE-----"",
            ""message"": ""update rename1
      "",
            ""parent"": Array [
              ""cc9bcf734480b44d2e884ae75a11805e42c938d8"",
            ],
            ""tree"": ""7ab59df3bfd122ef5d24c70f9c8977f03b35e720"",
          },
          ""oid"": ""1bc226bc219beea3fb177de96350d8ad2f4c57cd"",
          ""payload"": ""tree 7ab59df3bfd122ef5d24c70f9c8977f03b35e720
      parent cc9bcf734480b44d2e884ae75a11805e42c938d8
      author Riceball LEE <snowyu.lee@gmail.com> 1593510674 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593510674 +0800

      update rename1
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510498,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510498,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77CmIACgkQEPFehIUs
      uGi8fQ//VBw8UB5s5UvklkBbhhF/D6UsaH8ry1GU5fQoUZlf7ouBiKkdLv0Sqe7P
      dTsohbo1FGHK/+shXddsL9fsp9yQgySt0Zck7HcG2hM8TyeHycsHIZf2jdkfqWob
      3mjl2YoQLnht5z5+PoN7mHm6a4cNqFpKnQsHXuIMKjZLnvGDkgUOlxCiNrFsMmAx
      sho1ROVR+TCkSi8KrR66CvA6a8sIRVib7Y93WX7QgpFQgw24ZbpZvlDR0TjullLi
      df+9TBOEg89oZFtPBvpdURFSKltl6PMS7WnAoXgIFRAnwM5PnPZHkA37GanmSrj8
      awLBkCapWuTF4/K+Bhu5hfURRac6IPJi56ygQWKpThAwk3h2L/saKTJFqD9vb/Go
      +FM/fmex3lOGbVbZs1EtvkKwYIAb9pWKIcsnpzH6L6PrQE7DsLX2NP23hwMsXRt6
      9vQDUuY8Dd45ttM8XPcVP0bM5C4PqmCErxXVFLcuLUtkF98RaUNnEdkDCo0yfojF
      eQqn74zmQ0c3Q4WufxKM+4kQ1EflScv4uxOuBraj3hFcyac4u1CyLD0sv7InkdRB
      T0iS+pLIyaJQIHV4AximpRISitVGuYnNtSuTrJJDmjmGGSMyC/jCsDrr1t0lMxdb
      vdDuh3t+Ch9rvXHEPtnIokOW9U+hrVIeIGeiD0KM5QHD2CjcgwQ=
      =2hns
      -----END PGP SIGNATURE-----"",
            ""message"": ""rename it
      "",
            ""parent"": Array [
              ""b9a8e7ed4e394942ba0a45f19563e8ad90b94ea9"",
            ],
            ""tree"": ""641ca0a41cfbccf4fb5c366840270fd25ec48b4f"",
          },
          ""oid"": ""cc9bcf734480b44d2e884ae75a11805e42c938d8"",
          ""payload"": ""tree 641ca0a41cfbccf4fb5c366840270fd25ec48b4f
      parent b9a8e7ed4e394942ba0a45f19563e8ad90b94ea9
      author Riceball LEE <snowyu.lee@gmail.com> 1593510498 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593510498 +0800

      rename it
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510465,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510465,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77CkEACgkQEPFehIUs
      uGiGZA//Y5XlL5XeP05m7Jp2h2GBOc1nF6W7AAxRUSintdiX706aaoSAbVD3PwB3
      zMuGiBIePPvQk+Oo+U8E0h2cD0bIY13BHJ+z23Qmn/1I1Vtup9uuWRCDR7T1Gy0r
      3rUsdtyuZ3qIjliCP/j5254x6hspIUVBFUeHd/BWTWIimKIuYKRg8am9qNn2Dhir
      o889/ZKuImsgF1eNsIaqlWN71n8KUGmDNcTdQ7eZzk4wUSsASyWRvnr3+OYkhjTp
      ffJubsdA+FvixxCM8kg6UAoOFlMzJapVi/AdLXRQ6758tEpTPWdz2WVxrI3P1ACq
      HzqvSIDoEISZDkKw/5maL9/89dV0qSuJcv3EqZQKxB3I7DAQgseHBAgThtChtdkh
      a6OrCIkeJyNjQhgXpqtIJ71P6mVTDNnveDWO+9OilCrHfLa3nqYCz+xPZ2txRwG/
      Z6+491WZVJAzU9rICT9AvrDpllacofr95LZCYdLd5J6qTYxq4m92AoZLOq5iKH1w
      nCYyrfswZolEmbq50MhD7JdZKE3IPf5sfZfU+X4EfPYkr//P5M6wGzYVXYv6KttJ
      jsekDsWczkATsKkp0xiC0lRVMNYwxl2Ly03JBZ/U2lBWEKhDgz1ELKa1XM9qEqSH
      CbwmGwIWyAOFmjkBjWUHIqrm2zQFskpXu4a+03dqV5pCQlsf4qs=
      =qvhP
      -----END PGP SIGNATURE-----"",
            ""message"": ""update rename
      "",
            ""parent"": Array [
              ""01cd249eaaceb8572bee5b24d8ed728c95f61bd6"",
            ],
            ""tree"": ""b76aafd52bf2d588756a32ebc9fa1ae0e68052c9"",
          },
          ""oid"": ""b9a8e7ed4e394942ba0a45f19563e8ad90b94ea9"",
          ""payload"": ""tree b76aafd52bf2d588756a32ebc9fa1ae0e68052c9
      parent 01cd249eaaceb8572bee5b24d8ed728c95f61bd6
      author Riceball LEE <snowyu.lee@gmail.com> 1593510465 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593510465 +0800

      update rename
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510416,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510416,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77ChAACgkQEPFehIUs
      uGj/rxAAtVD1LSNM4gfyHQQB8G/E4JWmqoTlOJlC2s+zZRzMUgKPPqItt4p4FFMs
      4GstDmVhGVKNpZjCkzZUX5N2Htm6PzWDdjtI5t+yl1rLfCR73VQKA/ztdUT2w1tg
      jewPYRht9VrP46MqCxbnUpdt5zYhshGa3/Q9WRy11rakvjrbF9S9jKP+qiNyS1X2
      3LGyDNQlS7XymSUFz4PSiOVTEpkSoOuGM6PnOhzmdNgl/JPY2vVCFcejO+qDq2K+
      0EbLH6Ab0r7EiFQXufOSR0m6i3SXnfg66+ttiW5Olm2yfT0H05flvHUp93aeAoYf
      qOvnSR5nX4jzQaLyHBvSWlotNfAgLSgLVZlUSoShYjRm/4UuFShZn546ykEZ1vTZ
      rMU5PNvu8pqhCEneHnl7WEuxrlxt10vwtzWDUalaUZgNKXoIYDWISpVfzdOEuOu3
      xNaH1GwZuGEtGZbDwOzsdTkJC5OTRzkb5c0SF/wlCUaW6rWW0J1cc/PX3bi4euwH
      TdUe8v0KT2jX275FjpzvCQixduMrM9lm6vwOYSWplk6Au+v5ot2vaGob2ok5dMIP
      Ai2oopT87heuC/iPcL2DKES1TItiXbRvYYu6jB3qCxD2cQUFxXgYyTuAnS3uSnhx
      w89ElnO5qtr32gZ5+609hodFg8zrxZWxXxpNcIHfTgh17qHZuPg=
      =iSgt
      -----END PGP SIGNATURE-----"",
            ""message"": ""add rename.md
      "",
            ""parent"": Array [
              ""2584400512051e6cb07fda5ff7e8dde556fc3124"",
            ],
            ""tree"": ""8ad18556d7692aef283e7cf30a287b6010c362a4"",
          },
          ""oid"": ""01cd249eaaceb8572bee5b24d8ed728c95f61bd6"",
          ""payload"": ""tree 8ad18556d7692aef283e7cf30a287b6010c362a4
      parent 2584400512051e6cb07fda5ff7e8dde556fc3124
      author Riceball LEE <snowyu.lee@gmail.com> 1593510416 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593510416 +0800

      add rename.md
      "",
        },
      ]
    `)
  })",steel
/__tests__/test-log-file.js,Magic Number,"{'line': 743, 'column': 32, 'index': 30125}","it('a rename file forced without follow', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'a/rename1.md',
      force: true,
    })
    expect(commits.length).toBe(2)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510674,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510674,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77CxIACgkQEPFehIUs
      uGhgYg//c7Add1QPUgdVP11OSH9MGAyxjLes14+g6lyf+5raDa4bvQAgRVydiqbt
      yI9SKwDni7HkZUK9CrqDtGwivvDjNK7n0R+ebNXRa4LYPrm9v9Htd6AqFNpSU6LG
      Fvi/AQarINtnSt7prKAExgf4Dt9Q9tZrVLqNIxi/6AMq3yQHwcDb6hKubaAkXWdw
      fkjmkUKtSSzycUy2HdrDSWX04frjN9ostqZHWQRvEztI1DdStwMIGMWibDioJoi+
      xlT1I28NvRtF0hgGgjFUQoa5xN7WwVYpx2byXQdfFavhZxqfQjnR0MMyIouIBxGQ
      aQGQNNEAgzVCMcnbTynLyZuG31daIS55AuoHS73RlTn+cJey32oblvnWRje9x7Vo
      J52QpRJPu4CTWQM75vc43n9acZYxATNCr/tEW8SIb4PVR5q0lfh6M1+MyfHxNJrp
      iRLkZaOlSsXxdU+oV5rcFg7YlpDIaqHBWTHjffqSUvBQ26S0Wot5W/kNkua35qcl
      S4fomYCphl/zAxyp+O31MQYCS36MObIM3FXEGdfm1c6XWtrAhtMPTKtsk5YB2ltP
      7MmLM1OwKltT6b55+RUnmQ4GyN92xIop9JMgDNDQfln/TRW73DaDFZt7OyZOZxQm
      qkdT/ALm0qLz8iPf4q0zBbSd0e4RnYxD0FwfPQ7aVMAA77hzMoA=
      =1cFE
      -----END PGP SIGNATURE-----"",
            ""message"": ""update rename1
      "",
            ""parent"": Array [
              ""cc9bcf734480b44d2e884ae75a11805e42c938d8"",
            ],
            ""tree"": ""7ab59df3bfd122ef5d24c70f9c8977f03b35e720"",
          },
          ""oid"": ""1bc226bc219beea3fb177de96350d8ad2f4c57cd"",
          ""payload"": ""tree 7ab59df3bfd122ef5d24c70f9c8977f03b35e720
      parent cc9bcf734480b44d2e884ae75a11805e42c938d8
      author Riceball LEE <snowyu.lee@gmail.com> 1593510674 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593510674 +0800

      update rename1
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510498,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1593510498,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl77CmIACgkQEPFehIUs
      uGi8fQ//VBw8UB5s5UvklkBbhhF/D6UsaH8ry1GU5fQoUZlf7ouBiKkdLv0Sqe7P
      dTsohbo1FGHK/+shXddsL9fsp9yQgySt0Zck7HcG2hM8TyeHycsHIZf2jdkfqWob
      3mjl2YoQLnht5z5+PoN7mHm6a4cNqFpKnQsHXuIMKjZLnvGDkgUOlxCiNrFsMmAx
      sho1ROVR+TCkSi8KrR66CvA6a8sIRVib7Y93WX7QgpFQgw24ZbpZvlDR0TjullLi
      df+9TBOEg89oZFtPBvpdURFSKltl6PMS7WnAoXgIFRAnwM5PnPZHkA37GanmSrj8
      awLBkCapWuTF4/K+Bhu5hfURRac6IPJi56ygQWKpThAwk3h2L/saKTJFqD9vb/Go
      +FM/fmex3lOGbVbZs1EtvkKwYIAb9pWKIcsnpzH6L6PrQE7DsLX2NP23hwMsXRt6
      9vQDUuY8Dd45ttM8XPcVP0bM5C4PqmCErxXVFLcuLUtkF98RaUNnEdkDCo0yfojF
      eQqn74zmQ0c3Q4WufxKM+4kQ1EflScv4uxOuBraj3hFcyac4u1CyLD0sv7InkdRB
      T0iS+pLIyaJQIHV4AximpRISitVGuYnNtSuTrJJDmjmGGSMyC/jCsDrr1t0lMxdb
      vdDuh3t+Ch9rvXHEPtnIokOW9U+hrVIeIGeiD0KM5QHD2CjcgwQ=
      =2hns
      -----END PGP SIGNATURE-----"",
            ""message"": ""rename it
      "",
            ""parent"": Array [
              ""b9a8e7ed4e394942ba0a45f19563e8ad90b94ea9"",
            ],
            ""tree"": ""641ca0a41cfbccf4fb5c366840270fd25ec48b4f"",
          },
          ""oid"": ""cc9bcf734480b44d2e884ae75a11805e42c938d8"",
          ""payload"": ""tree 641ca0a41cfbccf4fb5c366840270fd25ec48b4f
      parent b9a8e7ed4e394942ba0a45f19563e8ad90b94ea9
      author Riceball LEE <snowyu.lee@gmail.com> 1593510498 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1593510498 +0800

      rename it
      "",
        },
      ]
    `)
  })",steel
/__tests__/test-log-file.js,Magic Number,"{'line': 850, 'column': 32, 'index': 34486}","it('a rename file with follow multi same content files', async () => {
    const { fs, gitdir } = await makeFixture('test-log-file')
    const commits = await log({
      fs,
      gitdir,
      ref: 'HEAD',
      filepath: 'rename-2.md',
      follow: true,
    })
    expect(commits.length).toBe(2)
    expect(commits).toMatchInlineSnapshot(`
      Array [
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1594594854,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1594594854,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl8LliYACgkQEPFehIUs
      uGgGvBAAy4yXnK1dpMDe0x4fzWcNo9r5Ong/UFPBN8Wda0OMivmg7RbhmF1ZJxwS
      J+IuSSVyunnFGqJPE6kF+CdNlCVC/Ol7LJV2rYIi+R+EBVLjU+eW1i6lSRCzJlPt
      rwyWsLzvNWWsA8S88ndHMvNcr9NliSepsdXsF0dbbjru5aHct9Crvz9blb9q8WrN
      yc2HLtE7TliPCxfNBqz5I2aLYwfjcEQbdnMYXQfseJBI1md0qzupY5YKkYTA+Yuf
      1yEcPEOsACNrSalCTGooMgfKBC051HBnUVebAfdqUeR6XHjl6fVHTRsMKETsBQeH
      hIHuN+dKjdX1zvzXbq3IStXTvTLAnK5f5td866FRvkuuTki3BiWYq/AfpwchpKKt
      S3HkZnPhQXvOBSyYwI6fz+leZvpJDp+HjGDiNbB+H6iO1rDc7tVTzGKVniRsXVKJ
      /L/OkP0B5pt+ElSGrlQ38Mk5uN0xtnbGPGCA074Tgry/rC8G5E8x9a1ZbsO5lQ1g
      WuDwTuyzPlb6fxrctGPBI7yD+dxx/xIRjXkMRUo3GwcQSzTALl+x63SxOl4AfvmQ
      Hyh2/osfJh8YUd67QDSQOY0tagXodZhAT4YkfXhqehHOBQ1Sc4GZI5wT/7nn0NTy
      CP5jdSuA/wAIac/vGIQ89C71keAlKMgeEVrDOh6PISUGp4q8wy8=
      =dlF4
      -----END PGP SIGNATURE-----"",
            ""message"": ""rename rename2 to rename-2
      "",
            ""parent"": Array [
              ""c7a666607cd986eee187b3df2c4adef3b7e56c94"",
            ],
            ""tree"": ""2d8cf1942da4577aa3f205108c228e1a95b33940"",
          },
          ""oid"": ""18f202dfed5cb66a295dc57f1f4ba1b7f6b74f36"",
          ""payload"": ""tree 2d8cf1942da4577aa3f205108c228e1a95b33940
      parent c7a666607cd986eee187b3df2c4adef3b7e56c94
      author Riceball LEE <snowyu.lee@gmail.com> 1594594854 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1594594854 +0800

      rename rename2 to rename-2
      "",
        },
        Object {
          ""commit"": Object {
            ""author"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1594594440,
              ""timezoneOffset"": -480,
            },
            ""committer"": Object {
              ""email"": ""snowyu.lee@gmail.com"",
              ""name"": ""Riceball LEE"",
              ""timestamp"": 1594594440,
              ""timezoneOffset"": -480,
            },
            ""gpgsig"": ""-----BEGIN PGP SIGNATURE-----

      iQIzBAABCgAdFiEEdmCAADTKSYRxNh/nEPFehIUsuGgFAl8LlIgACgkQEPFehIUs
      uGjWiA/+Oda2OuPc7X9TFgDvnAwIWMRFThUebrGe2NaVstvtAAHte3Y/9FYqU062
      0IWLycCENb7EbSTlIb6Lew09KXibnB4E39WrIcWYJJx2zICETNW56yedkd+1UJKZ
      XwCewsgxyOVA960awxyLa2au06aHDF8U6128lHPZDVYIVgdYzhrn+18j+TXc4anB
      p1whk5vAq7nkdTS0yATbLvlbBgymKaDxsGM7RO1giFSVQxzULb0RyH1BfnvkV4Ox
      QxkyMPIYuziZXBpYBZmZOdIq1E5zOVkyoQIELpXy8NrLZ4Wj+r2P9RujdlA6zitA
      xaeihDikZNRQc1vPsb119psabrrgXY/dxW9+p60kSXsUGWhX5RBKuPodfmpRHJTD
      XKe5lckrPTUkCwbVMGXUx2nj9jCcF5FEMDQKEd/dBFKX9QPY6JnjaimIY1E8ulAX
      rwXN91oECmt5OvPI2icOYLCkPkbNMy8rW3hEu4QDj8bCfPBtgHhon9SIsWKE6Bh9
      sRLGU9cJWFPXNlyV9nj3G2w5MXrzm2SqJrxH/reuDdkB1Y2kYMM5pSNmlS1+IGk8
      mTkYjlsCT4WxHRyyMJUtGxvdTisyp2odP7BEcEjq97ZHKKgUDtTbsmD0tfo0k0eL
      KBa7eI7ag4KMAJ4MWk3X70f2qAeoaSNXAsYDSI+kt/rFgFsYSH0=
      =AaPG
      -----END PGP SIGNATURE-----"",
            ""message"": ""add rename2
      "",
            ""parent"": Array [
              ""9a4eb099547166c9cf28628a127cfc9e59fa4f29"",
            ],
            ""tree"": ""795c22aa0265ce8c2d1cd3d4bf2d62ac1605b5ca"",
          },
          ""oid"": ""f44bab8dd4229486c7f6acc448cfc158bcbe5cfd"",
          ""payload"": ""tree 795c22aa0265ce8c2d1cd3d4bf2d62ac1605b5ca
      parent 9a4eb099547166c9cf28628a127cfc9e59fa4f29
      author Riceball LEE <snowyu.lee@gmail.com> 1594594440 +0800
      committer Riceball LEE <snowyu.lee@gmail.com> 1594594440 +0800

      add rename2
      "",
        },
      ]
    `)
  })",steel
/__tests__/test-listNotes.js,Magic Number,"{'line': 15, 'column': 30, 'index': 409}","it('from default branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-listNotes')
    // Test
    const notes = await listNotes({
      fs,
      gitdir,
    })
    expect(notes.length).toBe(3)
    expect(notes).toEqual([
      {
        note: '0bd2dc08e06dafbcdfe1c97fc64a99d0f206ef78',
        target: '199948939a0b95c6f27668689102496574b2c332',
      },
      {
        note: '6e2160d80f201db57a02415c47da5037ecc7c27f',
        target: '68aba62e560c0ebc3396e8ae9335232cd93a3f60',
      },
      {
        note: '40f0ba45e23b41630eabae9f4fc8d5007e37fcd6',
        target: 'f6d51b1f9a449079f6999be1fb249c359511f164',
      },
    ])
  })",steel
/__tests__/test-listNotes.js,Magic Number,"{'line': 40, 'column': 30, 'index': 1115}","it('from alternate branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-listNotes')
    // Test
    const notes = await listNotes({
      fs,
      gitdir,
      ref: 'refs/notes/alt',
    })
    expect(notes.length).toBe(1)
    expect(notes).toEqual([
      {
        note: '73ec9c00618d8ebb2648c47c9b05d78227569728',
        target: 'f6d51b1f9a449079f6999be1fb249c359511f164',
      },
    ])
  })",steel
/__tests__/test-listNotes.js,Magic Number,"{'line': 57, 'column': 30, 'index': 1555}","it('from non-existant branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-listNotes')
    // Test
    const notes = await listNotes({
      fs,
      gitdir,
      ref: 'refs/notes/alt2',
    })
    expect(notes.length).toBe(0)
    expect(notes).toEqual([])
  })",steel
/__tests__/test-isBinary.js,Conditional Test Logic,"{'line': 17, 'column': 2, 'index': 399}","describe('isBinary', () => {
  for (const file of binaryFiles) {
    it(`${path.extname(file)} is binary`, async () => {
      // Setup
      const { fs, dir } = await makeFixture('test-isBinary')
      const buffer = await fs.read(`${dir}/${file}`)
      // Test
      expect(isBinary(buffer)).toEqual(true)
    })
  }

  for (const file of textFiles) {
    it(`${path.extname(file)} is NOT binary`, async () => {
      // Setup
      const { fs, dir } = await makeFixture('test-isBinary')
      const buffer = await fs.read(`${dir}/${file}`)
      // Test
      expect(isBinary(buffer)).toEqual(false)
    })
  }
})",steel
/__tests__/test-isBinary.js,Conditional Test Logic,"{'line': 27, 'column': 2, 'index': 691}","describe('isBinary', () => {
  for (const file of binaryFiles) {
    it(`${path.extname(file)} is binary`, async () => {
      // Setup
      const { fs, dir } = await makeFixture('test-isBinary')
      const buffer = await fs.read(`${dir}/${file}`)
      // Test
      expect(isBinary(buffer)).toEqual(true)
    })
  }

  for (const file of textFiles) {
    it(`${path.extname(file)} is NOT binary`, async () => {
      // Setup
      const { fs, dir } = await makeFixture('test-isBinary')
      const buffer = await fs.read(`${dir}/${file}`)
      // Test
      expect(isBinary(buffer)).toEqual(false)
    })
  }
})",steel
/__tests__/test-init.js,Duplicate Assert,"{'line': 31, 'column': 4, 'index': 1135}","it('init does not overwrite existing config', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-init')
    const name = 'me'
    const email = 'meme'
    await init({ fs, dir })
    expect(await fs.exists(dir)).toBe(true)
    expect(await fs.exists(`${dir}/.git/config`)).toBe(true)
    await setConfig({ fs, dir, path: 'user.name', value: name })
    await setConfig({ fs, dir, path: 'user.email', value: email })
    // Test
    await init({ fs, dir })
    expect(await fs.exists(dir)).toBe(true)
    expect(await fs.exists(`${dir}/.git/config`)).toBe(true)
    // check that the properties we added are still there.
    expect(await getConfig({ fs, dir, path: 'user.name' })).toEqual(name)
    expect(await getConfig({ fs, dir, path: 'user.email' })).toEqual(email)
  })",steel
/__tests__/test-init.js,Duplicate Assert,"{'line': 31, 'column': 4, 'index': 1135}","it('init does not overwrite existing config', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-init')
    const name = 'me'
    const email = 'meme'
    await init({ fs, dir })
    expect(await fs.exists(dir)).toBe(true)
    expect(await fs.exists(`${dir}/.git/config`)).toBe(true)
    await setConfig({ fs, dir, path: 'user.name', value: name })
    await setConfig({ fs, dir, path: 'user.email', value: email })
    // Test
    await init({ fs, dir })
    expect(await fs.exists(dir)).toBe(true)
    expect(await fs.exists(`${dir}/.git/config`)).toBe(true)
    // check that the properties we added are still there.
    expect(await getConfig({ fs, dir, path: 'user.name' })).toEqual(name)
    expect(await getConfig({ fs, dir, path: 'user.email' })).toEqual(email)
  })",steel
/__tests__/test-init.js,Duplicate Assert,"{'line': 32, 'column': 4, 'index': 1179}","it('init does not overwrite existing config', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-init')
    const name = 'me'
    const email = 'meme'
    await init({ fs, dir })
    expect(await fs.exists(dir)).toBe(true)
    expect(await fs.exists(`${dir}/.git/config`)).toBe(true)
    await setConfig({ fs, dir, path: 'user.name', value: name })
    await setConfig({ fs, dir, path: 'user.email', value: email })
    // Test
    await init({ fs, dir })
    expect(await fs.exists(dir)).toBe(true)
    expect(await fs.exists(`${dir}/.git/config`)).toBe(true)
    // check that the properties we added are still there.
    expect(await getConfig({ fs, dir, path: 'user.name' })).toEqual(name)
    expect(await getConfig({ fs, dir, path: 'user.email' })).toEqual(email)
  })",steel
/__tests__/test-init.js,Duplicate Assert,"{'line': 32, 'column': 4, 'index': 1179}","it('init does not overwrite existing config', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-init')
    const name = 'me'
    const email = 'meme'
    await init({ fs, dir })
    expect(await fs.exists(dir)).toBe(true)
    expect(await fs.exists(`${dir}/.git/config`)).toBe(true)
    await setConfig({ fs, dir, path: 'user.name', value: name })
    await setConfig({ fs, dir, path: 'user.email', value: email })
    // Test
    await init({ fs, dir })
    expect(await fs.exists(dir)).toBe(true)
    expect(await fs.exists(`${dir}/.git/config`)).toBe(true)
    // check that the properties we added are still there.
    expect(await getConfig({ fs, dir, path: 'user.name' })).toEqual(name)
    expect(await getConfig({ fs, dir, path: 'user.email' })).toEqual(email)
  })",steel
/__tests__/test-init.js,Duplicate Assert,"{'line': 37, 'column': 4, 'index': 1412}","it('init does not overwrite existing config', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-init')
    const name = 'me'
    const email = 'meme'
    await init({ fs, dir })
    expect(await fs.exists(dir)).toBe(true)
    expect(await fs.exists(`${dir}/.git/config`)).toBe(true)
    await setConfig({ fs, dir, path: 'user.name', value: name })
    await setConfig({ fs, dir, path: 'user.email', value: email })
    // Test
    await init({ fs, dir })
    expect(await fs.exists(dir)).toBe(true)
    expect(await fs.exists(`${dir}/.git/config`)).toBe(true)
    // check that the properties we added are still there.
    expect(await getConfig({ fs, dir, path: 'user.name' })).toEqual(name)
    expect(await getConfig({ fs, dir, path: 'user.email' })).toEqual(email)
  })",steel
/__tests__/test-init.js,Duplicate Assert,"{'line': 37, 'column': 4, 'index': 1412}","it('init does not overwrite existing config', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-init')
    const name = 'me'
    const email = 'meme'
    await init({ fs, dir })
    expect(await fs.exists(dir)).toBe(true)
    expect(await fs.exists(`${dir}/.git/config`)).toBe(true)
    await setConfig({ fs, dir, path: 'user.name', value: name })
    await setConfig({ fs, dir, path: 'user.email', value: email })
    // Test
    await init({ fs, dir })
    expect(await fs.exists(dir)).toBe(true)
    expect(await fs.exists(`${dir}/.git/config`)).toBe(true)
    // check that the properties we added are still there.
    expect(await getConfig({ fs, dir, path: 'user.name' })).toEqual(name)
    expect(await getConfig({ fs, dir, path: 'user.email' })).toEqual(email)
  })",steel
/__tests__/test-init.js,Duplicate Assert,"{'line': 38, 'column': 4, 'index': 1456}","it('init does not overwrite existing config', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-init')
    const name = 'me'
    const email = 'meme'
    await init({ fs, dir })
    expect(await fs.exists(dir)).toBe(true)
    expect(await fs.exists(`${dir}/.git/config`)).toBe(true)
    await setConfig({ fs, dir, path: 'user.name', value: name })
    await setConfig({ fs, dir, path: 'user.email', value: email })
    // Test
    await init({ fs, dir })
    expect(await fs.exists(dir)).toBe(true)
    expect(await fs.exists(`${dir}/.git/config`)).toBe(true)
    // check that the properties we added are still there.
    expect(await getConfig({ fs, dir, path: 'user.name' })).toEqual(name)
    expect(await getConfig({ fs, dir, path: 'user.email' })).toEqual(email)
  })",steel
/__tests__/test-init.js,Duplicate Assert,"{'line': 38, 'column': 4, 'index': 1456}","it('init does not overwrite existing config', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-init')
    const name = 'me'
    const email = 'meme'
    await init({ fs, dir })
    expect(await fs.exists(dir)).toBe(true)
    expect(await fs.exists(`${dir}/.git/config`)).toBe(true)
    await setConfig({ fs, dir, path: 'user.name', value: name })
    await setConfig({ fs, dir, path: 'user.email', value: email })
    // Test
    await init({ fs, dir })
    expect(await fs.exists(dir)).toBe(true)
    expect(await fs.exists(`${dir}/.git/config`)).toBe(true)
    // check that the properties we added are still there.
    expect(await getConfig({ fs, dir, path: 'user.name' })).toEqual(name)
    expect(await getConfig({ fs, dir, path: 'user.email' })).toEqual(email)
  })",steel
/__tests__/test-getRemoteInfo2.js,Conditional Test Logic,"{'line': 20, 'column': 4, 'index': 645}","it('protocol 2', async () => {
    const info = await getRemoteInfo2({
      http,
      url: `http://${localhost}:8888/test-dumb-http-server.git`,
      protocolVersion: 2,
    })
    expect(info).toBeDefined()
    expect(info.capabilities).toBeDefined()
    expect(info.protocolVersion).toBe(2)
    if (info.protocolVersion === 2) {
      // The actual capabilities reported will vary depending on what version of git is installed on the machine running the test suite,
      // but I think it is fair to assume at least these two commands will be reported.
      expect(info.capabilities['ls-refs']).toBeDefined()
      expect(info.capabilities.fetch).toBeDefined()
    }
  })",steel
/__tests__/test-getRemoteInfo2.js,Conditional Test Logic,"{'line': 37, 'column': 4, 'index': 1328}","it('protocol 1', async () => {
    const info = await getRemoteInfo2({
      http,
      url: `http://${localhost}:8888/test-dumb-http-server.git`,
      protocolVersion: 1,
    })
    expect(info).toBeDefined()
    expect(info.capabilities).toBeDefined()
    expect(info.protocolVersion).toBe(1)
    if (info.protocolVersion === 1) {
      expect(info.refs).toBeDefined()
      expect(info.refs).toMatchInlineSnapshot(`
        Array [
          Object {
            ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
            ""ref"": ""HEAD"",
            ""target"": ""refs/heads/master"",
          },
          Object {
            ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
            ""ref"": ""refs/heads/master"",
          },
          Object {
            ""oid"": ""5a8905a02e181fe1821068b8c0f48cb6633d5b81"",
            ""ref"": ""refs/heads/test"",
          },
        ]
      `)
    }
  })",steel
/__tests__/test-getRemoteInfo2.js,Duplicate Assert,"{'line': 38, 'column': 6, 'index': 1368}","it('protocol 1', async () => {
    const info = await getRemoteInfo2({
      http,
      url: `http://${localhost}:8888/test-dumb-http-server.git`,
      protocolVersion: 1,
    })
    expect(info).toBeDefined()
    expect(info.capabilities).toBeDefined()
    expect(info.protocolVersion).toBe(1)
    if (info.protocolVersion === 1) {
      expect(info.refs).toBeDefined()
      expect(info.refs).toMatchInlineSnapshot(`
        Array [
          Object {
            ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
            ""ref"": ""HEAD"",
            ""target"": ""refs/heads/master"",
          },
          Object {
            ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
            ""ref"": ""refs/heads/master"",
          },
          Object {
            ""oid"": ""5a8905a02e181fe1821068b8c0f48cb6633d5b81"",
            ""ref"": ""refs/heads/test"",
          },
        ]
      `)
    }
  })",steel
/__tests__/test-getRemoteInfo2.js,Duplicate Assert,"{'line': 39, 'column': 6, 'index': 1406}","it('protocol 1', async () => {
    const info = await getRemoteInfo2({
      http,
      url: `http://${localhost}:8888/test-dumb-http-server.git`,
      protocolVersion: 1,
    })
    expect(info).toBeDefined()
    expect(info.capabilities).toBeDefined()
    expect(info.protocolVersion).toBe(1)
    if (info.protocolVersion === 1) {
      expect(info.refs).toBeDefined()
      expect(info.refs).toMatchInlineSnapshot(`
        Array [
          Object {
            ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
            ""ref"": ""HEAD"",
            ""target"": ""refs/heads/master"",
          },
          Object {
            ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
            ""ref"": ""refs/heads/master"",
          },
          Object {
            ""oid"": ""5a8905a02e181fe1821068b8c0f48cb6633d5b81"",
            ""ref"": ""refs/heads/test"",
          },
        ]
      `)
    }
  })",steel
/__tests__/test-getRemoteInfo2.js,Exception Handling,"{'line': 78, 'column': 4, 'index': 2483}","it('throws UnknownTransportError if using shorter scp-like syntax', async () => {
    // Test
    let err
    try {
      await getRemoteInfo2({
        http,
        url: `git@github.com:isomorphic-git/isomorphic-git.git`,
      })
    } catch (e) {
      err = e
    }
    expect(err).toBeDefined()
    expect(err.code).toEqual(Errors.UnknownTransportError.code)
  })",steel
/__tests__/test-getRemoteInfo2.js,Magic Number,"{'line': 19, 'column': 38, 'index': 638}","it('protocol 2', async () => {
    const info = await getRemoteInfo2({
      http,
      url: `http://${localhost}:8888/test-dumb-http-server.git`,
      protocolVersion: 2,
    })
    expect(info).toBeDefined()
    expect(info.capabilities).toBeDefined()
    expect(info.protocolVersion).toBe(2)
    if (info.protocolVersion === 2) {
      // The actual capabilities reported will vary depending on what version of git is installed on the machine running the test suite,
      // but I think it is fair to assume at least these two commands will be reported.
      expect(info.capabilities['ls-refs']).toBeDefined()
      expect(info.capabilities.fetch).toBeDefined()
    }
  })",steel
/__tests__/test-getRemoteInfo2.js,Magic Number,"{'line': 36, 'column': 38, 'index': 1321}","it('protocol 1', async () => {
    const info = await getRemoteInfo2({
      http,
      url: `http://${localhost}:8888/test-dumb-http-server.git`,
      protocolVersion: 1,
    })
    expect(info).toBeDefined()
    expect(info.capabilities).toBeDefined()
    expect(info.protocolVersion).toBe(1)
    if (info.protocolVersion === 1) {
      expect(info.refs).toBeDefined()
      expect(info.refs).toMatchInlineSnapshot(`
        Array [
          Object {
            ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
            ""ref"": ""HEAD"",
            ""target"": ""refs/heads/master"",
          },
          Object {
            ""oid"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
            ""ref"": ""refs/heads/master"",
          },
          Object {
            ""oid"": ""5a8905a02e181fe1821068b8c0f48cb6633d5b81"",
            ""ref"": ""refs/heads/test"",
          },
        ]
      `)
    }
  })",steel
/__tests__/test-getRemoteInfo.js,Duplicate Assert,"{'line': 18, 'column': 4, 'index': 580}","it('getRemoteInfo', async () => {
    const info = await getRemoteInfo({
      http,
      url: `http://${localhost}:8888/test-dumb-http-server.git`,
    })
    expect(info).not.toBeNull()
    expect(info.capabilities).not.toBeNull()
    expect(info.refs).not.toBeNull()
    expect(info.refs).toMatchInlineSnapshot(`
      Object {
        ""heads"": Object {
          ""master"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
          ""test"": ""5a8905a02e181fe1821068b8c0f48cb6633d5b81"",
        },
      }
    `)
  })",steel
/__tests__/test-getRemoteInfo.js,Duplicate Assert,"{'line': 19, 'column': 4, 'index': 617}","it('getRemoteInfo', async () => {
    const info = await getRemoteInfo({
      http,
      url: `http://${localhost}:8888/test-dumb-http-server.git`,
    })
    expect(info).not.toBeNull()
    expect(info.capabilities).not.toBeNull()
    expect(info.refs).not.toBeNull()
    expect(info.refs).toMatchInlineSnapshot(`
      Object {
        ""heads"": Object {
          ""master"": ""97c024f73eaab2781bf3691597bc7c833cb0e22f"",
          ""test"": ""5a8905a02e181fe1821068b8c0f48cb6633d5b81"",
        },
      }
    `)
  })",steel
/__tests__/test-getRemoteInfo.js,Exception Handling,"{'line': 47, 'column': 4, 'index': 1412}","it('throws UnknownTransportError if using shorter scp-like syntax', async () => {
    // Test
    let err
    try {
      await getRemoteInfo({
        http,
        url: `git@github.com:isomorphic-git/isomorphic-git.git`,
      })
    } catch (e) {
      err = e
    }
    expect(err).toBeDefined()
    expect(err.code).toEqual(Errors.UnknownTransportError.code)
  })",steel
/__tests__/test-flatFileListToDirectoryStructure.js,Magic Number,"{'line': 13, 'column': 39, 'index': 427}","it('simple', async () => {
    const inode = flatFileListToDirectoryStructure([
      { path: 'hello/there.txt' },
    ]).get('.')
    expect(inode.fullpath).toBe('.')
    expect(inode.type).toBe('tree')
    expect(inode.children.length).toBe(1)
    const hello = inode.children[0]
    expect(hello.type).toBe('tree')
    expect(hello.fullpath).toBe('hello')
    expect(hello.basename).toBe('hello')
    expect(hello.parent).toBe(inode)
    expect(hello.children.length).toBe(1)
    const there = hello.children[0]
    expect(there.type).toBe('blob')
    expect(there.fullpath).toBe('hello/there.txt')
    expect(there.basename).toBe('there.txt')
  })",steel
/__tests__/test-flatFileListToDirectoryStructure.js,Magic Number,"{'line': 19, 'column': 39, 'index': 660}","it('simple', async () => {
    const inode = flatFileListToDirectoryStructure([
      { path: 'hello/there.txt' },
    ]).get('.')
    expect(inode.fullpath).toBe('.')
    expect(inode.type).toBe('tree')
    expect(inode.children.length).toBe(1)
    const hello = inode.children[0]
    expect(hello.type).toBe('tree')
    expect(hello.fullpath).toBe('hello')
    expect(hello.basename).toBe('hello')
    expect(hello.parent).toBe(inode)
    expect(hello.children.length).toBe(1)
    const there = hello.children[0]
    expect(there.type).toBe('blob')
    expect(there.fullpath).toBe('hello/there.txt')
    expect(there.basename).toBe('there.txt')
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 19, 'column': 4, 'index': 585}","it('silly edge cases', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: ['9ec6646dd454e8f530c478c26f8b06e57f880bd6'],
    })
    expect(base).toEqual(['9ec6646dd454e8f530c478c26f8b06e57f880bd6'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6',
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6',
      ],
    })
    expect(base).toEqual(['9ec6646dd454e8f530c478c26f8b06e57f880bd6'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 19, 'column': 4, 'index': 585}","it('silly edge cases', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: ['9ec6646dd454e8f530c478c26f8b06e57f880bd6'],
    })
    expect(base).toEqual(['9ec6646dd454e8f530c478c26f8b06e57f880bd6'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6',
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6',
      ],
    })
    expect(base).toEqual(['9ec6646dd454e8f530c478c26f8b06e57f880bd6'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 29, 'column': 4, 'index': 848}","it('silly edge cases', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: ['9ec6646dd454e8f530c478c26f8b06e57f880bd6'],
    })
    expect(base).toEqual(['9ec6646dd454e8f530c478c26f8b06e57f880bd6'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6',
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6',
      ],
    })
    expect(base).toEqual(['9ec6646dd454e8f530c478c26f8b06e57f880bd6'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 29, 'column': 4, 'index': 848}","it('silly edge cases', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: ['9ec6646dd454e8f530c478c26f8b06e57f880bd6'],
    })
    expect(base).toEqual(['9ec6646dd454e8f530c478c26f8b06e57f880bd6'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6',
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6',
      ],
    })
    expect(base).toEqual(['9ec6646dd454e8f530c478c26f8b06e57f880bd6'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 58, 'column': 4, 'index': 1659}","it('fast-forward scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 58, 'column': 4, 'index': 1659}","it('fast-forward scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 68, 'column': 4, 'index': 1932}","it('fast-forward scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 68, 'column': 4, 'index': 1932}","it('fast-forward scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 78, 'column': 4, 'index': 2205}","it('fast-forward scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 78, 'column': 4, 'index': 2205}","it('fast-forward scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 89, 'column': 4, 'index': 2535}","it('fast-forward scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 89, 'column': 4, 'index': 2535}","it('fast-forward scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '21605c3fda133ae46f000a375c92c889fa0688ba', // F
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['f79577b91d302d87e310c8b5af8c274bbf45502f'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 104, 'column': 4, 'index': 2959}","it('diverging scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 104, 'column': 4, 'index': 2959}","it('diverging scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 114, 'column': 4, 'index': 3232}","it('diverging scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 124, 'column': 4, 'index': 3505}","it('diverging scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 124, 'column': 4, 'index': 3505}","it('diverging scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 134, 'column': 4, 'index': 3778}","it('diverging scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 134, 'column': 4, 'index': 3778}","it('diverging scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 145, 'column': 4, 'index': 4108}","it('diverging scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 145, 'column': 4, 'index': 4108}","it('diverging scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 157, 'column': 4, 'index': 4495}","it('diverging scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 157, 'column': 4, 'index': 4495}","it('diverging scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
        'f79577b91d302d87e310c8b5af8c274bbf45502f', // C
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
        '8d0e46852781eed81d32b91517f5d5f0979575c4', // E
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
        'c91a8aab1f086c8cc8914558f035e718a8a5c503', // B
      ],
    })
    expect(base).toEqual(['0526923cafece3d898dbe55ee2c2d69bfcc54c60'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 172, 'column': 4, 'index': 4922}","it('merge commit scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
      ],
    })
    expect(base).toEqual(['423489657e9529ecf285637eb21f40c8657ece3f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 172, 'column': 4, 'index': 4922}","it('merge commit scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
      ],
    })
    expect(base).toEqual(['423489657e9529ecf285637eb21f40c8657ece3f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 182, 'column': 4, 'index': 5195}","it('merge commit scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
      ],
    })
    expect(base).toEqual(['423489657e9529ecf285637eb21f40c8657ece3f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 192, 'column': 4, 'index': 5468}","it('merge commit scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
      ],
    })
    expect(base).toEqual(['423489657e9529ecf285637eb21f40c8657ece3f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 202, 'column': 4, 'index': 5741}","it('merge commit scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
      ],
    })
    expect(base).toEqual(['423489657e9529ecf285637eb21f40c8657ece3f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 202, 'column': 4, 'index': 5741}","it('merge commit scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
      ],
    })
    expect(base).toEqual(['423489657e9529ecf285637eb21f40c8657ece3f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 213, 'column': 4, 'index': 6071}","it('merge commit scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
      ],
    })
    expect(base).toEqual(['423489657e9529ecf285637eb21f40c8657ece3f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])
  })",steel
/__tests__/test-findMergeBase.js,Duplicate Assert,"{'line': 213, 'column': 4, 'index': 6071}","it('merge commit scenarios', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-findMergeBase')
    let base
    // Test
    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
      ],
    })
    expect(base).toEqual(['423489657e9529ecf285637eb21f40c8657ece3f'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8a7e4628451951581c6ce84850bd474e107ee750', // D
      ],
    })
    expect(base).toEqual(['592ad92519d993cc44c77663d85bb7e0f961a840'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])

    base = await findMergeBase({
      fs,
      gitdir,
      oids: [
        '423489657e9529ecf285637eb21f40c8657ece3f', // M
        '8d01f1824e6818db3461c06f09a0965810396a45', // G
        '9ec6646dd454e8f530c478c26f8b06e57f880bd6', // A
      ],
    })
    expect(base).toEqual(['21605c3fda133ae46f000a375c92c889fa0688ba'])
  })",steel
/__tests__/test-fetch.js,Duplicate Assert,"{'line': 230, 'column': 4, 'index': 6400}","it('shallow fetch relative (from Github)', async () => {
    const { fs, gitdir } = await makeFixture('test-fetch-cors')
    await setConfig({
      fs,
      gitdir,
      path: 'http.corsProxy',
      value: `http://${localhost}:9999`,
    })
    // Test
    await fetch({
      fs,
      http,
      gitdir,
      depth: 1,
      singleBranch: true,
      remote: 'origin',
      ref: 'test-branch-shallow-clone',
    })
    expect(await fs.exists(`${gitdir}/shallow`)).toBe(true)
    let shallow = (await fs.read(`${gitdir}/shallow`)).toString('utf8')
    expect(shallow).toEqual('92e7b4123fbf135f5ffa9b6fe2ec78d07bbc353e\n')
    // Now test deepen
    await fetch({
      fs,
      http,
      gitdir,
      relative: true,
      depth: 1,
      singleBranch: true,
      remote: 'origin',
      ref: 'test-branch-shallow-clone',
    })
    await sleep(1000) // seems to be a problem spot
    shallow = (await fs.read(`${gitdir}/shallow`)).toString('utf8')
    expect(shallow).toEqual('86ec153c7b48e02f92930d07542680f60d104d31\n')
  })",steel
/__tests__/test-fetch.js,Duplicate Assert,"{'line': 244, 'column': 4, 'index': 6806}","it('shallow fetch relative (from Github)', async () => {
    const { fs, gitdir } = await makeFixture('test-fetch-cors')
    await setConfig({
      fs,
      gitdir,
      path: 'http.corsProxy',
      value: `http://${localhost}:9999`,
    })
    // Test
    await fetch({
      fs,
      http,
      gitdir,
      depth: 1,
      singleBranch: true,
      remote: 'origin',
      ref: 'test-branch-shallow-clone',
    })
    expect(await fs.exists(`${gitdir}/shallow`)).toBe(true)
    let shallow = (await fs.read(`${gitdir}/shallow`)).toString('utf8')
    expect(shallow).toEqual('92e7b4123fbf135f5ffa9b6fe2ec78d07bbc353e\n')
    // Now test deepen
    await fetch({
      fs,
      http,
      gitdir,
      relative: true,
      depth: 1,
      singleBranch: true,
      remote: 'origin',
      ref: 'test-branch-shallow-clone',
    })
    await sleep(1000) // seems to be a problem spot
    shallow = (await fs.read(`${gitdir}/shallow`)).toString('utf8')
    expect(shallow).toEqual('86ec153c7b48e02f92930d07542680f60d104d31\n')
  })",steel
/__tests__/test-fetch.js,Duplicate Assert,"{'line': 300, 'column': 4, 'index': 8361}","it('fetch --prune from git-http-mock-server', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-fetch-client')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.origin.url',
      value: `http://${localhost}:8888/test-fetch-server.git`,
    })
    expect(await fs.exists(`${gitdir}/refs/remotes/origin/test-prune`)).toBe(
      true
    )
    const { pruned } = await fetch({
      fs,
      http,
      dir,
      gitdir,
      depth: 1,
      prune: true,
    })
    expect(pruned).toEqual(['refs/remotes/origin/test-prune'])
    expect(await fs.exists(`${gitdir}/refs/remotes/origin/test-prune`)).toBe(
      false
    )
  })",steel
/__tests__/test-fetch.js,Duplicate Assert,"{'line': 312, 'column': 4, 'index': 8645}","it('fetch --prune from git-http-mock-server', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-fetch-client')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.origin.url',
      value: `http://${localhost}:8888/test-fetch-server.git`,
    })
    expect(await fs.exists(`${gitdir}/refs/remotes/origin/test-prune`)).toBe(
      true
    )
    const { pruned } = await fetch({
      fs,
      http,
      dir,
      gitdir,
      depth: 1,
      prune: true,
    })
    expect(pruned).toEqual(['refs/remotes/origin/test-prune'])
    expect(await fs.exists(`${gitdir}/refs/remotes/origin/test-prune`)).toBe(
      false
    )
  })",steel
/__tests__/test-fetch.js,Duplicate Assert,"{'line': 325, 'column': 4, 'index': 9034}","it('fetch --prune-tags from git-http-mock-server', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-fetch-client')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.origin.url',
      value: `http://${localhost}:8888/test-fetch-server.git`,
    })
    expect(await fs.exists(`${gitdir}/refs/tags/v1.0.0-beta1`)).toBe(true)
    const oldValue = await fs.read(`${gitdir}/refs/tags/v1.0.0`, 'utf8')
    try {
      await fetch({
        fs,
        http,
        dir,
        gitdir,
        depth: 1,
        tags: true,
        pruneTags: true,
      })
    } catch (err) {
      // shrug
    }
    // assert that tag was deleted
    expect(await fs.exists(`${gitdir}/refs/tags/v1.0.0-beta1`)).toBe(false)
    // assert that tags was force-updated
    const newValue = await fs.read(`${gitdir}/refs/tags/v1.0.0`, 'utf8')
    expect(oldValue).not.toEqual(newValue)
  })",steel
/__tests__/test-fetch.js,Duplicate Assert,"{'line': 341, 'column': 4, 'index': 9415}","it('fetch --prune-tags from git-http-mock-server', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-fetch-client')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.origin.url',
      value: `http://${localhost}:8888/test-fetch-server.git`,
    })
    expect(await fs.exists(`${gitdir}/refs/tags/v1.0.0-beta1`)).toBe(true)
    const oldValue = await fs.read(`${gitdir}/refs/tags/v1.0.0`, 'utf8')
    try {
      await fetch({
        fs,
        http,
        dir,
        gitdir,
        depth: 1,
        tags: true,
        pruneTags: true,
      })
    } catch (err) {
      // shrug
    }
    // assert that tag was deleted
    expect(await fs.exists(`${gitdir}/refs/tags/v1.0.0-beta1`)).toBe(false)
    // assert that tags was force-updated
    const newValue = await fs.read(`${gitdir}/refs/tags/v1.0.0`, 'utf8')
    expect(oldValue).not.toEqual(newValue)
  })",steel
/__tests__/test-fetch.js,Exception Handling,"{'line': 94, 'column': 4, 'index': 2811}","it('throws UnknownTransportError if using shorter scp-like syntax', async () => {
    const { fs, gitdir } = await makeFixture('test-fetch-cors')
    await setConfig({
      fs,
      gitdir,
      path: 'http.corsProxy',
      value: `http://${localhost}:9999`,
    })
    // Test
    let err
    try {
      await fetch({
        fs,
        http,
        gitdir,
        depth: 1,
        singleBranch: true,
        remote: 'ssh',
        ref: 'test-branch-shallow-clone',
      })
    } catch (e) {
      err = e
    }
    expect(err).toBeDefined()
    expect(err.code).toEqual(Errors.UnknownTransportError.code)
  })",steel
/__tests__/test-fetch.js,Exception Handling,"{'line': 121, 'column': 4, 'index': 3433}","it('the SSH -> HTTPS UnknownTransportError suggestion feature', async () => {
    const { fs, gitdir } = await makeFixture('test-fetch-cors')
    await setConfig({
      fs,
      gitdir,
      path: 'http.corsProxy',
      value: `http://${localhost}:9999`,
    })
    // Test
    let err
    try {
      await fetch({
        fs,
        http,
        gitdir,
        depth: 1,
        singleBranch: true,
        remote: 'ssh',
        ref: 'test-branch-shallow-clone',
      })
    } catch (e) {
      err = e
    }
    expect(err).toBeDefined()
    expect(err.code).toBe(Errors.UnknownTransportError.code)
    expect(err.data.suggestion).toBe(
      'https://github.com/isomorphic-git/isomorphic-git.git'
    )
  })",steel
/__tests__/test-fetch.js,Exception Handling,"{'line': 257, 'column': 4, 'index': 7151}","it('errors if missing refspec', async () => {
    const { fs, gitdir } = await makeFixture('test-issue-84')
    await setConfig({
      fs,
      gitdir,
      path: 'http.corsProxy',
      value: `http://${localhost}:9999`,
    })
    // Test
    let err = null
    try {
      await fetch({
        fs,
        http,
        gitdir,
        since: new Date(1506571200000),
        singleBranch: true,
        remote: 'origin',
        ref: 'test-branch-shallow-clone',
      })
    } catch (e) {
      err = e
    }
    expect(err).toBeDefined()
    expect(err instanceof Errors.NoRefspecError).toBe(true)
  })",steel
/__tests__/test-fetch.js,Exception Handling,"{'line': 327, 'column': 4, 'index': 9182}","it('fetch --prune-tags from git-http-mock-server', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-fetch-client')
    await setConfig({
      fs,
      gitdir,
      path: 'remote.origin.url',
      value: `http://${localhost}:8888/test-fetch-server.git`,
    })
    expect(await fs.exists(`${gitdir}/refs/tags/v1.0.0-beta1`)).toBe(true)
    const oldValue = await fs.read(`${gitdir}/refs/tags/v1.0.0`, 'utf8')
    try {
      await fetch({
        fs,
        http,
        dir,
        gitdir,
        depth: 1,
        tags: true,
        pruneTags: true,
      })
    } catch (err) {
      // shrug
    }
    // assert that tag was deleted
    expect(await fs.exists(`${gitdir}/refs/tags/v1.0.0-beta1`)).toBe(false)
    // assert that tags was force-updated
    const newValue = await fs.read(`${gitdir}/refs/tags/v1.0.0`, 'utf8')
    expect(oldValue).not.toEqual(newValue)
  })",steel
/__tests__/test-expandOid.js,Exception Handling,"{'line': 22, 'column': 4, 'index': 654}","it('expand short oid (not found)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-expandOid')
    const oid = '01234567'
    // Test
    let error = null
    try {
      await expandOid({ fs, gitdir, oid })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",steel
/__tests__/test-expandOid.js,Exception Handling,"{'line': 37, 'column': 4, 'index': 1037}","it('expand short oid (ambiguous)', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-expandOid')
    const oid = '033417a'
    // Test
    let error = null
    try {
      await expandOid({ fs, gitdir, oid })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.AmbiguousError).toBe(true)
  })",steel
/__tests__/test-deleteTag.js,Exception Handling,"{'line': 28, 'column': 4, 'index': 678}","it('missing ref argument', async () => {
    // Setup
    const { dir, gitdir } = await makeFixture('test-deleteTag')
    let error = null
    // Test
    try {
      // @ts-ignore
      await deleteTag({ dir, gitdir })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.MissingParameterError).toBe(true)
  })",steel
/__tests__/test-deleteRemote.js,Exception Handling,"{'line': 21, 'column': 4, 'index': 710}","it('missing argument', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-addRemote')
    // Test
    let error = null
    try {
      // @ts-ignore
      await deleteRemote({ fs, dir, gitdir })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.MissingParameterError).toBe(true)
  })",steel
/__tests__/test-deleteBranch.js,Exception Handling,"{'line': 39, 'column': 4, 'index': 1146}","it('branch not exist', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-deleteBranch')
    let error = null
    // Test
    try {
      await deleteBranch({ fs, gitdir, ref: 'branch-not-exist' })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NotFoundError).toBe(true)
  })",steel
/__tests__/test-deleteBranch.js,Exception Handling,"{'line': 53, 'column': 4, 'index': 1521}","it('missing ref argument', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-deleteBranch')
    let error = null
    // Test
    try {
      // @ts-ignore
      await deleteBranch({ fs, gitdir })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.MissingParameterError).toBe(true)
  })",steel
/__tests__/test-config.js,Duplicate Assert,"{'line': 43, 'column': 4, 'index': 1451}","it('setting', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-config')
    // Test
    let bare
    // set to true
    await setConfig({ fs, gitdir, path: 'core.bare', value: true })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(true)
    // set to false
    await setConfig({ fs, gitdir, path: 'core.bare', value: false })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(false)
    // set to undefined
    await setConfig({ fs, gitdir, path: 'core.bare', value: undefined })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(undefined)
    // change a remote
    await setConfig({
      fs,
      gitdir,
      path: 'remote.origin.url',
      value: 'https://github.com/isomorphic-git/isomorphic-git',
    })
    const url = await getConfig({ fs, gitdir, path: 'remote.origin.url' })
    expect(url).toBe('https://github.com/isomorphic-git/isomorphic-git')
  })",steel
/__tests__/test-config.js,Duplicate Assert,"{'line': 47, 'column': 4, 'index': 1630}","it('setting', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-config')
    // Test
    let bare
    // set to true
    await setConfig({ fs, gitdir, path: 'core.bare', value: true })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(true)
    // set to false
    await setConfig({ fs, gitdir, path: 'core.bare', value: false })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(false)
    // set to undefined
    await setConfig({ fs, gitdir, path: 'core.bare', value: undefined })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(undefined)
    // change a remote
    await setConfig({
      fs,
      gitdir,
      path: 'remote.origin.url',
      value: 'https://github.com/isomorphic-git/isomorphic-git',
    })
    const url = await getConfig({ fs, gitdir, path: 'remote.origin.url' })
    expect(url).toBe('https://github.com/isomorphic-git/isomorphic-git')
  })",steel
/__tests__/test-config.js,Duplicate Assert,"{'line': 51, 'column': 4, 'index': 1818}","it('setting', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-config')
    // Test
    let bare
    // set to true
    await setConfig({ fs, gitdir, path: 'core.bare', value: true })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(true)
    // set to false
    await setConfig({ fs, gitdir, path: 'core.bare', value: false })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(false)
    // set to undefined
    await setConfig({ fs, gitdir, path: 'core.bare', value: undefined })
    bare = await getConfig({ fs, gitdir, path: 'core.bare' })
    expect(bare).toBe(undefined)
    // change a remote
    await setConfig({
      fs,
      gitdir,
      path: 'remote.origin.url',
      value: 'https://github.com/isomorphic-git/isomorphic-git',
    })
    const url = await getConfig({ fs, gitdir, path: 'remote.origin.url' })
    expect(url).toBe('https://github.com/isomorphic-git/isomorphic-git')
  })",steel
/__tests__/test-commit.js,Duplicate Assert,"{'line': 66, 'column': 4, 'index': 1715}","it('commit', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    const { oid: originalOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    // Test
    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }
    const sha = await commit({
      fs,
      gitdir,
      author,
      message: 'Initial commit',
    })
    expect(sha).toBe('7a51c0b1181d738198ff21c4679d3aa32eb52fe0')
    // updates branch pointer
    const { oid: currentOid, commit: currentCommit } = (
      await log({ fs, gitdir, depth: 1 })
    )[0]
    expect(currentCommit.parent).toEqual([originalOid])
    expect(currentCommit.author).toEqual(author)
    expect(currentCommit.committer).toEqual(author)
    expect(currentCommit.message).toEqual('Initial commit\n')
    expect(currentOid).not.toEqual(originalOid)
    expect(currentOid).toEqual(sha)
  })",steel
/__tests__/test-commit.js,Duplicate Assert,"{'line': 67, 'column': 4, 'index': 1763}","it('commit', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    const { oid: originalOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    // Test
    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }
    const sha = await commit({
      fs,
      gitdir,
      author,
      message: 'Initial commit',
    })
    expect(sha).toBe('7a51c0b1181d738198ff21c4679d3aa32eb52fe0')
    // updates branch pointer
    const { oid: currentOid, commit: currentCommit } = (
      await log({ fs, gitdir, depth: 1 })
    )[0]
    expect(currentCommit.parent).toEqual([originalOid])
    expect(currentCommit.author).toEqual(author)
    expect(currentCommit.committer).toEqual(author)
    expect(currentCommit.message).toEqual('Initial commit\n')
    expect(currentOid).not.toEqual(originalOid)
    expect(currentOid).toEqual(sha)
  })",steel
/__tests__/test-commit.js,Duplicate Assert,"{'line': 145, 'column': 4, 'index': 3702}","it('without updating branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    const { oid: originalOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    // Test
    const sha = await commit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      message: 'Initial commit',
      noUpdateBranch: true,
    })
    expect(sha).toBe('7a51c0b1181d738198ff21c4679d3aa32eb52fe0')
    // does NOT update branch pointer
    const { oid: currentOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    expect(currentOid).toEqual(originalOid)
    expect(currentOid).not.toEqual(sha)
    // but DID create commit object
    expect(
      await fs.exists(
        `${gitdir}/objects/7a/51c0b1181d738198ff21c4679d3aa32eb52fe0`
      )
    ).toBe(true)
  })",steel
/__tests__/test-commit.js,Duplicate Assert,"{'line': 146, 'column': 4, 'index': 3746}","it('without updating branch', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    const { oid: originalOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    // Test
    const sha = await commit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      message: 'Initial commit',
      noUpdateBranch: true,
    })
    expect(sha).toBe('7a51c0b1181d738198ff21c4679d3aa32eb52fe0')
    // does NOT update branch pointer
    const { oid: currentOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    expect(currentOid).toEqual(originalOid)
    expect(currentOid).not.toEqual(sha)
    // but DID create commit object
    expect(
      await fs.exists(
        `${gitdir}/objects/7a/51c0b1181d738198ff21c4679d3aa32eb52fe0`
      )
    ).toBe(true)
  })",steel
/__tests__/test-commit.js,Duplicate Assert,"{'line': 175, 'column': 4, 'index': 4585}","it('dry run', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    const { oid: originalOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    // Test
    const sha = await commit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      message: 'Initial commit',
      dryRun: true,
    })
    expect(sha).toBe('7a51c0b1181d738198ff21c4679d3aa32eb52fe0')
    // does NOT update branch pointer
    const { oid: currentOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    expect(currentOid).toEqual(originalOid)
    expect(currentOid).not.toEqual(sha)
    // and did NOT create commit object
    expect(
      await fs.exists(
        `${gitdir}/objects/7a/51c0b1181d738198ff21c4679d3aa32eb52fe0`
      )
    ).toBe(false)
  })",steel
/__tests__/test-commit.js,Duplicate Assert,"{'line': 176, 'column': 4, 'index': 4629}","it('dry run', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    const { oid: originalOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    // Test
    const sha = await commit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      message: 'Initial commit',
      dryRun: true,
    })
    expect(sha).toBe('7a51c0b1181d738198ff21c4679d3aa32eb52fe0')
    // does NOT update branch pointer
    const { oid: currentOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    expect(currentOid).toEqual(originalOid)
    expect(currentOid).not.toEqual(sha)
    // and did NOT create commit object
    expect(
      await fs.exists(
        `${gitdir}/objects/7a/51c0b1181d738198ff21c4679d3aa32eb52fe0`
      )
    ).toBe(false)
  })",steel
/__tests__/test-commit.js,Duplicate Assert,"{'line': 202, 'column': 4, 'index': 5317}","it('custom ref', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    const { oid: originalOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    // Test
    const sha = await commit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      message: 'Initial commit',
      ref: 'refs/heads/master-copy',
    })
    expect(sha).toBe('7a51c0b1181d738198ff21c4679d3aa32eb52fe0')
    // does NOT update master branch pointer
    const { oid: currentOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    expect(currentOid).toEqual(originalOid)
    expect(currentOid).not.toEqual(sha)
    // but DOES update master-copy
    const { oid: copyOid } = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'master-copy',
      })
    )[0]
    expect(sha).toEqual(copyOid)
  })",steel
/__tests__/test-commit.js,Duplicate Assert,"{'line': 205, 'column': 4, 'index': 5500}","it('custom ref', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    const { oid: originalOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    // Test
    const sha = await commit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      message: 'Initial commit',
      ref: 'refs/heads/master-copy',
    })
    expect(sha).toBe('7a51c0b1181d738198ff21c4679d3aa32eb52fe0')
    // does NOT update master branch pointer
    const { oid: currentOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    expect(currentOid).toEqual(originalOid)
    expect(currentOid).not.toEqual(sha)
    // but DOES update master-copy
    const { oid: copyOid } = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'master-copy',
      })
    )[0]
    expect(sha).toEqual(copyOid)
  })",steel
/__tests__/test-commit.js,Duplicate Assert,"{'line': 206, 'column': 4, 'index': 5544}","it('custom ref', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    const { oid: originalOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    // Test
    const sha = await commit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      message: 'Initial commit',
      ref: 'refs/heads/master-copy',
    })
    expect(sha).toBe('7a51c0b1181d738198ff21c4679d3aa32eb52fe0')
    // does NOT update master branch pointer
    const { oid: currentOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    expect(currentOid).toEqual(originalOid)
    expect(currentOid).not.toEqual(sha)
    // but DOES update master-copy
    const { oid: copyOid } = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'master-copy',
      })
    )[0]
    expect(sha).toEqual(copyOid)
  })",steel
/__tests__/test-commit.js,Duplicate Assert,"{'line': 216, 'column': 4, 'index': 5760}","it('custom ref', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    const { oid: originalOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    // Test
    const sha = await commit({
      fs,
      gitdir,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      message: 'Initial commit',
      ref: 'refs/heads/master-copy',
    })
    expect(sha).toBe('7a51c0b1181d738198ff21c4679d3aa32eb52fe0')
    // does NOT update master branch pointer
    const { oid: currentOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    expect(currentOid).toEqual(originalOid)
    expect(currentOid).not.toEqual(sha)
    // but DOES update master-copy
    const { oid: copyOid } = (
      await log({
        fs,
        gitdir,
        depth: 1,
        ref: 'master-copy',
      })
    )[0]
    expect(sha).toEqual(copyOid)
  })",steel
/__tests__/test-commit.js,Duplicate Assert,"{'line': 252, 'column': 4, 'index': 6755}","it('custom parents and tree', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    const { oid: originalOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    // Test
    const parent = [
      '1111111111111111111111111111111111111111',
      '2222222222222222222222222222222222222222',
      '3333333333333333333333333333333333333333',
    ]
    const tree = '4444444444444444444444444444444444444444'
    const sha = await commit({
      fs,
      gitdir,
      parent,
      tree,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      message: 'Initial commit',
    })
    expect(sha).toBe('43fbc94f2c1db655a833e08c72d005954ff32f32')
    // does NOT update master branch pointer
    const { parent: parents, tree: _tree } = (
      await log({
        fs,
        gitdir,
        depth: 1,
      })
    )[0].commit
    expect(parents).not.toEqual([originalOid])
    expect(parents).toEqual(parent)
    expect(_tree).toEqual(tree)
  })",steel
/__tests__/test-commit.js,Duplicate Assert,"{'line': 253, 'column': 4, 'index': 6802}","it('custom parents and tree', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    const { oid: originalOid } = (await log({ fs, gitdir, depth: 1 }))[0]
    // Test
    const parent = [
      '1111111111111111111111111111111111111111',
      '2222222222222222222222222222222222222222',
      '3333333333333333333333333333333333333333',
    ]
    const tree = '4444444444444444444444444444444444444444'
    const sha = await commit({
      fs,
      gitdir,
      parent,
      tree,
      author: {
        name: 'Mr. Test',
        email: 'mrtest@example.com',
        timestamp: 1262356920,
        timezoneOffset: -0,
      },
      message: 'Initial commit',
    })
    expect(sha).toBe('43fbc94f2c1db655a833e08c72d005954ff32f32')
    // does NOT update master branch pointer
    const { parent: parents, tree: _tree } = (
      await log({
        fs,
        gitdir,
        depth: 1,
      })
    )[0].commit
    expect(parents).not.toEqual([originalOid])
    expect(parents).toEqual(parent)
    expect(_tree).toEqual(tree)
  })",steel
/__tests__/test-commit.js,Exception Handling,"{'line': 22, 'column': 4, 'index': 455}","it('prevent commit if index has unmerged paths', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-GitIndex-unmerged')
    // Test
    let error = null
    try {
      await commit({
        fs,
        gitdir,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
        message: 'Initial commit',
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.UnmergedPathsError.code)
  })",steel
/__tests__/test-commit.js,Exception Handling,"{'line': 111, 'column': 4, 'index': 2814}","it('Cannot commit without message', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    // Test
    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }

    let error = null

    try {
      await commit({
        fs,
        gitdir,
        author,
      })
    } catch (err) {
      error = err
    }

    expect(error).not.toBeNull()
    expect(error instanceof Errors.MissingParameterError).toBe(true)
  })",steel
/__tests__/test-commit.js,Exception Handling,"{'line': 262, 'column': 4, 'index': 7034}","it('throw error if missing author', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-commit')
    // Test
    let error = null
    try {
      await commit({
        fs,
        gitdir,
        author: {
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: 0,
        },
        message: 'Initial commit',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MissingNameError.code)
  })",steel
/__tests__/test-commit.js,Exception Handling,"{'line': 476, 'column': 4, 'index': 12622}","it('Cannot amend without an initial commit', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-init')
    await init({ fs, dir })
    await fs.write(path.join(dir, 'hello.md'), 'Hello, World!')
    await add({ fs, dir, filepath: 'hello.md' })

    // Test
    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }

    let error = null
    try {
      await commit({
        fs,
        dir,
        author,
        message: 'Initial commit',
        amend: true,
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.NoCommitError).toBe(true)
  })",steel
/__tests__/test-commit.js,Magic Number,"{'line': 93, 'column': 32, 'index': 2372}","it('Initial commit', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-init')
    await init({ fs, dir })
    await fs.write(path.join(dir, 'hello.md'), 'Hello, World!')
    await add({ fs, dir, filepath: 'hello.md' })

    // Test
    const author = {
      name: 'Mr. Test',
      email: 'mrtest@example.com',
      timestamp: 1262356920,
      timezoneOffset: -0,
    }

    await commit({
      fs,
      dir,
      author,
      message: 'Initial commit',
    })

    const commits = await log({ fs, dir })
    expect(commits.length).toBe(1)
    expect(commits[0].commit.parent).toEqual([])
    expect(await resolveRef({ fs, dir, ref: 'HEAD' })).toEqual(commits[0].oid)
  })",steel
/__tests__/test-clone.js,Conditional Test Logic,"{'line': 168, 'column': 10, 'index': 5457}","it('should throw error if server resets connection before reading packetlines', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-before-packetlines'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('shallow')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })",steel
/__tests__/test-clone.js,Conditional Test Logic,"{'line': 185, 'column': 16, 'index': 6254}","it('should throw error if server resets connection before reading packetlines', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-before-packetlines'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('shallow')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })",steel
/__tests__/test-clone.js,Conditional Test Logic,"{'line': 229, 'column': 10, 'index': 7450}","it('should throw error if server resets connection while reading packetlines', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-during-packetlines'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0037unshallow 1f6d22958fa079fc2205bb5ae1224d9677f1eaf9
0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('shallow')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })",steel
/__tests__/test-clone.js,Conditional Test Logic,"{'line': 247, 'column': 16, 'index': 8302}","it('should throw error if server resets connection while reading packetlines', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-during-packetlines'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0037unshallow 1f6d22958fa079fc2205bb5ae1224d9677f1eaf9
0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('shallow')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })",steel
/__tests__/test-clone.js,Conditional Test Logic,"{'line': 291, 'column': 10, 'index': 9493}","it('should throw error if server resets connection before reading packfile', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-before-packfile'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('PACK')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })",steel
/__tests__/test-clone.js,Conditional Test Logic,"{'line': 308, 'column': 16, 'index': 10290}","it('should throw error if server resets connection before reading packfile', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-before-packfile'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('PACK')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })",steel
/__tests__/test-clone.js,Conditional Test Logic,"{'line': 352, 'column': 10, 'index': 11460}","it('should not throw TypeError error if packfile is empty', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-empty-packfile'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            response.body = `0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.name).not.toEqual('TypeError')
    expect(error.name).toEqual('CommitNotFetchedError')
    expect(error.caller).toEqual('git.clone')
  })",steel
/__tests__/test-clone.js,Conditional Test Logic,"{'line': 504, 'column': 2, 'index': 15756}","describe('clone', () => {
  // Note: for a long time this test was disabled because it took too long.
  // It seems to only take a couple seconds longer than the ""shallow fetch"" tests now,
  // so I'm enabling it.
  // Update: well, it's now slow enough on Edge that it's failing. Which is odd bc
  // it's the New Edge with is Chromium-based.
  ;(process.browser ? xit : it)('clone with noTags', async () => {
    const { fs, dir, gitdir } = await makeFixture('isomorphic-git')
    await clone({
      fs,
      http,
      dir,
      gitdir,
      depth: 1,
      ref: 'test-branch',
      noTags: true,
      url: 'https://github.com/isomorphic-git/isomorphic-git.git',
      corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
      noCheckout: true,
    })
    expect(await fs.exists(`${dir}`)).toBe(true)
    expect(await fs.exists(`${gitdir}/objects`)).toBe(true)
    expect(
      await resolveRef({ fs, gitdir, ref: 'refs/remotes/origin/test-branch' })
    ).toBe('e10ebb90d03eaacca84de1af0a59b444232da99e')
    expect(
      await resolveRef({ fs, gitdir, ref: 'refs/heads/test-branch' })
    ).toBe('e10ebb90d03eaacca84de1af0a59b444232da99e')
    let err = null
    try {
      await resolveRef({ fs, gitdir, ref: 'refs/tags/v0.0.1' })
    } catch (e) {
      err = e
    }
    expect(err).not.toBeNull()
    expect(err.code).toBe(Errors.NotFoundError.code)
  })
  it('clone with noCheckout', async () => {
    const { fs, dir, gitdir } = await makeFixture('isomorphic-git')
    await clone({
      fs,
      http,
      dir,
      gitdir,
      depth: 1,
      ref: 'test-branch',
      singleBranch: true,
      noCheckout: true,
      url: 'https://github.com/isomorphic-git/isomorphic-git.git',
      corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
    })
    expect(await fs.exists(`${dir}`)).toBe(true)
    expect(await fs.exists(`${gitdir}/objects`)).toBe(true)
    expect(await fs.exists(`${gitdir}/refs/remotes/origin/test-branch`)).toBe(
      true
    )
    expect(await fs.exists(`${gitdir}/refs/heads/test-branch`)).toBe(true)
    expect(await fs.exists(`${dir}/package.json`)).toBe(false)
  })
  it('clone a tag', async () => {
    const { fs, dir, gitdir } = await makeFixture('isomorphic-git')
    await clone({
      fs,
      http,
      dir,
      gitdir,
      depth: 1,
      singleBranch: true,
      ref: 'test-tag',
      url: 'https://github.com/isomorphic-git/isomorphic-git.git',
      corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
    })
    expect(await fs.exists(`${dir}`)).toBe(true)
    expect(await fs.exists(`${gitdir}/objects`)).toBe(true)
    expect(await fs.exists(`${gitdir}/refs/remotes/origin/test-tag`)).toBe(
      false
    )
    expect(await fs.exists(`${gitdir}/refs/heads/test-tag`)).toBe(false)
    expect(await fs.exists(`${gitdir}/refs/tags/test-tag`)).toBe(true)
    expect(await fs.exists(`${dir}/package.json`)).toBe(true)
  })
  it('clone should not peel tag', async () => {
    const { fs, dir, gitdir } = await makeFixture('isomorphic-git')
    await clone({
      fs,
      http,
      dir,
      gitdir,
      url: `http://${localhost}:8888/test-git-http-mock-server.git`,
    })
    const oid = await fs._readFile(`${gitdir}/refs/tags/v1.0.0`, 'utf8')
    expect(oid.trim()).toBe('db34227a52a6490fc80a13da3916ea91d183fc3f')
  })
  it('clone with an unregistered protocol', async () => {
    const { fs, dir, gitdir } = await makeFixture('isomorphic-git')
    const url = `foobar://github.com/isomorphic-git/isomorphic-git`
    let error = null
    try {
      await clone({
        fs,
        http,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        ref: 'test-tag',
        url,
      })
    } catch (err) {
      error = err
    }
    expect(error.message).toEqual(
      `Git remote ""${url}"" uses an unrecognized transport protocol: ""foobar""`
    )
    expect(error.caller).toEqual('git.clone')
  })

  it('clone from git-http-mock-server', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-clone-karma')
    await clone({
      fs,
      http,
      dir,
      gitdir,
      depth: 1,
      singleBranch: true,
      url: `http://${localhost}:8888/test-clone.git`,
    })
    expect(await fs.exists(`${dir}`)).toBe(true, `'dir' exists`)
    expect(await fs.exists(`${gitdir}/objects`)).toBe(
      true,
      `'gitdir/objects' exists`
    )
    expect(await fs.exists(`${gitdir}/refs/heads/master`)).toBe(
      true,
      `'gitdir/refs/heads/master' exists`
    )
    expect(await fs.exists(`${dir}/a.txt`)).toBe(true, `'a.txt' exists`)
  })

  it('should throw error if server resets connection before reading packetlines', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-before-packetlines'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('shallow')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })

  it('should throw error if server resets connection while reading packetlines', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-during-packetlines'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0037unshallow 1f6d22958fa079fc2205bb5ae1224d9677f1eaf9
0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('shallow')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })

  it('should throw error if server resets connection before reading packfile', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-before-packfile'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('PACK')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })

  it('should not throw TypeError error if packfile is empty', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-empty-packfile'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            response.body = `0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.name).not.toEqual('TypeError')
    expect(error.name).toEqual('CommitNotFetchedError')
    expect(error.caller).toEqual('git.clone')
  })

  it('clone default branch with --singleBranch', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-clone-karma')
    await clone({
      fs,
      http,
      dir,
      gitdir,
      depth: 1,
      singleBranch: true,
      url: `http://${localhost}:8888/test-clone-no-master.git`,
    })
    expect(await currentBranch({ fs, dir, gitdir })).toBe('i-am-not-master')
  })

  it('create tracking for remote branch', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-clone-branch-with-dot')
    await clone({
      fs,
      http,
      dir,
      gitdir,
      url: `http://${localhost}:8888/test-branch-with-dot.git`,
    })
    await checkout({ fs, dir, gitdir, ref: 'v1.0.x' })
    const config = await fs.read(gitdir + '/config', 'utf8')
    expect(config).toContain(
      '\n[branch ""v1.0.x""]\n\tmerge = refs/heads/v1.0.x\n\tremote = origin'
    )
  })

  it('clone empty repository from git-http-mock-server', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-clone-empty')
    await clone({
      fs,
      http,
      dir,
      gitdir,
      depth: 1,
      url: `http://${localhost}:8888/test-empty.git`,
    })
    expect(await fs.exists(`${dir}`)).toBe(true, `'dir' exists`)
    expect(await fs.exists(`${gitdir}/HEAD`)).toBe(true, `'gitdir/HEAD' exists`)
    expect((await fs.read(`${gitdir}/HEAD`)).toString('utf-8').trim()).toEqual(
      'ref: refs/heads/master',
      `'gitdir/HEAD' points to refs/heads/master`
    )
    expect(await fs.exists(`${gitdir}/refs/heads/master`)).toBe(
      false,
      `'gitdir/refs/heads/master' does not exist`
    )
  })

  it('removes the gitdir when clone fails', async () => {
    const { fs, dir, gitdir } = await makeFixture('isomorphic-git')
    const url = `foobar://github.com/isomorphic-git/isomorphic-git`
    try {
      await clone({
        fs,
        http,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        ref: 'test-tag',
        url,
      })
    } catch (err) {
      // Intentionally left blank.
    }
    expect(await fs.exists(gitdir)).toBe(false, `'gitdir' does not exist`)
  })

  it('should set up the remote tracking branch by default', async () => {
    const { fs, dir, gitdir } = await makeFixture('isomorphic-git')
    await clone({
      fs,
      http,
      dir,
      gitdir,
      depth: 1,
      singleBranch: true,
      remote: 'foo',
      url: 'https://github.com/isomorphic-git/isomorphic-git.git',
      corsProxy: process.browser ? `http://${localhost}:9999` : undefined,
    })

    const [merge, remote] = await Promise.all([
      await getConfig({ fs, dir, gitdir, path: 'branch.main.merge' }),
      await getConfig({ fs, dir, gitdir, path: 'branch.main.remote' }),
    ])

    expect(merge).toBe('refs/heads/main')
    expect(remote).toBe('foo')
  })

  it('clone with post-checkout hook', async () => {
    const { fs, dir, gitdir } = await makeFixture('test-clone-karma')
    const onPostCheckout = []
    await clone({
      fs,
      http,
      dir,
      gitdir,
      depth: 1,
      singleBranch: true,
      url: `http://${localhost}:8888/test-clone.git`,
      onPostCheckout: args => {
        onPostCheckout.push(args)
      },
    })

    expect(onPostCheckout).toEqual([
      {
        newHead: '97c024f73eaab2781bf3691597bc7c833cb0e22f',
        previousHead: '0000000000000000000000000000000000000000',
        type: 'branch',
      },
    ])
  })

  if (typeof process === 'object' && (process.versions || {}).node) {
    it('should allow agent to be used with built-in http plugin for Node.js', async () => {
      const { fs, dir, gitdir } = await makeFixture('isomorphic-git')
      const connectionLog = []
      const { Agent } = require('https')
      const httpWithAgent = {
        async request({ url, method, headers, body }) {
          const agent = new Agent()
          // @ts-ignore
          agent.createConnection = new Proxy(agent.createConnection, {
            apply(target, self, args) {
              const { hostname, port, method: method_ } = args[0]
              connectionLog.push(`${method_} ${hostname}:${port}`)
              return target.apply(self, args)
            },
          })
          return http.request({ url, method, headers, agent, body })
        },
      }
      await clone({
        fs,
        http: httpWithAgent,
        dir,
        gitdir,
        depth: 1,
        ref: 'test-branch',
        singleBranch: true,
        noCheckout: true,
        url: 'https://github.com/isomorphic-git/isomorphic-git.git',
      })
      expect(connectionLog.length).not.toBe(0)
      expect(connectionLog[0]).toEqual('GET github.com:443')
      expect(connectionLog[1]).toEqual('POST github.com:443')
    })
  }
})",steel
/__tests__/test-clone.js,Duplicate Assert,"{'line': 379, 'column': 4, 'index': 12139}","it('should not throw TypeError error if packfile is empty', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-empty-packfile'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            response.body = `0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.name).not.toEqual('TypeError')
    expect(error.name).toEqual('CommitNotFetchedError')
    expect(error.caller).toEqual('git.clone')
  })",steel
/__tests__/test-clone.js,Duplicate Assert,"{'line': 380, 'column': 4, 'index': 12187}","it('should not throw TypeError error if packfile is empty', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-empty-packfile'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            response.body = `0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.name).not.toEqual('TypeError')
    expect(error.name).toEqual('CommitNotFetchedError')
    expect(error.caller).toEqual('git.clone')
  })",steel
/__tests__/test-clone.js,Exception Handling,"{'line': 116, 'column': 4, 'index': 4000}","it('clone with an unregistered protocol', async () => {
    const { fs, dir, gitdir } = await makeFixture('isomorphic-git')
    const url = `foobar://github.com/isomorphic-git/isomorphic-git`
    let error = null
    try {
      await clone({
        fs,
        http,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        ref: 'test-tag',
        url,
      })
    } catch (err) {
      error = err
    }
    expect(error.message).toEqual(
      `Git remote ""${url}"" uses an unrecognized transport protocol: ""foobar""`
    )
    expect(error.caller).toEqual('git.clone')
  })",steel
/__tests__/test-clone.js,Exception Handling,"{'line': 186, 'column': 18, 'index': 6312}","it('should throw error if server resets connection before reading packetlines', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-before-packetlines'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('shallow')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })",steel
/__tests__/test-clone.js,Exception Handling,"{'line': 201, 'column': 4, 'index': 6624}","it('should throw error if server resets connection before reading packetlines', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-before-packetlines'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('shallow')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })",steel
/__tests__/test-clone.js,Exception Handling,"{'line': 248, 'column': 18, 'index': 8360}","it('should throw error if server resets connection while reading packetlines', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-during-packetlines'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0037unshallow 1f6d22958fa079fc2205bb5ae1224d9677f1eaf9
0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('shallow')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })",steel
/__tests__/test-clone.js,Exception Handling,"{'line': 263, 'column': 4, 'index': 8672}","it('should throw error if server resets connection while reading packetlines', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-during-packetlines'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0037unshallow 1f6d22958fa079fc2205bb5ae1224d9677f1eaf9
0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('shallow')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })",steel
/__tests__/test-clone.js,Exception Handling,"{'line': 309, 'column': 18, 'index': 10345}","it('should throw error if server resets connection before reading packfile', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-before-packfile'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('PACK')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })",steel
/__tests__/test-clone.js,Exception Handling,"{'line': 324, 'column': 4, 'index': 10657}","it('should throw error if server resets connection before reading packfile', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-before-packfile'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            const body = `0034shallow 97c024f73eaab2781bf3691597bc7c833cb0e22f00000008NAK
0023\x02Enumerating objects: 5, done.
0022\x02Counting objects:  20% (1/5)
0022\x02Counting objects:  40% (2/5)
0022\x02Counting objects:  60% (3/5)
0022\x02Counting objects:  80% (4/5)
0029\x02Counting objects: 100% (5/5), done.
002c\x02Compressing objects: 100% (2/2), done.
0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
            body.next = new Proxy(body.next, {
              apply(target, self, args) {
                const result = target.apply(self, args)
                if (~result.value.indexOf('PACK')) {
                  throw Object.assign(new Error('aborted'), {
                    code: 'ECONNRESET',
                  })
                }
                return result
              },
            })
            response.body = body
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.message).toEqual('aborted')
    expect(error.caller).toEqual('git.clone')
    expect(error.code).toEqual('ECONNRESET')
  })",steel
/__tests__/test-clone.js,Exception Handling,"{'line': 365, 'column': 4, 'index': 11852}","it('should not throw TypeError error if packfile is empty', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture(
      'test-clone-error-empty-packfile'
    )
    const instrumentedHttp = {
      request() {
        return http.request.apply(null, arguments).then(response => {
          const contentType = response.headers['content-type']
          if (contentType === 'application/x-git-upload-pack-result') {
            response.body = `0012\x01PACK\x00\x00\x00\x02\x00\x00\x00\x05
0039\x02Total 5 (delta 0), reused 0 (delta 0), pack-reused 0`
              .split('\n')
              .map(it => Buffer.from(it + '\n'))
              .values()
          }
          return response
        })
      },
    }
    // Test
    let error
    try {
      await clone({
        fs,
        http: instrumentedHttp,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        url: `http://${localhost}:8888/test-clone.git`,
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.name).not.toEqual('TypeError')
    expect(error.name).toEqual('CommitNotFetchedError')
    expect(error.caller).toEqual('git.clone')
  })",steel
/__tests__/test-clone.js,Exception Handling,"{'line': 439, 'column': 4, 'index': 14126}","it('removes the gitdir when clone fails', async () => {
    const { fs, dir, gitdir } = await makeFixture('isomorphic-git')
    const url = `foobar://github.com/isomorphic-git/isomorphic-git`
    try {
      await clone({
        fs,
        http,
        dir,
        gitdir,
        depth: 1,
        singleBranch: true,
        ref: 'test-tag',
        url,
      })
    } catch (err) {
      // Intentionally left blank.
    }
    expect(await fs.exists(gitdir)).toBe(false, `'gitdir' does not exist`)
  })",steel
/__tests__/test-clone.js,Magic Number,"{'line': 534, 'column': 44, 'index': 16922}","it('should allow agent to be used with built-in http plugin for Node.js', async () => {
      const { fs, dir, gitdir } = await makeFixture('isomorphic-git')
      const connectionLog = []
      const { Agent } = require('https')
      const httpWithAgent = {
        async request({ url, method, headers, body }) {
          const agent = new Agent()
          // @ts-ignore
          agent.createConnection = new Proxy(agent.createConnection, {
            apply(target, self, args) {
              const { hostname, port, method: method_ } = args[0]
              connectionLog.push(`${method_} ${hostname}:${port}`)
              return target.apply(self, args)
            },
          })
          return http.request({ url, method, headers, agent, body })
        },
      }
      await clone({
        fs,
        http: httpWithAgent,
        dir,
        gitdir,
        depth: 1,
        ref: 'test-branch',
        singleBranch: true,
        noCheckout: true,
        url: 'https://github.com/isomorphic-git/isomorphic-git.git',
      })
      expect(connectionLog.length).not.toBe(0)
      expect(connectionLog[0]).toEqual('GET github.com:443')
      expect(connectionLog[1]).toEqual('POST github.com:443')
    })",steel
/__tests__/test-checkout.js,Duplicate Assert,"{'line': 235, 'column': 4, 'index': 6361}","it('checkout unfetched branch', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-checkout')
    let error = null
    try {
      await checkout({ fs, dir, gitdir, ref: 'missing-branch' })
      throw new Error('Checkout should have failed.')
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.checkout')
    error = error.toJSON()
    delete error.stack
    expect(error).toMatchInlineSnapshot(`
      Object {
        ""caller"": ""git.checkout"",
        ""code"": ""CommitNotFetchedError"",
        ""data"": Object {
          ""oid"": ""033417ae18b174f078f2f44232cb7a374f4c60ce"",
          ""ref"": ""missing-branch"",
        },
        ""message"": ""Failed to checkout \\""missing-branch\\"" because commit 033417ae18b174f078f2f44232cb7a374f4c60ce is not available locally. Do a git fetch to make the branch available locally."",
      }
    `)
  })",steel
/__tests__/test-checkout.js,Duplicate Assert,"{'line': 239, 'column': 4, 'index': 6493}","it('checkout unfetched branch', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-checkout')
    let error = null
    try {
      await checkout({ fs, dir, gitdir, ref: 'missing-branch' })
      throw new Error('Checkout should have failed.')
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.checkout')
    error = error.toJSON()
    delete error.stack
    expect(error).toMatchInlineSnapshot(`
      Object {
        ""caller"": ""git.checkout"",
        ""code"": ""CommitNotFetchedError"",
        ""data"": Object {
          ""oid"": ""033417ae18b174f078f2f44232cb7a374f4c60ce"",
          ""ref"": ""missing-branch"",
        },
        ""message"": ""Failed to checkout \\""missing-branch\\"" because commit 033417ae18b174f078f2f44232cb7a374f4c60ce is not available locally. Do a git fetch to make the branch available locally."",
      }
    `)
  })",steel
/__tests__/test-checkout.js,Duplicate Assert,"{'line': 730, 'column': 4, 'index': 19114}","it('checkout should not delete ignored files', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-checkout')

    // Checkout the test-branch
    await checkout({
      fs,
      dir,
      gitdir,
      ref: 'test-branch',
    })

    // Create a branch from test-branch
    await branch({
      fs,
      dir,
      gitdir,
      ref: 'branch-w-ignored-dir',
      checkout: true,
    })
    // Add a regular file to the ignored dir
    await fs.write(`${dir}/ignored/regular-file.txt`, 'regular file', {
      mode: 0o666,
    })

    // Add and commit a gitignore, ignoring everything but itself
    const gitignoreContent = `*
!.gitignore`
    await fs.write(`${dir}/ignored/.gitignore`, gitignoreContent, {
      mode: 0o666,
    })
    await add({ fs, dir, gitdir, filepath: 'ignored/.gitignore' })

    await commit({
      fs,
      dir,
      gitdir,
      author: { name: 'Git', email: 'git@example.org' },
      message: 'add gitignore',
    })

    // Checkout the test-branch, which does not contain the ignore/.gitignore
    // should not delete files from ignore, but leave them as untracked in the working tree
    await checkout({
      fs,
      dir,
      gitdir,
      ref: 'test-branch',
    })
    const files = await fs.readdir(`${dir}/ignored`)
    expect(files).toContain('regular-file.txt')
    expect(files).not.toContain('.gitignore')
  })",steel
/__tests__/test-checkout.js,Duplicate Assert,"{'line': 731, 'column': 4, 'index': 19162}","it('checkout should not delete ignored files', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-checkout')

    // Checkout the test-branch
    await checkout({
      fs,
      dir,
      gitdir,
      ref: 'test-branch',
    })

    // Create a branch from test-branch
    await branch({
      fs,
      dir,
      gitdir,
      ref: 'branch-w-ignored-dir',
      checkout: true,
    })
    // Add a regular file to the ignored dir
    await fs.write(`${dir}/ignored/regular-file.txt`, 'regular file', {
      mode: 0o666,
    })

    // Add and commit a gitignore, ignoring everything but itself
    const gitignoreContent = `*
!.gitignore`
    await fs.write(`${dir}/ignored/.gitignore`, gitignoreContent, {
      mode: 0o666,
    })
    await add({ fs, dir, gitdir, filepath: 'ignored/.gitignore' })

    await commit({
      fs,
      dir,
      gitdir,
      author: { name: 'Git', email: 'git@example.org' },
      message: 'add gitignore',
    })

    // Checkout the test-branch, which does not contain the ignore/.gitignore
    // should not delete files from ignore, but leave them as untracked in the working tree
    await checkout({
      fs,
      dir,
      gitdir,
      ref: 'test-branch',
    })
    const files = await fs.readdir(`${dir}/ignored`)
    expect(files).toContain('regular-file.txt')
    expect(files).not.toContain('.gitignore')
  })",steel
/__tests__/test-checkout.js,Exception Handling,"{'line': 229, 'column': 4, 'index': 6188}","it('checkout unfetched branch', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-checkout')
    let error = null
    try {
      await checkout({ fs, dir, gitdir, ref: 'missing-branch' })
      throw new Error('Checkout should have failed.')
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.checkout')
    error = error.toJSON()
    delete error.stack
    expect(error).toMatchInlineSnapshot(`
      Object {
        ""caller"": ""git.checkout"",
        ""code"": ""CommitNotFetchedError"",
        ""data"": Object {
          ""oid"": ""033417ae18b174f078f2f44232cb7a374f4c60ce"",
          ""ref"": ""missing-branch"",
        },
        ""message"": ""Failed to checkout \\""missing-branch\\"" because commit 033417ae18b174f078f2f44232cb7a374f4c60ce is not available locally. Do a git fetch to make the branch available locally."",
      }
    `)
  })",steel
/__tests__/test-checkout.js,Exception Handling,"{'line': 231, 'column': 6, 'index': 6265}","it('checkout unfetched branch', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-checkout')
    let error = null
    try {
      await checkout({ fs, dir, gitdir, ref: 'missing-branch' })
      throw new Error('Checkout should have failed.')
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error.caller).toEqual('git.checkout')
    error = error.toJSON()
    delete error.stack
    expect(error).toMatchInlineSnapshot(`
      Object {
        ""caller"": ""git.checkout"",
        ""code"": ""CommitNotFetchedError"",
        ""data"": Object {
          ""oid"": ""033417ae18b174f078f2f44232cb7a374f4c60ce"",
          ""ref"": ""missing-branch"",
        },
        ""message"": ""Failed to checkout \\""missing-branch\\"" because commit 033417ae18b174f078f2f44232cb7a374f4c60ce is not available locally. Do a git fetch to make the branch available locally."",
      }
    `)
  })",steel
/__tests__/test-checkout.js,Exception Handling,"{'line': 377, 'column': 4, 'index': 10966}","it('checkout detects conflicts', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-checkout')
    await fs.write(`${dir}/README.md`, 'Hello world', 'utf8')
    // Test
    let error = null
    try {
      await checkout({
        fs,
        dir,
        gitdir,
        ref: 'test-branch',
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.CheckoutConflictError).toBe(true)
    expect(error.data.filepaths).toEqual(['README.md'])
  })",steel
/__tests__/test-checkout.js,Exception Handling,"{'line': 398, 'column': 4, 'index': 11520}","it('checkout files ignoring conflicts dry run', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-checkout')
    await fs.write(`${dir}/README.md`, 'Hello world', 'utf8')
    // Test
    let error = null
    try {
      await checkout({
        fs,
        dir,
        gitdir,
        ref: 'test-branch',
        force: true,
        dryRun: true,
      })
    } catch (e) {
      error = e
    }
    expect(error).toBeNull()
    expect(await fs.read(`${dir}/README.md`, 'utf8')).toBe('Hello world')
  })",steel
/__tests__/test-checkout.js,Exception Handling,"{'line': 420, 'column': 4, 'index': 12054}","it('checkout files ignoring conflicts', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-checkout')
    await fs.write(`${dir}/README.md`, 'Hello world', 'utf8')
    // Test
    let error = null
    try {
      await checkout({
        fs,
        dir,
        gitdir,
        ref: 'test-branch',
        force: true,
      })
    } catch (e) {
      error = e
    }
    expect(error).toBeNull()
    expect(await fs.read(`${dir}/README.md`, 'utf8')).not.toBe('Hello world')
  })",steel
/__tests__/test-checkout.js,Exception Handling,"{'line': 447, 'column': 4, 'index': 12676}","it('restore files to HEAD state by not providing a ref', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-checkout')
    await checkout({
      fs,
      dir,
      gitdir,
      ref: 'test-branch',
    })
    await fs.write(`${dir}/README.md`, 'Hello world', 'utf8')
    // Test
    let error = null
    try {
      await checkout({
        fs,
        dir,
        gitdir,
        force: true,
      })
    } catch (e) {
      error = e
    }
    expect(error).toBeNull()
    expect(await fs.read(`${dir}/README.md`, 'utf8')).not.toBe('Hello world')
  })",steel
/__tests__/test-branch.js,Duplicate Assert,"{'line': 30, 'column': 4, 'index': 862}","it('branch with start point', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-branch-start-point')
    // Test
    let files = await fs.readdir(path.resolve(gitdir, 'refs', 'heads'))
    expect(files).toEqual(['main', 'start-point'])
    await branch({ fs, dir, gitdir, ref: 'test-branch', object: 'start-point' })
    files = await fs.readdir(path.resolve(gitdir, 'refs', 'heads'))
    expect(files).toEqual(['main', 'start-point', 'test-branch'])
    expect(await currentBranch({ fs, dir, gitdir })).toEqual('main')
    expect(
      await fs.read(
        path.resolve(gitdir, 'refs', 'heads', 'test-branch'),
        'utf8'
      )
    ).toEqual(
      await fs.read(
        path.resolve(gitdir, 'refs', 'heads', 'start-point'),
        'utf8'
      )
    )
    expect(await listFiles({ fs, dir, gitdir, ref: 'HEAD' })).toEqual([
      'new-file.txt',
    ])
    expect(await listFiles({ fs, dir, gitdir, ref: 'test-branch' })).toEqual([])
  })",steel
/__tests__/test-branch.js,Duplicate Assert,"{'line': 33, 'column': 4, 'index': 1062}","it('branch with start point', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-branch-start-point')
    // Test
    let files = await fs.readdir(path.resolve(gitdir, 'refs', 'heads'))
    expect(files).toEqual(['main', 'start-point'])
    await branch({ fs, dir, gitdir, ref: 'test-branch', object: 'start-point' })
    files = await fs.readdir(path.resolve(gitdir, 'refs', 'heads'))
    expect(files).toEqual(['main', 'start-point', 'test-branch'])
    expect(await currentBranch({ fs, dir, gitdir })).toEqual('main')
    expect(
      await fs.read(
        path.resolve(gitdir, 'refs', 'heads', 'test-branch'),
        'utf8'
      )
    ).toEqual(
      await fs.read(
        path.resolve(gitdir, 'refs', 'heads', 'start-point'),
        'utf8'
      )
    )
    expect(await listFiles({ fs, dir, gitdir, ref: 'HEAD' })).toEqual([
      'new-file.txt',
    ])
    expect(await listFiles({ fs, dir, gitdir, ref: 'test-branch' })).toEqual([])
  })",steel
/__tests__/test-branch.js,Exception Handling,"{'line': 62, 'column': 4, 'index': 2006}","it('branch force', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-branch')
    let error = null
    // Test
    await branch({ fs, dir, gitdir, ref: 'test-branch' })
    expect(await currentBranch({ fs, dir, gitdir })).toEqual('master')
    expect(
      await fs.exists(path.resolve(gitdir, 'refs/heads/test-branch'))
    ).toBeTruthy()
    try {
      await branch({ fs, dir, gitdir, ref: 'test-branch', force: true })
    } catch (err) {
      error = err
    }
    expect(error).toBeNull()
  })",steel
/__tests__/test-branch.js,Exception Handling,"{'line': 80, 'column': 4, 'index': 2594}","it('branch with start point force', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-branch-start-point')
    let error = null
    // Test
    await branch({ fs, dir, gitdir, ref: 'test-branch', object: 'start-point' })
    expect(await currentBranch({ fs, dir, gitdir })).toEqual('main')
    expect(
      await fs.exists(path.resolve(gitdir, 'refs/heads/test-branch'))
    ).toBeTruthy()
    try {
      await branch({ fs, dir, gitdir, ref: 'test-branch', force: true })
    } catch (err) {
      error = err
    }
    expect(error).toBeNull()
    expect(await listFiles({ fs, dir, gitdir, ref: 'test-branch' })).toEqual([
      'new-file.txt',
    ])
  })",steel
/__tests__/test-branch.js,Exception Handling,"{'line': 104, 'column': 4, 'index': 3303}","it('invalid branch name', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-branch')
    let error = null
    // Test
    try {
      await branch({ fs, dir, gitdir, ref: 'inv@{id..branch.lock' })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidRefNameError).toBe(true)
  })",steel
/__tests__/test-branch.js,Exception Handling,"{'line': 118, 'column': 4, 'index': 3686}","it('missing ref argument', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-branch')
    let error = null
    // Test
    try {
      // @ts-ignore
      await branch({ fs, dir, gitdir })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.MissingParameterError).toBe(true)
  })",steel
/__tests__/test-branch.js,Exception Handling,"{'line': 134, 'column': 4, 'index': 4099}","it('empty repo', async () => {
    // Setup
    const { dir, fs, gitdir } = await makeFixture('test-branch-empty-repo')
    await init({ fs, dir, gitdir })
    let error = null
    // Test
    try {
      await branch({ fs, dir, gitdir, ref: 'test-branch', checkout: true })
    } catch (err) {
      error = err
    }
    expect(error).toBeNull()
    const file = await fs.read(path.resolve(gitdir, 'HEAD'), 'utf8')
    expect(file).toBe(`ref: refs/heads/test-branch\n`)
  })",steel
/__tests__/test-branch.js,Exception Handling,"{'line': 149, 'column': 4, 'index': 4562}","it('create branch with same name as a remote', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-branch')
    let error = null
    // Test
    try {
      await branch({ fs, dir, gitdir, ref: 'origin' })
    } catch (err) {
      error = err
    }
    expect(error).toBeNull()
    expect(
      await fs.exists(path.resolve(gitdir, 'refs/heads/origin'))
    ).toBeTruthy()
  })",steel
/__tests__/test-branch.js,Exception Handling,"{'line': 165, 'column': 4, 'index': 4962}","it('create branch named ""HEAD""', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-branch')
    let error = null
    // Test
    try {
      await branch({ fs, dir, gitdir, ref: 'HEAD' })
    } catch (err) {
      error = err
    }
    expect(error).toBeNull()
    expect(
      await fs.exists(path.resolve(gitdir, 'refs/heads/HEAD'))
    ).toBeTruthy()
  })",steel
/__tests__/test-addRemote.js,Exception Handling,"{'line': 28, 'column': 4, 'index': 929}","it('missing argument', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-addRemote')
    const remote = 'baz'
    const url = undefined
    // Test
    let error = null
    try {
      await addRemote({
        fs,
        dir,
        gitdir,
        remote,
        // @ts-ignore
        url,
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.MissingParameterError).toBe(true)
  })",steel
/__tests__/test-addRemote.js,Exception Handling,"{'line': 50, 'column': 4, 'index': 1447}","it('invalid remote name', async () => {
    // Setup
    const { fs, dir, gitdir } = await makeFixture('test-addRemote')
    const remote = '@{HEAD~1}'
    const url = 'git@github.com:baz/baz.git'
    // Test
    let error = null
    try {
      await addRemote({ fs, dir, gitdir, remote, url })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.InvalidRefNameError).toBe(true)
  })",steel
/__tests__/test-addNote.js,Duplicate Assert,"{'line': 118, 'column': 6, 'index': 3605}","it('consecutive notes accumulate', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-addNote')
    // Test
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
        note: 'This is a note about a commit.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(1)
    }
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: '199948939a0b95c6f27668689102496574b2c332',
        note: 'This is a note about a tree.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(2)
    }
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: '68aba62e560c0ebc3396e8ae9335232cd93a3f60',
        note: 'This is a note about a blob.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(3)
    }
  })",steel
/__tests__/test-addNote.js,Duplicate Assert,"{'line': 134, 'column': 6, 'index': 4050}","it('consecutive notes accumulate', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-addNote')
    // Test
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
        note: 'This is a note about a commit.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(1)
    }
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: '199948939a0b95c6f27668689102496574b2c332',
        note: 'This is a note about a tree.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(2)
    }
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: '68aba62e560c0ebc3396e8ae9335232cd93a3f60',
        note: 'This is a note about a blob.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(3)
    }
  })",steel
/__tests__/test-addNote.js,Duplicate Assert,"{'line': 150, 'column': 6, 'index': 4495}","it('consecutive notes accumulate', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-addNote')
    // Test
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
        note: 'This is a note about a commit.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(1)
    }
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: '199948939a0b95c6f27668689102496574b2c332',
        note: 'This is a note about a tree.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(2)
    }
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: '68aba62e560c0ebc3396e8ae9335232cd93a3f60',
        note: 'This is a note about a blob.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(3)
    }
  })",steel
/__tests__/test-addNote.js,Exception Handling,"{'line': 200, 'column': 4, 'index': 5995}","it('throws if note already exists', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-addNote')
    await addNote({
      fs,
      gitdir,
      author: {
        name: 'William Hilton',
        email: 'wmhilton@gmail.com',
        timestamp: 1578937310,
        timezoneOffset: 300,
      },
      oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
      note: 'This is a note about a commit.',
    })
    // Test
    let error = null
    try {
      await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
        note: 'This is a note about a commit.',
      })
    } catch (err) {
      error = err
    }
    expect(error).not.toBeNull()
    expect(error instanceof Errors.AlreadyExistsError).toBe(true)
  })",steel
/__tests__/test-addNote.js,Magic Number,"{'line': 118, 'column': 31, 'index': 3630}","it('consecutive notes accumulate', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-addNote')
    // Test
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
        note: 'This is a note about a commit.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(1)
    }
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: '199948939a0b95c6f27668689102496574b2c332',
        note: 'This is a note about a tree.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(2)
    }
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: '68aba62e560c0ebc3396e8ae9335232cd93a3f60',
        note: 'This is a note about a blob.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(3)
    }
  })",steel
/__tests__/test-addNote.js,Magic Number,"{'line': 134, 'column': 31, 'index': 4075}","it('consecutive notes accumulate', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-addNote')
    // Test
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
        note: 'This is a note about a commit.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(1)
    }
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: '199948939a0b95c6f27668689102496574b2c332',
        note: 'This is a note about a tree.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(2)
    }
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: '68aba62e560c0ebc3396e8ae9335232cd93a3f60',
        note: 'This is a note about a blob.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(3)
    }
  })",steel
/__tests__/test-addNote.js,Magic Number,"{'line': 150, 'column': 31, 'index': 4520}","it('consecutive notes accumulate', async () => {
    // Setup
    const { fs, gitdir } = await makeFixture('test-addNote')
    // Test
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: 'f6d51b1f9a449079f6999be1fb249c359511f164',
        note: 'This is a note about a commit.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(1)
    }
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: '199948939a0b95c6f27668689102496574b2c332',
        note: 'This is a note about a tree.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(2)
    }
    {
      const oid = await addNote({
        fs,
        gitdir,
        author: {
          name: 'William Hilton',
          email: 'wmhilton@gmail.com',
          timestamp: 1578937310,
          timezoneOffset: 300,
        },
        oid: '68aba62e560c0ebc3396e8ae9335232cd93a3f60',
        note: 'This is a note about a blob.',
      })
      const { tree } = await readTree({ fs, gitdir, oid })
      expect(tree.length).toBe(3)
    }
  })",steel
/__tests__/test-add.js,Conditional Test Logic,"{'line': 140, 'column': 4, 'index': 4154}","it('symlink', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // it's not currently possible to tests symlinks in the browser since there's no way to create them
    const symlinkCreated = await writeSymlink(fs, dir)
      .then(() => true)
      .catch(() => false)
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'c/e.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    if (!symlinkCreated) return
    await add({ fs, dir, filepath: 'e-link.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    const walkResult = await walk({
      fs,
      dir,
      trees: [STAGE()],
      map: async (filepath, [stage]) =>
        filepath === 'e-link.txt' && stage ? stage.oid() : undefined,
    })
    expect(walkResult.length).toEqual(1)
    const oid = walkResult[0]
    const { blob: symlinkTarget } = await readBlob({ fs, dir, oid })
    let symlinkTargetStr = Buffer.from(symlinkTarget).toString('utf8')
    if (symlinkTargetStr.startsWith('./')) {
      symlinkTargetStr = symlinkTargetStr.substr(2)
    }
    expect(symlinkTargetStr).toEqual('c/e.txt')
  })",steel
/__tests__/test-add.js,Conditional Test Logic,"{'line': 154, 'column': 4, 'index': 4707}","it('symlink', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // it's not currently possible to tests symlinks in the browser since there's no way to create them
    const symlinkCreated = await writeSymlink(fs, dir)
      .then(() => true)
      .catch(() => false)
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'c/e.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    if (!symlinkCreated) return
    await add({ fs, dir, filepath: 'e-link.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    const walkResult = await walk({
      fs,
      dir,
      trees: [STAGE()],
      map: async (filepath, [stage]) =>
        filepath === 'e-link.txt' && stage ? stage.oid() : undefined,
    })
    expect(walkResult.length).toEqual(1)
    const oid = walkResult[0]
    const { blob: symlinkTarget } = await readBlob({ fs, dir, oid })
    let symlinkTargetStr = Buffer.from(symlinkTarget).toString('utf8')
    if (symlinkTargetStr.startsWith('./')) {
      symlinkTargetStr = symlinkTargetStr.substr(2)
    }
    expect(symlinkTargetStr).toEqual('c/e.txt')
  })",steel
/__tests__/test-add.js,Duplicate Assert,"{'line': 33, 'column': 4, 'index': 893}","it('file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a-copy.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    await add({ fs, dir, filepath: 'b.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(3)
  })",steel
/__tests__/test-add.js,Duplicate Assert,"{'line': 33, 'column': 4, 'index': 893}","it('file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a-copy.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    await add({ fs, dir, filepath: 'b.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(3)
  })",steel
/__tests__/test-add.js,Duplicate Assert,"{'line': 35, 'column': 4, 'index': 1000}","it('file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a-copy.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    await add({ fs, dir, filepath: 'b.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(3)
  })",steel
/__tests__/test-add.js,Duplicate Assert,"{'line': 35, 'column': 4, 'index': 1000}","it('file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a-copy.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    await add({ fs, dir, filepath: 'b.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(3)
  })",steel
/__tests__/test-add.js,Duplicate Assert,"{'line': 37, 'column': 4, 'index': 1112}","it('file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a-copy.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    await add({ fs, dir, filepath: 'b.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(3)
  })",steel
/__tests__/test-add.js,Duplicate Assert,"{'line': 39, 'column': 4, 'index': 1219}","it('file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a-copy.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    await add({ fs, dir, filepath: 'b.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(3)
  })",steel
/__tests__/test-add.js,Duplicate Assert,"{'line': 139, 'column': 4, 'index': 4093}","it('symlink', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // it's not currently possible to tests symlinks in the browser since there's no way to create them
    const symlinkCreated = await writeSymlink(fs, dir)
      .then(() => true)
      .catch(() => false)
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'c/e.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    if (!symlinkCreated) return
    await add({ fs, dir, filepath: 'e-link.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    const walkResult = await walk({
      fs,
      dir,
      trees: [STAGE()],
      map: async (filepath, [stage]) =>
        filepath === 'e-link.txt' && stage ? stage.oid() : undefined,
    })
    expect(walkResult.length).toEqual(1)
    const oid = walkResult[0]
    const { blob: symlinkTarget } = await readBlob({ fs, dir, oid })
    let symlinkTargetStr = Buffer.from(symlinkTarget).toString('utf8')
    if (symlinkTargetStr.startsWith('./')) {
      symlinkTargetStr = symlinkTargetStr.substr(2)
    }
    expect(symlinkTargetStr).toEqual('c/e.txt')
  })",steel
/__tests__/test-add.js,Duplicate Assert,"{'line': 142, 'column': 4, 'index': 4237}","it('symlink', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // it's not currently possible to tests symlinks in the browser since there's no way to create them
    const symlinkCreated = await writeSymlink(fs, dir)
      .then(() => true)
      .catch(() => false)
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'c/e.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    if (!symlinkCreated) return
    await add({ fs, dir, filepath: 'e-link.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    const walkResult = await walk({
      fs,
      dir,
      trees: [STAGE()],
      map: async (filepath, [stage]) =>
        filepath === 'e-link.txt' && stage ? stage.oid() : undefined,
    })
    expect(walkResult.length).toEqual(1)
    const oid = walkResult[0]
    const { blob: symlinkTarget } = await readBlob({ fs, dir, oid })
    let symlinkTargetStr = Buffer.from(symlinkTarget).toString('utf8')
    if (symlinkTargetStr.startsWith('./')) {
      symlinkTargetStr = symlinkTargetStr.substr(2)
    }
    expect(symlinkTargetStr).toEqual('c/e.txt')
  })",steel
/__tests__/test-add.js,Duplicate Assert,"{'line': 195, 'column': 4, 'index': 5920}","it('folder', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: 'c' })
    expect((await listFiles({ fs, dir })).length).toEqual(4)
  })",steel
/__tests__/test-add.js,Duplicate Assert,"{'line': 197, 'column': 4, 'index': 6023}","it('folder', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: 'c' })
    expect((await listFiles({ fs, dir })).length).toEqual(4)
  })",steel
/__tests__/test-add.js,Duplicate Assert,"{'line': 205, 'column': 4, 'index': 6275}","it('folder with .gitignore', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: 'c' })
    expect((await listFiles({ fs, dir })).length).toEqual(3)
  })",steel
/__tests__/test-add.js,Duplicate Assert,"{'line': 207, 'column': 4, 'index': 6378}","it('folder with .gitignore', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: 'c' })
    expect((await listFiles({ fs, dir })).length).toEqual(3)
  })",steel
/__tests__/test-add.js,Duplicate Assert,"{'line': 215, 'column': 4, 'index': 6640}","it('folder with .gitignore and force', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: 'c', force: true })
    expect((await listFiles({ fs, dir })).length).toEqual(4)
  })",steel
/__tests__/test-add.js,Duplicate Assert,"{'line': 217, 'column': 4, 'index': 6756}","it('folder with .gitignore and force', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: 'c', force: true })
    expect((await listFiles({ fs, dir })).length).toEqual(4)
  })",steel
/__tests__/test-add.js,Duplicate Assert,"{'line': 225, 'column': 4, 'index': 6995}","it('git add .', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: '.' })
    expect((await listFiles({ fs, dir })).length).toEqual(7)
  })",steel
/__tests__/test-add.js,Duplicate Assert,"{'line': 227, 'column': 4, 'index': 7098}","it('git add .', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: '.' })
    expect((await listFiles({ fs, dir })).length).toEqual(7)
  })",steel
/__tests__/test-add.js,Duplicate Assert,"{'line': 235, 'column': 4, 'index': 7357}","it('git add . with parallel=false', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: '.', parallel: false })
    expect((await listFiles({ fs, dir })).length).toEqual(7)
  })",steel
/__tests__/test-add.js,Duplicate Assert,"{'line': 237, 'column': 4, 'index': 7477}","it('git add . with parallel=false', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: '.', parallel: false })
    expect((await listFiles({ fs, dir })).length).toEqual(7)
  })",steel
/__tests__/test-add.js,Exception Handling,"{'line': 68, 'column': 4, 'index': 2108}","it('multiple files with one failure (normal error)', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    let err = null
    try {
      await add({ fs, dir, filepath: ['a.txt', 'a-copy.txt', 'non-existent'] })
    } catch (e) {
      err = e
    }
    expect(err.caller).toEqual('git.add')
    expect(err.name).toEqual('NotFoundError')
  })",steel
/__tests__/test-add.js,Exception Handling,"{'line': 84, 'column': 4, 'index': 2582}","it('multiple files with 2 failures (MultipleGitError) and an ignored file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)

    // Test
    await init({ fs, dir })
    let err = null
    try {
      await add({
        fs,
        dir,
        filepath: ['a.txt', 'i.txt', 'non-existent', 'also-non-existent'],
      })
    } catch (e) {
      err = e
    }
    expect(err.caller).toEqual('git.add')
    expect(err.name).toEqual('MultipleGitError')
    expect(err.errors.length).toEqual(2)
    err.errors.forEach(e => {
      expect(e.name).toEqual('NotFoundError')
    })
  })",steel
/__tests__/test-add.js,Exception Handling,"{'line': 183, 'column': 4, 'index': 5638}","it('non-existant file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    let err = null
    try {
      await add({ fs, dir, filepath: 'asdf.txt' })
    } catch (e) {
      err = e
    }
    expect(err.caller).toEqual('git.add')
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 33, 'column': 58, 'index': 947}","it('file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a-copy.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    await add({ fs, dir, filepath: 'b.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(3)
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 35, 'column': 58, 'index': 1054}","it('file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a-copy.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    await add({ fs, dir, filepath: 'b.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(3)
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 37, 'column': 58, 'index': 1166}","it('file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a-copy.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    await add({ fs, dir, filepath: 'b.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(3)
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 39, 'column': 58, 'index': 1273}","it('file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    await add({ fs, dir, filepath: 'a-copy.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    await add({ fs, dir, filepath: 'b.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(3)
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 47, 'column': 58, 'index': 1554}","it('multiple files', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: ['a.txt', 'a-copy.txt', 'b.txt'] })
    expect((await listFiles({ fs, dir })).length).toEqual(3)
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 60, 'column': 58, 'index': 1901}","it('multiple files with parallel=false', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    await add({
      fs,
      dir,
      filepath: ['a.txt', 'a-copy.txt', 'b.txt'],
      parallel: false,
    })
    expect((await listFiles({ fs, dir })).length).toEqual(3)
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 95, 'column': 38, 'index': 2882}","it('multiple files with 2 failures (MultipleGitError) and an ignored file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)

    // Test
    await init({ fs, dir })
    let err = null
    try {
      await add({
        fs,
        dir,
        filepath: ['a.txt', 'i.txt', 'non-existent', 'also-non-existent'],
      })
    } catch (e) {
      err = e
    }
    expect(err.caller).toEqual('git.add')
    expect(err.name).toEqual('MultipleGitError')
    expect(err.errors.length).toEqual(2)
    err.errors.forEach(e => {
      expect(e.name).toEqual('NotFoundError')
    })
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 126, 'column': 58, 'index': 3618}","it('multiple files with 1 ignored and force:true', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)

    // Test
    await init({ fs, dir })
    await add({
      fs,
      dir,
      filepath: ['a.txt', 'i.txt'],
      force: true,
    })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    expect(await listFiles({ fs, dir })).toEqual(['a.txt', 'i.txt'])
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 139, 'column': 58, 'index': 4147}","it('symlink', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // it's not currently possible to tests symlinks in the browser since there's no way to create them
    const symlinkCreated = await writeSymlink(fs, dir)
      .then(() => true)
      .catch(() => false)
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'c/e.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    if (!symlinkCreated) return
    await add({ fs, dir, filepath: 'e-link.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    const walkResult = await walk({
      fs,
      dir,
      trees: [STAGE()],
      map: async (filepath, [stage]) =>
        filepath === 'e-link.txt' && stage ? stage.oid() : undefined,
    })
    expect(walkResult.length).toEqual(1)
    const oid = walkResult[0]
    const { blob: symlinkTarget } = await readBlob({ fs, dir, oid })
    let symlinkTargetStr = Buffer.from(symlinkTarget).toString('utf8')
    if (symlinkTargetStr.startsWith('./')) {
      symlinkTargetStr = symlinkTargetStr.substr(2)
    }
    expect(symlinkTargetStr).toEqual('c/e.txt')
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 142, 'column': 58, 'index': 4291}","it('symlink', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // it's not currently possible to tests symlinks in the browser since there's no way to create them
    const symlinkCreated = await writeSymlink(fs, dir)
      .then(() => true)
      .catch(() => false)
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'c/e.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    if (!symlinkCreated) return
    await add({ fs, dir, filepath: 'e-link.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    const walkResult = await walk({
      fs,
      dir,
      trees: [STAGE()],
      map: async (filepath, [stage]) =>
        filepath === 'e-link.txt' && stage ? stage.oid() : undefined,
    })
    expect(walkResult.length).toEqual(1)
    const oid = walkResult[0]
    const { blob: symlinkTarget } = await readBlob({ fs, dir, oid })
    let symlinkTargetStr = Buffer.from(symlinkTarget).toString('utf8')
    if (symlinkTargetStr.startsWith('./')) {
      symlinkTargetStr = symlinkTargetStr.substr(2)
    }
    expect(symlinkTargetStr).toEqual('c/e.txt')
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 150, 'column': 38, 'index': 4530}","it('symlink', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // it's not currently possible to tests symlinks in the browser since there's no way to create them
    const symlinkCreated = await writeSymlink(fs, dir)
      .then(() => true)
      .catch(() => false)
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'c/e.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
    if (!symlinkCreated) return
    await add({ fs, dir, filepath: 'e-link.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(2)
    const walkResult = await walk({
      fs,
      dir,
      trees: [STAGE()],
      map: async (filepath, [stage]) =>
        filepath === 'e-link.txt' && stage ? stage.oid() : undefined,
    })
    expect(walkResult.length).toEqual(1)
    const oid = walkResult[0]
    const { blob: symlinkTarget } = await readBlob({ fs, dir, oid })
    let symlinkTargetStr = Buffer.from(symlinkTarget).toString('utf8')
    if (symlinkTargetStr.startsWith('./')) {
      symlinkTargetStr = symlinkTargetStr.substr(2)
    }
    expect(symlinkTargetStr).toEqual('c/e.txt')
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 166, 'column': 58, 'index': 5139}","it('ignored file', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'i.txt' })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 175, 'column': 58, 'index': 5460}","it('ignored file but with force=true', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    await add({ fs, dir, filepath: 'i.txt', force: true })
    expect((await listFiles({ fs, dir })).length).toEqual(1)
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 195, 'column': 58, 'index': 5974}","it('folder', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: 'c' })
    expect((await listFiles({ fs, dir })).length).toEqual(4)
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 197, 'column': 58, 'index': 6077}","it('folder', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: 'c' })
    expect((await listFiles({ fs, dir })).length).toEqual(4)
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 205, 'column': 58, 'index': 6329}","it('folder with .gitignore', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: 'c' })
    expect((await listFiles({ fs, dir })).length).toEqual(3)
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 207, 'column': 58, 'index': 6432}","it('folder with .gitignore', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: 'c' })
    expect((await listFiles({ fs, dir })).length).toEqual(3)
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 215, 'column': 58, 'index': 6694}","it('folder with .gitignore and force', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: 'c', force: true })
    expect((await listFiles({ fs, dir })).length).toEqual(4)
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 217, 'column': 58, 'index': 6810}","it('folder with .gitignore and force', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: 'c', force: true })
    expect((await listFiles({ fs, dir })).length).toEqual(4)
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 225, 'column': 58, 'index': 7049}","it('git add .', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: '.' })
    expect((await listFiles({ fs, dir })).length).toEqual(7)
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 227, 'column': 58, 'index': 7152}","it('git add .', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: '.' })
    expect((await listFiles({ fs, dir })).length).toEqual(7)
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 235, 'column': 58, 'index': 7411}","it('git add . with parallel=false', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: '.', parallel: false })
    expect((await listFiles({ fs, dir })).length).toEqual(7)
  })",steel
/__tests__/test-add.js,Magic Number,"{'line': 237, 'column': 58, 'index': 7531}","it('git add . with parallel=false', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)
    // Test
    await init({ fs, dir })
    expect((await listFiles({ fs, dir })).length).toEqual(0)
    await add({ fs, dir, filepath: '.', parallel: false })
    expect((await listFiles({ fs, dir })).length).toEqual(7)
  })",steel
/__tests__/test-add.js,Unknown Test,"{'column': 2, 'line': 100}","it('multiple files with 1 ignored', async () => {
    // Setup
    const { fs, dir } = await makeFixture('test-add')
    await writeGitIgnore(fs, dir)

    // Test
    await init({ fs, dir })
    await add({
      fs,
      dir,
      filepath: ['a.txt', 'i.txt'],
    })
  })",steel
/__tests__/test-abortMerge.js,Conditional Test Logic,"{'line': 148, 'column': 8, 'index': 3966}","it('abort merge without touching anything', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await abortMerge({ fs, dir, gitdir })

    const trees = [TREE({ ref: 'HEAD' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (path === '.') return

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)

        // only since we didn't touch anything
        expect(await modified(workdir, head)).toBe(false)

        expect(await modified(index, workdir)).toBe(false)
      },
    })
  })",steel
/__tests__/test-abortMerge.js,Conditional Test Logic,"{'line': 150, 'column': 8, 'index': 4000}","it('abort merge without touching anything', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await abortMerge({ fs, dir, gitdir })

    const trees = [TREE({ ref: 'HEAD' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (path === '.') return

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)

        // only since we didn't touch anything
        expect(await modified(workdir, head)).toBe(false)

        expect(await modified(index, workdir)).toBe(false)
      },
    })
  })",steel
/__tests__/test-abortMerge.js,Conditional Test Logic,"{'line': 207, 'column': 8, 'index': 5487}","it('abort merge after modifying files in a directory', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'c',
        theirs: 'd',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.rm(`${dir}/a/a`)
    await fs.rmdir(`${dir}/a`)
    await fs.write(`${dir}/b/b`, 'new text for file b')
    await fs.write(`${dir}/c/c`, 'new text for file c')

    await abortMerge({ fs, dir, gitdir, commit: 'c' })

    const trees = [TREE({ ref: 'c' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (head && (await head.type()) === 'tree') return

        if (path === 'b') {
          expect(await modified(workdir, head)).toBe(false)
          expect(await modified(workdir, index)).toBe(false)
        }

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)
      },
    })
    const fileCContent = new TextDecoder().decode(await fs.read(`${dir}/c/c`))
    const fileBContent = new TextDecoder().decode(await fs.read(`${dir}/b/b`))
    expect(fileCContent).toEqual('new text for file c')
    expect(fileBContent).not.toEqual('new text for file b')
  })",steel
/__tests__/test-abortMerge.js,Conditional Test Logic,"{'line': 209, 'column': 8, 'index': 5547}","it('abort merge after modifying files in a directory', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'c',
        theirs: 'd',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.rm(`${dir}/a/a`)
    await fs.rmdir(`${dir}/a`)
    await fs.write(`${dir}/b/b`, 'new text for file b')
    await fs.write(`${dir}/c/c`, 'new text for file c')

    await abortMerge({ fs, dir, gitdir, commit: 'c' })

    const trees = [TREE({ ref: 'c' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (head && (await head.type()) === 'tree') return

        if (path === 'b') {
          expect(await modified(workdir, head)).toBe(false)
          expect(await modified(workdir, index)).toBe(false)
        }

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)
      },
    })
    const fileCContent = new TextDecoder().decode(await fs.read(`${dir}/c/c`))
    const fileBContent = new TextDecoder().decode(await fs.read(`${dir}/b/b`))
    expect(fileCContent).toEqual('new text for file c')
    expect(fileBContent).not.toEqual('new text for file b')
  })",steel
/__tests__/test-abortMerge.js,Conditional Test Logic,"{'line': 214, 'column': 8, 'index': 5707}","it('abort merge after modifying files in a directory', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'c',
        theirs: 'd',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.rm(`${dir}/a/a`)
    await fs.rmdir(`${dir}/a`)
    await fs.write(`${dir}/b/b`, 'new text for file b')
    await fs.write(`${dir}/c/c`, 'new text for file c')

    await abortMerge({ fs, dir, gitdir, commit: 'c' })

    const trees = [TREE({ ref: 'c' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (head && (await head.type()) === 'tree') return

        if (path === 'b') {
          expect(await modified(workdir, head)).toBe(false)
          expect(await modified(workdir, index)).toBe(false)
        }

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)
      },
    })
    const fileCContent = new TextDecoder().decode(await fs.read(`${dir}/c/c`))
    const fileBContent = new TextDecoder().decode(await fs.read(`${dir}/b/b`))
    expect(fileCContent).toEqual('new text for file c')
    expect(fileBContent).not.toEqual('new text for file b')
  })",steel
/__tests__/test-abortMerge.js,Conditional Test Logic,"{'line': 269, 'column': 8, 'index': 7240}","it('abort merge after modifying files', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.rm(`${dir}/a`)
    await fs.write(`${dir}/b`, 'new text for file b')
    await fs.write(`${dir}/c`, 'new text for file c')

    await abortMerge({ fs, dir, gitdir })

    const trees = [TREE({ ref: 'HEAD' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (path === '.') return

        if (path === 'b') {
          expect(await modified(workdir, head)).toBe(false)
          expect(await modified(workdir, index)).toBe(false)
        }

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)
      },
    })
    const fileCContent = new TextDecoder().decode(await fs.read(`${dir}/c`))
    const fileBContent = new TextDecoder().decode(await fs.read(`${dir}/b`))
    expect(fileCContent).toEqual('new text for file c')
    expect(fileBContent).not.toEqual('new text for file b')
  })",steel
/__tests__/test-abortMerge.js,Conditional Test Logic,"{'line': 271, 'column': 8, 'index': 7274}","it('abort merge after modifying files', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.rm(`${dir}/a`)
    await fs.write(`${dir}/b`, 'new text for file b')
    await fs.write(`${dir}/c`, 'new text for file c')

    await abortMerge({ fs, dir, gitdir })

    const trees = [TREE({ ref: 'HEAD' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (path === '.') return

        if (path === 'b') {
          expect(await modified(workdir, head)).toBe(false)
          expect(await modified(workdir, index)).toBe(false)
        }

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)
      },
    })
    const fileCContent = new TextDecoder().decode(await fs.read(`${dir}/c`))
    const fileBContent = new TextDecoder().decode(await fs.read(`${dir}/b`))
    expect(fileCContent).toEqual('new text for file c')
    expect(fileBContent).not.toEqual('new text for file b')
  })",steel
/__tests__/test-abortMerge.js,Conditional Test Logic,"{'line': 276, 'column': 8, 'index': 7434}","it('abort merge after modifying files', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.rm(`${dir}/a`)
    await fs.write(`${dir}/b`, 'new text for file b')
    await fs.write(`${dir}/c`, 'new text for file c')

    await abortMerge({ fs, dir, gitdir })

    const trees = [TREE({ ref: 'HEAD' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (path === '.') return

        if (path === 'b') {
          expect(await modified(workdir, head)).toBe(false)
          expect(await modified(workdir, index)).toBe(false)
        }

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)
      },
    })
    const fileCContent = new TextDecoder().decode(await fs.read(`${dir}/c`))
    const fileBContent = new TextDecoder().decode(await fs.read(`${dir}/b`))
    expect(fileCContent).toEqual('new text for file c')
    expect(fileBContent).not.toEqual('new text for file b')
  })",steel
/__tests__/test-abortMerge.js,Duplicate Assert,"{'line': 67, 'column': 6, 'index': 1897}","it('write conflicted files to index at different stages', async () => {
    // Setup
    const { gitdir, dir, fs } = await makeFixture('test-abortMerge')

    const branchA = await resolveRef({ fs, gitdir, ref: 'a' })
    const branchB = await resolveRef({ fs, gitdir, ref: 'b' })
    const ancestor = '2d7b1a9b82e52bd8648cf156aa559eff3a27a678' // common ancestor, hard coded, not ideal

    const fileAVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'a' }),
    ]

    const fileBVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'b' }),
    ]

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
      const fileAStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[3].oid,
        }),
      ]
      const fileBStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[3].oid,
        }),
      ]
      expect(fileAVersions).toEqual(fileAStages)
      expect(fileBVersions).toEqual(fileBStages)
    })
  })",steel
/__tests__/test-abortMerge.js,Duplicate Assert,"{'line': 68, 'column': 6, 'index': 1946}","it('write conflicted files to index at different stages', async () => {
    // Setup
    const { gitdir, dir, fs } = await makeFixture('test-abortMerge')

    const branchA = await resolveRef({ fs, gitdir, ref: 'a' })
    const branchB = await resolveRef({ fs, gitdir, ref: 'b' })
    const ancestor = '2d7b1a9b82e52bd8648cf156aa559eff3a27a678' // common ancestor, hard coded, not ideal

    const fileAVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'a' }),
    ]

    const fileBVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'b' }),
    ]

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
      const fileAStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[3].oid,
        }),
      ]
      const fileBStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[3].oid,
        }),
      ]
      expect(fileAVersions).toEqual(fileAStages)
      expect(fileBVersions).toEqual(fileBStages)
    })
  })",steel
/__tests__/test-abortMerge.js,Duplicate Assert,"{'line': 315, 'column': 4, 'index': 8530}","it('uncache a file that has changes in the workdir (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    fs.write(`${dir}/c`, 'new changes to file c')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      index.delete({ filepath: 'c' })
    })

    const fileAWorkdirVersion = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual(fileAWorkdirVersion)
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",steel
/__tests__/test-abortMerge.js,Duplicate Assert,"{'line': 315, 'column': 4, 'index': 8530}","it('uncache a file that has changes in the workdir (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    fs.write(`${dir}/c`, 'new changes to file c')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      index.delete({ filepath: 'c' })
    })

    const fileAWorkdirVersion = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual(fileAWorkdirVersion)
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",steel
/__tests__/test-abortMerge.js,Duplicate Assert,"{'line': 316, 'column': 4, 'index': 8563}","it('uncache a file that has changes in the workdir (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    fs.write(`${dir}/c`, 'new changes to file c')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      index.delete({ filepath: 'c' })
    })

    const fileAWorkdirVersion = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual(fileAWorkdirVersion)
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",steel
/__tests__/test-abortMerge.js,Duplicate Assert,"{'line': 341, 'column': 4, 'index': 9252}","it('uncache a file that has changes in the workdir (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    fs.write(`${dir}/c`, 'new changes to file c')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      index.delete({ filepath: 'c' })
    })

    const fileAWorkdirVersion = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual(fileAWorkdirVersion)
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",steel
/__tests__/test-abortMerge.js,Duplicate Assert,"{'line': 341, 'column': 4, 'index': 9252}","it('uncache a file that has changes in the workdir (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    fs.write(`${dir}/c`, 'new changes to file c')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      index.delete({ filepath: 'c' })
    })

    const fileAWorkdirVersion = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual(fileAWorkdirVersion)
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",steel
/__tests__/test-abortMerge.js,Duplicate Assert,"{'line': 342, 'column': 4, 'index': 9285}","it('uncache a file that has changes in the workdir (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    fs.write(`${dir}/c`, 'new changes to file c')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      index.delete({ filepath: 'c' })
    })

    const fileAWorkdirVersion = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual(fileAWorkdirVersion)
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",steel
/__tests__/test-abortMerge.js,Duplicate Assert,"{'line': 387, 'column': 4, 'index': 10499}","it('workdir != index && index != head [stage a file and them modify in workdir] (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.write(`${dir}/a`, 'text that is in the index')
    await add({ fs, dir, gitdir, filepath: 'a' })
    await fs.write(`${dir}/a`, 'text that is in the workdir')

    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual('text that is in the workdir')
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",steel
/__tests__/test-abortMerge.js,Duplicate Assert,"{'line': 387, 'column': 4, 'index': 10499}","it('workdir != index && index != head [stage a file and them modify in workdir] (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.write(`${dir}/a`, 'text that is in the index')
    await add({ fs, dir, gitdir, filepath: 'a' })
    await fs.write(`${dir}/a`, 'text that is in the workdir')

    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual('text that is in the workdir')
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",steel
/__tests__/test-abortMerge.js,Duplicate Assert,"{'line': 388, 'column': 4, 'index': 10532}","it('workdir != index && index != head [stage a file and them modify in workdir] (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.write(`${dir}/a`, 'text that is in the index')
    await add({ fs, dir, gitdir, filepath: 'a' })
    await fs.write(`${dir}/a`, 'text that is in the workdir')

    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual('text that is in the workdir')
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",steel
/__tests__/test-abortMerge.js,Duplicate Assert,"{'line': 407, 'column': 4, 'index': 11088}","it('workdir != index && index != head [stage a file and them modify in workdir] (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.write(`${dir}/a`, 'text that is in the index')
    await add({ fs, dir, gitdir, filepath: 'a' })
    await fs.write(`${dir}/a`, 'text that is in the workdir')

    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual('text that is in the workdir')
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",steel
/__tests__/test-abortMerge.js,Duplicate Assert,"{'line': 407, 'column': 4, 'index': 11088}","it('workdir != index && index != head [stage a file and them modify in workdir] (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.write(`${dir}/a`, 'text that is in the index')
    await add({ fs, dir, gitdir, filepath: 'a' })
    await fs.write(`${dir}/a`, 'text that is in the workdir')

    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual('text that is in the workdir')
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",steel
/__tests__/test-abortMerge.js,Duplicate Assert,"{'line': 408, 'column': 4, 'index': 11121}","it('workdir != index && index != head [stage a file and them modify in workdir] (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.write(`${dir}/a`, 'text that is in the index')
    await add({ fs, dir, gitdir, filepath: 'a' })
    await fs.write(`${dir}/a`, 'text that is in the workdir')

    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual('text that is in the workdir')
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",steel
/__tests__/test-abortMerge.js,Exception Handling,"{'line': 41, 'column': 4, 'index': 1254}","it('write conflicted files to index at different stages', async () => {
    // Setup
    const { gitdir, dir, fs } = await makeFixture('test-abortMerge')

    const branchA = await resolveRef({ fs, gitdir, ref: 'a' })
    const branchB = await resolveRef({ fs, gitdir, ref: 'b' })
    const ancestor = '2d7b1a9b82e52bd8648cf156aa559eff3a27a678' // common ancestor, hard coded, not ideal

    const fileAVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'a' }),
    ]

    const fileBVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'b' }),
    ]

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
      const fileAStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[3].oid,
        }),
      ]
      const fileBStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[3].oid,
        }),
      ]
      expect(fileAVersions).toEqual(fileAStages)
      expect(fileBVersions).toEqual(fileBStages)
    })
  })",steel
/__tests__/test-abortMerge.js,Exception Handling,"{'line': 117, 'column': 4, 'index': 3288}","it('abort merge without touching anything', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await abortMerge({ fs, dir, gitdir })

    const trees = [TREE({ ref: 'HEAD' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (path === '.') return

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)

        // only since we didn't touch anything
        expect(await modified(workdir, head)).toBe(false)

        expect(await modified(index, workdir)).toBe(false)
      },
    })
  })",steel
/__tests__/test-abortMerge.js,Exception Handling,"{'line': 171, 'column': 4, 'index': 4625}","it('abort merge after modifying files in a directory', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'c',
        theirs: 'd',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.rm(`${dir}/a/a`)
    await fs.rmdir(`${dir}/a`)
    await fs.write(`${dir}/b/b`, 'new text for file b')
    await fs.write(`${dir}/c/c`, 'new text for file c')

    await abortMerge({ fs, dir, gitdir, commit: 'c' })

    const trees = [TREE({ ref: 'c' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (head && (await head.type()) === 'tree') return

        if (path === 'b') {
          expect(await modified(workdir, head)).toBe(false)
          expect(await modified(workdir, index)).toBe(false)
        }

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)
      },
    })
    const fileCContent = new TextDecoder().decode(await fs.read(`${dir}/c/c`))
    const fileBContent = new TextDecoder().decode(await fs.read(`${dir}/b/b`))
    expect(fileCContent).toEqual('new text for file c')
    expect(fileBContent).not.toEqual('new text for file b')
  })",steel
/__tests__/test-abortMerge.js,Exception Handling,"{'line': 234, 'column': 4, 'index': 6425}","it('abort merge after modifying files', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.rm(`${dir}/a`)
    await fs.write(`${dir}/b`, 'new text for file b')
    await fs.write(`${dir}/c`, 'new text for file c')

    await abortMerge({ fs, dir, gitdir })

    const trees = [TREE({ ref: 'HEAD' }), WORKDIR(), STAGE()]
    await walk({
      fs,
      dir,
      gitdir,
      trees,
      map: async function(path, [head, workdir, index]) {
        if (path === '.') return

        if (path === 'b') {
          expect(await modified(workdir, head)).toBe(false)
          expect(await modified(workdir, index)).toBe(false)
        }

        if (head && index) {
          expect([path, await head.mode()]).toEqual([path, await index.mode()])
          expect([path, await head.oid()]).toEqual([path, await index.oid()])
        }

        expect(await modified(index, head)).toBe(false)
      },
    })
    const fileCContent = new TextDecoder().decode(await fs.read(`${dir}/c`))
    const fileBContent = new TextDecoder().decode(await fs.read(`${dir}/b`))
    expect(fileCContent).toEqual('new text for file c')
    expect(fileBContent).not.toEqual('new text for file b')
  })",steel
/__tests__/test-abortMerge.js,Exception Handling,"{'line': 296, 'column': 4, 'index': 8178}","it('uncache a file that has changes in the workdir (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    fs.write(`${dir}/c`, 'new changes to file c')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      index.delete({ filepath: 'c' })
    })

    const fileAWorkdirVersion = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual(fileAWorkdirVersion)
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",steel
/__tests__/test-abortMerge.js,Exception Handling,"{'line': 335, 'column': 4, 'index': 9157}","it('uncache a file that has changes in the workdir (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    fs.write(`${dir}/c`, 'new changes to file c')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      index.delete({ filepath: 'c' })
    })

    const fileAWorkdirVersion = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual(fileAWorkdirVersion)
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",steel
/__tests__/test-abortMerge.js,Exception Handling,"{'line': 368, 'column': 4, 'index': 10147}","it('workdir != index && index != head [stage a file and them modify in workdir] (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.write(`${dir}/a`, 'text that is in the index')
    await add({ fs, dir, gitdir, filepath: 'a' })
    await fs.write(`${dir}/a`, 'text that is in the workdir')

    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual('text that is in the workdir')
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",steel
/__tests__/test-abortMerge.js,Exception Handling,"{'line': 401, 'column': 4, 'index': 10993}","it('workdir != index && index != head [stage a file and them modify in workdir] (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.write(`${dir}/a`, 'text that is in the index')
    await add({ fs, dir, gitdir, filepath: 'a' })
    await fs.write(`${dir}/a`, 'text that is in the workdir')

    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual('text that is in the workdir')
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",steel
/__tests__/test-abortMerge.js,Exception Handling,"{'line': 453, 'column': 4, 'index': 12399}","it('workdir != index && index === head (keep our changes)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    const head = await resolveRef({ fs, gitdir, ref: 'HEAD' })

    const fileAHeadVersion = await readBlob({
      fs,
      gitdir,
      oid: head,
      filepath: 'a',
    }).then(result => {
      return new TextDecoder().decode(result.blob)
    })
    const fileBHeadVersion = await readBlob({
      fs,
      gitdir,
      oid: head,
      filepath: 'b',
    }).then(result => {
      return new TextDecoder().decode(result.blob)
    })

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.write(`${dir}/c`, 'new text for file c')
    await abortMerge({ fs, dir, gitdir })

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual(fileAHeadVersion)
    expect(fileBContent).toEqual(fileBHeadVersion)
    expect(fileCContent).toEqual('new text for file c')
  })",steel
/__tests__/test-abortMerge.js,Magic Number,"{'line': 65, 'column': 49, 'index': 1841}","it('write conflicted files to index at different stages', async () => {
    // Setup
    const { gitdir, dir, fs } = await makeFixture('test-abortMerge')

    const branchA = await resolveRef({ fs, gitdir, ref: 'a' })
    const branchB = await resolveRef({ fs, gitdir, ref: 'b' })
    const ancestor = '2d7b1a9b82e52bd8648cf156aa559eff3a27a678' // common ancestor, hard coded, not ideal

    const fileAVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'a' }),
    ]

    const fileBVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'b' }),
    ]

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
      const fileAStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[3].oid,
        }),
      ]
      const fileBStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[3].oid,
        }),
      ]
      expect(fileAVersions).toEqual(fileAStages)
      expect(fileBVersions).toEqual(fileBStages)
    })
  })",steel
/__tests__/test-abortMerge.js,Magic Number,"{'line': 66, 'column': 44, 'index': 1888}","it('write conflicted files to index at different stages', async () => {
    // Setup
    const { gitdir, dir, fs } = await makeFixture('test-abortMerge')

    const branchA = await resolveRef({ fs, gitdir, ref: 'a' })
    const branchB = await resolveRef({ fs, gitdir, ref: 'b' })
    const ancestor = '2d7b1a9b82e52bd8648cf156aa559eff3a27a678' // common ancestor, hard coded, not ideal

    const fileAVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'a' }),
    ]

    const fileBVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'b' }),
    ]

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
      const fileAStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[3].oid,
        }),
      ]
      const fileBStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[3].oid,
        }),
      ]
      expect(fileAVersions).toEqual(fileAStages)
      expect(fileBVersions).toEqual(fileBStages)
    })
  })",steel
/__tests__/test-abortMerge.js,Magic Number,"{'line': 69, 'column': 59, 'index': 2048}","it('write conflicted files to index at different stages', async () => {
    // Setup
    const { gitdir, dir, fs } = await makeFixture('test-abortMerge')

    const branchA = await resolveRef({ fs, gitdir, ref: 'a' })
    const branchB = await resolveRef({ fs, gitdir, ref: 'b' })
    const ancestor = '2d7b1a9b82e52bd8648cf156aa559eff3a27a678' // common ancestor, hard coded, not ideal

    const fileAVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'a' }),
    ]

    const fileBVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'b' }),
    ]

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
      const fileAStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[3].oid,
        }),
      ]
      const fileBStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[3].oid,
        }),
      ]
      expect(fileAVersions).toEqual(fileAStages)
      expect(fileBVersions).toEqual(fileBStages)
    })
  })",steel
/__tests__/test-abortMerge.js,Magic Number,"{'line': 70, 'column': 59, 'index': 2110}","it('write conflicted files to index at different stages', async () => {
    // Setup
    const { gitdir, dir, fs } = await makeFixture('test-abortMerge')

    const branchA = await resolveRef({ fs, gitdir, ref: 'a' })
    const branchB = await resolveRef({ fs, gitdir, ref: 'b' })
    const ancestor = '2d7b1a9b82e52bd8648cf156aa559eff3a27a678' // common ancestor, hard coded, not ideal

    const fileAVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'a' }),
    ]

    const fileBVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'b' }),
    ]

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
      const fileAStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[3].oid,
        }),
      ]
      const fileBStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[3].oid,
        }),
      ]
      expect(fileAVersions).toEqual(fileAStages)
      expect(fileBVersions).toEqual(fileBStages)
    })
  })",steel
/__tests__/test-abortMerge.js,Magic Number,"{'line': 71, 'column': 59, 'index': 2172}","it('write conflicted files to index at different stages', async () => {
    // Setup
    const { gitdir, dir, fs } = await makeFixture('test-abortMerge')

    const branchA = await resolveRef({ fs, gitdir, ref: 'a' })
    const branchB = await resolveRef({ fs, gitdir, ref: 'b' })
    const ancestor = '2d7b1a9b82e52bd8648cf156aa559eff3a27a678' // common ancestor, hard coded, not ideal

    const fileAVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'a' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'a' }),
    ]

    const fileBVersions = [
      await readBlob({ fs, gitdir, oid: ancestor, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchA, filepath: 'b' }),
      await readBlob({ fs, gitdir, oid: branchB, filepath: 'b' }),
    ]

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }
    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
      const fileAStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('a').stages[3].oid,
        }),
      ]
      const fileBStages = [
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[1].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[2].oid,
        }),
        await readBlob({
          fs,
          gitdir,
          oid: index.entriesMap.get('b').stages[3].oid,
        }),
      ]
      expect(fileAVersions).toEqual(fileAStages)
      expect(fileBVersions).toEqual(fileBStages)
    })
  })",steel
/__tests__/test-abortMerge.js,Magic Number,"{'line': 356, 'column': 36, 'index': 9741}","it('uncache a file that has changes in the workdir (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    fs.write(`${dir}/c`, 'new changes to file c')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      index.delete({ filepath: 'c' })
    })

    const fileAWorkdirVersion = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual(fileAWorkdirVersion)
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",steel
/__tests__/test-abortMerge.js,Magic Number,"{'line': 422, 'column': 36, 'index': 11577}","it('workdir != index && index != head [stage a file and them modify in workdir] (throw an error)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.write(`${dir}/a`, 'text that is in the index')
    await add({ fs, dir, gitdir, filepath: 'a' })
    await fs.write(`${dir}/a`, 'text that is in the workdir')

    const fileBWorkdirVersion = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCWorkdirVersion = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    try {
      await abortMerge({ fs, dir, gitdir })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.IndexResetError.code)

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual('text that is in the workdir')
    expect(fileBContent).toEqual(fileBWorkdirVersion)
    expect(fileCContent).toEqual(fileCWorkdirVersion)
  })",steel
/__tests__/test-abortMerge.js,Magic Number,"{'line': 490, 'column': 36, 'index': 13340}","it('workdir != index && index === head (keep our changes)', async () => {
    // Setup
    const { fs, gitdir, dir } = await makeFixture('test-abortMerge')

    const head = await resolveRef({ fs, gitdir, ref: 'HEAD' })

    const fileAHeadVersion = await readBlob({
      fs,
      gitdir,
      oid: head,
      filepath: 'a',
    }).then(result => {
      return new TextDecoder().decode(result.blob)
    })
    const fileBHeadVersion = await readBlob({
      fs,
      gitdir,
      oid: head,
      filepath: 'b',
    }).then(result => {
      return new TextDecoder().decode(result.blob)
    })

    // Test
    let error = null
    try {
      await merge({
        fs,
        dir,
        gitdir,
        ours: 'a',
        theirs: 'b',
        abortOnConflict: false,
        author: {
          name: 'Mr. Test',
          email: 'mrtest@example.com',
          timestamp: 1262356920,
          timezoneOffset: -0,
        },
      })
    } catch (e) {
      error = e
    }

    expect(error).not.toBeNull()
    expect(error.code).toBe(Errors.MergeConflictError.code)

    await fs.write(`${dir}/c`, 'new text for file c')
    await abortMerge({ fs, dir, gitdir })

    const fileAContent = await fs.read(`${dir}/a`).then(buffer => {
      return buffer.toString()
    })
    const fileBContent = await fs.read(`${dir}/b`).then(buffer => {
      return buffer.toString()
    })
    const fileCContent = await fs.read(`${dir}/c`).then(buffer => {
      return buffer.toString()
    })

    const dirContents = await fs.readdir(dir)

    expect(dirContents.length).toBe(3)
    expect(fileAContent).toEqual(fileAHeadVersion)
    expect(fileBContent).toEqual(fileBHeadVersion)
    expect(fileCContent).toEqual('new text for file c')
  })",steel
/__tests__/test-GitSideBand.js,Conditional Test Logic,"{'line': 18, 'column': 6, 'index': 634}","it('demux - packetlines, packfile, and progress', async () => {
    const data = `001e# service=git-upload-pack
003dfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/main
000e\x01packfile
000e\x02hi there
0000`
    const expectedPacketlines = []
    const expectedProgress = []
    const expectedPackfile = []
    const lines = data.split(/\n/)
    const lastLineIdx = lines.length - 1
    lines.forEach((it, idx) => {
      it = it.slice(4) + (idx === lastLineIdx ? '' : '\n')
      if (it.startsWith('\x01')) {
        expectedPackfile.push(it.slice(1))
      } else if (it.startsWith('\x02')) {
        expectedProgress.push(it.slice(1))
      } else {
        expectedPacketlines.push(it)
      }
    })
    const stream = [Buffer.from(data)]
    const { packetlines, packfile, progress } = GitSideBand.demux(stream)
    const collectedPacketlines = await collect(packetlines)
    const collectedProgress = await collect(progress)
    const collectedPackfile = await collect(packfile)
    expect(collectedPacketlines.length > 0).toBe(true)
    expect(Buffer.from(collectedPacketlines).toString()).toEqual(
      expectedPacketlines.join('')
    )
    expect(collectedProgress.length > 0).toBe(true)
    expect(Buffer.from(collectedProgress).toString()).toEqual(
      expectedProgress.join('')
    )
    expect(collectedPackfile.length > 0).toBe(true)
    expect(Buffer.from(collectedPackfile).toString()).toEqual(
      expectedPackfile.join('')
    )
  })",steel
/__tests__/test-GitSideBand.js,Conditional Test Logic,"{'line': 20, 'column': 13, 'index': 719}","it('demux - packetlines, packfile, and progress', async () => {
    const data = `001e# service=git-upload-pack
003dfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/main
000e\x01packfile
000e\x02hi there
0000`
    const expectedPacketlines = []
    const expectedProgress = []
    const expectedPackfile = []
    const lines = data.split(/\n/)
    const lastLineIdx = lines.length - 1
    lines.forEach((it, idx) => {
      it = it.slice(4) + (idx === lastLineIdx ? '' : '\n')
      if (it.startsWith('\x01')) {
        expectedPackfile.push(it.slice(1))
      } else if (it.startsWith('\x02')) {
        expectedProgress.push(it.slice(1))
      } else {
        expectedPacketlines.push(it)
      }
    })
    const stream = [Buffer.from(data)]
    const { packetlines, packfile, progress } = GitSideBand.demux(stream)
    const collectedPacketlines = await collect(packetlines)
    const collectedProgress = await collect(progress)
    const collectedPackfile = await collect(packfile)
    expect(collectedPacketlines.length > 0).toBe(true)
    expect(Buffer.from(collectedPacketlines).toString()).toEqual(
      expectedPacketlines.join('')
    )
    expect(collectedProgress.length > 0).toBe(true)
    expect(Buffer.from(collectedProgress).toString()).toEqual(
      expectedProgress.join('')
    )
    expect(collectedPackfile.length > 0).toBe(true)
    expect(Buffer.from(collectedPackfile).toString()).toEqual(
      expectedPackfile.join('')
    )
  })",steel
/__tests__/test-GitSideBand.js,Conditional Test Logic,"{'line': 55, 'column': 6, 'index': 1973}","it('demux - error line', async () => {
    const data = `001e# service=git-upload-pack
0015\x03error in stream
0000`
    const expectedPacketlines = []
    const expectedProgress = []
    const lines = data.split(/\n/)
    const lastLineIdx = lines.length - 1
    lines.forEach((it, idx) => {
      it = it.slice(4) + (idx === lastLineIdx ? '' : '\n')
      if (it.startsWith('\x03')) {
        expectedProgress.push(it.slice(1))
      } else {
        expectedPacketlines.push(it)
      }
    })
    const stream = [Buffer.from(data)]
    const { packetlines, packfile, progress } = GitSideBand.demux(stream)
    const collectedPacketlines = await collect(packetlines)
    const collectedProgress = await collect(progress)
    const collectedPackfile = await collect(packfile)
    expect(collectedPacketlines.length > 0).toBe(true)
    expect(Buffer.from(collectedPacketlines).toString()).toEqual(
      expectedPacketlines.join('')
    )
    expect(collectedProgress.length > 0).toBe(true)
    expect(Buffer.from(collectedProgress).toString()).toEqual(
      expectedProgress.join('')
    )
    expect(collectedPackfile.length === 0).toBe(true)
    expect('error' in packfile).toBe(true)
    expect(packfile.error.message).toEqual('error in stream\n')
  })",steel
/__tests__/test-GitRemoteManager.js,Exception Handling,"{'line': 13, 'column': 4, 'index': 319}","it('getRemoteHelperFor (http)', async () => {
    // Test
    let helper = null
    let error = null
    try {
      helper = await GitRemoteManager.getRemoteHelperFor({
        url: 'http://github.com/isomorphic-git-isomorphic-git',
      })
    } catch (err) {
      error = err
    }
    expect(error).toBeNull()
    expect(helper).toBe(GitRemoteHTTP)
  })",steel
/__tests__/test-GitRemoteManager.js,Exception Handling,"{'line': 28, 'column': 4, 'index': 691}","it('getRemoteHelperFor (http override)', async () => {
    // Test
    let helper = null
    let error = null
    try {
      helper = await GitRemoteManager.getRemoteHelperFor({
        url: 'http::https://github.com/isomorphic-git-isomorphic-git',
      })
    } catch (err) {
      error = err
    }
    expect(error).toBeNull()
    expect(helper).toBe(GitRemoteHTTP)
  })",steel
/__tests__/test-GitRemoteManager.js,Exception Handling,"{'line': 43, 'column': 4, 'index': 1062}","it('getRemoteHelperFor (https)', async () => {
    // Test
    let helper = null
    let error = null
    try {
      helper = await GitRemoteManager.getRemoteHelperFor({
        url: 'https://github.com/isomorphic-git-isomorphic-git',
      })
    } catch (err) {
      error = err
    }
    expect(error).toBeNull()
    expect(helper).toBe(GitRemoteHTTP)
  })",steel
/__tests__/test-GitRemoteManager.js,Exception Handling,"{'line': 58, 'column': 4, 'index': 1429}","it('getRemoteHelperFor (unknown)', async () => {
    // Test
    let helper = null
    let error = null
    try {
      helper = await GitRemoteManager.getRemoteHelperFor({
        url:
          'hypergit://5701a1c08ae15dba17e181b1a9a28bdfb8b95200d77a25be6051bb018e25439a',
      })
    } catch (err) {
      error = err
    }
    expect(helper).toBeNull()
    expect(error.code).toBe(Errors.UnknownTransportError.code)
  })",steel
/__tests__/test-GitRemoteManager.js,Exception Handling,"{'line': 74, 'column': 4, 'index': 1867}","it('getRemoteHelperFor (unknown override)', async () => {
    // Test
    let helper = null
    let error = null
    try {
      helper = await GitRemoteManager.getRemoteHelperFor({
        url: 'oid::c3c2a92aa2bda58d667cb57493270b83bd14d1ed',
      })
    } catch (err) {
      error = err
    }
    expect(helper).toBeNull()
    expect(error.code).toBe(Errors.UnknownTransportError.code)
  })",steel
/__tests__/test-GitRemoteManager.js,Exception Handling,"{'line': 89, 'column': 4, 'index': 2260}","it('getRemoteHelperFor (unparseable)', async () => {
    // Test
    let helper = null
    let error = null
    try {
      helper = await GitRemoteManager.getRemoteHelperFor({
        url: 'oid:c3c2a92aa2bda58d667cb57493270b83bd14d1ed',
      })
    } catch (err) {
      error = err
    }
    expect(helper).toBeNull()
    expect(error.code).toBe(Errors.UrlParseError.code)
  })",steel
/__tests__/test-GitRefManager.js,Conditional Test Logic,"{'line': 262, 'column': 4, 'index': 10199}","it('concurrently reading/writing a ref should not cause a NotFoundError resolving it', async () => {
    // There are some expect() calls below, but as of 2023-03-15, if this test fails it will do so by logging instances
    // of 'NotFoundError: Could not find myRef', which should not happen.
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    const ref = 'myRef'
    const value = '1234567890123456789012345678901234567890'
    await GitRefManager.writeRef({ fs, gitdir, ref, value }) // Guarantee that the file for the ref exists on disk

    const writePromises = []
    const resolvePromises = []
    // Some arbitrary number of iterations that seems to guarantee that the error (pre-fix) is hit.
    // With 100 the test *mostly* failed but still passed every now and then.
    const iterations = 500

    for (let i = 0; i < iterations; i++) {
      // I was only able to cause the error to reproduce consistently by mixing awaited and non-awaited versions of the
      // calls to writeRef() and resolve(). I tried several variations of the combination but none of them caused the
      // error to happen as consistently.
      if (Math.random() < 0.5) {
        await GitRefManager.writeRef({ fs, gitdir, ref, value })
      } else {
        writePromises.push(GitRefManager.writeRef({ fs, gitdir, ref, value }))
      }
      if (Math.random() < 0.5) {
        const resolvedRef = await GitRefManager.resolve({ fs, gitdir, ref })
        expect(resolvedRef).toMatch(value)
      } else {
        resolvePromises.push(GitRefManager.resolve({ fs, gitdir, ref }))
      }
    }

    const resolvedRefs = await Promise.all(resolvePromises)
    for (const resolvedRef of resolvedRefs) {
      expect(resolvedRef).toMatch(value)
    }
    await Promise.all(writePromises)
  })",steel
/__tests__/test-GitRefManager.js,Conditional Test Logic,"{'line': 266, 'column': 6, 'index': 10524}","it('concurrently reading/writing a ref should not cause a NotFoundError resolving it', async () => {
    // There are some expect() calls below, but as of 2023-03-15, if this test fails it will do so by logging instances
    // of 'NotFoundError: Could not find myRef', which should not happen.
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    const ref = 'myRef'
    const value = '1234567890123456789012345678901234567890'
    await GitRefManager.writeRef({ fs, gitdir, ref, value }) // Guarantee that the file for the ref exists on disk

    const writePromises = []
    const resolvePromises = []
    // Some arbitrary number of iterations that seems to guarantee that the error (pre-fix) is hit.
    // With 100 the test *mostly* failed but still passed every now and then.
    const iterations = 500

    for (let i = 0; i < iterations; i++) {
      // I was only able to cause the error to reproduce consistently by mixing awaited and non-awaited versions of the
      // calls to writeRef() and resolve(). I tried several variations of the combination but none of them caused the
      // error to happen as consistently.
      if (Math.random() < 0.5) {
        await GitRefManager.writeRef({ fs, gitdir, ref, value })
      } else {
        writePromises.push(GitRefManager.writeRef({ fs, gitdir, ref, value }))
      }
      if (Math.random() < 0.5) {
        const resolvedRef = await GitRefManager.resolve({ fs, gitdir, ref })
        expect(resolvedRef).toMatch(value)
      } else {
        resolvePromises.push(GitRefManager.resolve({ fs, gitdir, ref }))
      }
    }

    const resolvedRefs = await Promise.all(resolvePromises)
    for (const resolvedRef of resolvedRefs) {
      expect(resolvedRef).toMatch(value)
    }
    await Promise.all(writePromises)
  })",steel
/__tests__/test-GitRefManager.js,Conditional Test Logic,"{'line': 271, 'column': 6, 'index': 10724}","it('concurrently reading/writing a ref should not cause a NotFoundError resolving it', async () => {
    // There are some expect() calls below, but as of 2023-03-15, if this test fails it will do so by logging instances
    // of 'NotFoundError: Could not find myRef', which should not happen.
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    const ref = 'myRef'
    const value = '1234567890123456789012345678901234567890'
    await GitRefManager.writeRef({ fs, gitdir, ref, value }) // Guarantee that the file for the ref exists on disk

    const writePromises = []
    const resolvePromises = []
    // Some arbitrary number of iterations that seems to guarantee that the error (pre-fix) is hit.
    // With 100 the test *mostly* failed but still passed every now and then.
    const iterations = 500

    for (let i = 0; i < iterations; i++) {
      // I was only able to cause the error to reproduce consistently by mixing awaited and non-awaited versions of the
      // calls to writeRef() and resolve(). I tried several variations of the combination but none of them caused the
      // error to happen as consistently.
      if (Math.random() < 0.5) {
        await GitRefManager.writeRef({ fs, gitdir, ref, value })
      } else {
        writePromises.push(GitRefManager.writeRef({ fs, gitdir, ref, value }))
      }
      if (Math.random() < 0.5) {
        const resolvedRef = await GitRefManager.resolve({ fs, gitdir, ref })
        expect(resolvedRef).toMatch(value)
      } else {
        resolvePromises.push(GitRefManager.resolve({ fs, gitdir, ref }))
      }
    }

    const resolvedRefs = await Promise.all(resolvePromises)
    for (const resolvedRef of resolvedRefs) {
      expect(resolvedRef).toMatch(value)
    }
    await Promise.all(writePromises)
  })",steel
/__tests__/test-GitRefManager.js,Conditional Test Logic,"{'line': 280, 'column': 4, 'index': 11038}","it('concurrently reading/writing a ref should not cause a NotFoundError resolving it', async () => {
    // There are some expect() calls below, but as of 2023-03-15, if this test fails it will do so by logging instances
    // of 'NotFoundError: Could not find myRef', which should not happen.
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    const ref = 'myRef'
    const value = '1234567890123456789012345678901234567890'
    await GitRefManager.writeRef({ fs, gitdir, ref, value }) // Guarantee that the file for the ref exists on disk

    const writePromises = []
    const resolvePromises = []
    // Some arbitrary number of iterations that seems to guarantee that the error (pre-fix) is hit.
    // With 100 the test *mostly* failed but still passed every now and then.
    const iterations = 500

    for (let i = 0; i < iterations; i++) {
      // I was only able to cause the error to reproduce consistently by mixing awaited and non-awaited versions of the
      // calls to writeRef() and resolve(). I tried several variations of the combination but none of them caused the
      // error to happen as consistently.
      if (Math.random() < 0.5) {
        await GitRefManager.writeRef({ fs, gitdir, ref, value })
      } else {
        writePromises.push(GitRefManager.writeRef({ fs, gitdir, ref, value }))
      }
      if (Math.random() < 0.5) {
        const resolvedRef = await GitRefManager.resolve({ fs, gitdir, ref })
        expect(resolvedRef).toMatch(value)
      } else {
        resolvePromises.push(GitRefManager.resolve({ fs, gitdir, ref }))
      }
    }

    const resolvedRefs = await Promise.all(resolvePromises)
    for (const resolvedRef of resolvedRefs) {
      expect(resolvedRef).toMatch(value)
    }
    await Promise.all(writePromises)
  })",steel
/__tests__/test-GitRefManager.js,Duplicate Assert,"{'line': 92, 'column': 4, 'index': 6090}","it('listRefs', async () => {
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    let refs = await GitRefManager.listRefs({
      fs,
      gitdir,
      filepath: 'refs/remotes/origin',
    })
    expect(refs).toMatchInlineSnapshot(`
      Array [
        ""develop"",
        ""dist"",
        ""gh-pages"",
        ""git-fetch"",
        ""greenkeeper/semantic-release-11.0.2"",
        ""master"",
        ""test-branch"",
        ""test-branch-shallow-clone"",
      ]
    `)
    refs = await GitRefManager.listRefs({
      fs,
      gitdir,
      filepath: 'refs/tags',
    })
    expect(refs).toMatchInlineSnapshot(`
      Array [
        ""local-tag"",
        ""test-tag"",
        ""v0.0.1"",
        ""v0.0.10"",
        ""v0.0.10^{}"",
        ""v0.0.11"",
        ""v0.0.11^{}"",
        ""v0.0.12"",
        ""v0.0.12^{}"",
        ""v0.0.13"",
        ""v0.0.13^{}"",
        ""v0.0.14"",
        ""v0.0.14^{}"",
        ""v0.0.15"",
        ""v0.0.15^{}"",
        ""v0.0.16"",
        ""v0.0.16^{}"",
        ""v0.0.17"",
        ""v0.0.17^{}"",
        ""v0.0.18"",
        ""v0.0.18^{}"",
        ""v0.0.19"",
        ""v0.0.19^{}"",
        ""v0.0.2"",
        ""v0.0.20"",
        ""v0.0.20^{}"",
        ""v0.0.21"",
        ""v0.0.21^{}"",
        ""v0.0.22"",
        ""v0.0.22^{}"",
        ""v0.0.23"",
        ""v0.0.23^{}"",
        ""v0.0.24"",
        ""v0.0.24^{}"",
        ""v0.0.25"",
        ""v0.0.25^{}"",
        ""v0.0.26"",
        ""v0.0.26^{}"",
        ""v0.0.27"",
        ""v0.0.28"",
        ""v0.0.29"",
        ""v0.0.3"",
        ""v0.0.3^{}"",
        ""v0.0.30"",
        ""v0.0.31"",
        ""v0.0.32"",
        ""v0.0.33"",
        ""v0.0.34"",
        ""v0.0.35"",
        ""v0.0.36"",
        ""v0.0.37"",
        ""v0.0.38"",
        ""v0.0.4"",
        ""v0.0.4^{}"",
        ""v0.0.5"",
        ""v0.0.6"",
        ""v0.0.6^{}"",
        ""v0.0.7"",
        ""v0.0.8"",
        ""v0.0.8^{}"",
        ""v0.0.9"",
        ""v0.0.9^{}"",
        ""v0.1.0"",
      ]
    `)
  })",steel
/__tests__/test-GitRefManager.js,Duplicate Assert,"{'line': 109, 'column': 4, 'index': 6463}","it('listRefs', async () => {
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    let refs = await GitRefManager.listRefs({
      fs,
      gitdir,
      filepath: 'refs/remotes/origin',
    })
    expect(refs).toMatchInlineSnapshot(`
      Array [
        ""develop"",
        ""dist"",
        ""gh-pages"",
        ""git-fetch"",
        ""greenkeeper/semantic-release-11.0.2"",
        ""master"",
        ""test-branch"",
        ""test-branch-shallow-clone"",
      ]
    `)
    refs = await GitRefManager.listRefs({
      fs,
      gitdir,
      filepath: 'refs/tags',
    })
    expect(refs).toMatchInlineSnapshot(`
      Array [
        ""local-tag"",
        ""test-tag"",
        ""v0.0.1"",
        ""v0.0.10"",
        ""v0.0.10^{}"",
        ""v0.0.11"",
        ""v0.0.11^{}"",
        ""v0.0.12"",
        ""v0.0.12^{}"",
        ""v0.0.13"",
        ""v0.0.13^{}"",
        ""v0.0.14"",
        ""v0.0.14^{}"",
        ""v0.0.15"",
        ""v0.0.15^{}"",
        ""v0.0.16"",
        ""v0.0.16^{}"",
        ""v0.0.17"",
        ""v0.0.17^{}"",
        ""v0.0.18"",
        ""v0.0.18^{}"",
        ""v0.0.19"",
        ""v0.0.19^{}"",
        ""v0.0.2"",
        ""v0.0.20"",
        ""v0.0.20^{}"",
        ""v0.0.21"",
        ""v0.0.21^{}"",
        ""v0.0.22"",
        ""v0.0.22^{}"",
        ""v0.0.23"",
        ""v0.0.23^{}"",
        ""v0.0.24"",
        ""v0.0.24^{}"",
        ""v0.0.25"",
        ""v0.0.25^{}"",
        ""v0.0.26"",
        ""v0.0.26^{}"",
        ""v0.0.27"",
        ""v0.0.28"",
        ""v0.0.29"",
        ""v0.0.3"",
        ""v0.0.3^{}"",
        ""v0.0.30"",
        ""v0.0.31"",
        ""v0.0.32"",
        ""v0.0.33"",
        ""v0.0.34"",
        ""v0.0.35"",
        ""v0.0.36"",
        ""v0.0.37"",
        ""v0.0.38"",
        ""v0.0.4"",
        ""v0.0.4^{}"",
        ""v0.0.5"",
        ""v0.0.6"",
        ""v0.0.6^{}"",
        ""v0.0.7"",
        ""v0.0.8"",
        ""v0.0.8^{}"",
        ""v0.0.9"",
        ""v0.0.9^{}"",
        ""v0.1.0"",
      ]
    `)
  })",steel
/__tests__/test-GitRefManager.js,Duplicate Assert,"{'line': 180, 'column': 4, 'index': 7955}","it('listBranches', async () => {
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    let refs = await GitRefManager.listBranches({ fs, gitdir })
    expect(refs).toEqual([])
    refs = await GitRefManager.listBranches({
      fs,
      gitdir,
      remote: 'origin',
    })
    expect(refs).toMatchInlineSnapshot(`
      Array [
        ""develop"",
        ""dist"",
        ""gh-pages"",
        ""git-fetch"",
        ""greenkeeper/semantic-release-11.0.2"",
        ""master"",
        ""test-branch"",
        ""test-branch-shallow-clone"",
      ]
    `)
  })",steel
/__tests__/test-GitRefManager.js,Duplicate Assert,"{'line': 186, 'column': 4, 'index': 8085}","it('listBranches', async () => {
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    let refs = await GitRefManager.listBranches({ fs, gitdir })
    expect(refs).toEqual([])
    refs = await GitRefManager.listBranches({
      fs,
      gitdir,
      remote: 'origin',
    })
    expect(refs).toMatchInlineSnapshot(`
      Array [
        ""develop"",
        ""dist"",
        ""gh-pages"",
        ""git-fetch"",
        ""greenkeeper/semantic-release-11.0.2"",
        ""master"",
        ""test-branch"",
        ""test-branch-shallow-clone"",
      ]
    `)
  })",steel
/__tests__/test-GitRefManager.js,Duplicate Assert,"{'line': 273, 'column': 8, 'index': 10836}","it('concurrently reading/writing a ref should not cause a NotFoundError resolving it', async () => {
    // There are some expect() calls below, but as of 2023-03-15, if this test fails it will do so by logging instances
    // of 'NotFoundError: Could not find myRef', which should not happen.
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    const ref = 'myRef'
    const value = '1234567890123456789012345678901234567890'
    await GitRefManager.writeRef({ fs, gitdir, ref, value }) // Guarantee that the file for the ref exists on disk

    const writePromises = []
    const resolvePromises = []
    // Some arbitrary number of iterations that seems to guarantee that the error (pre-fix) is hit.
    // With 100 the test *mostly* failed but still passed every now and then.
    const iterations = 500

    for (let i = 0; i < iterations; i++) {
      // I was only able to cause the error to reproduce consistently by mixing awaited and non-awaited versions of the
      // calls to writeRef() and resolve(). I tried several variations of the combination but none of them caused the
      // error to happen as consistently.
      if (Math.random() < 0.5) {
        await GitRefManager.writeRef({ fs, gitdir, ref, value })
      } else {
        writePromises.push(GitRefManager.writeRef({ fs, gitdir, ref, value }))
      }
      if (Math.random() < 0.5) {
        const resolvedRef = await GitRefManager.resolve({ fs, gitdir, ref })
        expect(resolvedRef).toMatch(value)
      } else {
        resolvePromises.push(GitRefManager.resolve({ fs, gitdir, ref }))
      }
    }

    const resolvedRefs = await Promise.all(resolvePromises)
    for (const resolvedRef of resolvedRefs) {
      expect(resolvedRef).toMatch(value)
    }
    await Promise.all(writePromises)
  })",steel
/__tests__/test-GitRefManager.js,Duplicate Assert,"{'line': 273, 'column': 8, 'index': 10836}","it('concurrently reading/writing a ref should not cause a NotFoundError resolving it', async () => {
    // There are some expect() calls below, but as of 2023-03-15, if this test fails it will do so by logging instances
    // of 'NotFoundError: Could not find myRef', which should not happen.
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    const ref = 'myRef'
    const value = '1234567890123456789012345678901234567890'
    await GitRefManager.writeRef({ fs, gitdir, ref, value }) // Guarantee that the file for the ref exists on disk

    const writePromises = []
    const resolvePromises = []
    // Some arbitrary number of iterations that seems to guarantee that the error (pre-fix) is hit.
    // With 100 the test *mostly* failed but still passed every now and then.
    const iterations = 500

    for (let i = 0; i < iterations; i++) {
      // I was only able to cause the error to reproduce consistently by mixing awaited and non-awaited versions of the
      // calls to writeRef() and resolve(). I tried several variations of the combination but none of them caused the
      // error to happen as consistently.
      if (Math.random() < 0.5) {
        await GitRefManager.writeRef({ fs, gitdir, ref, value })
      } else {
        writePromises.push(GitRefManager.writeRef({ fs, gitdir, ref, value }))
      }
      if (Math.random() < 0.5) {
        const resolvedRef = await GitRefManager.resolve({ fs, gitdir, ref })
        expect(resolvedRef).toMatch(value)
      } else {
        resolvePromises.push(GitRefManager.resolve({ fs, gitdir, ref }))
      }
    }

    const resolvedRefs = await Promise.all(resolvePromises)
    for (const resolvedRef of resolvedRefs) {
      expect(resolvedRef).toMatch(value)
    }
    await Promise.all(writePromises)
  })",steel
/__tests__/test-GitRefManager.js,Duplicate Assert,"{'line': 281, 'column': 6, 'index': 11086}","it('concurrently reading/writing a ref should not cause a NotFoundError resolving it', async () => {
    // There are some expect() calls below, but as of 2023-03-15, if this test fails it will do so by logging instances
    // of 'NotFoundError: Could not find myRef', which should not happen.
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    const ref = 'myRef'
    const value = '1234567890123456789012345678901234567890'
    await GitRefManager.writeRef({ fs, gitdir, ref, value }) // Guarantee that the file for the ref exists on disk

    const writePromises = []
    const resolvePromises = []
    // Some arbitrary number of iterations that seems to guarantee that the error (pre-fix) is hit.
    // With 100 the test *mostly* failed but still passed every now and then.
    const iterations = 500

    for (let i = 0; i < iterations; i++) {
      // I was only able to cause the error to reproduce consistently by mixing awaited and non-awaited versions of the
      // calls to writeRef() and resolve(). I tried several variations of the combination but none of them caused the
      // error to happen as consistently.
      if (Math.random() < 0.5) {
        await GitRefManager.writeRef({ fs, gitdir, ref, value })
      } else {
        writePromises.push(GitRefManager.writeRef({ fs, gitdir, ref, value }))
      }
      if (Math.random() < 0.5) {
        const resolvedRef = await GitRefManager.resolve({ fs, gitdir, ref })
        expect(resolvedRef).toMatch(value)
      } else {
        resolvePromises.push(GitRefManager.resolve({ fs, gitdir, ref }))
      }
    }

    const resolvedRefs = await Promise.all(resolvePromises)
    for (const resolvedRef of resolvedRefs) {
      expect(resolvedRef).toMatch(value)
    }
    await Promise.all(writePromises)
  })",steel
/__tests__/test-GitRefManager.js,Duplicate Assert,"{'line': 281, 'column': 6, 'index': 11086}","it('concurrently reading/writing a ref should not cause a NotFoundError resolving it', async () => {
    // There are some expect() calls below, but as of 2023-03-15, if this test fails it will do so by logging instances
    // of 'NotFoundError: Could not find myRef', which should not happen.
    const { fs, gitdir } = await makeFixture('test-GitRefManager')
    const ref = 'myRef'
    const value = '1234567890123456789012345678901234567890'
    await GitRefManager.writeRef({ fs, gitdir, ref, value }) // Guarantee that the file for the ref exists on disk

    const writePromises = []
    const resolvePromises = []
    // Some arbitrary number of iterations that seems to guarantee that the error (pre-fix) is hit.
    // With 100 the test *mostly* failed but still passed every now and then.
    const iterations = 500

    for (let i = 0; i < iterations; i++) {
      // I was only able to cause the error to reproduce consistently by mixing awaited and non-awaited versions of the
      // calls to writeRef() and resolve(). I tried several variations of the combination but none of them caused the
      // error to happen as consistently.
      if (Math.random() < 0.5) {
        await GitRefManager.writeRef({ fs, gitdir, ref, value })
      } else {
        writePromises.push(GitRefManager.writeRef({ fs, gitdir, ref, value }))
      }
      if (Math.random() < 0.5) {
        const resolvedRef = await GitRefManager.resolve({ fs, gitdir, ref })
        expect(resolvedRef).toMatch(value)
      } else {
        resolvePromises.push(GitRefManager.resolve({ fs, gitdir, ref }))
      }
    }

    const resolvedRefs = await Promise.all(resolvePromises)
    for (const resolvedRef of resolvedRefs) {
      expect(resolvedRef).toMatch(value)
    }
    await Promise.all(writePromises)
  })",steel
/__tests__/test-GitPktLine.js,Conditional Test Logic,"{'line': 87, 'column': 6, 'index': 3442}","it('read stream - with error', async () => {
    const hookStream = (subject, fn) => {
      const unhook = function(write) {
        this.write = write
      }.bind(subject, subject.write)
      subject.write = fn
      return unhook
    }
    let unhook
    try {
      const output = []
      if (!process.browser) {
        const onLog = chunk => output.push(chunk) && undefined
        unhook = hookStream(process.stdout, onLog)
      }
      let err
      const stream = {
        next() {
          throw (err = new Error('something went wrong'))
        },
      }
      const read = GitPktLine.streamReader(stream)
      const line = await read()
      expect(output.length === 0).toBe(true)
      expect(line).toBe(true)
      expect(stream.error === err).toBe(true)
    } finally {
      if (unhook) unhook()
    }
  })",steel
/__tests__/test-GitPktLine.js,Conditional Test Logic,"{'line': 103, 'column': 6, 'index': 3945}","it('read stream - with error', async () => {
    const hookStream = (subject, fn) => {
      const unhook = function(write) {
        this.write = write
      }.bind(subject, subject.write)
      subject.write = fn
      return unhook
    }
    let unhook
    try {
      const output = []
      if (!process.browser) {
        const onLog = chunk => output.push(chunk) && undefined
        unhook = hookStream(process.stdout, onLog)
      }
      let err
      const stream = {
        next() {
          throw (err = new Error('something went wrong'))
        },
      }
      const read = GitPktLine.streamReader(stream)
      const line = await read()
      expect(output.length === 0).toBe(true)
      expect(line).toBe(true)
      expect(stream.error === err).toBe(true)
    } finally {
      if (unhook) unhook()
    }
  })",steel
/__tests__/test-GitPktLine.js,Duplicate Assert,"{'line': 31, 'column': 4, 'index': 1462}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",steel
/__tests__/test-GitPktLine.js,Duplicate Assert,"{'line': 31, 'column': 4, 'index': 1462}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",steel
/__tests__/test-GitPktLine.js,Duplicate Assert,"{'line': 64, 'column': 4, 'index': 2842}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",steel
/__tests__/test-GitPktLine.js,Duplicate Assert,"{'line': 64, 'column': 4, 'index': 2842}","it('read stream - realistic', async () => {
    const buffer = Buffer.from(
      `001e# service=git-upload-pack
000001059ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac
003cfb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2
003c5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3
003f9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master
0040c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2
0040d85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3
004018f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4
0040e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5
0000`
    )
    const stream = [buffer]
    const read = GitPktLine.streamReader(stream)
    expect(
      (await read()).toString('utf8') === '# service=git-upload-pack\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow deepen-since deepen-not deepen-relative no-progress include-tag multi_ack_detailed no-done symref=HEAD:refs/heads/master agent=git/github-g91c094cac\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'fb74ea1a9b6a9601df18c38d3de751c51f064bf7 refs/heads/js2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '5faa96fe725306e060386975a70e4b6eacb576ed refs/heads/js3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '9ea43b479f5fedc679e3eb37803275d727bf51b7 refs/heads/master\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'c1751a5447a7b025e5bca507af483dde7b0b956f refs/heads/master2\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'd85135a47c42c9c906e20c08def2fbceac4c2a4f refs/heads/master3\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        '18f4b62440abf61285fbfdcbfd990ab8434ff35c refs/heads/master4\n'
    ).toBe(true)
    expect(
      (await read()).toString('utf8') ===
        'e5c144897b64a44bd1164a0db60738452c9eaf87 refs/heads/master5\n'
    ).toBe(true)
    expect((await read()) === null).toBe(true)
    expect(await read()).toBe(true)
  })",steel
/__tests__/test-GitPktLine.js,Exception Handling,"{'line': 85, 'column': 4, 'index': 3406}","it('read stream - with error', async () => {
    const hookStream = (subject, fn) => {
      const unhook = function(write) {
        this.write = write
      }.bind(subject, subject.write)
      subject.write = fn
      return unhook
    }
    let unhook
    try {
      const output = []
      if (!process.browser) {
        const onLog = chunk => output.push(chunk) && undefined
        unhook = hookStream(process.stdout, onLog)
      }
      let err
      const stream = {
        next() {
          throw (err = new Error('something went wrong'))
        },
      }
      const read = GitPktLine.streamReader(stream)
      const line = await read()
      expect(output.length === 0).toBe(true)
      expect(line).toBe(true)
      expect(stream.error === err).toBe(true)
    } finally {
      if (unhook) unhook()
    }
  })",steel
/__tests__/test-GitPktLine.js,Exception Handling,"{'line': 94, 'column': 10, 'index': 3652}","it('read stream - with error', async () => {
    const hookStream = (subject, fn) => {
      const unhook = function(write) {
        this.write = write
      }.bind(subject, subject.write)
      subject.write = fn
      return unhook
    }
    let unhook
    try {
      const output = []
      if (!process.browser) {
        const onLog = chunk => output.push(chunk) && undefined
        unhook = hookStream(process.stdout, onLog)
      }
      let err
      const stream = {
        next() {
          throw (err = new Error('something went wrong'))
        },
      }
      const read = GitPktLine.streamReader(stream)
      const line = await read()
      expect(output.length === 0).toBe(true)
      expect(line).toBe(true)
      expect(stream.error === err).toBe(true)
    } finally {
      if (unhook) unhook()
    }
  })",steel
/__tests__/test-GitPackIndex.js,Magic Number,"{'line': 28, 'column': 6, 'index': 901}","it('from .idx', async () => {
    const { fs, gitdir } = await makeFixture('test-GitPackIndex')
    const idx = await fs.read(
      path.join(
        gitdir,
        'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.idx'
      )
    )
    const p = await GitPackIndex.fromIdx({ idx })
    expect(
      await shasum(Buffer.from(JSON.stringify(p.hashes)))
    ).toMatchInlineSnapshot('""fd2404a29d1e5dc72066541366d5f75bc9d51c9b""')
    expect(p.packfileSha).toBe('1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888')
    // Test a handful of known offsets.
    expect(p.offsets.get('0b8faa11b353db846b40eb064dfb299816542a46')).toEqual(
      40077
    )
    expect(p.offsets.get('637c4e69d85e0dcc18898ec251377453d0891585')).toEqual(
      39860
    )
    expect(p.offsets.get('98e9fde3ee878fa985a143fc5fe05d4e6d8e637b')).toEqual(
      39036
    )
    expect(p.offsets.get('43c49edb213748626fc363c890c01a9e55a1b8da')).toEqual(
      38202
    )
    expect(p.offsets.get('5f1f014326b1d7e8079d00b87fa7a9913bd91324')).toEqual(
      20855
    )
  })",steel
/__tests__/test-GitPackIndex.js,Magic Number,"{'line': 31, 'column': 6, 'index': 998}","it('from .idx', async () => {
    const { fs, gitdir } = await makeFixture('test-GitPackIndex')
    const idx = await fs.read(
      path.join(
        gitdir,
        'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.idx'
      )
    )
    const p = await GitPackIndex.fromIdx({ idx })
    expect(
      await shasum(Buffer.from(JSON.stringify(p.hashes)))
    ).toMatchInlineSnapshot('""fd2404a29d1e5dc72066541366d5f75bc9d51c9b""')
    expect(p.packfileSha).toBe('1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888')
    // Test a handful of known offsets.
    expect(p.offsets.get('0b8faa11b353db846b40eb064dfb299816542a46')).toEqual(
      40077
    )
    expect(p.offsets.get('637c4e69d85e0dcc18898ec251377453d0891585')).toEqual(
      39860
    )
    expect(p.offsets.get('98e9fde3ee878fa985a143fc5fe05d4e6d8e637b')).toEqual(
      39036
    )
    expect(p.offsets.get('43c49edb213748626fc363c890c01a9e55a1b8da')).toEqual(
      38202
    )
    expect(p.offsets.get('5f1f014326b1d7e8079d00b87fa7a9913bd91324')).toEqual(
      20855
    )
  })",steel
/__tests__/test-GitPackIndex.js,Magic Number,"{'line': 34, 'column': 6, 'index': 1095}","it('from .idx', async () => {
    const { fs, gitdir } = await makeFixture('test-GitPackIndex')
    const idx = await fs.read(
      path.join(
        gitdir,
        'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.idx'
      )
    )
    const p = await GitPackIndex.fromIdx({ idx })
    expect(
      await shasum(Buffer.from(JSON.stringify(p.hashes)))
    ).toMatchInlineSnapshot('""fd2404a29d1e5dc72066541366d5f75bc9d51c9b""')
    expect(p.packfileSha).toBe('1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888')
    // Test a handful of known offsets.
    expect(p.offsets.get('0b8faa11b353db846b40eb064dfb299816542a46')).toEqual(
      40077
    )
    expect(p.offsets.get('637c4e69d85e0dcc18898ec251377453d0891585')).toEqual(
      39860
    )
    expect(p.offsets.get('98e9fde3ee878fa985a143fc5fe05d4e6d8e637b')).toEqual(
      39036
    )
    expect(p.offsets.get('43c49edb213748626fc363c890c01a9e55a1b8da')).toEqual(
      38202
    )
    expect(p.offsets.get('5f1f014326b1d7e8079d00b87fa7a9913bd91324')).toEqual(
      20855
    )
  })",steel
/__tests__/test-GitPackIndex.js,Magic Number,"{'line': 37, 'column': 6, 'index': 1192}","it('from .idx', async () => {
    const { fs, gitdir } = await makeFixture('test-GitPackIndex')
    const idx = await fs.read(
      path.join(
        gitdir,
        'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.idx'
      )
    )
    const p = await GitPackIndex.fromIdx({ idx })
    expect(
      await shasum(Buffer.from(JSON.stringify(p.hashes)))
    ).toMatchInlineSnapshot('""fd2404a29d1e5dc72066541366d5f75bc9d51c9b""')
    expect(p.packfileSha).toBe('1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888')
    // Test a handful of known offsets.
    expect(p.offsets.get('0b8faa11b353db846b40eb064dfb299816542a46')).toEqual(
      40077
    )
    expect(p.offsets.get('637c4e69d85e0dcc18898ec251377453d0891585')).toEqual(
      39860
    )
    expect(p.offsets.get('98e9fde3ee878fa985a143fc5fe05d4e6d8e637b')).toEqual(
      39036
    )
    expect(p.offsets.get('43c49edb213748626fc363c890c01a9e55a1b8da')).toEqual(
      38202
    )
    expect(p.offsets.get('5f1f014326b1d7e8079d00b87fa7a9913bd91324')).toEqual(
      20855
    )
  })",steel
/__tests__/test-GitPackIndex.js,Magic Number,"{'line': 40, 'column': 6, 'index': 1289}","it('from .idx', async () => {
    const { fs, gitdir } = await makeFixture('test-GitPackIndex')
    const idx = await fs.read(
      path.join(
        gitdir,
        'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.idx'
      )
    )
    const p = await GitPackIndex.fromIdx({ idx })
    expect(
      await shasum(Buffer.from(JSON.stringify(p.hashes)))
    ).toMatchInlineSnapshot('""fd2404a29d1e5dc72066541366d5f75bc9d51c9b""')
    expect(p.packfileSha).toBe('1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888')
    // Test a handful of known offsets.
    expect(p.offsets.get('0b8faa11b353db846b40eb064dfb299816542a46')).toEqual(
      40077
    )
    expect(p.offsets.get('637c4e69d85e0dcc18898ec251377453d0891585')).toEqual(
      39860
    )
    expect(p.offsets.get('98e9fde3ee878fa985a143fc5fe05d4e6d8e637b')).toEqual(
      39036
    )
    expect(p.offsets.get('43c49edb213748626fc363c890c01a9e55a1b8da')).toEqual(
      38202
    )
    expect(p.offsets.get('5f1f014326b1d7e8079d00b87fa7a9913bd91324')).toEqual(
      20855
    )
  })",steel
/__tests__/test-GitPackIndex.js,Magic Number,"{'line': 58, 'column': 6, 'index': 1954}","it('from .pack', async () => {
    const { fs, gitdir } = await makeFixture('test-GitPackIndex')
    const pack = await fs.read(
      path.join(
        gitdir,
        'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
      )
    )
    const p = await GitPackIndex.fromPack({ pack })
    expect(
      await shasum(Buffer.from(JSON.stringify(p.hashes)))
    ).toMatchInlineSnapshot('""fd2404a29d1e5dc72066541366d5f75bc9d51c9b""')
    expect(p.packfileSha).toBe('1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888')
    // Test a handful of known offsets.
    expect(p.offsets.get('0b8faa11b353db846b40eb064dfb299816542a46')).toEqual(
      40077
    )
    expect(p.offsets.get('637c4e69d85e0dcc18898ec251377453d0891585')).toEqual(
      39860
    )
    expect(p.offsets.get('98e9fde3ee878fa985a143fc5fe05d4e6d8e637b')).toEqual(
      39036
    )
    expect(p.offsets.get('43c49edb213748626fc363c890c01a9e55a1b8da')).toEqual(
      38202
    )
    expect(p.offsets.get('5f1f014326b1d7e8079d00b87fa7a9913bd91324')).toEqual(
      20855
    )
  })",steel
/__tests__/test-GitPackIndex.js,Magic Number,"{'line': 61, 'column': 6, 'index': 2051}","it('from .pack', async () => {
    const { fs, gitdir } = await makeFixture('test-GitPackIndex')
    const pack = await fs.read(
      path.join(
        gitdir,
        'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
      )
    )
    const p = await GitPackIndex.fromPack({ pack })
    expect(
      await shasum(Buffer.from(JSON.stringify(p.hashes)))
    ).toMatchInlineSnapshot('""fd2404a29d1e5dc72066541366d5f75bc9d51c9b""')
    expect(p.packfileSha).toBe('1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888')
    // Test a handful of known offsets.
    expect(p.offsets.get('0b8faa11b353db846b40eb064dfb299816542a46')).toEqual(
      40077
    )
    expect(p.offsets.get('637c4e69d85e0dcc18898ec251377453d0891585')).toEqual(
      39860
    )
    expect(p.offsets.get('98e9fde3ee878fa985a143fc5fe05d4e6d8e637b')).toEqual(
      39036
    )
    expect(p.offsets.get('43c49edb213748626fc363c890c01a9e55a1b8da')).toEqual(
      38202
    )
    expect(p.offsets.get('5f1f014326b1d7e8079d00b87fa7a9913bd91324')).toEqual(
      20855
    )
  })",steel
/__tests__/test-GitPackIndex.js,Magic Number,"{'line': 64, 'column': 6, 'index': 2148}","it('from .pack', async () => {
    const { fs, gitdir } = await makeFixture('test-GitPackIndex')
    const pack = await fs.read(
      path.join(
        gitdir,
        'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
      )
    )
    const p = await GitPackIndex.fromPack({ pack })
    expect(
      await shasum(Buffer.from(JSON.stringify(p.hashes)))
    ).toMatchInlineSnapshot('""fd2404a29d1e5dc72066541366d5f75bc9d51c9b""')
    expect(p.packfileSha).toBe('1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888')
    // Test a handful of known offsets.
    expect(p.offsets.get('0b8faa11b353db846b40eb064dfb299816542a46')).toEqual(
      40077
    )
    expect(p.offsets.get('637c4e69d85e0dcc18898ec251377453d0891585')).toEqual(
      39860
    )
    expect(p.offsets.get('98e9fde3ee878fa985a143fc5fe05d4e6d8e637b')).toEqual(
      39036
    )
    expect(p.offsets.get('43c49edb213748626fc363c890c01a9e55a1b8da')).toEqual(
      38202
    )
    expect(p.offsets.get('5f1f014326b1d7e8079d00b87fa7a9913bd91324')).toEqual(
      20855
    )
  })",steel
/__tests__/test-GitPackIndex.js,Magic Number,"{'line': 67, 'column': 6, 'index': 2245}","it('from .pack', async () => {
    const { fs, gitdir } = await makeFixture('test-GitPackIndex')
    const pack = await fs.read(
      path.join(
        gitdir,
        'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
      )
    )
    const p = await GitPackIndex.fromPack({ pack })
    expect(
      await shasum(Buffer.from(JSON.stringify(p.hashes)))
    ).toMatchInlineSnapshot('""fd2404a29d1e5dc72066541366d5f75bc9d51c9b""')
    expect(p.packfileSha).toBe('1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888')
    // Test a handful of known offsets.
    expect(p.offsets.get('0b8faa11b353db846b40eb064dfb299816542a46')).toEqual(
      40077
    )
    expect(p.offsets.get('637c4e69d85e0dcc18898ec251377453d0891585')).toEqual(
      39860
    )
    expect(p.offsets.get('98e9fde3ee878fa985a143fc5fe05d4e6d8e637b')).toEqual(
      39036
    )
    expect(p.offsets.get('43c49edb213748626fc363c890c01a9e55a1b8da')).toEqual(
      38202
    )
    expect(p.offsets.get('5f1f014326b1d7e8079d00b87fa7a9913bd91324')).toEqual(
      20855
    )
  })",steel
/__tests__/test-GitPackIndex.js,Magic Number,"{'line': 70, 'column': 6, 'index': 2342}","it('from .pack', async () => {
    const { fs, gitdir } = await makeFixture('test-GitPackIndex')
    const pack = await fs.read(
      path.join(
        gitdir,
        'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
      )
    )
    const p = await GitPackIndex.fromPack({ pack })
    expect(
      await shasum(Buffer.from(JSON.stringify(p.hashes)))
    ).toMatchInlineSnapshot('""fd2404a29d1e5dc72066541366d5f75bc9d51c9b""')
    expect(p.packfileSha).toBe('1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888')
    // Test a handful of known offsets.
    expect(p.offsets.get('0b8faa11b353db846b40eb064dfb299816542a46')).toEqual(
      40077
    )
    expect(p.offsets.get('637c4e69d85e0dcc18898ec251377453d0891585')).toEqual(
      39860
    )
    expect(p.offsets.get('98e9fde3ee878fa985a143fc5fe05d4e6d8e637b')).toEqual(
      39036
    )
    expect(p.offsets.get('43c49edb213748626fc363c890c01a9e55a1b8da')).toEqual(
      38202
    )
    expect(p.offsets.get('5f1f014326b1d7e8079d00b87fa7a9913bd91324')).toEqual(
      20855
    )
  })",steel
/__tests__/test-GitPackIndex.js,Magic Number,"{'line': 82, 'column': 32, 'index': 2737}","it('from .pack when pack is truncated', async () => {
    const { fs, gitdir } = await makeFixture('test-GitPackIndex')
    const pack = await fs.read(
      path.join(
        gitdir,
        'objects/pack/pack-1a1e70d2f116e8cb0cb42d26019e5c7d0eb01888.pack'
      )
    )
    const p = await GitPackIndex.fromPack({ pack: pack.slice(0, 12) })
    expect(p.offsets.size).toBe(0)
  })",steel
/__tests__/test-GitIndex.js,Duplicate Assert,"{'line': 80, 'column': 6, 'index': 4256}","it('write unmerged index to disk and read it back', async () => {
    const { gitdir, fs } = await makeFixture('test-GitIndex')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(0)
      expect(index.entriesFlat.length).toBe(0)
      index.insert({ filepath: 'a', oid: '01', stage: 1 })
      index.insert({ filepath: 'a', oid: '10', stage: 2 })
      index.insert({ filepath: 'a', oid: '11', stage: 3 })
      expect(index.unmergedPaths).toContain('a')
    })
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(1)
      expect(index.entriesFlat.length).toBe(3)
      expect(index.unmergedPaths).toContain('a')

      const entryA = index.entriesMap.get('a')

      expect(entryA.stages.length).toBe(4)
      expect(entryA.stages[1]).toBe(index.entriesFlat[0])
      expect(entryA.stages[2]).toBe(index.entriesFlat[1])
      expect(entryA.stages[3]).toBe(index.entriesFlat[2])
    })
  })",steel
/__tests__/test-GitIndex.js,Duplicate Assert,"{'line': 81, 'column': 6, 'index': 4299}","it('write unmerged index to disk and read it back', async () => {
    const { gitdir, fs } = await makeFixture('test-GitIndex')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(0)
      expect(index.entriesFlat.length).toBe(0)
      index.insert({ filepath: 'a', oid: '01', stage: 1 })
      index.insert({ filepath: 'a', oid: '10', stage: 2 })
      index.insert({ filepath: 'a', oid: '11', stage: 3 })
      expect(index.unmergedPaths).toContain('a')
    })
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(1)
      expect(index.entriesFlat.length).toBe(3)
      expect(index.unmergedPaths).toContain('a')

      const entryA = index.entriesMap.get('a')

      expect(entryA.stages.length).toBe(4)
      expect(entryA.stages[1]).toBe(index.entriesFlat[0])
      expect(entryA.stages[2]).toBe(index.entriesFlat[1])
      expect(entryA.stages[3]).toBe(index.entriesFlat[2])
    })
  })",steel
/__tests__/test-GitIndex.js,Duplicate Assert,"{'line': 85, 'column': 6, 'index': 4523}","it('write unmerged index to disk and read it back', async () => {
    const { gitdir, fs } = await makeFixture('test-GitIndex')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(0)
      expect(index.entriesFlat.length).toBe(0)
      index.insert({ filepath: 'a', oid: '01', stage: 1 })
      index.insert({ filepath: 'a', oid: '10', stage: 2 })
      index.insert({ filepath: 'a', oid: '11', stage: 3 })
      expect(index.unmergedPaths).toContain('a')
    })
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(1)
      expect(index.entriesFlat.length).toBe(3)
      expect(index.unmergedPaths).toContain('a')

      const entryA = index.entriesMap.get('a')

      expect(entryA.stages.length).toBe(4)
      expect(entryA.stages[1]).toBe(index.entriesFlat[0])
      expect(entryA.stages[2]).toBe(index.entriesFlat[1])
      expect(entryA.stages[3]).toBe(index.entriesFlat[2])
    })
  })",steel
/__tests__/test-GitIndex.js,Duplicate Assert,"{'line': 85, 'column': 6, 'index': 4523}","it('write unmerged index to disk and read it back', async () => {
    const { gitdir, fs } = await makeFixture('test-GitIndex')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(0)
      expect(index.entriesFlat.length).toBe(0)
      index.insert({ filepath: 'a', oid: '01', stage: 1 })
      index.insert({ filepath: 'a', oid: '10', stage: 2 })
      index.insert({ filepath: 'a', oid: '11', stage: 3 })
      expect(index.unmergedPaths).toContain('a')
    })
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(1)
      expect(index.entriesFlat.length).toBe(3)
      expect(index.unmergedPaths).toContain('a')

      const entryA = index.entriesMap.get('a')

      expect(entryA.stages.length).toBe(4)
      expect(entryA.stages[1]).toBe(index.entriesFlat[0])
      expect(entryA.stages[2]).toBe(index.entriesFlat[1])
      expect(entryA.stages[3]).toBe(index.entriesFlat[2])
    })
  })",steel
/__tests__/test-GitIndex.js,Duplicate Assert,"{'line': 90, 'column': 6, 'index': 4676}","it('write unmerged index to disk and read it back', async () => {
    const { gitdir, fs } = await makeFixture('test-GitIndex')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(0)
      expect(index.entriesFlat.length).toBe(0)
      index.insert({ filepath: 'a', oid: '01', stage: 1 })
      index.insert({ filepath: 'a', oid: '10', stage: 2 })
      index.insert({ filepath: 'a', oid: '11', stage: 3 })
      expect(index.unmergedPaths).toContain('a')
    })
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(1)
      expect(index.entriesFlat.length).toBe(3)
      expect(index.unmergedPaths).toContain('a')

      const entryA = index.entriesMap.get('a')

      expect(entryA.stages.length).toBe(4)
      expect(entryA.stages[1]).toBe(index.entriesFlat[0])
      expect(entryA.stages[2]).toBe(index.entriesFlat[1])
      expect(entryA.stages[3]).toBe(index.entriesFlat[2])
    })
  })",steel
/__tests__/test-GitIndex.js,Duplicate Assert,"{'line': 91, 'column': 6, 'index': 4719}","it('write unmerged index to disk and read it back', async () => {
    const { gitdir, fs } = await makeFixture('test-GitIndex')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(0)
      expect(index.entriesFlat.length).toBe(0)
      index.insert({ filepath: 'a', oid: '01', stage: 1 })
      index.insert({ filepath: 'a', oid: '10', stage: 2 })
      index.insert({ filepath: 'a', oid: '11', stage: 3 })
      expect(index.unmergedPaths).toContain('a')
    })
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(1)
      expect(index.entriesFlat.length).toBe(3)
      expect(index.unmergedPaths).toContain('a')

      const entryA = index.entriesMap.get('a')

      expect(entryA.stages.length).toBe(4)
      expect(entryA.stages[1]).toBe(index.entriesFlat[0])
      expect(entryA.stages[2]).toBe(index.entriesFlat[1])
      expect(entryA.stages[3]).toBe(index.entriesFlat[2])
    })
  })",steel
/__tests__/test-GitIndex.js,Duplicate Assert,"{'line': 92, 'column': 6, 'index': 4766}","it('write unmerged index to disk and read it back', async () => {
    const { gitdir, fs } = await makeFixture('test-GitIndex')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(0)
      expect(index.entriesFlat.length).toBe(0)
      index.insert({ filepath: 'a', oid: '01', stage: 1 })
      index.insert({ filepath: 'a', oid: '10', stage: 2 })
      index.insert({ filepath: 'a', oid: '11', stage: 3 })
      expect(index.unmergedPaths).toContain('a')
    })
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(1)
      expect(index.entriesFlat.length).toBe(3)
      expect(index.unmergedPaths).toContain('a')

      const entryA = index.entriesMap.get('a')

      expect(entryA.stages.length).toBe(4)
      expect(entryA.stages[1]).toBe(index.entriesFlat[0])
      expect(entryA.stages[2]).toBe(index.entriesFlat[1])
      expect(entryA.stages[3]).toBe(index.entriesFlat[2])
    })
  })",steel
/__tests__/test-GitIndex.js,Duplicate Assert,"{'line': 92, 'column': 6, 'index': 4766}","it('write unmerged index to disk and read it back', async () => {
    const { gitdir, fs } = await makeFixture('test-GitIndex')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(0)
      expect(index.entriesFlat.length).toBe(0)
      index.insert({ filepath: 'a', oid: '01', stage: 1 })
      index.insert({ filepath: 'a', oid: '10', stage: 2 })
      index.insert({ filepath: 'a', oid: '11', stage: 3 })
      expect(index.unmergedPaths).toContain('a')
    })
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(1)
      expect(index.entriesFlat.length).toBe(3)
      expect(index.unmergedPaths).toContain('a')

      const entryA = index.entriesMap.get('a')

      expect(entryA.stages.length).toBe(4)
      expect(entryA.stages[1]).toBe(index.entriesFlat[0])
      expect(entryA.stages[2]).toBe(index.entriesFlat[1])
      expect(entryA.stages[3]).toBe(index.entriesFlat[2])
    })
  })",steel
/__tests__/test-GitIndex.js,Duplicate Assert,"{'line': 113, 'column': 6, 'index': 5438}","it('read existing unmerged index', async () => {
    // Setup
    const { gitdir, fs } = await makeFixture('test-GitIndex-unmerged')

    // Test
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
    })
  })",steel
/__tests__/test-GitIndex.js,Duplicate Assert,"{'line': 114, 'column': 6, 'index': 5487}","it('read existing unmerged index', async () => {
    // Setup
    const { gitdir, fs } = await makeFixture('test-GitIndex-unmerged')

    // Test
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
    })
  })",steel
/__tests__/test-GitIndex.js,Magic Number,"{'line': 80, 'column': 40, 'index': 4290}","it('write unmerged index to disk and read it back', async () => {
    const { gitdir, fs } = await makeFixture('test-GitIndex')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(0)
      expect(index.entriesFlat.length).toBe(0)
      index.insert({ filepath: 'a', oid: '01', stage: 1 })
      index.insert({ filepath: 'a', oid: '10', stage: 2 })
      index.insert({ filepath: 'a', oid: '11', stage: 3 })
      expect(index.unmergedPaths).toContain('a')
    })
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(1)
      expect(index.entriesFlat.length).toBe(3)
      expect(index.unmergedPaths).toContain('a')

      const entryA = index.entriesMap.get('a')

      expect(entryA.stages.length).toBe(4)
      expect(entryA.stages[1]).toBe(index.entriesFlat[0])
      expect(entryA.stages[2]).toBe(index.entriesFlat[1])
      expect(entryA.stages[3]).toBe(index.entriesFlat[2])
    })
  })",steel
/__tests__/test-GitIndex.js,Magic Number,"{'line': 81, 'column': 44, 'index': 4337}","it('write unmerged index to disk and read it back', async () => {
    const { gitdir, fs } = await makeFixture('test-GitIndex')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(0)
      expect(index.entriesFlat.length).toBe(0)
      index.insert({ filepath: 'a', oid: '01', stage: 1 })
      index.insert({ filepath: 'a', oid: '10', stage: 2 })
      index.insert({ filepath: 'a', oid: '11', stage: 3 })
      expect(index.unmergedPaths).toContain('a')
    })
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(1)
      expect(index.entriesFlat.length).toBe(3)
      expect(index.unmergedPaths).toContain('a')

      const entryA = index.entriesMap.get('a')

      expect(entryA.stages.length).toBe(4)
      expect(entryA.stages[1]).toBe(index.entriesFlat[0])
      expect(entryA.stages[2]).toBe(index.entriesFlat[1])
      expect(entryA.stages[3]).toBe(index.entriesFlat[2])
    })
  })",steel
/__tests__/test-GitIndex.js,Magic Number,"{'line': 90, 'column': 40, 'index': 4710}","it('write unmerged index to disk and read it back', async () => {
    const { gitdir, fs } = await makeFixture('test-GitIndex')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(0)
      expect(index.entriesFlat.length).toBe(0)
      index.insert({ filepath: 'a', oid: '01', stage: 1 })
      index.insert({ filepath: 'a', oid: '10', stage: 2 })
      index.insert({ filepath: 'a', oid: '11', stage: 3 })
      expect(index.unmergedPaths).toContain('a')
    })
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(1)
      expect(index.entriesFlat.length).toBe(3)
      expect(index.unmergedPaths).toContain('a')

      const entryA = index.entriesMap.get('a')

      expect(entryA.stages.length).toBe(4)
      expect(entryA.stages[1]).toBe(index.entriesFlat[0])
      expect(entryA.stages[2]).toBe(index.entriesFlat[1])
      expect(entryA.stages[3]).toBe(index.entriesFlat[2])
    })
  })",steel
/__tests__/test-GitIndex.js,Magic Number,"{'line': 91, 'column': 44, 'index': 4757}","it('write unmerged index to disk and read it back', async () => {
    const { gitdir, fs } = await makeFixture('test-GitIndex')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(0)
      expect(index.entriesFlat.length).toBe(0)
      index.insert({ filepath: 'a', oid: '01', stage: 1 })
      index.insert({ filepath: 'a', oid: '10', stage: 2 })
      index.insert({ filepath: 'a', oid: '11', stage: 3 })
      expect(index.unmergedPaths).toContain('a')
    })
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(1)
      expect(index.entriesFlat.length).toBe(3)
      expect(index.unmergedPaths).toContain('a')

      const entryA = index.entriesMap.get('a')

      expect(entryA.stages.length).toBe(4)
      expect(entryA.stages[1]).toBe(index.entriesFlat[0])
      expect(entryA.stages[2]).toBe(index.entriesFlat[1])
      expect(entryA.stages[3]).toBe(index.entriesFlat[2])
    })
  })",steel
/__tests__/test-GitIndex.js,Magic Number,"{'line': 96, 'column': 40, 'index': 4898}","it('write unmerged index to disk and read it back', async () => {
    const { gitdir, fs } = await makeFixture('test-GitIndex')
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(0)
      expect(index.entriesFlat.length).toBe(0)
      index.insert({ filepath: 'a', oid: '01', stage: 1 })
      index.insert({ filepath: 'a', oid: '10', stage: 2 })
      index.insert({ filepath: 'a', oid: '11', stage: 3 })
      expect(index.unmergedPaths).toContain('a')
    })
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.entries.length).toBe(1)
      expect(index.entriesFlat.length).toBe(3)
      expect(index.unmergedPaths).toContain('a')

      const entryA = index.entriesMap.get('a')

      expect(entryA.stages.length).toBe(4)
      expect(entryA.stages[1]).toBe(index.entriesFlat[0])
      expect(entryA.stages[2]).toBe(index.entriesFlat[1])
      expect(entryA.stages[3]).toBe(index.entriesFlat[2])
    })
  })",steel
/__tests__/test-GitIndex.js,Magic Number,"{'line': 111, 'column': 49, 'index': 5382}","it('read existing unmerged index', async () => {
    // Setup
    const { gitdir, fs } = await makeFixture('test-GitIndex-unmerged')

    // Test
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
    })
  })",steel
/__tests__/test-GitIndex.js,Magic Number,"{'line': 112, 'column': 44, 'index': 5429}","it('read existing unmerged index', async () => {
    // Setup
    const { gitdir, fs } = await makeFixture('test-GitIndex-unmerged')

    // Test
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
    })
  })",steel
/__tests__/test-GitIndex.js,Magic Number,"{'line': 115, 'column': 59, 'index': 5589}","it('read existing unmerged index', async () => {
    // Setup
    const { gitdir, fs } = await makeFixture('test-GitIndex-unmerged')

    // Test
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
    })
  })",steel
/__tests__/test-GitIndex.js,Magic Number,"{'line': 116, 'column': 59, 'index': 5651}","it('read existing unmerged index', async () => {
    // Setup
    const { gitdir, fs } = await makeFixture('test-GitIndex-unmerged')

    // Test
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
    })
  })",steel
/__tests__/test-GitIndex.js,Magic Number,"{'line': 117, 'column': 59, 'index': 5713}","it('read existing unmerged index', async () => {
    // Setup
    const { gitdir, fs } = await makeFixture('test-GitIndex-unmerged')

    // Test
    await GitIndexManager.acquire({ fs, gitdir, cache: {} }, async function(
      index
    ) {
      expect(index.unmergedPaths.length).toEqual(2)
      expect(index.entriesFlat.length).toBe(7)
      expect(index.unmergedPaths).toContain('a')
      expect(index.unmergedPaths).toContain('b')
      expect(index.entriesMap.get('a').stages.length).toBe(4)
      expect(index.entriesMap.get('b').stages.length).toBe(4)
      expect(index.entriesMap.get('c').stages.length).toBe(1)
    })
  })",steel
/__tests__/test-GitError.js,Conditional Test Logic,"{'line': 7, 'column': 4, 'index': 194}","it('have the correct value for their static property code', async () => {
    for (const [name, Value] of Object.entries(Errors)) {
      // @ts-ignore
      expect(name).toBe(Value.code)
    }
  })",steel
/__tests__/test-GitError.js,Duplicate Assert,"{'line': 19, 'column': 4, 'index': 482}","it('create a NotFoundError', async () => {
    let e = null
    try {
      throw new Errors.NotFoundError('foobar.txt')
    } catch (err) {
      e = err
    }
    expect(e).not.toBeNull()
    expect(e.code).toBe('NotFoundError')
    expect(e instanceof Error).toBe(true)
    expect(e instanceof Errors.NotFoundError).toBe(true)
    e = e.toJSON()
    delete e.stack
    expect(e).toMatchInlineSnapshot(`
      Object {
        ""caller"": """",
        ""code"": ""NotFoundError"",
        ""data"": Object {
          ""what"": ""foobar.txt"",
        },
        ""message"": ""Could not find foobar.txt."",
      }
    `)
  })",steel
/__tests__/test-GitError.js,Duplicate Assert,"{'line': 25, 'column': 4, 'index': 689}","it('create a NotFoundError', async () => {
    let e = null
    try {
      throw new Errors.NotFoundError('foobar.txt')
    } catch (err) {
      e = err
    }
    expect(e).not.toBeNull()
    expect(e.code).toBe('NotFoundError')
    expect(e instanceof Error).toBe(true)
    expect(e instanceof Errors.NotFoundError).toBe(true)
    e = e.toJSON()
    delete e.stack
    expect(e).toMatchInlineSnapshot(`
      Object {
        ""caller"": """",
        ""code"": ""NotFoundError"",
        ""data"": Object {
          ""what"": ""foobar.txt"",
        },
        ""message"": ""Could not find foobar.txt."",
      }
    `)
  })",steel
/__tests__/test-GitError.js,Exception Handling,"{'line': 14, 'column': 4, 'index': 381}","it('create a NotFoundError', async () => {
    let e = null
    try {
      throw new Errors.NotFoundError('foobar.txt')
    } catch (err) {
      e = err
    }
    expect(e).not.toBeNull()
    expect(e.code).toBe('NotFoundError')
    expect(e instanceof Error).toBe(true)
    expect(e instanceof Errors.NotFoundError).toBe(true)
    e = e.toJSON()
    delete e.stack
    expect(e).toMatchInlineSnapshot(`
      Object {
        ""caller"": """",
        ""code"": ""NotFoundError"",
        ""data"": Object {
          ""what"": ""foobar.txt"",
        },
        ""message"": ""Could not find foobar.txt."",
      }
    `)
  })",steel
/__tests__/test-GitError.js,Exception Handling,"{'line': 15, 'column': 6, 'index': 393}","it('create a NotFoundError', async () => {
    let e = null
    try {
      throw new Errors.NotFoundError('foobar.txt')
    } catch (err) {
      e = err
    }
    expect(e).not.toBeNull()
    expect(e.code).toBe('NotFoundError')
    expect(e instanceof Error).toBe(true)
    expect(e instanceof Errors.NotFoundError).toBe(true)
    e = e.toJSON()
    delete e.stack
    expect(e).toMatchInlineSnapshot(`
      Object {
        ""caller"": """",
        ""code"": ""NotFoundError"",
        ""data"": Object {
          ""what"": ""foobar.txt"",
        },
        ""message"": ""Could not find foobar.txt."",
      }
    `)
  })",steel
/__tests__/test-GitConfig.js,Magic Number,"{'line': 227, 'column': 24, 'index': 6939}","it('using schema', async () => {
      const config = GitConfig.from(`[core]
      repositoryformatversion = 0
      filemode = true
      bare = false
      logallrefupdates = true
      symlinks = false
      ignorecase = true
      bigFileThreshold = 2`)
      const a = await config.get('core.repositoryformatversion')
      const b = await config.get('core.filemode')
      const c = await config.get('core.bare')
      const d = await config.get('core.logallrefupdates')
      const e = await config.get('core.symlinks')
      const f = await config.get('core.ignorecase')
      const g = await config.get('core.bigFileThreshold')
      expect(a).toEqual('0')
      expect(b).toEqual(true)
      expect(c).toEqual(false)
      expect(d).toEqual(true)
      expect(e).toEqual(false)
      expect(f).toEqual(true)
      expect(g).toEqual(2)
    })",steel
/__tests__/test-GitConfig.js,Magic Number,"{'line': 256, 'column': 24, 'index': 7922}","it('numeric suffix', async () => {
      const configA = GitConfig.from(`[core]
      bigFileThreshold = 2k`)
      const configB = GitConfig.from(`[core]
      bigFileThreshold = 2m`)
      const configC = GitConfig.from(`[core]
      bigFileThreshold = 2g`)
      const a = await configA.get('core.bigFileThreshold')
      const b = await configB.get('core.bigFileThreshold')
      const c = await configC.get('core.bigFileThreshold')
      expect(a).toEqual(2048)
      expect(b).toEqual(2097152)
      expect(c).toEqual(2147483648)
    })",steel
/__tests__/test-GitConfig.js,Magic Number,"{'line': 257, 'column': 24, 'index': 7952}","it('numeric suffix', async () => {
      const configA = GitConfig.from(`[core]
      bigFileThreshold = 2k`)
      const configB = GitConfig.from(`[core]
      bigFileThreshold = 2m`)
      const configC = GitConfig.from(`[core]
      bigFileThreshold = 2g`)
      const a = await configA.get('core.bigFileThreshold')
      const b = await configB.get('core.bigFileThreshold')
      const c = await configC.get('core.bigFileThreshold')
      expect(a).toEqual(2048)
      expect(b).toEqual(2097152)
      expect(c).toEqual(2147483648)
    })",steel
/__tests__/test-GitConfig.js,Magic Number,"{'line': 258, 'column': 24, 'index': 7985}","it('numeric suffix', async () => {
      const configA = GitConfig.from(`[core]
      bigFileThreshold = 2k`)
      const configB = GitConfig.from(`[core]
      bigFileThreshold = 2m`)
      const configC = GitConfig.from(`[core]
      bigFileThreshold = 2g`)
      const a = await configA.get('core.bigFileThreshold')
      const b = await configB.get('core.bigFileThreshold')
      const c = await configC.get('core.bigFileThreshold')
      expect(a).toEqual(2048)
      expect(b).toEqual(2097152)
      expect(c).toEqual(2147483648)
    })",steel
